# ğŸ”§ æŠ€æœ¯å®æ–½æŒ‡å—ï¼šFluxåˆ‡æ¢ + CogVideoXé›†æˆ

> **ç›®æ ‡**: å°†Flux 1.1åˆ‡æ¢ä¸ºä¸»åŠ›å›¾åƒæ¨¡å‹ï¼Œé›†æˆCogVideoX-5Bè§†é¢‘æ¨¡å‹  
> **æ—¶é—´çº¿**: 2-3å‘¨  
> **ä¼˜å…ˆçº§**: P0ï¼ˆå¿…é¡»å®Œæˆï¼‰

---

## ğŸ“‹ ç¬¬ä¸€éƒ¨åˆ†ï¼šFlux 1.1åˆ‡æ¢ä¸ºä¸»åŠ›ï¼ˆç¬¬1å‘¨ï¼‰

### 1.1 å½“å‰çŠ¶æ€æ£€æŸ¥

#### æ£€æŸ¥Fluxæ˜¯å¦å·²é›†æˆ

```bash
# æ£€æŸ¥Fluxç›¸å…³ä»£ç 
grep -r "flux" gen_video/image_generator.py
grep -r "FLUX" gen_video/config.yaml
```

#### æ£€æŸ¥Fluxæ¨¡å‹æ˜¯å¦å·²ä¸‹è½½

```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -lh /vepfs-dev/shawn/vid/fanren/gen_video/models/flux1-dev
```

**å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆä¸‹è½½**:
```bash
# Flux 1.1 Devæ¨¡å‹ä¸‹è½½ï¼ˆéœ€è¦HuggingFace tokenï¼‰
# å‚è€ƒ: gen_video/Fluxæ¨¡å‹é€‰æ‹©è¯´æ˜.md
```

---

### 1.2 ä¿®æ”¹é…ç½®æ–‡ä»¶

#### æ­¥éª¤1: ä¿®æ”¹`gen_video/config.yaml`

**å½“å‰é…ç½®**:
```yaml
image:
  engine: auto  # å½“å‰æ˜¯autoï¼Œéœ€è¦æ”¹ä¸ºflux-instantid
```

**ä¿®æ”¹ä¸º**:
```yaml
image:
  engine: flux-instantid  # ç›´æ¥ä½¿ç”¨Flux + InstantID
  # æˆ–è€…ä¿æŒautoï¼Œä½†ç¡®ä¿model_selectionä¼˜å…ˆé€‰æ‹©Flux
```

**ä¿®æ”¹model_selectioné…ç½®**:
```yaml
image:
  model_selection:
    character:
      engine: flux-instantid  # äººç‰©ç”Ÿæˆä½¿ç”¨Flux
      # ... å…¶ä»–é…ç½®ä¿æŒä¸å˜
    scene:
      engine: flux-instantid  # åœºæ™¯ç”Ÿæˆä¹Ÿä½¿ç”¨Fluxï¼ˆå¯é€‰ï¼Œå¯ä»¥å…ˆæµ‹è¯•ï¼‰
```

---

#### æ­¥éª¤2: ä¼˜åŒ–Fluxå‚æ•°

**å½“å‰Fluxé…ç½®**ï¼ˆåœ¨`config.yaml`ä¸­ï¼‰:
```yaml
model_selection:
  character:
    num_inference_steps: 28  # å·²ä¼˜åŒ–ï¼Œä¿æŒ
    guidance_scale: 7.5      # å·²ä¼˜åŒ–ï¼Œä¿æŒ
    width: 1536
    height: 864
```

**å»ºè®®ä¼˜åŒ–**:
- âœ… ä¿æŒå½“å‰å‚æ•°ï¼ˆå·²ç»ä¼˜åŒ–è¿‡ï¼‰
- âœ… å¦‚æœè´¨é‡ä¸å¤Ÿï¼Œå¯ä»¥æé«˜åˆ°30-35æ­¥
- âœ… å¦‚æœé€Ÿåº¦å¤ªæ…¢ï¼Œå¯ä»¥é™ä½åˆ°25æ­¥

---

### 1.3 ä¿®æ”¹ä»£ç é€»è¾‘

#### æ­¥éª¤1: æ£€æŸ¥`gen_video/model_selector.py`

**ç¡®ä¿Fluxä¼˜å…ˆé€‰æ‹©**:
```python
# åœ¨model_selector.pyä¸­
def select_engine(self, task_type, ...):
    if task_type == TaskType.CHARACTER:
        return "flux-instantid"  # ç¡®ä¿è¿”å›Flux
    # ...
```

---

#### æ­¥éª¤2: æ£€æŸ¥`gen_video/image_generator.py`

**ç¡®ä¿Flux pipelineæ­£ç¡®åŠ è½½**:
```python
# æ£€æŸ¥æ˜¯å¦æœ‰_load_flux_pipelineæ–¹æ³•
# æ£€æŸ¥Flux pipelineæ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
```

**å¦‚æœç¼ºå°‘ï¼Œéœ€è¦æ·»åŠ **:
```python
def _load_flux_pipeline(self):
    """åŠ è½½Flux pipeline"""
    from diffusers import DiffusionPipeline
    import torch
    
    flux_model_path = self.config.get("model_selection", {}).get("character", {}).get("flux1_model_path")
    
    self.flux_pipeline = DiffusionPipeline.from_pretrained(
        flux_model_path,
        torch_dtype=torch.float16,
        variant="fp16"
    )
    
    if torch.cuda.is_available():
        self.flux_pipeline = self.flux_pipeline.to("cuda")
```

---

### 1.4 æµ‹è¯•éªŒè¯

#### æµ‹è¯•1: å•å›¾ç”Ÿæˆæµ‹è¯•

```python
# åˆ›å»ºæµ‹è¯•è„šæœ¬: test_flux_switch.py
from gen_video.image_generator import ImageGenerator

generator = ImageGenerator("gen_video/config.yaml")

# æµ‹è¯•äººç‰©ç”Ÿæˆ
result = generator.generate(
    prompt="ä¸€ä¸ªå¹´è½»çš„ç§‘æ™®ä¸»æŒäººï¼Œç«™åœ¨ç§‘å­¦å®éªŒå®¤ä¸­",
    task_type="character"
)

print(f"ç”ŸæˆæˆåŠŸ: {result['image_path']}")
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… å›¾åƒç”ŸæˆæˆåŠŸ
- âœ… è§’è‰²ä¸€è‡´æ€§è‰¯å¥½
- âœ… ç”Ÿæˆæ—¶é—´ < 30ç§’
- âœ… å›¾åƒè´¨é‡ > SDXL

---

#### æµ‹è¯•2: æ‰¹é‡ç”Ÿæˆæµ‹è¯•

```python
# æµ‹è¯•æ‰¹é‡ç”Ÿæˆ
prompts = [
    "ä¸€ä¸ªå¹´è½»çš„ç§‘æ™®ä¸»æŒäººï¼Œç«™åœ¨ç§‘å­¦å®éªŒå®¤ä¸­",
    "ä¸€ä¸ªå¹´è½»çš„ç§‘æ™®ä¸»æŒäººï¼Œç«™åœ¨å¤©æ–‡å°",
    "ä¸€ä¸ªå¹´è½»çš„ç§‘æ™®ä¸»æŒäººï¼Œç«™åœ¨æ£®æ—ä¸­"
]

for prompt in prompts:
    result = generator.generate(prompt=prompt, task_type="character")
    print(f"ç”ŸæˆæˆåŠŸ: {result['image_path']}")
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰å›¾åƒç”ŸæˆæˆåŠŸ
- âœ… è§’è‰²ä¸€è‡´æ€§ç¨³å®š
- âœ… æ— å†…å­˜æ³„æ¼

---

### 1.5 æ€§èƒ½ä¼˜åŒ–

#### ä¼˜åŒ–1: æ¨¡å‹é¢„çƒ­

```python
# åœ¨image_generator.pyä¸­æ·»åŠ 
def warmup(self):
    """æ¨¡å‹é¢„çƒ­ï¼Œå‡å°‘é¦–æ¬¡ç”Ÿæˆå»¶è¿Ÿ"""
    if self.flux_pipeline is None:
        self._load_flux_pipeline()
    
    # ç”Ÿæˆä¸€å¼ å°å›¾é¢„çƒ­
    dummy_prompt = "test"
    _ = self.flux_pipeline(
        prompt=dummy_prompt,
        num_inference_steps=1,
        height=512,
        width=512
    )
```

---

#### ä¼˜åŒ–2: æ˜¾å­˜ä¼˜åŒ–

```python
# å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œä½¿ç”¨CPU offload
if torch.cuda.get_device_properties(0).total_memory < 24 * 1024**3:  # < 24GB
    self.flux_pipeline.enable_model_cpu_offload()
else:
    self.flux_pipeline = self.flux_pipeline.to("cuda")
```

---

## ğŸ“‹ ç¬¬äºŒéƒ¨åˆ†ï¼šCogVideoX-5Bé›†æˆï¼ˆç¬¬2-3å‘¨ï¼‰

### 2.1 æ¨¡å‹è°ƒç ”å’Œä¸‹è½½

#### æ­¥éª¤1: æŸ¥æ‰¾CogVideoX-5Bæ¨¡å‹

**å¯èƒ½çš„æ¥æº**:
1. HuggingFace: `THUDM/CogVideoX-5b`ï¼ˆéœ€è¦ç¡®è®¤ï¼‰
2. å®˜æ–¹GitHub: https://github.com/THUDM/CogVideoX
3. æ¨¡å‹ç¤¾åŒº: ModelScope, OpenXLab

**è°ƒç ”ä»»åŠ¡**:
- [ ] ç¡®è®¤æ¨¡å‹ä¸‹è½½åœ°å€
- [ ] ç¡®è®¤æ¨¡å‹å¤§å°ï¼ˆé¢„è®¡20-30GBï¼‰
- [ ] ç¡®è®¤ä½¿ç”¨æ–‡æ¡£
- [ ] ç¡®è®¤ä¾èµ–è¦æ±‚

---

#### æ­¥éª¤2: ä¸‹è½½æ¨¡å‹

```bash
# æ–¹å¼1: ä½¿ç”¨HuggingFace CLIï¼ˆå¦‚æœæœ‰ï¼‰
huggingface-cli download THUDM/CogVideoX-5b --local-dir /vepfs-dev/shawn/vid/fanren/gen_video/models/cogvideox-5b

# æ–¹å¼2: ä½¿ç”¨git lfsï¼ˆå¦‚æœæ¨¡å‹åœ¨GitHubï¼‰
git lfs clone https://huggingface.co/THUDM/CogVideoX-5b /vepfs-dev/shawn/vid/fanren/gen_video/models/cogvideox-5b

# æ–¹å¼3: æ‰‹åŠ¨ä¸‹è½½ï¼ˆå¦‚æœæä¾›ä¸‹è½½é“¾æ¥ï¼‰
# ä¸‹è½½åè§£å‹åˆ°æŒ‡å®šç›®å½•
```

**é¢„è®¡æ—¶é—´**: 2-4å°æ—¶ï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰

---

### 2.2 å®‰è£…ä¾èµ–

#### æ£€æŸ¥CogVideoXä¾èµ–

```bash
# æŸ¥çœ‹CogVideoXå®˜æ–¹æ–‡æ¡£ï¼Œç¡®è®¤ä¾èµ–
# å¯èƒ½éœ€è¦:
# - transformers
# - diffusers (ç‰¹å®šç‰ˆæœ¬)
# - torch (ç‰¹å®šç‰ˆæœ¬)
# - å…¶ä»–ä¾èµ–
```

**å®‰è£…ä¾èµ–**:
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source /vepfs-dev/shawn/venv/py312/bin/activate

# å®‰è£…ä¾èµ–ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
pip install transformers diffusers torch
# æˆ–å…¶ä»–ä¾èµ–
```

---

### 2.3 ä»£ç é›†æˆ

#### æ­¥éª¤1: ä¿®æ”¹`gen_video/video_generator.py`

**æ·»åŠ CogVideoXæ”¯æŒ**:
```python
def _load_cogvideox_model(self, model_path: str):
    """åŠ è½½CogVideoX-5Bæ¨¡å‹"""
    try:
        from transformers import AutoModelForCausalLM, AutoTokenizer
        # æˆ–ä½¿ç”¨diffusersï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
        # from diffusers import CogVideoXPipeline
        
        # åŠ è½½æ¨¡å‹ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£è°ƒæ•´ï¼‰
        self.cogvideox_pipeline = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        
        if torch.cuda.is_available():
            self.cogvideox_pipeline = self.cogvideox_pipeline.to("cuda")
            
    except Exception as e:
        print(f"CogVideoXåŠ è½½å¤±è´¥: {e}")
        raise
```

---

#### æ­¥éª¤2: æ·»åŠ æ¨¡å‹é€‰æ‹©é€»è¾‘

**ä¿®æ”¹`load_model`æ–¹æ³•**:
```python
def load_model(self):
    """åŠ è½½è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆæ”¯æŒSVDã€AnimateDiffã€CogVideoXï¼‰"""
    if self.model_loaded:
        return
    
    model_type = self.video_config.get('model_type', 'svd-xt')
    model_path = self.video_config.get('model_path')
    
    if model_type == 'cogvideox-5b':
        self._load_cogvideox_model(model_path)
    elif model_type in ['svd', 'svd-xt']:
        self._load_svd_model(model_path)
    # ... å…¶ä»–æ¨¡å‹
```

---

#### æ­¥éª¤3: å®ç°CogVideoXç”Ÿæˆæ–¹æ³•

**æ·»åŠ ç”Ÿæˆæ–¹æ³•**:
```python
def generate_with_cogvideox(
    self,
    image: Image,
    prompt: str = "",
    num_frames: int = 120,
    fps: int = 24,
    **kwargs
) -> str:
    """ä½¿ç”¨CogVideoXç”Ÿæˆè§†é¢‘"""
    # æ ¹æ®å®˜æ–¹æ–‡æ¡£å®ç°
    # æ³¨æ„: CogVideoXå¯èƒ½éœ€è¦ç‰¹å®šçš„è¾“å…¥æ ¼å¼
    
    output_path = self._get_output_path()
    
    # è°ƒç”¨CogVideoX pipeline
    video = self.cogvideox_pipeline(
        image=image,
        prompt=prompt,
        num_frames=num_frames,
        fps=fps,
        **kwargs
    )
    
    # ä¿å­˜è§†é¢‘
    video.save(output_path)
    
    return output_path
```

---

#### æ­¥éª¤4: ä¿®æ”¹ä¸»ç”Ÿæˆæ–¹æ³•

**ä¿®æ”¹`generate`æ–¹æ³•ï¼Œæ”¯æŒæ¨¡å‹é€‰æ‹©**:
```python
def generate(
    self,
    image_path: str,
    prompt: str = "",
    model_type: Optional[str] = None,
    **kwargs
) -> str:
    """ç”Ÿæˆè§†é¢‘ï¼ˆæ”¯æŒå¤šæ¨¡å‹ï¼‰"""
    # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
    if model_type is None:
        model_type = self.video_config.get('model_type', 'svd-xt')
    
    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ç”Ÿæˆæ–¹æ³•
    if model_type == 'cogvideox-5b':
        return self.generate_with_cogvideox(
            image=load_image(image_path),
            prompt=prompt,
            **kwargs
        )
    elif model_type in ['svd', 'svd-xt']:
        return self.generate_with_svd(
            image_path=image_path,
            prompt=prompt,
            **kwargs
        )
    # ...
```

---

### 2.4 é…ç½®æ–‡ä»¶æ›´æ–°

#### ä¿®æ”¹`gen_video/config.yaml`

**æ·»åŠ CogVideoXé…ç½®**:
```yaml
video:
  # æ¨¡å‹ç±»å‹ï¼šsvd-xt, cogvideox-5b, hunyuanvideo
  model_type: cogvideox-5b  # åˆ‡æ¢ä¸ºCogVideoXï¼ˆæµ‹è¯•åï¼‰
  # æˆ–ä¿æŒsvd-xtï¼Œé€šè¿‡APIå‚æ•°é€‰æ‹©
  
  # CogVideoXé…ç½®
  cogvideox:
    model_path: /vepfs-dev/shawn/vid/fanren/gen_video/models/cogvideox-5b
    num_frames: 120
    fps: 24
    width: 1280
    height: 768
    num_inference_steps: 50
    guidance_scale: 7.5
    # å…¶ä»–å‚æ•°æ ¹æ®å®˜æ–¹æ–‡æ¡£
```

---

### 2.5 æµ‹è¯•éªŒè¯

#### æµ‹è¯•1: åŸºç¡€ç”Ÿæˆæµ‹è¯•

```python
# åˆ›å»ºæµ‹è¯•è„šæœ¬: test_cogvideox.py
from gen_video.video_generator import VideoGenerator
from PIL import Image

generator = VideoGenerator("gen_video/config.yaml")
generator.load_model()

# æµ‹è¯•å›¾åƒè½¬è§†é¢‘
image_path = "test_image.png"
result = generator.generate(
    image_path=image_path,
    prompt="ä¸€ä¸ªç§‘æ™®ä¸»æŒäººåœ¨è®²è§£",
    model_type="cogvideox-5b"
)

print(f"ç”ŸæˆæˆåŠŸ: {result}")
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ
- âœ… è§†é¢‘è´¨é‡ > SVD-XTï¼ˆå†™å®åœºæ™¯ï¼‰
- âœ… è„¸éƒ¨ç¨³å®šæ€§å¥½
- âœ… ç”Ÿæˆæ—¶é—´ < 5åˆ†é’Ÿ

---

#### æµ‹è¯•2: æ€§èƒ½æµ‹è¯•

```python
# æµ‹è¯•æ˜¾å­˜ä½¿ç”¨
import torch

torch.cuda.empty_cache()
before = torch.cuda.memory_allocated()

# ç”Ÿæˆè§†é¢‘
result = generator.generate(...)

after = torch.cuda.memory_allocated()
print(f"æ˜¾å­˜ä½¿ç”¨: {(after - before) / 1024**3:.2f} GB")
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ˜¾å­˜ä½¿ç”¨ < 24GBï¼ˆ4090å¯ç”¨ï¼‰
- âœ… æ— å†…å­˜æ³„æ¼
- âœ… å¯ä»¥è¿ç»­ç”Ÿæˆå¤šä¸ªè§†é¢‘

---

#### æµ‹è¯•3: è´¨é‡å¯¹æ¯”æµ‹è¯•

```python
# å¯¹æ¯”SVD-XTå’ŒCogVideoX
test_cases = [
    {"image": "test1.png", "prompt": "ç§‘æ™®ä¸»æŒäººè®²è§£"},
    {"image": "test2.png", "prompt": "ç§‘æ™®ä¸»æŒäººç«™åœ¨å®éªŒå®¤"},
]

for case in test_cases:
    # ä½¿ç”¨SVD-XTç”Ÿæˆ
    svd_result = generator.generate(
        image_path=case["image"],
        prompt=case["prompt"],
        model_type="svd-xt"
    )
    
    # ä½¿ç”¨CogVideoXç”Ÿæˆ
    cogvideox_result = generator.generate(
        image_path=case["image"],
        prompt=case["prompt"],
        model_type="cogvideox-5b"
    )
    
    # å¯¹æ¯”è´¨é‡ï¼ˆäººå·¥è¯„ä¼°ï¼‰
    print(f"æµ‹è¯•æ¡ˆä¾‹: {case['prompt']}")
    print(f"SVD-XT: {svd_result}")
    print(f"CogVideoX: {cogvideox_result}")
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… CogVideoXè´¨é‡ > SVD-XTï¼ˆå†™å®åœºæ™¯ï¼‰
- âœ… è„¸éƒ¨ç¨³å®šæ€§æ›´å¥½
- âœ… è¿åŠ¨æ›´è‡ªç„¶

---

### 2.6 APIæ¥å£é€‚é…

#### ä¿®æ”¹`gen_video/api/mvp_main.py`

**æ·»åŠ æ¨¡å‹é€‰æ‹©å‚æ•°**:
```python
@app.post("/api/v1/videos/generate")
async def generate_video(
    request: VideoGenerateRequest,
    api_key: str = Header(..., alias="X-API-Key")
):
    """ç”Ÿæˆè§†é¢‘ï¼ˆæ”¯æŒå¤šæ¨¡å‹ï¼‰"""
    # éªŒè¯API Key
    user = verify_api_key(api_key)
    
    # æ£€æŸ¥é…é¢
    if not check_quota(user, "video"):
        raise HTTPException(status_code=403, detail="é…é¢ä¸è¶³")
    
    # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
    model_type = request.model_type or "cogvideox-5b"  # é»˜è®¤CogVideoX
    
    # ç”Ÿæˆè§†é¢‘
    generator = VideoGenerator()
    result = generator.generate(
        image_path=request.image_path,
        prompt=request.prompt,
        model_type=model_type,
        **request.params
    )
    
    return {
        "task_id": generate_task_id(),
        "status": "completed",
        "video_url": f"/api/v1/files/videos/{result}"
    }
```

---

## ğŸ“‹ ç¬¬ä¸‰éƒ¨åˆ†ï¼šå·¥ä½œæµä¼˜åŒ–ï¼ˆç¬¬4å‘¨ï¼‰

### 3.1 çŸ­å‰§æ¨æ–‡å·¥ä½œæµè®¾è®¡

#### å·¥ä½œæµæ­¥éª¤

```
1. åŸæ–‡è¾“å…¥
   â†“
2. LLMåˆ†é•œï¼ˆè‡ªåŠ¨æ‹†åˆ†åœºæ™¯ï¼‰
   â†“
3. Fluxç”Ÿæˆè§’è‰²åº•å›¾ + åœºæ™¯å›¾
   â†“
4. CogVideoXç”Ÿæˆè§†é¢‘ç‰‡æ®µ
   â†“
5. CosyVoiceç”Ÿæˆé…éŸ³
   â†“
6. å­—å¹•ç”Ÿæˆå’Œåˆæˆ
   â†“
7. è§†é¢‘æ‹¼æ¥å’Œå¯¼å‡º
```

---

### 3.2 å®ç°è‡ªåŠ¨åˆ†é•œ

#### ä½¿ç”¨LLMè¿›è¡Œåˆ†é•œ

```python
# åˆ›å»ºæ–°æ–‡ä»¶: gen_video/script_splitter.py
from openai import OpenAI  # æˆ–å…¶ä»–LLM API

class ScriptSplitter:
    """è„šæœ¬åˆ†é•œå™¨"""
    
    def __init__(self, llm_api_key: str):
        self.client = OpenAI(api_key=llm_api_key)
    
    def split_script(self, script: str) -> List[Dict]:
        """å°†è„šæœ¬æ‹†åˆ†ä¸ºåœºæ™¯"""
        prompt = f"""
è¯·å°†ä»¥ä¸‹å°è¯´/æ¨æ–‡å†…å®¹æ‹†åˆ†ä¸ºå¤šä¸ªåœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯åŒ…å«ï¼š
1. åœºæ™¯æè¿°ï¼ˆç”¨äºç”Ÿæˆå›¾åƒï¼‰
2. è§’è‰²åŠ¨ä½œï¼ˆç”¨äºç”Ÿæˆè§†é¢‘ï¼‰
3. æ—ç™½æ–‡æœ¬ï¼ˆç”¨äºé…éŸ³ï¼‰

åŸæ–‡ï¼š
{script}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "scene_id": 1,
    "description": "åœºæ™¯æè¿°",
    "action": "è§’è‰²åŠ¨ä½œ",
    "narration": "æ—ç™½æ–‡æœ¬",
    "duration": 5
  }}
]
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        # è§£æJSON
        scenes = json.loads(response.choices[0].message.content)
        
        return scenes
```

---

### 3.3 æ‰¹é‡ç”Ÿæˆä¼˜åŒ–

#### å®ç°æ‰¹é‡ç”Ÿæˆ

```python
# åœ¨video_generator.pyä¸­æ·»åŠ 
def generate_batch(
    self,
    scenes: List[Dict],
    model_type: str = "cogvideox-5b"
) -> List[str]:
    """æ‰¹é‡ç”Ÿæˆè§†é¢‘ç‰‡æ®µ"""
    results = []
    
    for i, scene in enumerate(scenes):
        print(f"ç”Ÿæˆåœºæ™¯ {i+1}/{len(scenes)}: {scene['description']}")
        
        # ç”Ÿæˆå›¾åƒ
        image_generator = ImageGenerator()
        image_path = image_generator.generate(
            prompt=scene['description'],
            task_type="character"
        )
        
        # ç”Ÿæˆè§†é¢‘
        video_path = self.generate(
            image_path=image_path,
            prompt=scene['action'],
            model_type=model_type
        )
        
        results.append({
            "scene_id": scene['scene_id'],
            "video_path": video_path,
            "narration": scene['narration']
        })
    
    return results
```

---

## ğŸ“‹ ç¬¬å››éƒ¨åˆ†ï¼šé—®é¢˜æ’æŸ¥

### 4.1 å¸¸è§é—®é¢˜

#### é—®é¢˜1: Fluxæ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶**: `FileNotFoundError` æˆ– `Model not found`

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å®Œæ•´ä¸‹è½½
3. æ£€æŸ¥HuggingFace tokenæ˜¯å¦æœ‰æ•ˆ

---

#### é—®é¢˜2: CogVideoXæ˜¾å­˜ä¸è¶³

**ç—‡çŠ¶**: `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨æ¨¡å‹é‡åŒ–ï¼ˆINT8/FP16ï¼‰
2. ä½¿ç”¨CPU offload
3. é™ä½åˆ†è¾¨ç‡æˆ–å¸§æ•°
4. ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæ”¯æŒï¼‰

---

#### é—®é¢˜3: è§†é¢‘è´¨é‡ä¸ä½³

**ç—‡çŠ¶**: è§†é¢‘æ¨¡ç³Šã€æŠ–åŠ¨ã€ä¸è¿è´¯

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ æ¨ç†æ­¥æ•°
2. ä¼˜åŒ–æç¤ºè¯
3. è°ƒæ•´è¿åŠ¨å‚æ•°
4. ä½¿ç”¨æ’å¸§ï¼ˆRIFEï¼‰

---

## ğŸ“‹ ç¬¬äº”éƒ¨åˆ†ï¼šéªŒæ”¶æ ‡å‡†

### 5.1 Fluxåˆ‡æ¢éªŒæ”¶

- [ ] Fluxç”Ÿæˆè´¨é‡ > SDXL
- [ ] è§’è‰²ä¸€è‡´æ€§ç¨³å®š
- [ ] å•å›¾ç”Ÿæˆæ—¶é—´ < 30ç§’
- [ ] æ— å†…å­˜æ³„æ¼
- [ ] APIæ¥å£æ­£å¸¸

---

### 5.2 CogVideoXé›†æˆéªŒæ”¶

- [ ] CogVideoXå¯æ­£å¸¸ç”Ÿæˆè§†é¢‘
- [ ] è§†é¢‘è´¨é‡ > SVD-XTï¼ˆå†™å®åœºæ™¯ï¼‰
- [ ] è„¸éƒ¨ç¨³å®šæ€§å¥½
- [ ] å•è§†é¢‘ç”Ÿæˆæ—¶é—´ < 5åˆ†é’Ÿ
- [ ] æ˜¾å­˜ä½¿ç”¨ < 24GB
- [ ] APIæ¥å£æ­£å¸¸

---

### 5.3 å·¥ä½œæµéªŒæ”¶

- [ ] å…¨æµç¨‹è‡ªåŠ¨åŒ–
- [ ] å¯ä»¥æ‰¹é‡ç”Ÿæˆ
- [ ] è§†é¢‘è´¨é‡ç¨³å®š
- [ ] ç”¨æˆ·ä½“éªŒè‰¯å¥½

---

## ğŸš€ ä¸‹ä¸€æ­¥

1. âœ… å¼€å§‹æ‰§è¡ŒDay 1ä»»åŠ¡ï¼ˆFluxåˆ‡æ¢ï¼‰
2. âœ… å‡†å¤‡CogVideoXè°ƒç ”
3. âœ… å‡†å¤‡æµ‹è¯•æ•°æ®

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ  
**å‚è€ƒæ–‡æ¡£**: 
- `æœ€ç»ˆå†³ç­–æ–¹æ¡ˆ-æ¨¡å‹é€‰æ‹©ä¸ä¸šåŠ¡è·¯å¾„.md`
- `Fluxæ¨¡å‹é€‰æ‹©è¯´æ˜.md`
- CogVideoXå®˜æ–¹æ–‡æ¡£


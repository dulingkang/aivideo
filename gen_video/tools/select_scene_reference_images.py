#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åœºæ™¯å‚è€ƒå›¾åƒé€‰æ‹©å™¨

æ ¹æ®åœºæ™¯æè¿°ï¼Œä»processedç›®å½•ä¸­çš„keyframesä¸­æ£€ç´¢æœ€ç›¸å…³çš„å‚è€ƒå›¾åƒã€‚
ä½¿ç”¨FAISSç´¢å¼•å’Œæ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰æ¥åŒ¹é…åœºæ™¯ã€‚
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import faiss
import numpy as np

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("âš  è­¦å‘Š: sentence-transformers æœªå®‰è£…ï¼Œå°†åªä½¿ç”¨å…³é”®è¯æ£€ç´¢")


def load_index(index_path: Path, metadata_path: Path) -> Tuple[faiss.Index, Dict]:
    """åŠ è½½FAISSç´¢å¼•å’Œå…ƒæ•°æ®"""
    print(f"åŠ è½½ç´¢å¼•: {index_path}")
    index = faiss.read_index(str(index_path))
    
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"  ç´¢å¼•ç»´åº¦: {index.d}, å‘é‡æ•°: {index.ntotal}")
    return index, metadata


def load_scene_metadata(metadata_files: List[Path]) -> Dict[str, Dict]:
    """åŠ è½½æ‰€æœ‰åœºæ™¯metadata"""
    all_scenes = {}
    
    for metadata_file in metadata_files:
        if not metadata_file.exists():
            print(f"âš  è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {metadata_file}")
            continue
        
        with open(metadata_file, 'r', encoding='utf-8') as f:
            scenes = json.load(f)
        
        for scene_id, scene_data in scenes.items():
            all_scenes[scene_id] = scene_data
    
    return all_scenes


def build_keyword_index(scenes: Dict[str, Dict]) -> Dict[str, List[str]]:
    """æ„å»ºå…³é”®è¯ç´¢å¼•ï¼ˆTF-IDFé£æ ¼ï¼‰"""
    keyword_index = {}
    
    for scene_id, scene_data in scenes.items():
        # ç»„åˆæ‰€æœ‰æ–‡æœ¬å­—æ®µ
        text_parts = []
        if scene_data.get("text"):
            text_parts.append(scene_data["text"])
        if scene_data.get("visual_caption"):
            text_parts.append(scene_data["visual_caption"])
        if scene_data.get("subtitle_text"):
            text_parts.append(scene_data["subtitle_text"])
        
        combined_text = " ".join(text_parts).lower()
        
        # æå–å…³é”®è¯ï¼ˆç®€å•åˆ†è¯ï¼‰
        keywords = combined_text.split()
        
        for keyword in keywords:
            if len(keyword) > 1:  # å¿½ç•¥å•å­—ç¬¦
                if keyword not in keyword_index:
                    keyword_index[keyword] = []
                keyword_index[keyword].append(scene_id)
    
    return keyword_index


def keyword_search(query: str, keyword_index: Dict[str, List[str]], scenes: Dict,
                   top_k: int = 10) -> List[Tuple[str, float]]:
    """å…³é”®è¯æ£€ç´¢"""
    query_lower = query.lower()
    query_keywords = query_lower.split()
    
    scene_scores = {}
    
    for keyword in query_keywords:
        if keyword in keyword_index:
            for scene_id in keyword_index[keyword]:
                scene_scores[scene_id] = scene_scores.get(scene_id, 0) + 1
    
    # å½’ä¸€åŒ–åˆ†æ•°
    if scene_scores:
        max_score = max(scene_scores.values())
        if max_score > 0:
            scene_scores = {k: v / max_score for k, v in scene_scores.items()}
    
    sorted_results = sorted(scene_scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_results[:top_k]


def vector_search(query: str, index: faiss.Index, metadata: Dict,
                 clip_model: SentenceTransformer, top_k: int = 10) -> List[Tuple[int, float]]:
    """å‘é‡æ£€ç´¢ï¼ˆåŸºäºembeddingç›¸ä¼¼åº¦ï¼‰"""
    if not SENTENCE_TRANSFORMERS_AVAILABLE:
        return []
    
    # å°†æŸ¥è¯¢æ–‡æœ¬ç¼–ç ä¸ºå‘é‡
    query_embedding = clip_model.encode([query], convert_to_numpy=True).astype('float32')
    
    # æœç´¢
    distances, indices = index.search(query_embedding, top_k)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    results = [(int(indices[0][i]), float(distances[0][i])) for i in range(len(indices[0]))]
    return results


def hybrid_search(query: str, index: faiss.Index, metadata: Dict, scenes: Dict,
                 keyword_index: Dict[str, List[str]], clip_model: Optional[SentenceTransformer],
                 vector_weight: float = 0.7, keyword_weight: float = 0.3,
                 top_k: int = 10) -> List[Tuple[str, float, Dict]]:
    """æ··åˆæ£€ç´¢ï¼šç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢"""
    scene_scores = {}
    
    # 1. å‘é‡æ£€ç´¢
    if SENTENCE_TRANSFORMERS_AVAILABLE and clip_model is not None:
        vector_results = vector_search(query, index, metadata, clip_model, top_k=top_k * 2)
        
        if vector_results:
            max_distance = max(d for _, d in vector_results) if vector_results else 1.0
            min_distance = min(d for _, d in vector_results) if vector_results else 0.0
            distance_range = max_distance - min_distance if max_distance > min_distance else 1.0
            
            for idx_pos, distance in vector_results:
                scene_id = metadata["id_mapping"].get(str(idx_pos), "")
                if scene_id:
                    normalized_score = 1.0 - ((distance - min_distance) / distance_range) if distance_range > 0 else 1.0
                    scene_scores[scene_id] = scene_scores.get(scene_id, 0.0) + normalized_score * vector_weight
    
    # 2. å…³é”®è¯æ£€ç´¢
    keyword_results = keyword_search(query, keyword_index, scenes, top_k=top_k * 2)
    
    if keyword_results:
        max_keyword_score = max(s for _, s in keyword_results) if keyword_results else 1.0
        for scene_id, score in keyword_results:
            normalized_score = score / max_keyword_score if max_keyword_score > 0 else score
            scene_scores[scene_id] = scene_scores.get(scene_id, 0.0) + normalized_score * keyword_weight
    
    # 3. æ’åºå¹¶è¿”å›
    sorted_results = sorted(scene_scores.items(), key=lambda x: x[1], reverse=True)
    results = [(scene_id, final_score, scenes.get(scene_id, {})) 
               for scene_id, final_score in sorted_results[:top_k] if scene_id in scenes]
    
    return results


def find_keyframe_path(scene_id: str, base_dir: Path) -> Optional[Path]:
    """æ ¹æ®scene_idæŸ¥æ‰¾å¯¹åº”çš„keyframeå›¾åƒè·¯å¾„"""
    # scene_idæ ¼å¼: "171_scene_001" æˆ– "episode_171_scene_001"
    parts = scene_id.split('_')
    
    if len(parts) >= 2:
        episode_num = parts[0]
        scene_num = parts[-1] if len(parts) > 2 else parts[1]
        
        # å°è¯•ä¸åŒçš„è·¯å¾„æ ¼å¼
        possible_paths = [
            base_dir / f"episode_{episode_num}" / "keyframes" / f"episode_{episode_num}_clean-Scene-{scene_num.zfill(3)}_middle.jpg",
            base_dir / f"episode_{episode_num}" / "keyframes" / f"episode_{episode_num}_clean-Scene-{scene_num.zfill(3)}_start.jpg",
            base_dir / f"episode_{episode_num}" / "keyframes" / f"scene_{scene_num.zfill(3)}_middle.jpg",
            base_dir / f"episode_{episode_num}" / "keyframes" / f"scene_{scene_num.zfill(3)}_start.jpg",
        ]
        
        for path in possible_paths:
            if path.exists():
                return path
    
    return None


def build_scene_query(scene: Dict[str, Any]) -> str:
    """æ ¹æ®åœºæ™¯æ•°æ®æ„å»ºæŸ¥è¯¢æ–‡æœ¬"""
    query_parts = []
    
    # 1. åœºæ™¯æè¿°
    if scene.get("description"):
        query_parts.append(scene["description"])
    
    # 2. visual.composition
    if scene.get("visual", {}).get("composition"):
        query_parts.append(scene["visual"]["composition"])
    
    # 3. visual.environment
    if scene.get("visual", {}).get("environment"):
        query_parts.append(scene["visual"]["environment"])
    
    # 4. visual.character_pose
    if scene.get("visual", {}).get("character_pose"):
        query_parts.append(scene["visual"]["character_pose"])
    
    # 5. åŸå§‹promptï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if scene.get("prompt"):
        query_parts.append(scene["prompt"])
    
    return " ".join(query_parts)


def select_reference_images(
    scene: Dict[str, Any],
    index_path: Path,
    metadata_path: Path,
    scene_metadata_files: List[Path],
    keyframes_base_dir: Path,
    top_k: int = 3,
    method: str = "hybrid"
) -> List[Tuple[Path, float, Dict]]:
    """
    ä¸ºåœºæ™¯é€‰æ‹©å‚è€ƒå›¾åƒ
    
    Returns:
        [(keyframe_path, score, scene_data), ...] æŒ‰åˆ†æ•°é™åºæ’åˆ—
    """
    # æ„å»ºæŸ¥è¯¢æ–‡æœ¬
    query = build_scene_query(scene)
    
    if not query:
        print("  âš  åœºæ™¯æ²¡æœ‰è¶³å¤Ÿçš„æè¿°ä¿¡æ¯ï¼Œæ— æ³•æ£€ç´¢")
        return []
    
    print(f"  ğŸ” åœºæ™¯æŸ¥è¯¢: {query[:100]}...")
    
    # åŠ è½½ç´¢å¼•
    index, index_metadata = load_index(index_path, metadata_path)
    
    # åŠ è½½åœºæ™¯metadata
    all_scenes = load_scene_metadata(scene_metadata_files)
    
    # åŠ è½½CLIPæ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
    clip_model = None
    if method in ['vector', 'hybrid'] and SENTENCE_TRANSFORMERS_AVAILABLE:
        print("  åŠ è½½CLIPæ¨¡å‹...")
        clip_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    # æ„å»ºå…³é”®è¯ç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
    keyword_index = None
    if method in ['keyword', 'hybrid']:
        keyword_index = build_keyword_index(all_scenes)
    
    # æ‰§è¡Œæ£€ç´¢
    if method == 'vector':
        vector_results = vector_search(query, index, index_metadata, clip_model, top_k=top_k)
        results = []
        for idx_pos, distance in vector_results:
            scene_id = index_metadata["id_mapping"].get(str(idx_pos), "")
            if scene_id in all_scenes:
                keyframe_path = find_keyframe_path(scene_id, keyframes_base_dir)
                if keyframe_path:
                    score = 1.0 / (1.0 + distance)
                    results.append((keyframe_path, score, all_scenes[scene_id]))
    
    elif method == 'keyword':
        keyword_results = keyword_search(query, keyword_index, all_scenes, top_k=top_k)
        results = []
        for scene_id, score in keyword_results:
            keyframe_path = find_keyframe_path(scene_id, keyframes_base_dir)
            if keyframe_path:
                results.append((keyframe_path, score, all_scenes[scene_id]))
    
    else:  # hybrid
        hybrid_results = hybrid_search(
            query, index, index_metadata, all_scenes, keyword_index, clip_model,
            vector_weight=0.7, keyword_weight=0.3, top_k=top_k
        )
        results = []
        for scene_id, score, scene_data in hybrid_results:
            keyframe_path = find_keyframe_path(scene_id, keyframes_base_dir)
            if keyframe_path:
                results.append((keyframe_path, score, scene_data))
    
    return results


def main():
    parser = argparse.ArgumentParser(description='ä¸ºåœºæ™¯é€‰æ‹©å‚è€ƒå›¾åƒ')
    parser.add_argument('--scene', required=True, help='åœºæ™¯JSONæ–‡ä»¶æˆ–JSONå­—ç¬¦ä¸²')
    parser.add_argument('--index', default='processed/global_index.faiss', help='FAISSç´¢å¼•è·¯å¾„')
    parser.add_argument('--metadata', default='processed/index_metadata.json', help='ç´¢å¼•metadataè·¯å¾„')
    parser.add_argument('--scenes', nargs='+', default=['processed/episode_*/scene_metadata.json'],
                       help='åœºæ™¯metadata JSONæ–‡ä»¶ï¼ˆæ”¯æŒglobæ¨¡å¼ï¼‰')
    parser.add_argument('--keyframes-base', default='processed', help='keyframesåŸºç¡€ç›®å½•')
    parser.add_argument('--top-k', type=int, default=3, help='è¿”å›top kä¸ªå‚è€ƒå›¾åƒ')
    parser.add_argument('--method', choices=['vector', 'keyword', 'hybrid'], 
                       default='hybrid', help='æ£€ç´¢æ–¹æ³•')
    parser.add_argument('--output', help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    # è§£æåœºæ™¯æ•°æ®
    scene_path = Path(args.scene)
    if scene_path.exists():
        with open(scene_path, 'r', encoding='utf-8') as f:
            scene = json.load(f)
    else:
        # å°è¯•ä½œä¸ºJSONå­—ç¬¦ä¸²è§£æ
        scene = json.loads(args.scene)
    
    # å±•å¼€globæ¨¡å¼
    from glob import glob
    scene_metadata_files = []
    for pattern in args.scenes:
        scene_metadata_files.extend([Path(f) for f in glob(pattern)])
    
    # é€‰æ‹©å‚è€ƒå›¾åƒ
    results = select_reference_images(
        scene,
        Path(args.index),
        Path(args.metadata),
        scene_metadata_files,
        Path(args.keyframes_base),
        top_k=args.top_k,
        method=args.method
    )
    
    # è¾“å‡ºç»“æœ
    print(f"\næ‰¾åˆ° {len(results)} ä¸ªå‚è€ƒå›¾åƒ:\n")
    output_data = []
    for i, (keyframe_path, score, scene_data) in enumerate(results, 1):
        print(f"{i}. {keyframe_path.name}")
        print(f"   ç›¸ä¼¼åº¦: {score:.3f}")
        print(f"   åœºæ™¯ID: {scene_data.get('scene_id', 'unknown')}")
        print(f"   æè¿°: {scene_data.get('text', '')[:50]}...")
        print()
        
        output_data.append({
            "keyframe_path": str(keyframe_path),
            "score": score,
            "scene_data": scene_data
        })
    
    # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")


if __name__ == "__main__":
    main()


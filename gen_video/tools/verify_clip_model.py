#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯ CLIP æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

æ£€æŸ¥å·²ä¸‹è½½çš„ CLIP æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´å’Œæœ‰æ•ˆ
"""

import os
import sys
import json
from pathlib import Path

def verify_safetensors_file(file_path):
    """éªŒè¯ safetensors æ–‡ä»¶å®Œæ•´æ€§"""
    try:
        with open(file_path, "rb") as f:
            # è¯»å–æ–‡ä»¶å¤´é•¿åº¦ï¼ˆ8å­—èŠ‚ï¼‰
            header_len_bytes = f.read(8)
            if len(header_len_bytes) < 8:
                return False, "æ–‡ä»¶å¤´ä¸å®Œæ•´"
            
            header_len = int.from_bytes(header_len_bytes, "little")
            if header_len <= 0 or header_len > 10 * 1024 * 1024:  # é™åˆ¶æœ€å¤§ 10MB
                return False, f"æ–‡ä»¶å¤´é•¿åº¦å¼‚å¸¸: {header_len} bytes"
            
            # è¯»å–å¹¶éªŒè¯ JSON
            header_json = f.read(header_len).decode("utf-8")
            header_data = json.loads(header_json)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            expected_size = header_len + 8  # è‡³å°‘æ˜¯å¤´éƒ¨å¤§å°
            for tensor_info in header_data.values():
                if isinstance(tensor_info, dict) and "data_offsets" in tensor_info:
                    offsets = tensor_info["data_offsets"]
                    expected_size = max(expected_size, offsets[1] + 8)
            
            if file_size < expected_size:
                return False, f"æ–‡ä»¶å¤§å°ä¸å®Œæ•´: {file_size} < {expected_size}"
            
            return True, f"æ–‡ä»¶å®Œæ•´ ({file_size / 1024 / 1024:.2f} MB)"
    except json.JSONDecodeError as e:
        return False, f"JSON è§£æå¤±è´¥: {e}"
    except Exception as e:
        return False, f"éªŒè¯å¤±è´¥: {e}"

def verify_clip_model(model_path):
    """éªŒè¯ CLIP æ¨¡å‹ç›®å½•"""
    model_path = Path(model_path)
    
    if not model_path.exists():
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"ğŸ“¦ æ£€æŸ¥æ¨¡å‹è·¯å¾„: {model_path}")
    print("")
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    required_files = [
        "tokenizer_config.json",
        "vocab.json",
        "merges.txt",
        "special_tokens_map.json",
    ]
    
    all_ok = True
    
    print("1ï¸âƒ£ æ£€æŸ¥ Tokenizer æ–‡ä»¶...")
    for file in required_files:
        file_path = model_path / file
        if file_path.exists():
            file_size = file_path.stat().st_size
            print(f"   âœ“ {file} ({file_size / 1024:.2f} KB)")
        else:
            print(f"   âŒ {file} ä¸å­˜åœ¨")
            all_ok = False
    
    print("\n2ï¸âƒ£ æ£€æŸ¥ Model æ–‡ä»¶...")
    safetensors_files = list(model_path.glob("*.safetensors"))
    if not safetensors_files:
        print("   âŒ æœªæ‰¾åˆ° .safetensors æ–‡ä»¶")
        all_ok = False
    else:
        for safetensors_file in safetensors_files:
            print(f"   éªŒè¯: {safetensors_file.name}...")
            is_valid, message = verify_safetensors_file(safetensors_file)
            if is_valid:
                print(f"      âœ“ {message}")
            else:
                print(f"      âŒ {message}")
                all_ok = False
    
    print("\n3ï¸âƒ£ å°è¯•åŠ è½½æ¨¡å‹éªŒè¯...")
    try:
        from transformers import CLIPTextModel, CLIPTokenizer
        
        print("   åŠ è½½ Tokenizer...")
        tokenizer = CLIPTokenizer.from_pretrained(str(model_path), local_files_only=True)
        print("   âœ“ Tokenizer åŠ è½½æˆåŠŸ")
        
        print("   åŠ è½½ Model...")
        model = CLIPTextModel.from_pretrained(str(model_path), local_files_only=True)
        print("   âœ“ Model åŠ è½½æˆåŠŸ")
        
        print("\nâœ… æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸”å¯æ­£å¸¸åŠ è½½ï¼")
        return True
    except Exception as e:
        print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # é»˜è®¤æ£€æŸ¥ models ç›®å½•
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
    else:
        project_root = Path(__file__).parent.parent
        model_path = project_root / "models" / "clip" / "openai-clip-vit-large-patch14"
    
    success = verify_clip_model(model_path)
    sys.exit(0 if success else 1)


#!/usr/bin/env python3
# âš¡ å…³é”®ä¿®å¤ï¼šè®¾ç½® PyTorch CUDA allocator ä¸ºå¯æ‰©å±•æ®µæ¨¡å¼ï¼ˆè§£å†³æ˜¾å­˜ç¢ç‰‡åŒ–é—®é¢˜ï¼‰
# è¿™å¿…é¡»åœ¨å¯¼å…¥ä»»ä½• torch æ¨¡å—ä¹‹å‰è®¾ç½®
import os
if "PYTORCH_CUDA_ALLOC_CONF" not in os.environ:
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
# -*- coding: utf-8 -*-
"""
å°è¯´æ¨æ–‡æ‰¹é‡ç”Ÿæˆå·¥å…·

åŠŸèƒ½ï¼š
1. æ‰¹é‡å¤„ç† JSON åœºæ™¯æ–‡ä»¶
2. æ”¯æŒå¤šåœºæ™¯å¹¶è¡Œ/ä¸²è¡Œç”Ÿæˆ
3. è‡ªåŠ¨é”™è¯¯é‡è¯•
4. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import traceback
import yaml
import gc

# å°è¯•å¯¼å…¥ torchï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from generate_novel_video import NovelVideoGenerator


class BatchNovelGenerator:
    """æ‰¹é‡å°è¯´æ¨æ–‡ç”Ÿæˆå™¨
    
    ä¸‰é˜¶æ®µæµç¨‹ï¼š
    1. é˜¶æ®µ1ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡
    2. é˜¶æ®µ2ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰é…éŸ³ï¼Œå¹¶è·å–å®é™…æ—¶é•¿
    3. é˜¶æ®µ3ï¼šæ ¹æ®é…éŸ³æ—¶é•¿æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è§†é¢‘
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        """
        åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        # è§£æé…ç½®æ–‡ä»¶è·¯å¾„
        if config_path is None:
            config_path = project_root / "config.yaml"
        if not config_path.is_absolute():
            config_path = (project_root / config_path).resolve()
        
        self.config_path = config_path
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        self.generator = NovelVideoGenerator(str(self.config_path))
        
        # åˆå§‹åŒ– TTS ç”Ÿæˆå™¨ï¼ˆç”¨äºé˜¶æ®µ2ï¼šé…éŸ³ç”Ÿæˆï¼‰
        self.tts_generator = None
        try:
            from tts_generator import TTSGenerator
            self.tts_generator = TTSGenerator(str(self.config_path))
            print("  âœ“ TTS ç”Ÿæˆå™¨å·²åŠ è½½")
        except Exception as e:
            print(f"  âš  TTS ç”Ÿæˆå™¨åŠ è½½å¤±è´¥: {e}ï¼Œå°†è·³è¿‡é…éŸ³ç”Ÿæˆ")
        
        self.results = []
        self.errors = []
        
    def load_scenes_from_json(self, json_path: Path, auto_convert_v21: bool = True) -> List[Dict[str, Any]]:
        """
        ä» JSON æ–‡ä»¶åŠ è½½åœºæ™¯åˆ—è¡¨
        
        Args:
            json_path: JSON æ–‡ä»¶è·¯å¾„
            auto_convert_v21: æ˜¯å¦è‡ªåŠ¨å°†v2æ ¼å¼è½¬æ¢ä¸ºv2.1-exec
        
        Returns:
            åœºæ™¯åˆ—è¡¨
        """
        if not json_path.exists():
            raise FileNotFoundError(f"JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data.get('scenes', [])
        print(f"  âœ“ ä» {json_path} åŠ è½½äº† {len(scenes)} ä¸ªåœºæ™¯")
        
        # âš¡ v2.1-execæ”¯æŒï¼šæ£€æµ‹å¹¶è½¬æ¢v2æ ¼å¼
        converted_count = 0
        for i, scene in enumerate(scenes):
            scene_version = scene.get('version', '')
            
            # å¦‚æœæ˜¯v2æ ¼å¼ä¸”å¯ç”¨è‡ªåŠ¨è½¬æ¢
            if scene_version == 'v2' and auto_convert_v21:
                try:
                    from utils.json_v2_to_v21_converter import JSONV2ToV21Converter
                    converter = JSONV2ToV21Converter()
                    scenes[i] = converter.convert_scene(scene)
                    converted_count += 1
                    print(f"  â„¹ åœºæ™¯ {scene.get('scene_id', i)}: v2 â†’ v2.1-exec è½¬æ¢å®Œæˆ")
                except Exception as e:
                    print(f"  âš  åœºæ™¯ {scene.get('scene_id', i)} è½¬æ¢å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ ¼å¼")
            # å¦‚æœå·²ç»æ˜¯v2.1-execæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
            elif scene_version.startswith('v2.1'):
                print(f"  âœ“ åœºæ™¯ {scene.get('scene_id', i)}: å·²æ˜¯v2.1-execæ ¼å¼")
        
        if converted_count > 0:
            print(f"  âœ“ å…±è½¬æ¢ {converted_count} ä¸ªåœºæ™¯ä¸ºv2.1-execæ ¼å¼")
        
        return scenes
    
    def extract_prompt_from_scene(self, scene: Dict[str, Any]) -> str:
        """
        ä»åœºæ™¯å­—å…¸ä¸­æå– prompt
        
        Args:
            scene: åœºæ™¯å­—å…¸
        
        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        # âš¡ å…³é”®ä¿®å¤ï¼šç¡®ä¿åŒ…å« character.pose ä¿¡æ¯ï¼ˆv2 æ ¼å¼ï¼‰
        # å¦‚æœåœºæ™¯ä¸­æœ‰ character.poseï¼Œéœ€è¦å°†å…¶åŒ…å«åœ¨ prompt ä¸­ï¼Œä»¥ä¾¿ LLM æ­£ç¡®è¯†åˆ«å§¿æ€
        character = scene.get('character', {})
        character_pose = character.get('pose', '')
        
        # å°è¯•å¤šç§æ–¹å¼æå– prompt
        prompt_parts = []
        
        # 1. ä» visual_constraints æå–
        visual = scene.get('visual_constraints', {})
        if isinstance(visual, dict):
            environment = visual.get('environment', '')
            if environment:
                prompt_parts.append(environment)
        
        # 2. ä» narration æå–ï¼ˆâš ï¸ æ³¨æ„ï¼šä¸è¦ç›´æ¥ä½¿ç”¨æ—ç™½æ–‡æœ¬ï¼Œé¿å…åœ¨å›¾åƒä¸­æ¸²æŸ“æ–‡å­—ï¼‰
        # narration æ˜¯è¯­éŸ³æ—ç™½ï¼Œä¸åº”è¯¥å‡ºç°åœ¨è§†è§‰ prompt ä¸­
        # å¦‚æœéœ€è¦ä»æ—ç™½ä¸­æå–è§†è§‰æè¿°ï¼Œåº”è¯¥ä½¿ç”¨æ›´æ™ºèƒ½çš„æå–æ–¹å¼
        # æš‚æ—¶è·³è¿‡ narrationï¼Œé¿å…æ–‡å­—å‡ºç°åœ¨å›¾åƒä¸­
        
        # 3. ä» character æå–
        character = scene.get('character', {})
        if character.get('present', False):
            character_id = character.get('id', '')
            if character_id == 'hanli':
                prompt_parts.insert(0, "éŸ©ç«‹")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šåŒ…å« character.pose ä¿¡æ¯ï¼Œç¡®ä¿ LLM èƒ½è¯†åˆ«å§¿æ€
            character_pose = character.get('pose', '')
            if character_pose:
                # å°† pose è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æè¿°
                pose_descriptions = {
                    'lying_motionless': 'lying motionless on the ground',
                    'lying': 'lying on the ground',
                    'sitting': 'sitting',
                    'standing': 'standing',
                    'walking': 'walking',
                    'running': 'running',
                }
                pose_desc = pose_descriptions.get(character_pose.lower(), character_pose)
                # å°†å§¿æ€æè¿°æ·»åŠ åˆ° prompt ä¸­ï¼ˆæ”¾åœ¨è§’è‰²åä¹‹åï¼‰
                if character_id == 'hanli' and len(prompt_parts) > 0:
                    # å¦‚æœå·²ç»æœ‰"éŸ©ç«‹"ï¼Œåœ¨å®ƒåé¢æ·»åŠ å§¿æ€æè¿°
                    prompt_parts[0] = f"éŸ©ç«‹, {pose_desc}"
                else:
                    prompt_parts.append(pose_desc)
        
        # 4. ä»å…¶ä»–å­—æ®µæå–
        if not prompt_parts:
            # å°è¯•ä»å…¶ä»–å­—æ®µæå–
            description = scene.get('description', '')
            if description:
                prompt_parts.append(description)
            else:
                prompt_parts.append("ä¸€ä¸ªä»™ä¾ åœºæ™¯")
        
        return ", ".join(prompt_parts) if prompt_parts else "ä¸€ä¸ªä»™ä¾ åœºæ™¯"
    
    def generate_scene(
        self,
        scene: Dict[str, Any],
        output_base_dir: Path,
        scene_index: int,
        total_scenes: int,
        enable_m6: bool = True,
        quick_mode: bool = False,
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå•ä¸ªåœºæ™¯
        
        Args:
            scene: åœºæ™¯å­—å…¸
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            scene_index: åœºæ™¯ç´¢å¼•
            total_scenes: æ€»åœºæ™¯æ•°
            enable_m6: æ˜¯å¦å¯ç”¨ M6 èº«ä»½éªŒè¯
            quick_mode: å¿«é€Ÿæ¨¡å¼ï¼ˆå‡å°‘å¸§æ•°ï¼‰
        
        Returns:
            ç”Ÿæˆç»“æœå­—å…¸
        """
        scene_id = scene.get('scene_id', scene_index)
        print(f"\n{'='*60}")
        print(f"ç”Ÿæˆåœºæ™¯ {scene_index + 1}/{total_scenes} (ID: {scene_id})")
        print(f"{'='*60}")
        
        # æå– prompt
        prompt = self.extract_prompt_from_scene(scene)
        print(f"  æç¤ºè¯: {prompt[:100]}...")
        
        # æå–åœºæ™¯å‚æ•°
        character = scene.get('character', {})
        character_present = character.get('present', False)
        character_id = character.get('id') if character_present else None
        
        camera = scene.get('camera', {})
        shot_type = camera.get('shot', 'medium')
        
        quality_target = scene.get('quality_target', {})
        motion_intensity = quality_target.get('motion_intensity', 'moderate')
        
        # æ„å»ºè¾“å‡ºç›®å½•
        scene_output_dir = output_base_dir / f"scene_{scene_id:03d}"
        scene_output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆå‚æ•°
        width = scene.get('width', 768)
        height = scene.get('height', 1152)
        fps = scene.get('target_fps', 24) or 24
        
        # âš¡ å…³é”®ä¿®å¤ï¼šæ ¹æ®é…éŸ³æ—¶é•¿ï¼ˆduration_secï¼‰è®¡ç®—å¸§æ•°
        # ä¼˜å…ˆçº§ï¼šduration_sec > num_frames > é»˜è®¤å€¼
        duration_sec = scene.get('duration_sec')
        if duration_sec:
            # æ ¹æ®é…éŸ³æ—¶é•¿è®¡ç®—å¸§æ•°ï¼šå¸§æ•° = æ—¶é•¿(ç§’) Ã— å¸§ç‡
            calculated_frames = int(duration_sec * fps)
            if quick_mode:
                # å¿«é€Ÿæ¨¡å¼ï¼šè‡³å°‘24å¸§ï¼Œä½†ä¸è¶…è¿‡è®¡ç®—å€¼
                num_frames = max(24, min(calculated_frames, 60))  # å¿«é€Ÿæ¨¡å¼æœ€å¤š60å¸§
            else:
                num_frames = calculated_frames
            print(f"  â„¹ æ ¹æ®é…éŸ³æ—¶é•¿è®¡ç®—: {duration_sec}ç§’ Ã— {fps}fps = {num_frames}å¸§")
        else:
            # å¦‚æœæ²¡æœ‰ duration_secï¼Œä½¿ç”¨ num_frames æˆ–é»˜è®¤å€¼
            num_frames = 24 if quick_mode else scene.get('num_frames', 120)
            print(f"  âš  æœªæ‰¾åˆ° duration_secï¼Œä½¿ç”¨é»˜è®¤å¸§æ•°: {num_frames}å¸§")
        
        print(f"  å‚æ•°: {width}x{height}, {num_frames}å¸§, {fps}fps (æ—¶é•¿: {num_frames/fps:.2f}ç§’)")
        print(f"  é•œå¤´: {shot_type}, è¿åŠ¨å¼ºåº¦: {motion_intensity}")
        if character_present:
            print(f"  è§’è‰²: {character_id} (M6: {'å¯ç”¨' if enable_m6 else 'ç¦ç”¨'})")
        
        try:
            # ç”Ÿæˆè§†é¢‘
            result = self.generator.generate(
                prompt=prompt,
                output_dir=scene_output_dir,
                width=width,
                height=height,
                num_frames=num_frames,
                fps=fps,
                scene=scene,
                include_character=character_present,
                character_id=character_id,
                auto_character=True,
                enable_m6_identity=enable_m6 if character_present else False,
                auto_m6_identity=enable_m6,
                shot_type=shot_type,
                motion_intensity=motion_intensity,
                m6_quick=quick_mode,
            )
            
            print(f"  âœ… ç”ŸæˆæˆåŠŸ!")
            print(f"     å›¾ç‰‡: {result.get('image')}")
            if 'video' in result:
                print(f"     è§†é¢‘: {result.get('video')}")
            
            return {
                'scene_id': scene_id,
                'scene_index': scene_index,
                'status': 'success',
                'prompt': prompt,
                'result': result,
                'error': None,
            }
            
        except Exception as e:
            error_msg = str(e)
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {error_msg}")
            traceback.print_exc()
            
            return {
                'scene_id': scene_id,
                'scene_index': scene_index,
                'status': 'error',
                'prompt': prompt,
                'result': None,
                'error': error_msg,
            }
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
        try:
            from video_composer import VideoComposer
            composer = VideoComposer(str(self.config_path))
            return composer.get_media_duration(audio_path)
        except Exception as e:
            print(f"  âš  æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ {audio_path}: {e}")
            return 0.0
    
    def generate_batch(
        self,
        json_path: Path,
        output_dir: Path,
        enable_m6: bool = True,
        quick_mode: bool = False,
        max_retries: int = 2,
        start_index: int = 0,
        end_index: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡ç”Ÿæˆåœºæ™¯ï¼ˆä¸‰é˜¶æ®µæµç¨‹ï¼‰
        
        é˜¶æ®µ1ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡
        é˜¶æ®µ2ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰é…éŸ³ï¼Œå¹¶è·å–å®é™…æ—¶é•¿
        é˜¶æ®µ3ï¼šæ ¹æ®é…éŸ³æ—¶é•¿æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è§†é¢‘
        
        Args:
            json_path: JSON åœºæ™¯æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            enable_m6: æ˜¯å¦å¯ç”¨ M6 èº«ä»½éªŒè¯
            quick_mode: å¿«é€Ÿæ¨¡å¼
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            start_index: å¼€å§‹ç´¢å¼•ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
            end_index: ç»“æŸç´¢å¼•ï¼ˆç”¨äºåˆ†æ‰¹å¤„ç†ï¼‰
        
        Returns:
            æ‰¹é‡ç”Ÿæˆç»“æœ
        """
        print("="*60)
        print("å°è¯´æ¨æ–‡æ‰¹é‡ç”Ÿæˆï¼ˆä¸‰é˜¶æ®µæµç¨‹ï¼‰")
        print("="*60)
        
        # åŠ è½½åœºæ™¯
        scenes = self.load_scenes_from_json(json_path)
        
        # è¿‡æ»¤åœºæ™¯èŒƒå›´
        if end_index is None:
            end_index = len(scenes)
        scenes = scenes[start_index:end_index]
        
        print(f"\nç”ŸæˆèŒƒå›´: {start_index} - {end_index-1} (å…± {len(scenes)} ä¸ªåœºæ™¯)")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"M6 èº«ä»½éªŒè¯: {'å¯ç”¨' if enable_m6 else 'ç¦ç”¨'}")
        print(f"å¿«é€Ÿæ¨¡å¼: {'æ˜¯' if quick_mode else 'å¦'}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir.mkdir(parents=True, exist_ok=True)
        audios_dir = output_dir / "audios"
        audios_dir.mkdir(parents=True, exist_ok=True)
        
        # ==========================================
        # é˜¶æ®µ1ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡
        # ==========================================
        print("\n" + "="*60)
        print("é˜¶æ®µ1ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡")
        print("="*60)
        
        image_results = []
        for i, scene in enumerate(scenes):
            scene_index = start_index + i
            scene_id = scene.get('scene_id', scene_index)
            scene_output_dir = output_dir / f"scene_{scene_id:03d}"
            scene_output_dir.mkdir(parents=True, exist_ok=True)
            
            print(f"\n[é˜¶æ®µ1] ç”Ÿæˆå›¾ç‰‡ {i+1}/{len(scenes)} (åœºæ™¯ID: {scene_id})")
            
            # æå– prompt
            prompt = self.extract_prompt_from_scene(scene)
            
            # æå–åœºæ™¯å‚æ•°
            character = scene.get('character', {})
            character_present = character.get('present', False)
            character_id = character.get('id') if character_present else None
            
            camera = scene.get('camera', {})
            shot_type = camera.get('shot', 'medium')
            
            quality_target = scene.get('quality_target', {})
            motion_intensity = quality_target.get('motion_intensity', 'moderate')
            
            width = scene.get('width', 768)
            height = scene.get('height', 1152)
            
            try:
                # é˜¶æ®µ1ï¼šåªç”Ÿæˆå›¾ç‰‡ï¼ˆä¸ç”Ÿæˆè§†é¢‘ï¼‰
                # ç›´æ¥ä½¿ç”¨ image_generatorï¼Œé¿å…ç”Ÿæˆè§†é¢‘
                image_output_path = scene_output_dir / "novel_image.png"
                
                # æ„å»º scene å­—å…¸ç”¨äºå›¾ç‰‡ç”Ÿæˆ
                image_scene = scene.copy() if scene else {}
                image_scene['width'] = width
                image_scene['height'] = height
                if character_present:
                    image_scene.setdefault("character", {})
                    if isinstance(image_scene.get("character"), dict):
                        if character_id:
                            image_scene["character"].setdefault("id", character_id)
                image_scene.setdefault("motion_intensity", motion_intensity)
                
                # âš¡ v2.1-execæ”¯æŒï¼šå¦‚æœsceneæ˜¯v2.1-execæ ¼å¼ï¼Œä½¿ç”¨v2.1æµç¨‹
                scene_version = scene.get('version', '')
                if scene_version.startswith('v2.1'):
                    # ä½¿ç”¨v2.1-execæµç¨‹
                    print(f"  â„¹ ä½¿ç”¨v2.1-execæ¨¡å¼ç”Ÿæˆ")
                    try:
                        result = self.generator.generate(
                            prompt=prompt,
                            output_dir=scene_output_dir,
                            width=width,
                            height=height,
                            num_frames=24,  # é˜¶æ®µ1åªç”Ÿæˆå›¾ç‰‡ï¼Œå¸§æ•°ä¸é‡è¦
                            fps=24,
                            scene=scene,  # ä¼ å…¥å®Œæ•´çš„v2.1-execæ ¼å¼scene
                            use_v21_exec=True,  # å¯ç”¨v2.1-execæ¨¡å¼
                        )
                        if result and result.get('image'):
                            image_path = result['image']
                        else:
                            raise ValueError("v2.1-execæ¨¡å¼ç”Ÿæˆå¤±è´¥")
                    except Exception as e:
                        print(f"  âš  v2.1-execæ¨¡å¼å¤±è´¥: {e}ï¼Œå›é€€åˆ°åŸæœ‰æµç¨‹")
                        # å›é€€åˆ°åŸæœ‰æµç¨‹
                        image_path = self.generator.image_generator.generate_image(
                            prompt=prompt,
                            output_path=image_output_path,
                            scene=image_scene,
                        )
                else:
                    # åŸæœ‰æµç¨‹
                    image_path = self.generator.image_generator.generate_image(
                        prompt=prompt,
                        output_path=image_output_path,
                        scene=image_scene,
                    )
                
                if image_path and Path(image_path).exists():
                    print(f"  âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {image_path}")
                    image_results.append({
                        'scene_id': scene_id,
                        'scene_index': scene_index,
                        'image_path': image_path,
                        'status': 'success'
                    })
                else:
                    print(f"  âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
                    image_results.append({
                        'scene_id': scene_id,
                        'scene_index': scene_index,
                        'image_path': None,
                        'status': 'error'
                    })
                
                # âš¡ å…³é”®ä¿®å¤ï¼šæ¯å¼ å›¾ç‰‡ç”Ÿæˆåæ¸…ç†æ˜¾å­˜ï¼Œé¿å…ç¬¬äºŒå¼ å›¾ç‰‡å¡ä½
                print(f"  ğŸ§¹ æ¸…ç†æ˜¾å­˜...")
                gc.collect()
                if TORCH_AVAILABLE and torch.cuda.is_available():
                    # å¤šæ¬¡æ¸…ç†ï¼Œç¡®ä¿æ˜¾å­˜çœŸæ­£é‡Šæ”¾
                    for _ in range(3):
                        torch.cuda.empty_cache()
                        gc.collect()
                    torch.cuda.synchronize()
                    
                    # æ˜¾ç¤ºæ¸…ç†åçš„æ˜¾å­˜çŠ¶æ€
                    allocated = torch.cuda.memory_allocated() / 1024**3
                    reserved = torch.cuda.memory_reserved() / 1024**3
                    print(f"  â„¹ æ¸…ç†åæ˜¾å­˜: å·²åˆ†é…={allocated:.2f}GB, å·²ä¿ç•™={reserved:.2f}GB")
                
                print(f"  âœ“ æ˜¾å­˜æ¸…ç†å®Œæˆ")
                
            except Exception as e:
                print(f"  âŒ å›¾ç‰‡ç”Ÿæˆå¼‚å¸¸: {e}")
                traceback.print_exc()
                image_results.append({
                    'scene_id': scene_id,
                    'scene_index': scene_index,
                    'image_path': None,
                    'status': 'error',
                    'error': str(e)
                })
                
                # å³ä½¿å¤±è´¥ä¹Ÿè¦æ¸…ç†æ˜¾å­˜
                gc.collect()
                if TORCH_AVAILABLE and torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # ==========================================
        # é˜¶æ®µ2ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰é…éŸ³ï¼Œå¹¶è·å–å®é™…æ—¶é•¿
        # ==========================================
        print("\n" + "="*60)
        print("é˜¶æ®µ2ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰é…éŸ³ï¼Œå¹¶è·å–å®é™…æ—¶é•¿")
        print("="*60)
        
        audio_durations = {}
        if self.tts_generator is None:
            print("  âš  TTS ç”Ÿæˆå™¨æœªåŠ è½½ï¼Œè·³è¿‡é…éŸ³ç”Ÿæˆ")
            print("  âš  å°†ä½¿ç”¨ JSON ä¸­çš„ duration_secï¼ˆå¦‚æœå­˜åœ¨ï¼‰")
        else:
            for i, scene in enumerate(scenes):
                scene_index = start_index + i
                scene_id = scene.get('scene_id', scene_index)
                
                print(f"\n[é˜¶æ®µ2] ç”Ÿæˆé…éŸ³ {i+1}/{len(scenes)} (åœºæ™¯ID: {scene_id})")
                
                # æå–æ—ç™½æ–‡æœ¬
                narration = scene.get('narration', {})
                if isinstance(narration, dict):
                    narration_text = narration.get('text', '')
                else:
                    narration_text = str(narration) if narration else ''
                
                if not narration_text:
                    print(f"  âš  æ— æ—ç™½æ–‡æœ¬ï¼Œè·³è¿‡")
                    continue
                
                # ç”Ÿæˆé…éŸ³
                audio_path = audios_dir / f"audio_scene_{scene_id:03d}.wav"
                try:
                    self.tts_generator.generate(narration_text, str(audio_path))
                    print(f"  âœ… é…éŸ³ç”ŸæˆæˆåŠŸ: {audio_path}")
                    
                    # è·å–å®é™…éŸ³é¢‘æ—¶é•¿
                    duration = self._get_audio_duration(str(audio_path))
                    if duration > 0:
                        audio_durations[scene_id] = duration
                        print(f"  âœ… éŸ³é¢‘æ—¶é•¿: {duration:.3f}ç§’")
                    else:
                        print(f"  âš  æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œä½¿ç”¨ JSON ä¸­çš„ duration_sec")
                except Exception as e:
                    print(f"  âŒ é…éŸ³ç”Ÿæˆå¤±è´¥: {e}")
                    traceback.print_exc()
        
        # é˜¶æ®µ2å®Œæˆç»Ÿè®¡
        print(f"\n[é˜¶æ®µ2å®Œæˆ] é…éŸ³ç”Ÿæˆç»Ÿè®¡:")
        print(f"  æˆåŠŸ: {len(audio_durations)} ä¸ªåœºæ™¯")
        print(f"  å¤±è´¥: {len(scenes) - len(audio_durations)} ä¸ªåœºæ™¯")
        if audio_durations:
            total_duration = sum(audio_durations.values())
            avg_duration = total_duration / len(audio_durations)
            print(f"  æ€»æ—¶é•¿: {total_duration:.2f}ç§’")
            print(f"  å¹³å‡æ—¶é•¿: {avg_duration:.2f}ç§’")
        
        # ==========================================
        # é˜¶æ®µ3ï¼šæ ¹æ®é…éŸ³æ—¶é•¿æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è§†é¢‘
        # ==========================================
        print("\n" + "="*60)
        print("é˜¶æ®µ3ï¼šæ ¹æ®é…éŸ³æ—¶é•¿æ‰¹é‡ç”Ÿæˆæ‰€æœ‰è§†é¢‘")
        print("="*60)
        
        results = []
        for i, scene in enumerate(scenes):
            scene_index = start_index + i
            scene_id = scene.get('scene_id', scene_index)
            
            print(f"\n[é˜¶æ®µ3] ç”Ÿæˆè§†é¢‘ {i+1}/{len(scenes)} (åœºæ™¯ID: {scene_id})")
            
            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦ç”ŸæˆæˆåŠŸ
            image_result = image_results[i] if i < len(image_results) else None
            if not image_result or image_result['status'] != 'success' or not image_result.get('image_path'):
                print(f"  âš  å›¾ç‰‡æœªç”Ÿæˆï¼Œè·³è¿‡è§†é¢‘ç”Ÿæˆ")
                results.append({
                    'scene_id': scene_id,
                    'scene_index': scene_index,
                    'status': 'error',
                    'error': 'å›¾ç‰‡æœªç”Ÿæˆ'
                })
                continue
            
            image_path = image_result['image_path']
            
            # è·å–é…éŸ³æ—¶é•¿ï¼ˆä¼˜å…ˆçº§ï¼šå®é™…éŸ³é¢‘æ—¶é•¿ > JSON duration_sec > é»˜è®¤å€¼ï¼‰
            fps = scene.get('target_fps', 24) or 24
            duration_sec = None
            
            if scene_id in audio_durations:
                duration_sec = audio_durations[scene_id]
                print(f"  â„¹ ä½¿ç”¨å®é™…é…éŸ³æ—¶é•¿: {duration_sec:.3f}ç§’")
            elif scene.get('duration_sec'):
                duration_sec = scene.get('duration_sec')
                print(f"  â„¹ ä½¿ç”¨ JSON ä¸­çš„ duration_sec: {duration_sec}ç§’")
            else:
                print(f"  âš  æœªæ‰¾åˆ°é…éŸ³æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            # è®¡ç®—å¸§æ•°
            if duration_sec:
                calculated_frames = int(duration_sec * fps)
                if quick_mode:
                    num_frames = max(24, min(calculated_frames, 60))
                else:
                    num_frames = calculated_frames
                print(f"  â„¹ è®¡ç®—å¸§æ•°: {duration_sec:.3f}ç§’ Ã— {fps}fps = {num_frames}å¸§")
            else:
                num_frames = 24 if quick_mode else scene.get('num_frames', 120)
                print(f"  âš  ä½¿ç”¨é»˜è®¤å¸§æ•°: {num_frames}å¸§")
            
            # æå–åœºæ™¯å‚æ•°
            character = scene.get('character', {})
            character_present = character.get('present', False)
            character_id = character.get('id') if character_present else None
            
            camera = scene.get('camera', {})
            shot_type = camera.get('shot', 'medium')
            
            quality_target = scene.get('quality_target', {})
            motion_intensity = quality_target.get('motion_intensity', 'moderate')
            
            width = scene.get('width', 768)
            height = scene.get('height', 1152)
            
            scene_output_dir = output_dir / f"scene_{scene_id:03d}"
            
            # ç”Ÿæˆè§†é¢‘ï¼ˆå¸¦é‡è¯•ï¼‰
            result = None
            for retry in range(max_retries + 1):
                if retry > 0:
                    print(f"  ğŸ”„ é‡è¯• {retry}/{max_retries}...")
                
                try:
                    # âš¡ å…³é”®ä¿®å¤ï¼šåœ¨è§†é¢‘ç”Ÿæˆå‰ï¼Œæ¸…ç†å›¾ç‰‡ç”Ÿæˆå™¨ç•™ä¸‹çš„æ¨¡å‹ï¼ˆSDXL pipelineï¼‰
                    # é¿å…æ˜¾å­˜ç¢ç‰‡åŒ–å¯¼è‡´ HunyuanVideo åŠ è½½å¤±è´¥
                    if hasattr(self.generator, 'image_generator') and self.generator.image_generator is not None:
                        print("  ğŸ”§ æ¸…ç†å›¾ç‰‡ç”Ÿæˆå™¨æ¨¡å‹ä»¥é‡Šæ”¾æ˜¾å­˜...")
                        try:
                            # æ¸…ç† SDXL pipeline
                            if hasattr(self.generator.image_generator, 'pipeline') and self.generator.image_generator.pipeline is not None:
                                try:
                                    self.generator.image_generator.pipeline.to("cpu")
                                    del self.generator.image_generator.pipeline
                                    self.generator.image_generator.pipeline = None
                                except:
                                    pass
                            if hasattr(self.generator.image_generator, 'sdxl_pipeline') and self.generator.image_generator.sdxl_pipeline is not None:
                                try:
                                    self.generator.image_generator.sdxl_pipeline.to("cpu")
                                    del self.generator.image_generator.sdxl_pipeline
                                    self.generator.image_generator.sdxl_pipeline = None
                                except:
                                    pass
                            # æ¸…ç†å¢å¼ºç”Ÿæˆå™¨
                            if hasattr(self.generator.image_generator, 'enhanced_generator') and self.generator.image_generator.enhanced_generator is not None:
                                try:
                                    if hasattr(self.generator.image_generator.enhanced_generator, '_unload_all_models'):
                                        self.generator.image_generator.enhanced_generator._unload_all_models()
                                except:
                                    pass
                            # æ¸…ç† GPU ç¼“å­˜
                            if TORCH_AVAILABLE:
                                # âš¡ å…³é”®ä¿®å¤ï¼štorch å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œä¸éœ€è¦å†æ¬¡å¯¼å…¥
                                # å¦‚æœ TORCH_AVAILABLE ä¸º Trueï¼Œtorch å·²ç»å…¨å±€å¯ç”¨
                                for _ in range(3):
                                    torch.cuda.empty_cache()
                                    gc.collect()
                            print("  âœ“ å›¾ç‰‡ç”Ÿæˆå™¨æ¨¡å‹å·²æ¸…ç†")
                        except Exception as e:
                            print(f"  âš  æ¸…ç†å›¾ç‰‡ç”Ÿæˆå™¨æ¨¡å‹æ—¶å‡ºé”™: {e}")
                    
                    # é˜¶æ®µ3ï¼šä½¿ç”¨å·²ç”Ÿæˆçš„å›¾ç‰‡ç”Ÿæˆè§†é¢‘
                    # ä¼ å…¥å·²ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„ï¼Œé¿å…é‡æ–°ç”Ÿæˆ
                    video_output_path = scene_output_dir / "novel_video.mp4"
                    
                    # æ„å»ºè§†é¢‘åœºæ™¯å‚æ•°
                    video_scene = scene.copy() if scene else {}
                    video_scene['width'] = width
                    video_scene['height'] = height
                    video_scene['motion_intensity'] = motion_intensity
                    
                    # ä½¿ç”¨è§†é¢‘ç”Ÿæˆå™¨ç›´æ¥ç”Ÿæˆè§†é¢‘ï¼ˆå›¾ç‰‡å·²å­˜åœ¨ï¼‰
                    if character_present and enable_m6:
                        # ä½¿ç”¨ M6 è§†é¢‘ç”Ÿæˆå™¨
                        if self.generator._m6_video_generator is None:
                            from enhanced_video_generator_m6 import EnhancedVideoGeneratorM6
                            self.generator._m6_video_generator = EnhancedVideoGeneratorM6(str(self.generator.config_path))
                        
                        # æŸ¥æ‰¾å‚è€ƒå›¾
                        reference_image = None
                        if character_id == 'hanli':
                            ref_candidates = [
                                project_root / "reference_image" / "hanli_mid.jpg",
                                project_root / "reference_image" / "hanli_mid.png",
                            ]
                            for ref_candidate in ref_candidates:
                                if ref_candidate.exists():
                                    reference_image = str(ref_candidate)
                                    break
                        
                        if not reference_image:
                            reference_image = image_path  # ä½¿ç”¨ç”Ÿæˆçš„å›¾ç‰‡ä½œä¸ºå‚è€ƒ
                        
                        # ä»é…ç½®ä¸­è·å– M6 æœ€å¤§é‡è¯•æ¬¡æ•°
                        m6_max_retries_config = self.config.get('identity_verification', {}).get('max_retries', 3)
                        # âš¡ å…³é”®ä¿®å¤ï¼šç¡®ä¿ image_path æ˜¯å­—ç¬¦ä¸²ç±»å‹
                        image_path_str = str(image_path) if image_path else None
                        video_path, m6_result = self.generator._m6_video_generator.generate_video_with_identity_check(
                            image_path=image_path_str,
                            output_path=str(video_output_path),
                            reference_image=reference_image,
                            scene=video_scene,
                            shot_type=shot_type,
                            enable_verification=True,
                            max_retries=m6_max_retries_config,
                            num_frames=num_frames,
                            fps=fps,
                        )
                    else:
                        # ä½¿ç”¨æ™®é€šè§†é¢‘ç”Ÿæˆå™¨
                        # âš¡ å…³é”®ä¿®å¤ï¼šç¡®ä¿ image_path æ˜¯å­—ç¬¦ä¸²ç±»å‹
                        image_path_str = str(image_path) if image_path else None
                        video_path = self.generator.video_generator.generate_video(
                            image_path=image_path_str,
                            output_path=str(video_output_path),
                            num_frames=num_frames,
                            fps=fps,
                            scene=video_scene,
                        )
                    
                    # æ£€æŸ¥è§†é¢‘æ˜¯å¦ç”ŸæˆæˆåŠŸ
                    if video_path and Path(video_path).exists():
                        print(f"  âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_path}")
                        result = {
                            'scene_id': scene_id,
                            'scene_index': scene_index,
                            'status': 'success',
                            'image': str(image_path) if image_path else None,  # âš¡ ä¿®å¤ï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            'video': str(video_path) if video_path else None,  # âš¡ ä¿®å¤ï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            'audio_duration': duration_sec,
                            'num_frames': num_frames,
                        }
                        break  # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                    else:
                        print(f"  âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼šæ–‡ä»¶ä¸å­˜åœ¨")
                        result = {
                            'scene_id': scene_id,
                            'scene_index': scene_index,
                            'status': 'error',
                            'error': 'è§†é¢‘æ–‡ä»¶æœªç”Ÿæˆ'
                        }
                except Exception as e:
                    print(f"  âŒ è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
                    traceback.print_exc()
                    result = {
                        'scene_id': scene_id,
                        'scene_index': scene_index,
                        'status': 'error',
                        'error': str(e)
                    }
            
            results.append(result)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            if (i + 1) % 5 == 0:
                self._save_progress(output_dir, results, scenes)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_progress(output_dir, results, scenes)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(results, output_dir)
        
        return {
            'results': results,
            'report': report,
        }
    
    def _save_progress(self, output_dir: Path, results: List[Dict], scenes: List[Dict]):
        """ä¿å­˜è¿›åº¦"""
        progress_file = output_dir / "progress.json"
        
        # âš¡ å…³é”®ä¿®å¤ï¼šå°† results ä¸­çš„ PosixPath è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        def convert_paths(obj):
            """é€’å½’è½¬æ¢ PosixPath ä¸ºå­—ç¬¦ä¸²"""
            if isinstance(obj, Path):
                return str(obj)
            elif isinstance(obj, dict):
                return {k: convert_paths(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_paths(item) for item in obj]
            else:
                return obj
        
        serializable_results = convert_paths(results)
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'total_scenes': len(scenes),
                'completed': len(results),
                'results': serializable_results,
            }, f, ensure_ascii=False, indent=2)
    
    def _generate_report(self, results: List[Dict], output_dir: Path) -> Dict[str, Any]:
        """ç”ŸæˆæŠ¥å‘Š"""
        total = len(results)
        success = sum(1 for r in results if r['status'] == 'success')
        errors = sum(1 for r in results if r['status'] == 'error')
        
        success_rate = (success / total * 100) if total > 0 else 0
        
        # ç»Ÿè®¡é”™è¯¯
        error_details = []
        for r in results:
            if r['status'] == 'error':
                error_details.append({
                    'scene_id': r.get('scene_id', 'unknown'),
                    'prompt': r.get('prompt', 'N/A')[:50] + '...' if r.get('prompt') else 'N/A',
                    'error': r['error'],
                })
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total': total,
                'success': success,
                'errors': errors,
                'success_rate': f"{success_rate:.1f}%",
            },
            'errors': error_details,
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = output_dir / "batch_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        md_report = self._generate_markdown_report(report, results)
        md_file = output_dir / "batch_report.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_report)
        
        print(f"\n{'='*60}")
        print("æ‰¹é‡ç”Ÿæˆå®Œæˆ")
        print(f"{'='*60}")
        print(f"æ€»è®¡: {total}")
        print(f"æˆåŠŸ: {success} ({success_rate:.1f}%)")
        print(f"å¤±è´¥: {errors}")
        print(f"\næŠ¥å‘Šå·²ä¿å­˜:")
        print(f"  JSON: {report_file}")
        print(f"  Markdown: {md_file}")
        
        return report
    
    def _generate_markdown_report(self, report: Dict, results: List[Dict]) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        md = f"""# å°è¯´æ¨æ–‡æ‰¹é‡ç”ŸæˆæŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {report['timestamp']}

## æ‘˜è¦

- **æ€»è®¡**: {report['summary']['total']} ä¸ªåœºæ™¯
- **æˆåŠŸ**: {report['summary']['success']} ä¸ª
- **å¤±è´¥**: {report['summary']['errors']} ä¸ª
- **æˆåŠŸç‡**: {report['summary']['success_rate']}

## å¤±è´¥åœºæ™¯è¯¦æƒ…

"""
        if report['errors']:
            for error in report['errors']:
                md += f"### åœºæ™¯ {error['scene_id']}\n\n"
                md += f"- **æç¤ºè¯**: {error['prompt']}\n"
                md += f"- **é”™è¯¯**: {error['error']}\n\n"
        else:
            md += "æ— å¤±è´¥åœºæ™¯ âœ…\n"
        
        md += "\n## æˆåŠŸåœºæ™¯åˆ—è¡¨\n\n"
        for r in results:
            if r['status'] == 'success':
                md += f"- åœºæ™¯ {r['scene_id']}: {r['prompt'][:50]}...\n"
        
        return md


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å°è¯´æ¨æ–‡æ‰¹é‡ç”Ÿæˆå·¥å…·")
    parser.add_argument(
        '--json',
        type=str,
        required=True,
        help='JSON åœºæ™¯æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: outputs/batch_novel_<timestamp>ï¼‰'
    )
    parser.add_argument(
        '--enable-m6',
        action='store_true',
        default=True,
        help='å¯ç”¨ M6 èº«ä»½éªŒè¯ï¼ˆé»˜è®¤: å¯ç”¨ï¼‰'
    )
    parser.add_argument(
        '--disable-m6',
        action='store_true',
        help='ç¦ç”¨ M6 èº«ä»½éªŒè¯'
    )
    parser.add_argument(
        '--quick',
        action='store_true',
        help='å¿«é€Ÿæ¨¡å¼ï¼ˆå‡å°‘å¸§æ•°ï¼Œç”¨äºæµ‹è¯•ï¼‰'
    )
    parser.add_argument(
        '--start',
        type=int,
        default=0,
        help='å¼€å§‹ç´¢å¼•ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰'
    )
    parser.add_argument(
        '--end',
        type=int,
        default=None,
        help='ç»“æŸç´¢å¼•ï¼ˆç”¨äºåˆ†æ‰¹å¤„ç†ï¼‰'
    )
    parser.add_argument(
        '--max-retries',
        type=int,
        default=2,
        help='æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤: 2ï¼‰'
    )
    
    args = parser.parse_args()
    
    # è§£æè·¯å¾„
    # å¦‚æœæ˜¯åœ¨ gen_video ç›®å½•ä¸‹æ‰§è¡Œï¼Œç›¸å¯¹è·¯å¾„åº”è¯¥ç›¸å¯¹äº gen_video ç›®å½•
    json_path_str = args.json
    json_path = Path(json_path_str)
    
    if not json_path.is_absolute():
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        # å¦‚æœè·¯å¾„ä»¥ ../ å¼€å¤´ï¼Œä» gen_video ç›®å½•å‘ä¸ŠæŸ¥æ‰¾
        # å¦åˆ™ï¼Œç›¸å¯¹äº gen_video ç›®å½•
        if json_path_str.startswith('../'):
            # å»æ‰ ../ å‰ç¼€ï¼Œç„¶åä» fanren ç›®å½•å¼€å§‹
            relative_path = json_path_str[3:]  # å»æ‰ '../'
            json_path = project_root.parent / relative_path
        else:
            # ç›¸å¯¹äº gen_video ç›®å½•
            json_path = project_root / json_path
        
        # è§„èŒƒåŒ–è·¯å¾„ï¼ˆå¤„ç† .. å’Œ .ï¼‰
        json_path = json_path.resolve()
    
    # è§£æè¾“å‡ºç›®å½•è·¯å¾„
    if args.output_dir:
        output_dir_str = args.output_dir
        output_dir = Path(output_dir_str)
        if not output_dir.is_absolute():
            # å¤„ç†ç›¸å¯¹è·¯å¾„
            if output_dir_str.startswith('../'):
                # å»æ‰ ../ å‰ç¼€ï¼Œç„¶åä» fanren ç›®å½•å¼€å§‹
                relative_path = output_dir_str[3:]  # å»æ‰ '../'
                output_dir = project_root.parent / relative_path
            else:
                # ç›¸å¯¹äº gen_video ç›®å½•
                output_dir = project_root / output_dir
            output_dir = output_dir.resolve()
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = project_root / "outputs" / f"batch_novel_{timestamp}"
    
    # M6 è®¾ç½®
    enable_m6 = args.enable_m6 and not args.disable_m6
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = BatchNovelGenerator()
    
    # æ‰¹é‡ç”Ÿæˆ
    result = generator.generate_batch(
        json_path=json_path,
        output_dir=output_dir,
        enable_m6=enable_m6,
        quick_mode=args.quick,
        max_retries=args.max_retries,
        start_index=args.start,
        end_index=args.end,
    )
    
    # è¿”å›çŠ¶æ€ç 
    success_count = result['report']['summary']['success']
    total_count = result['report']['summary']['total']
    
    if success_count == total_count:
        return 0
    else:
        return 1


if __name__ == "__main__":
    sys.exit(main())


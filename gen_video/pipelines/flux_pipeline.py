#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Flux Pipelineï¼ˆFlux.1 å’Œ Flux.2ï¼‰
æ ‡å‡† diffusers æ ¼å¼
"""

import torch
from diffusers import DiffusionPipeline
from PIL import Image
from typing import Optional
from .base_pipeline import BasePipeline


class FluxPipeline(BasePipeline):
    """Flux Pipelineï¼ˆæ”¯æŒ Flux.1 å’Œ Flux.2ï¼‰"""
    
    def __init__(self, model_path: str, device: Optional[str] = None, model_type: str = "flux2"):
        """
        åˆå§‹åŒ– Flux Pipeline
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡
            model_type: æ¨¡å‹ç±»å‹ ("flux1" æˆ– "flux2")
        """
        super().__init__(model_path, device)
        self.model_type = model_type
        self.loaded = False
    
    def load(self) -> None:
        """åŠ è½½ Flux æ¨¡å‹"""
        if self.loaded and self.pipe is not None:
            return
        
        print(f"åŠ è½½ Flux ({self.model_type}) æ¨¡å‹: {self.model_path}")
        
        self.pipe = DiffusionPipeline.from_pretrained(
            self.model_path,
            torch_dtype=torch.float16,
            device_map="balanced"
        )
        
        self.loaded = True
        print(f"âœ… Flux ({self.model_type}) æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def generate(
        self,
        prompt: str,
        negative_prompt: Optional[str] = None,
        width: int = 1024,
        height: int = 1024,
        num_inference_steps: int = 18,
        guidance_scale: float = 3.5,
        seed: Optional[int] = None,
        lora_path: Optional[str] = None,
        lora_alpha: float = 1.0,
        **kwargs
    ) -> Image.Image:
        """
        ç”Ÿæˆå›¾åƒ
        
        Args:
            prompt: æç¤ºè¯
            negative_prompt: è´Ÿé¢æç¤ºè¯
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            num_inference_steps: æ¨ç†æ­¥æ•°
            guidance_scale: å¼•å¯¼å¼ºåº¦
            seed: éšæœºç§å­
            lora_path: LoRA æƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            lora_alpha: LoRA æƒé‡ï¼ˆ0.0-1.0ï¼Œé»˜è®¤ 1.0ï¼‰
            **kwargs: å…¶ä»–å‚æ•°
        """
        if not self.loaded:
            self.load()
        
        # åŠ è½½ LoRAï¼ˆå¦‚æœæä¾›ï¼‰
        if lora_path:
            from pathlib import Path
            from safetensors import safe_open
            import torch
            
            lora_path_obj = Path(lora_path)
            if lora_path_obj.exists():
                try:
                    # ç›´æ¥å¤„ç† PEFT æ ¼å¼çš„ LoRAï¼ˆè·³è¿‡ diffusers çš„è‡ªåŠ¨è½¬æ¢ï¼Œé¿å…è¯¯åˆ¤ä¸º FAL/Kontext æ ¼å¼ï¼‰
                    print(f"  ğŸ”§ åŠ è½½ PEFT æ ¼å¼ LoRA: {lora_path_obj.name}")
                    
                    # è¯»å– LoRA æƒé‡å¹¶è½¬æ¢é”®åï¼ˆPEFT æ ¼å¼ â†’ diffusers æ ¼å¼ï¼‰
                    lora_state_dict = {}
                    with safe_open(str(lora_path_obj), framework="pt") as f:
                        for key in f.keys():
                            new_key = key
                            # æ­¥éª¤ 1ï¼šç§»é™¤ base_model.model. å‰ç¼€ï¼ˆPEFT æ ¼å¼ï¼‰
                            if key.startswith("base_model.model."):
                                new_key = key.replace("base_model.model.", "")
                            
                            # æ­¥éª¤ 2ï¼šå°† single_transformer_blocks æ›¿æ¢ä¸º transformer_blocks
                            # LoRA: single_transformer_blocks.0.attn.to_k.lora_A.default.weight
                            # Flux: transformer_blocks.0.attn.to_k.weight
                            if "single_transformer_blocks" in new_key:
                                new_key = new_key.replace("single_transformer_blocks", "transformer_blocks")
                            
                            # æ­¥éª¤ 3ï¼šç§»é™¤ .default éƒ¨åˆ†ï¼ˆPEFT æ ¼å¼ï¼‰
                            if ".default." in new_key:
                                new_key = new_key.replace(".default.", ".")
                            
                            # æ­¥éª¤ 4ï¼šæ·»åŠ  transformer. å‰ç¼€ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼Œä¸”æ˜¯ transformer_blocks ç›¸å…³çš„é”®ï¼‰
                            # diffusers çš„ load_lora_weights æœŸæœ›é”®åæ ¼å¼ä¸º transformer.transformer_blocks...
                            # è¿™æ ·å¯ä»¥æ­£ç¡®åŒ¹é…åˆ° FluxTransformer2DModel
                            if "transformer_blocks" in new_key and not new_key.startswith("transformer."):
                                new_key = f"transformer.{new_key}"
                            
                            lora_state_dict[new_key] = f.get_tensor(key)
                    
                    # ä¿å­˜è½¬æ¢åçš„æƒé‡åˆ°ä¸´æ—¶æ–‡ä»¶
                    import tempfile
                    import os
                    with tempfile.NamedTemporaryFile(suffix=".safetensors", delete=False) as tmp_file:
                        from safetensors.torch import save_file
                        save_file(lora_state_dict, tmp_file.name)
                        tmp_path = tmp_file.name
                    
                    try:
                        # æ–¹æ³• 1ï¼šä½¿ç”¨ load_lora_weights åŠ è½½è½¬æ¢åçš„æƒé‡ï¼ŒæŒ‡å®š prefix=None ä»¥é¿å…è­¦å‘Š
                        try:
                            # æŒ‡å®š prefix=None è®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹æ­£ç¡®çš„é”®åæ ¼å¼
                            self.pipe.load_lora_weights(tmp_path, adapter_name="character_lora", weight_name=None)
                            self.pipe.set_adapters(["character_lora"], adapter_weights=[lora_alpha])
                            print(f"  âœ… å·²åŠ è½½ LoRA: {lora_path_obj.name} (alpha={lora_alpha})")
                        except Exception as e2:
                            # æ–¹æ³• 2ï¼šå¦‚æœæ–¹æ³• 1 å¤±è´¥ï¼Œå°è¯•ä¸æŒ‡å®š adapter_name
                            print(f"  âš  æ–¹æ³• 1 å¤±è´¥ï¼Œå°è¯•æ–¹æ³• 2: {e2}")
                            self.pipe.load_lora_weights(tmp_path)
                            # è·å–åŠ è½½çš„ adapter åç§°
                            adapters = list(self.pipe.get_active_adapters()) if hasattr(self.pipe, 'get_active_adapters') else []
                            if adapters:
                                self.pipe.set_adapters(adapters, adapter_weights=[lora_alpha])
                            print(f"  âœ… å·²åŠ è½½ LoRA (æ–¹æ³•2): {lora_path_obj.name} (alpha={lora_alpha})")
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(tmp_path):
                            os.unlink(tmp_path)
                        
                except Exception as e:
                    print(f"  âš  LoRA åŠ è½½å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"  âš  LoRA æ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")
        
        # éªŒè¯ LoRA æ˜¯å¦å·²æ¿€æ´»ï¼ˆå¦‚æœåŠ è½½äº† LoRAï¼‰
        if lora_path and hasattr(self.pipe, 'get_active_adapters'):
            active_adapters = self.pipe.get_active_adapters()
            if active_adapters:
                print(f"  âœ… LoRA å·²æ¿€æ´»: {active_adapters}, æƒé‡: {lora_alpha}")
            else:
                print(f"  âš  LoRA å·²åŠ è½½ä½†æœªæ¿€æ´»ï¼Œå°è¯•é‡æ–°æ¿€æ´»...")
                # å°è¯•é‡æ–°æ¿€æ´»
                try:
                    self.pipe.set_adapters(["character_lora"], adapter_weights=[lora_alpha])
                    print(f"  âœ… LoRA å·²é‡æ–°æ¿€æ´»ï¼Œæƒé‡: {lora_alpha}")
                except Exception as e:
                    print(f"  âš  LoRA æ¿€æ´»å¤±è´¥: {e}")
        
        generator = None
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        
        # æ‰“å°æœ€ç»ˆä½¿ç”¨çš„æç¤ºè¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if lora_path:
            print(f"  ğŸ” ç”Ÿæˆå‚æ•°: prompté•¿åº¦={len(prompt)}, LoRAæƒé‡={lora_alpha}, steps={num_inference_steps}, guidance={guidance_scale}")
        
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=generator,
            **kwargs
        )
        
        return result.images[0]


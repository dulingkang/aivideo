"""
Promptæ„å»ºå™¨

è´Ÿè´£æ ¹æ®åœºæ™¯æ•°æ®æ„å»ºå®Œæ•´çš„Promptï¼Œè¿™æ˜¯Promptæ¨¡å—çš„æ ¸å¿ƒç»„ä»¶ã€‚
"""

from typing import Dict, Any, List, Optional
from pathlib import Path
from .token_estimator import TokenEstimator
from .parser import PromptParser
from .optimizer import PromptOptimizer


class PromptBuilder:
    """Promptæ„å»ºå™¨"""
    
    def __init__(
        self,
        token_estimator: TokenEstimator,
        parser: PromptParser,
        optimizer: PromptOptimizer,
        intent_analyzer: Any,  # SceneIntentAnalyzer
        character_profiles: Dict[str, Any],
        scene_profiles: Dict[str, Any],
        ascii_only_prompt: bool = False,
        identify_characters_fn: Any = None,  # è§’è‰²è¯†åˆ«å‡½æ•°
        needs_character_fn: Any = None,  # åˆ¤æ–­æ˜¯å¦éœ€è¦è§’è‰²å‡½æ•°
        clip_tokenizer: Any = None,  # CLIP tokenizerï¼ˆå¯é€‰ï¼‰
    ):
        """
        åˆå§‹åŒ–Promptæ„å»ºå™¨
        
        Args:
            token_estimator: Tokenä¼°ç®—å™¨
            parser: Promptè§£æå™¨
            optimizer: Promptä¼˜åŒ–å™¨
            intent_analyzer: åœºæ™¯æ„å›¾åˆ†æå™¨
            character_profiles: è§’è‰²é…ç½®å­—å…¸
            scene_profiles: åœºæ™¯é…ç½®å­—å…¸
            ascii_only_prompt: æ˜¯å¦åªä½¿ç”¨ASCIIå­—ç¬¦
            identify_characters_fn: è§’è‰²è¯†åˆ«å‡½æ•°ï¼ˆä»ImageGeneratoræ³¨å…¥ï¼‰
            needs_character_fn: åˆ¤æ–­æ˜¯å¦éœ€è¦è§’è‰²å‡½æ•°ï¼ˆä»ImageGeneratoræ³¨å…¥ï¼‰
            clip_tokenizer: CLIP tokenizerï¼ˆå¯é€‰ï¼Œç”¨äºå‡†ç¡®è®¡ç®—tokenæ•°ï¼‰
        """
        self.token_estimator = token_estimator
        self.parser = parser
        self.optimizer = optimizer
        self.intent_analyzer = intent_analyzer
        self.character_profiles = character_profiles
        self.scene_profiles = scene_profiles
        self.ascii_only_prompt = ascii_only_prompt
        self._identify_characters = identify_characters_fn
        self._needs_character = needs_character_fn
        self._clip_tokenizer = clip_tokenizer
    
    def build(
        self,
        scene: Dict[str, Any],
        include_character: Optional[bool] = None,
        script_data: Dict[str, Any] = None,
        previous_scene: Optional[Dict[str, Any]] = None,
        use_semantic_prompt: Optional[bool] = None,  # âš¡ æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨è¯­ä¹‰åŒ– promptï¼ˆFLUX ä¸“ç”¨ï¼‰
    ) -> str:
        """
        æ ¹æ®åœºæ™¯æ•°æ®æ„å»º prompt
        
        é€šç”¨ç‰ˆæœ¬ï¼šåŸºäºåœºæ™¯æ„å›¾åˆ†æï¼Œæ™ºèƒ½æ„å»ºPromptï¼Œä¸ä¾èµ–ç‰¹æ®Šè§„åˆ™ã€‚
        
        Args:
            scene: åœºæ™¯æ•°æ®å­—å…¸
            include_character: æ˜¯å¦åŒ…å«ä¸»è§’æè¿°ã€‚None æ—¶è‡ªåŠ¨åˆ¤æ–­
            script_data: è„šæœ¬æ•°æ®ï¼ˆç”¨äºåœºæ™¯æ¨¡æ¿åŒ¹é…ï¼‰
            previous_scene: å‰ä¸€ä¸ªåœºæ™¯ï¼ˆç”¨äºè¿è´¯æ€§ï¼‰
            
        Returns:
            æ„å»ºå¥½çš„promptå­—ç¬¦ä¸²
        """
        # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•éå¸¸å¤æ‚ï¼ˆçº¦1500è¡Œï¼‰ï¼Œéœ€è¦ä» ImageGenerator.build_prompt ä¸­å®Œæ•´æå–
        # ä¸ºäº†ä¿æŒä»£ç å®Œæ•´æ€§ï¼Œè¿™é‡Œå…ˆåˆ›å»ºä¸€ä¸ªå ä½å®ç°
        # å®é™…å®ç°éœ€è¦é€æ­¥è¿ç§»
        
        # TODO: å®Œæ•´è¿ç§» build_prompt æ–¹æ³•çš„æ‰€æœ‰é€»è¾‘
        # è¿™æ˜¯ä¸€ä¸ªå¤§å·¥ç¨‹ï¼Œéœ€è¦ä»”ç»†æå–ä»¥ä¸‹éƒ¨åˆ†ï¼š
        # 1. åœºæ™¯æ„å›¾åˆ†æ
        # 2. è§’è‰²å¤„ç†é€»è¾‘
        # 3. æ— äººç‰©åœºæ™¯å¤„ç†
        # 4. Promptä¼˜åŒ–å’Œtokenç®¡ç†
        # 5. ä¸­è‹±æ–‡ç¿»è¯‘
        
        # ========== ç¬¬ä¸€æ­¥ï¼šåœºæ™¯æ„å›¾åˆ†æï¼ˆé€šç”¨åˆ†æï¼Œä¸ä¾èµ–ç‰¹æ®Šè§„åˆ™ï¼‰==========
        intent = self.intent_analyzer.analyze(scene)
        
        print(f"  â„¹ åœºæ™¯æ„å›¾åˆ†æ:")
        if intent['primary_entity']:
            print(f"    - ä¸»è¦å®ä½“: {intent['primary_entity']['type']} (æƒé‡: {intent['primary_entity'].get('weight', 1.5)})")
        else:
            print(f"    - ä¸»è¦å®ä½“: None")
        print(f"    - åŠ¨ä½œç±»å‹: {intent['action_type']}")
        print(f"    - è§†è§’: {intent['viewpoint']['type']} (æƒé‡: {intent['viewpoint']['weight']})")
        if intent['emphasis']:
            print(f"    - å¼ºè°ƒé¡¹: {', '.join(intent['emphasis'][:3])}")
        if intent['exclusions']:
            print(f"    - æ’é™¤é¡¹: {', '.join(intent['exclusions'])}")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šFLUX ä¸“ç”¨è¯­ä¹‰åŒ– prompt æ„å»ºï¼ˆwide + top_down + lying åœºæ™¯ï¼‰
        # âš¡ é‡è¦ï¼šFLUX ä½¿ç”¨ T5 tokenizerï¼Œæ”¯æŒ 512+ tokensï¼Œä¸éœ€è¦ 77 token é™åˆ¶
        if use_semantic_prompt:
            # FLUX ä¸éœ€è¦ token é™åˆ¶ï¼Œç›´æ¥è¿”å›å®Œæ•´è¯­ä¹‰åŒ– prompt
            return self._build_semantic_prompt_for_flux(scene, intent)
        
        # æ ¹æ®æ„å›¾åˆ†æç»“æœåˆ¤æ–­æ˜¯å¦éœ€è¦è§’è‰²
        # âš¡ v2 æ ¼å¼æ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨ character.present å­—æ®µ
        character = scene.get("character", {}) or {}
        character_present_v2 = character.get("present", False)
        
        if include_character is None:
            # ä¼˜å…ˆä½¿ç”¨ v2 æ ¼å¼çš„ character.present å­—æ®µ
            if character_present_v2:
                include_character = True
                print(f"  â„¹ v2 æ ¼å¼ï¼šcharacter.present=trueï¼Œéœ€è¦è§’è‰²")
            # å¦‚æœä¸»è¦å®ä½“æ˜¯è§’è‰²ï¼Œåˆ™éœ€è¦è§’è‰²
            elif intent['primary_entity'] and intent['primary_entity'].get('type') == 'character':
                include_character = True
            else:
                include_character = False
                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯"äººç‰©è§‚å¯Ÿç¯å¢ƒ/ç‰©ä½“"çš„åœºæ™¯ï¼Œæ˜ç¡®æ’é™¤äººç‰©
                # æ£€æµ‹è§‚å¯Ÿå…³é”®è¯ï¼ˆsees, revealing, showingç­‰ï¼‰
                all_text_lower = " ".join([
                    str(scene.get("description", "")),
                    str(scene.get("prompt", "")),
                    str(scene.get("visual", {}).get("composition", "") if isinstance(scene.get("visual"), dict) else "")
                ]).lower()
                observation_keywords = ["sees", "revealing", "showing", "åªè§", "æ˜ å…¥çœ¼å¸˜", "å±•ç°"]
                has_observation = any(kw in all_text_lower for kw in observation_keywords)
                if has_observation and intent['primary_entity'] and intent['primary_entity'].get('type') != 'character':
                    print(f"  â„¹ æ£€æµ‹åˆ°è§‚å¯Ÿåœºæ™¯ï¼ˆäººç‰©è§‚å¯Ÿ{intent['primary_entity'].get('type')}ï¼‰ï¼Œæ’é™¤äººç‰©ï¼Œä»¥{intent['primary_entity'].get('type')}ä¸ºä¸»")
        
        # ä½¿ç”¨ä¼˜å…ˆçº§åˆ—è¡¨ï¼Œç¡®ä¿å…³é”®ä¿¡æ¯åœ¨å‰
        priority_parts: List[str] = []  # é«˜ä¼˜å…ˆçº§ï¼ˆå‰ 77 tokensï¼‰
        secondary_parts: List[str] = []  # æ¬¡è¦ä¿¡æ¯ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰
        
        raw_prompt = scene.get("prompt") or ""
        used_prompt_as_camera = False
        
        # å…ˆç¡®å®šé•œå¤´ç±»å‹ï¼ˆç”¨äºåç»­åˆ¤æ–­ï¼‰
        camera_desc = scene.get("camera") or ""
        
        # å¤„ç† v2 æ ¼å¼ï¼šå¦‚æœ camera æ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(camera_desc, dict):
            camera_desc = self._convert_camera_v2_to_string(camera_desc)
        
        if not camera_desc and raw_prompt and self._looks_like_camera_prompt(raw_prompt):
            camera_desc = raw_prompt
            used_prompt_as_camera = True
        
        shot_type_for_prompt = {
            "is_wide": False,
            "is_medium": False,
            "is_close": False,
            "is_full_body": False,
            "is_eye_closeup": False,  # çœ¼ç›ç‰¹å†™æ ‡è®°
            "is_face_closeup": False,  # é¢éƒ¨ç‰¹å†™æ ‡è®°
        }
        
        if camera_desc:
            # ç¡®ä¿ camera_desc æ˜¯å­—ç¬¦ä¸²
            if not isinstance(camera_desc, str):
                camera_desc = str(camera_desc)
            lowered = camera_desc.lower()
            if any(kw in lowered for kw in ["wide", "long", "é æ™¯", "è¿œæ™¯", "å…¨æ™¯"]):
                shot_type_for_prompt["is_wide"] = True
            if any(kw in lowered for kw in ["medium", "mid", "ä¸­æ™¯"]):
                shot_type_for_prompt["is_medium"] = True
            if any(kw in lowered for kw in ["close", "closeup", "portrait", "headshot", "ç‰¹å†™", "è¿‘æ™¯"]):
                # æ£€æŸ¥æ˜¯å¦æ˜¯çœ¼ç›ç‰¹å†™æˆ–é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼ˆéœ€è¦ä¿æŒç‰¹å†™ï¼‰
                is_eye_closeup = any(kw in lowered for kw in ['eye', 'eyes', 'pupil', 'pupils', 'çœ¼ç›', 'ç³å­”', 'extreme close'])
                is_face_closeup = any(kw in lowered for kw in ['face', 'facial', 'portrait', 'headshot', 'é¢éƒ¨', 'è„¸éƒ¨', 'å¤´åƒ', 'close-up on face', 'closeup on face'])
                if is_eye_closeup:
                    # çœ¼ç›ç‰¹å†™åœºæ™¯ï¼šä¿æŒç‰¹å†™æ ‡è®°
                    shot_type_for_prompt["is_close"] = True
                    shot_type_for_prompt["is_eye_closeup"] = True  # æ·»åŠ çœ¼ç›ç‰¹å†™æ ‡è®°
                elif is_face_closeup:
                    # é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼šä¿æŒç‰¹å†™æ ‡è®°ï¼Œä¸è½¬æ¢ä¸ºä¸­æ™¯
                    shot_type_for_prompt["is_close"] = True
                    shot_type_for_prompt["is_face_closeup"] = True  # æ·»åŠ é¢éƒ¨ç‰¹å†™æ ‡è®°
                else:
                    # å…¶ä»–ç‰¹å†™åœºæ™¯ï¼šæ ‡è®°ä¸ºç‰¹å†™ï¼Œä½†åç»­ä¼šè½¬æ¢ä¸ºä¸­æ™¯
                    shot_type_for_prompt["is_close"] = True
            if any(kw in lowered for kw in ["full", "å…¨èº«"]):
                shot_type_for_prompt["is_full_body"] = True
        
        # ========== ç¬¬ä¸€éƒ¨åˆ†ï¼šé£æ ¼æ ‡ç­¾ï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹å†³å®šï¼‰==========
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç§‘æ™®è§†é¢‘ï¼ˆé€šè¿‡ script_data æˆ– scene ä¸­çš„ category åˆ¤æ–­ï¼‰
        is_kepu_video = False
        
        # æ–¹æ³•1: é€šè¿‡ script_data åˆ¤æ–­
        if script_data:
            category = script_data.get('category', '')
            topic = script_data.get('topic', '')
            # æ£€æŸ¥ category æ˜¯å¦æ˜¯ç§‘æ™®ç±»åˆ«
            if category and category in ['universe', 'quantum', 'earth', 'energy', 'city', 'biology', 'ai']:
                is_kepu_video = True
            # æ£€æŸ¥ topic æ˜¯å¦åŒ…å«ç§‘æ™®å…³é”®è¯
            elif topic and any(kw in topic.lower() for kw in ['ç§‘æ™®', 'ç§‘å­¦', 'å®‡å®™', 'é‡å­', 'åœ°çƒ', 'èƒ½æº', 'åŸå¸‚', 'ç”Ÿç‰©', 'äººå·¥æ™ºèƒ½']):
                is_kepu_video = True
        
        # æ–¹æ³•2: é€šè¿‡ scene åˆ¤æ–­
        if not is_kepu_video and scene:
            # æ£€æŸ¥ scene ä¸­æ˜¯å¦æœ‰ç§‘æ™®ç›¸å…³çš„æ ‡è®°
            scene_category = scene.get('category', '')
            if scene_category in ['universe', 'quantum', 'earth', 'energy', 'city', 'biology', 'ai']:
                is_kepu_video = True
            # æ£€æŸ¥ prompt ä¸­æ˜¯å¦åŒ…å«ç§‘æ™®å…³é”®è¯
            scene_prompt = scene.get('prompt', '').lower()
            if any(kw in scene_prompt for kw in ['space', 'scientific', 'quantum', 'earth', 'energy', 'city', 'biology', 'ai', 'ç§‘æ™®', 'ç§‘å­¦', 'å®‡å®™', 'é‡å­', 'åœ°çƒ', 'èƒ½æº', 'åŸå¸‚', 'ç”Ÿç‰©', 'äººå·¥æ™ºèƒ½', 'astronaut', 'space station', 'planet', 'satellite', 'nebula', 'black hole', 'mars', 'solar system']):
                is_kepu_video = True
        
        # æ–¹æ³•3: é€šè¿‡ task_type åˆ¤æ–­ï¼ˆå¦‚æœ scene ä¸­æœ‰ task_type å­—æ®µï¼‰
        if not is_kepu_video and scene:
            task_type = scene.get('task_type', '')
            if task_type == 'scene':
                # åœºæ™¯ç”Ÿæˆé€šå¸¸æ˜¯ç§‘æ™®èƒŒæ™¯ï¼Œä½†éœ€è¦è¿›ä¸€æ­¥ç¡®è®¤
                # å¦‚æœ prompt ä¸­æ²¡æœ‰æ˜ç¡®çš„ä»™ä¾ å…³é”®è¯ï¼Œåˆ™è®¤ä¸ºæ˜¯ç§‘æ™®
                scene_prompt_lower = scene.get('prompt', '').lower()
                has_xianxia_keywords = any(kw in scene_prompt_lower for kw in ['xianxia', 'fantasy', 'ä»™ä¾ ', 'ä¿®ä»™', 'cultivator', 'han li', 'éŸ©ç«‹'])
                if not has_xianxia_keywords:
                    is_kepu_video = True
        
        use_chinese_prompt = not self.ascii_only_prompt
        
        # åˆå§‹åŒ– xianxia_styleï¼ˆç”¨äºåç»­ä»£ç ï¼‰
        if use_chinese_prompt:
            xianxia_style = "ä»™ä¾ é£æ ¼"
        else:
            xianxia_style = "xianxia fantasy"
        
        # å…ˆè¯†åˆ«è§’è‰²ï¼ˆç”¨äºå†³å®šä½¿ç”¨å“ªç§é£æ ¼ï¼‰
        identified_characters = []
        if self._identify_characters:
            identified_characters = self._identify_characters(scene)
        
        # âš¡ ä¿®å¤åœºæ™¯2ï¼šå¦‚æœè§’è‰²è¯†åˆ«æœªæ£€æµ‹åˆ°hanliï¼Œä½†prompt/compositionä¸­åŒ…å«"Han Li"æˆ–"hanli"ï¼Œå¼ºåˆ¶è¯†åˆ«
        if not identified_characters or "hanli" not in [c.lower() for c in identified_characters]:
            # æ£€æŸ¥promptã€compositionã€descriptionä¸­æ˜¯å¦åŒ…å«Han Li
            scene_text = " ".join([
                str(scene.get("prompt", "")),
                str(scene.get("description", "")),
                str(scene.get("visual", {}).get("composition", "") if isinstance(scene.get("visual"), dict) else ""),
            ]).lower()
            if "han li" in scene_text or "hanli" in scene_text or "éŸ©ç«‹" in scene_text:
                if not identified_characters:
                    identified_characters = ["hanli"]
                elif "hanli" not in [c.lower() for c in identified_characters]:
                    identified_characters.insert(0, "hanli")  # æ·»åŠ åˆ°æœ€å‰é¢
                print(f"  âœ“ å¼ºåˆ¶è¯†åˆ«ï¼šåœ¨prompt/compositionä¸­æ£€æµ‹åˆ°Han Liï¼Œå·²æ·»åŠ hanliåˆ°è§’è‰²åˆ—è¡¨")
        
        # âš¡ æ ¸å¿ƒä¿®å¤ï¼šäººç‰©èµ„äº§åŒ– + é£æ ¼åˆ†ç¦»
        # åŸåˆ™ï¼šäººç‰©å±‚ä¸ä½¿ç”¨é£æ ¼è¯ï¼Œé£æ ¼åªåœ¨Sceneå±‚æ³¨å…¥
        # ä¸åœ¨è¿™é‡Œæ·»åŠ é£æ ¼æ ‡ç­¾ï¼Œé£æ ¼å°†åœ¨åœºæ™¯å±‚æ·»åŠ ï¼ˆå¦‚æœæœ‰è§’è‰²ï¼Œåœ¨è§’è‰²æè¿°ä¹‹åï¼‰
        is_hanli = "hanli" in [c.lower() for c in identified_characters] if identified_characters else False
        
        if is_kepu_video:
            # ç§‘æ™®è§†é¢‘ï¼šä¸æ·»åŠ ä»™ä¾ é£æ ¼ï¼Œä½¿ç”¨ç§‘å­¦/ä¸“ä¸šé£æ ¼ï¼ˆåœ¨åœºæ™¯å±‚æ·»åŠ ï¼‰
            pass  # é£æ ¼åœ¨åœºæ™¯å±‚å¤„ç†
        else:
            # ä»™ä¾ è§†é¢‘ï¼šä¸åœ¨è¿™é‡Œæ·»åŠ é£æ ¼ï¼Œé£æ ¼å°†åœ¨åœºæ™¯å±‚æ·»åŠ 
            pass  # é£æ ¼åœ¨åœºæ™¯å±‚å¤„ç†
        
        # ========== åŸºäºæ„å›¾åˆ†ææ·»åŠ ä¸»è¦å®ä½“ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡è°ƒæ•´ï¼‰==========
        if intent['primary_entity']:
            entity = intent['primary_entity']
            entity_text = " ".join(entity.get("keywords", []))
            if entity_text:
                # ä½¿ç”¨ç»¼åˆæƒé‡è°ƒæ•´åçš„å®ä½“æƒé‡
                weight_adjustments = intent.get('weight_adjustments', {})
                entity_weight = weight_adjustments.get('entity_weight', entity.get("weight", 1.5))
                
                # å¦‚æœæ˜¯ç‰©ä½“ï¼Œä½¿ç”¨æ›´é«˜æƒé‡å¹¶å¼ºè°ƒï¼ˆå»é™¤é‡å¤ï¼Œä½¿ç”¨æ›´ç®€æ´çš„æè¿°ï¼‰
                if entity.get('type') == 'object':
                    # å»é™¤é‡å¤ï¼Œä½¿ç”¨æ›´ç®€æ´çš„æè¿°ï¼šåªå‡ºç°ä¸€æ¬¡å®ä½“åç§°ï¼Œç”¨ä¸åŒçš„æè¿°è¯å¼ºè°ƒ
                    # å¯¹äºç‰¹å®šç‰©ä½“ï¼ˆå¦‚scrollï¼‰ï¼Œæ·»åŠ æ›´å…·ä½“çš„æè¿°è¯ï¼Œé¿å…ç”Ÿæˆå…¶ä»–ç‰©ä½“
                    if "scroll" in entity_text.lower() or "å·è½´" in entity_text.lower():
                        # æ£€æŸ¥ entity_text ä¸­æ˜¯å¦å·²ç»æœ‰ "golden"ï¼Œå¦‚æœæœ‰å°±ä¸é‡å¤æ·»åŠ 
                        entity_lower = entity_text.lower()
                        if "golden" not in entity_lower:
                            entity_text = f"{entity_text}, golden scroll"
                        # æ·»åŠ å¼ºè°ƒè¯ï¼ˆå»é‡ï¼‰
                        emphasis_parts = []
                        if "prominent" not in entity_lower:
                            emphasis_parts.append("prominent")
                        if "clearly visible" not in entity_lower:
                            emphasis_parts.append("clearly visible")
                        if "main element" not in entity_lower:
                            emphasis_parts.append("main element")
                        if emphasis_parts:
                            entity_text = f"{entity_text}, {', '.join(emphasis_parts)}"
                        # æ·»åŠ æ’é™¤é¡¹
                        exclusion_parts = []
                        if "no weapons" not in entity_lower and "weapon" not in entity_lower:
                            exclusion_parts.append("no weapons")
                        if "no tools" not in entity_lower and "tool" not in entity_lower:
                            exclusion_parts.append("no tools")
                        if exclusion_parts:
                            entity_text = f"{entity_text}, {', '.join(exclusion_parts)}"
                        priority_parts.append(f"({entity_text}:{entity_weight:.2f})")
                        print(f"  âœ“ æ·»åŠ ä¸»è¦ç‰©ä½“ï¼ˆå·è½´ï¼Œæ™ºèƒ½ç»¼åˆæƒé‡{entity_weight:.2f}ï¼‰: {entity_text[:60]}...")
                    elif "city" in entity_text.lower() or "åŸå¸‚" in entity_text.lower() or "immortal city" in entity_text.lower():
                        priority_parts.append(f"({entity_text}, city silhouette, prominent, clearly visible, main element, no people, no characters:{entity_weight:.2f})")
                        print(f"  âœ“ æ·»åŠ ä¸»è¦ç‰©ä½“ï¼ˆåŸå¸‚ï¼Œæ™ºèƒ½ç»¼åˆæƒé‡{entity_weight:.2f}ï¼‰: {entity_text}")
                    else:
                        priority_parts.append(f"({entity_text}, prominent, clearly visible, main element:{entity_weight:.2f})")
                        print(f"  âœ“ æ·»åŠ ä¸»è¦ç‰©ä½“ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡{entity_weight:.2f}ï¼‰: {entity_text}")
                else:
                    priority_parts.append(f"({entity_text}:{entity_weight:.2f})")
                    print(f"  âœ“ æ·»åŠ ä¸»è¦å®ä½“ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡{entity_weight:.2f}ï¼‰: {entity_text}")
        
        # ========== åŸºäºæ„å›¾åˆ†ææ·»åŠ å¼ºè°ƒé¡¹ï¼ˆé€šç”¨å¤„ç†ï¼‰==========
        if intent['emphasis']:
            emphasis_text = ", ".join(intent['emphasis'][:3])  # æœ€å¤š3ä¸ªå¼ºè°ƒé¡¹
            priority_parts.append(f"({emphasis_text}:1.8)")
            print(f"  âœ“ æ·»åŠ å¼ºè°ƒé¡¹: {emphasis_text}")
        
        # ========== æ— äººç‰©åœºæ™¯å¤„ç†ï¼šæ™ºèƒ½æ’åºï¼Œä¼˜å…ˆæœ€é‡è¦çš„ç»†èŠ‚ ==========
        if not include_character:
            # æ³¨æ„ï¼šæ— äººç‰©åœºæ™¯çš„å®Œæ•´å¤„ç†é€»è¾‘éå¸¸å¤æ‚ï¼ˆçº¦700è¡Œï¼‰
            # è¿™é‡Œå…ˆåˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´é€»è¾‘éœ€è¦ä» ImageGenerator.build_prompt() ä¸­è¿ç§»
            # TODO: å®Œæ•´è¿ç§»æ— äººç‰©åœºæ™¯å¤„ç†é€»è¾‘ï¼ˆä» line 1963 åˆ° line 2531ï¼‰
            print(f"  â„¹ æ£€æµ‹åˆ°æ— äººç‰©åœºæ™¯ï¼Œæ™ºèƒ½æ„å»ºPromptï¼ˆä¼˜å…ˆæœ€é‡è¦çš„ç»†èŠ‚ï¼‰")
            
            # ç®€åŒ–ç‰ˆï¼šæå–æ ¸å¿ƒä¿¡æ¯
            description_text = self._clean_prompt_text(scene.get("description") or "")
            prompt_text = self._clean_prompt_text(scene.get("prompt") or "")
            visual = scene.get("visual", {}) or {}
            
            # âš¡ v2 æ ¼å¼æ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨ visual_constraints.environment
            visual_constraints = scene.get("visual_constraints", {}) or {}
            environment = self._clean_prompt_text(visual_constraints.get("environment", "") or "")
            if not environment and isinstance(visual, dict):
                environment = self._clean_prompt_text(visual.get("environment", "") or "")
            
            # âš¡ v2 æ ¼å¼æ”¯æŒï¼šå¤„ç† visual_constraints.elementsï¼ˆå…³é”®ç‰©ä½“ï¼Œå¦‚å·è½´ï¼‰
            elements = visual_constraints.get("elements", [])
            if elements and isinstance(elements, list):
                # å°†å…ƒç´ è½¬æ¢ä¸ºå¯è¯»æè¿°
                element_descriptions = []
                for element in elements:
                    if isinstance(element, str):
                        element_lower = element.lower()
                        # æ˜ å°„å¸¸è§å…ƒç´ åˆ°å¯è¯»æè¿°
                        element_map = {
                            "golden_scroll": "golden scroll, prominent, clearly visible, main element, unrolling, glowing with spiritual light",
                            "scroll": "scroll, prominent, clearly visible, main element",
                            "golden_scroll_unrolling": "golden scroll unrolling, prominent, clearly visible, main element, glowing with spiritual light",
                        }
                        element_desc = element_map.get(element_lower, element.replace("_", " "))
                        element_descriptions.append(element_desc)
                
                if element_descriptions:
                    elements_text = ", ".join(element_descriptions)
                    priority_parts.append(f"({elements_text}:2.0)")
                    print(f"  âœ“ æ·»åŠ å…³é”®å…ƒç´ ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæƒé‡2.0ï¼‰: {elements_text[:60]}...")
            
            # ä¼˜å…ˆä½¿ç”¨ environmentï¼ˆv2 æ ¼å¼ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ composition
            if environment:
                # ä½¿ç”¨ environment ä½œä¸ºä¸»è¦æè¿°
                priority_parts.append(f"({environment}:2.0)")
                print(f"  âœ“ æ·»åŠ ç¯å¢ƒæè¿°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæƒé‡2.0ï¼‰: {environment[:60]}...")
            elif description_text:
                # å¦‚æœæ²¡æœ‰ environmentï¼Œä½¿ç”¨ description
                priority_parts.append(f"({description_text}:2.0)")
                print(f"  âœ“ æ·»åŠ åœºæ™¯æè¿°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæƒé‡2.0ï¼‰: {description_text[:60]}...")
            elif prompt_text:
                # å¦‚æœæ²¡æœ‰ environment å’Œ descriptionï¼Œä½¿ç”¨ prompt
                priority_parts.append(f"({prompt_text}:2.0)")
                print(f"  âœ“ æ·»åŠ åœºæ™¯ promptï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæƒé‡2.0ï¼‰: {prompt_text[:60]}...")
            
            # ä»compositionä¸­æå–å…³é”®ä¿¡æ¯ï¼ˆä½œä¸ºè¡¥å……ï¼‰
            if isinstance(visual, dict):
                composition = self._clean_prompt_text(visual.get("composition") or "")
                if composition:
                    # æ£€æŸ¥ composition ä¸­æ˜¯å¦å·²ç»æœ‰æ’é™¤é¡¹ï¼ˆå¦‚ "no person", "no character"ï¼‰
                    composition_lower = composition.lower()
                    has_exclusion_in_composition = any(kw in composition_lower for kw in [
                        'no person', 'no character', 'no human', 'no people',
                        'æ— äººç‰©', 'æ— è§’è‰²', 'æ— äºº', 'æ— äººç‰©åœºæ™¯'
                    ])
                    
                    # å¦‚æœ composition ä¸­å·²ç»æœ‰æ’é™¤é¡¹ï¼Œå°±ä¸æ·»åŠ é¢å¤–çš„æ’é™¤é¡¹
                    exclusion_text = ""
                    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯è§‚å¯Ÿåœºæ™¯ï¼Œå¼ºåˆ¶æ·»åŠ äººç‰©æ’é™¤é¡¹
                    observation_keywords = ["sees", "revealing", "showing", "åªè§", "æ˜ å…¥çœ¼å¸˜", "å±•ç°"]
                    has_observation = any(kw in composition_lower for kw in observation_keywords)
                    force_exclude_character = has_observation and not has_exclusion_in_composition
                    
                    if not has_exclusion_in_composition and (intent.get('exclusions') or force_exclude_character):
                        # å¦‚æœæ˜¯è§‚å¯Ÿåœºæ™¯ï¼Œå¼ºåˆ¶æ·»åŠ äººç‰©æ’é™¤é¡¹
                        if force_exclude_character:
                            if self.ascii_only_prompt:
                                exclusion_text = ", no person, no character, no human, no people"
                            else:
                                exclusion_text = ", no person, no character, no human, no people, æ— äººç‰©, æ— è§’è‰², æ— äºº"
                            print(f"  âœ“ è§‚å¯Ÿåœºæ™¯ï¼šå¼ºåˆ¶æ·»åŠ äººç‰©æ’é™¤é¡¹ï¼Œç¡®ä¿ä»¥ç¯å¢ƒ/ç‰©ä½“ä¸ºä¸»")
                        else:
                            # åªæ·»åŠ è‹±æ–‡æ’é™¤é¡¹ï¼ˆå¦‚æœ ascii_only_prompt ä¸º Trueï¼‰
                            exclusions = intent['exclusions']
                            if self.ascii_only_prompt:
                                # è¿‡æ»¤æ‰ä¸­æ–‡ï¼Œåªä¿ç•™è‹±æ–‡
                                exclusions = [e for e in exclusions if not any('\u4e00' <= c <= '\u9fff' for c in e)]
                            # å»é‡ï¼šæ£€æŸ¥ composition ä¸­æ˜¯å¦å·²ç»æœ‰ç±»ä¼¼çš„æ’é™¤é¡¹
                            filtered_exclusions = []
                            for exc in exclusions:
                                exc_lower = exc.lower()
                                # æ£€æŸ¥æ˜¯å¦ä¸ composition ä¸­çš„å†…å®¹é‡å¤
                                if not any(kw in composition_lower for kw in exc_lower.split()):
                                    filtered_exclusions.append(exc)
                            if filtered_exclusions:
                                exclusion_text = ", " + ", ".join(filtered_exclusions)
                    
                    # æ„å»ºæœ€ç»ˆ promptï¼Œé¿å…é‡å¤ "prominent, main element"
                    composition_clean = composition
                    # å¦‚æœ composition ä¸­å·²ç»æœ‰ "prominent" æˆ– "main element"ï¼Œå°±ä¸é‡å¤æ·»åŠ 
                    if "prominent" not in composition_lower and "main element" not in composition_lower:
                        composition_clean = f"{composition}, prominent, main element"
                    
                    priority_parts.append(f"({composition_clean}{exclusion_text}:2.0)")
                    print(f"  âœ“ æ·»åŠ ä¸»è¦ç‰©ä½“ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæƒé‡2.0ï¼‰: {composition[:60]}...")
            
            # æ„å»ºæœ€ç»ˆæç¤ºè¯å¹¶æ£€æŸ¥tokenæ•°
            # âš¡ Prompt ä¼˜åŒ–ï¼šç¡®ä¿é€—å·åˆ†éš”æ¸…æ™°ï¼ˆç¬¦åˆ Flux æœ€ä½³å®è·µï¼‰
            cleaned_parts = []
            for part in priority_parts:
                if part:
                    part = part.strip().strip(',').strip()
                    if part:
                        cleaned_parts.append(part)
            priority_prompt = ", ".join(cleaned_parts)
            estimated_tokens = self.token_estimator.estimate(priority_prompt)
            
            # å¦‚æœä½¿ç”¨ä¸­æ–‡ä¸”SDXLæ¨¡å‹å¯¹ä¸­æ–‡æ”¯æŒä¸å¥½ï¼Œè€ƒè™‘ç¿»è¯‘æˆè‹±æ–‡
            if not self.ascii_only_prompt:
                final_prompt = priority_prompt
                print(f"  â„¹ ä½¿ç”¨ä¸­æ–‡ promptï¼ˆSDXLå¯èƒ½ç†è§£ä¸ä½³ï¼Œå¦‚æœç”Ÿæˆæ•ˆæœä¸å¥½ï¼Œå»ºè®®è®¾ç½® ascii_only_prompt: trueï¼‰")
            else:
                final_prompt = self._translate_chinese_to_english(priority_prompt)
                print(f"  â„¹ å·²ç¿»è¯‘ä¸ºè‹±æ–‡ prompt")
            
            print(f"  ğŸ“Š æ— äººç‰©åœºæ™¯Prompté•¿åº¦: {estimated_tokens} tokens (æ ¸å¿ƒéƒ¨åˆ†: {len(priority_parts)} é¡¹)")
            print(f"  ğŸ“ æœ€ç»ˆPromptæ–‡æœ¬: {final_prompt}")
            return final_prompt
        
        # ========== ç¬¬äºŒéƒ¨åˆ†ï¼šè§’è‰²/äººè„¸ç‰¹å¾ï¼ˆç´§è·Ÿé£æ ¼ä¹‹åï¼Œä»…å½“éœ€è¦è§’è‰²æ—¶ï¼‰==========
        if include_character:
            # âš¡ Prompt ä¼˜åŒ–ï¼šå•äººçº¦æŸæ”¾åœ¨é£æ ¼ä¹‹åï¼ˆç¬¬1ä½ï¼‰ï¼Œç¡®ä¿é£æ ¼æ ‡ç­¾åœ¨æœ€å‰é¢
            # ç”¨æˆ·åé¦ˆï¼šåœºæ™¯5å’Œ7ç”Ÿæˆäº†å¤šä¸ªäººç‰©ï¼Œåœ¨æ‰€æœ‰äººç‰©åœºæ™¯éƒ½æ·»åŠ å•äººçº¦æŸ
            # ä½†é£æ ¼æ ‡ç­¾å¿…é¡»åœ¨æœ€å‰é¢ï¼ˆSDXL/Flux æœ€ä½³å®è·µï¼‰
            if self.ascii_only_prompt:
                priority_parts.insert(1, "(single person:2.0)")  # æ’å…¥åˆ°ç¬¬1ä½ï¼ˆé£æ ¼ä¹‹åï¼‰
            else:
                priority_parts.insert(1, "(å•äºº:2.0)")  # æ’å…¥åˆ°ç¬¬1ä½ï¼ˆé£æ ¼ä¹‹åï¼‰
            # print(f"  âœ“ äººç‰©åœºæ™¯ï¼šåœ¨é£æ ¼ä¹‹åæ·»åŠ å•äººçº¦æŸï¼ˆç¬¬1ä½ï¼Œæƒé‡2.0ï¼Œé˜²æ­¢å¤šä¸ªäººç‰©ï¼‰")  # å‡å°‘æ—¥å¿—
            # è¯†åˆ«åœºæ™¯ä¸­çš„æ‰€æœ‰è§’è‰²
            if self._identify_characters:
                identified_characters = self._identify_characters(scene)
            else:
                identified_characters = []
            
            # âš¡ v2 æ ¼å¼æ”¯æŒï¼šå¦‚æœè§’è‰²è¯†åˆ«å¤±è´¥ï¼Œç›´æ¥ä» character.id è¯»å–
            if not identified_characters:
                character = scene.get("character", {}) or {}
                if isinstance(character, dict):
                    character_id = character.get("id", "")
                    if character_id:
                        identified_characters = [character_id]
                        print(f"  âœ“ v2 æ ¼å¼ï¼šä» character.id è¯†åˆ«åˆ°è§’è‰²: {character_id}")
            
            # âš¡ ä¿®å¤åœºæ™¯2ï¼šå¦‚æœè§’è‰²è¯†åˆ«æœªæ£€æµ‹åˆ°hanliï¼Œä½†prompt/compositionä¸­åŒ…å«"Han Li"ï¼Œå¼ºåˆ¶è¯†åˆ«
            if not identified_characters or "hanli" not in [c.lower() for c in identified_characters]:
                # æ£€æŸ¥promptã€compositionã€descriptionä¸­æ˜¯å¦åŒ…å«Han Li
                scene_text = " ".join([
                    str(scene.get("prompt", "")),
                    str(scene.get("description", "")),
                    str(scene.get("visual", {}).get("composition", "") if isinstance(scene.get("visual"), dict) else ""),
                ]).lower()
                if "han li" in scene_text or "hanli" in scene_text or "éŸ©ç«‹" in scene_text:
                    if not identified_characters:
                        identified_characters = ["hanli"]
                    elif "hanli" not in [c.lower() for c in identified_characters]:
                        identified_characters.insert(0, "hanli")  # æ·»åŠ åˆ°æœ€å‰é¢
                    # print(f"  âœ“ å¼ºåˆ¶è¯†åˆ«ï¼ˆäººç‰©åœºæ™¯ï¼‰ï¼šåœ¨prompt/compositionä¸­æ£€æµ‹åˆ°Han Liï¼Œå·²æ·»åŠ hanliåˆ°è§’è‰²åˆ—è¡¨")  # å‡å°‘æ—¥å¿—
            
            # å¦‚æœè¯†åˆ«åˆ°å…¶ä»–è§’è‰²ï¼ˆä¸ä»…ä»…æ˜¯éŸ©ç«‹ï¼‰ï¼Œä½¿ç”¨è§’è‰²æè¿°ç”Ÿæˆ
            if identified_characters:
                # ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªè¯†åˆ«çš„è§’è‰²ï¼ˆé€šå¸¸æ˜¯ä¸»è¦è§’è‰²ï¼‰
                primary_character = identified_characters[0]
                
                # âš¡ æ ¸å¿ƒä¿®å¤ï¼šäººç‰©èµ„äº§åŒ– - éŸ©ç«‹ä½¿ç”¨Promptæ¨¡æ¿ï¼ˆæ— é£æ ¼è¯ï¼‰
                is_hanli_char = primary_character.lower() == "hanli"
                if is_hanli_char:
                    # åŠ è½½HanLi.promptæ¨¡æ¿ï¼ˆçº¯äººç‰©æè¿°ï¼Œæ— é£æ ¼è¯ï¼‰
                    hanli_prompt = self._load_character_template("HanLi")
                    if hanli_prompt:
                        character_desc = hanli_prompt.strip()
                        # æ’å…¥åˆ°ç¬¬1ä½ï¼ˆçº¦æŸä¹‹åï¼‰
                        if len(priority_parts) >= 1:
                            priority_parts.insert(1, character_desc)
                            insert_pos = 1
                        else:
                            priority_parts.append(character_desc)
                            insert_pos = len(priority_parts) - 1
                        # print(f"  âœ“ ä½¿ç”¨HanLi.promptæ¨¡æ¿ï¼ˆäººç‰©èµ„äº§ï¼Œæ— é£æ ¼è¯ï¼Œç¬¬{insert_pos}ä½ï¼‰")  # å‡å°‘æ—¥å¿—
                    else:
                        # é™çº§åˆ°è§’è‰²æ¨¡æ¿
                        character_profile = self._get_character_profile(primary_character)
                        if character_profile:
                            character_desc = self._build_character_description_prompt(character_profile, shot_type_for_prompt)
                            if character_desc:
                                if len(priority_parts) >= 1:
                                    priority_parts.insert(1, character_desc)
                                    insert_pos = 1
                                else:
                                    priority_parts.append(character_desc)
                                    insert_pos = len(priority_parts) - 1
                                print(f"  âœ“ ä½¿ç”¨è§’è‰²æ¨¡æ¿ï¼ˆé™çº§æ–¹æ¡ˆï¼Œç¬¬{insert_pos}ä½ï¼‰")
                        else:
                            character_desc = None
                else:
                    # å…¶ä»–è§’è‰²ï¼šä½¿ç”¨è§’è‰²æ¨¡æ¿
                    character_profile = self._get_character_profile(primary_character)
                    if character_profile:
                        # æ„å»ºè§’è‰²æè¿° prompt
                        character_desc = self._build_character_description_prompt(character_profile, shot_type_for_prompt)
                        if character_desc:
                            # æ’å…¥åˆ°ç¬¬1ä½ï¼ˆçº¦æŸä¹‹åï¼‰
                            if len(priority_parts) >= 1:
                                priority_parts.insert(1, character_desc)
                                insert_pos = 1
                            else:
                                priority_parts.append(character_desc)
                                insert_pos = len(priority_parts) - 1
                            print(f"  âœ“ åº”ç”¨è§’è‰²æè¿°ï¼ˆç¬¬{insert_pos}ä½ï¼‰: {character_profile.get('character_name', primary_character)}")
                            print(f"  ğŸ“ è§’è‰²æè¿°å†…å®¹: {character_desc[:100]}...")
                    else:
                        # å¦‚æœæ²¡æœ‰è§’è‰²æ¨¡æ¿ï¼Œä»åœºæ™¯æè¿°ä¸­æå–è§’è‰²ä¿¡æ¯
                        print(f"  âš  æœªæ‰¾åˆ°è§’è‰²æ¨¡æ¿: {primary_character}ï¼Œå°†ä»åœºæ™¯æè¿°ä¸­æå–è§’è‰²ä¿¡æ¯")
                        # å°è¯•ä» character_pose æˆ– description ä¸­æå–è§’è‰²æè¿°
                        visual = scene.get("visual", {}) or {}
                        if isinstance(visual, dict):
                            character_pose = visual.get("character_pose", "")
                            if character_pose:
                                priority_parts.append(f"({character_pose}:1.5)")
                                print(f"  âœ“ ä½¿ç”¨ character_pose ä½œä¸ºè§’è‰²æè¿°: {character_pose[:50]}...")
                
                # åŸºäºæ„å›¾åˆ†æå¤„ç†è§†è§’ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡è°ƒæ•´ï¼‰
                weight_adjustments = intent.get('weight_adjustments', {})
                viewpoint = intent.get('viewpoint', {})
                viewpoint_type = viewpoint.get('type', 'front')
                viewpoint_weight = weight_adjustments.get('viewpoint_weight', viewpoint.get('weight', 1.0))
                
                # ä½¿ç”¨ç»¼åˆæƒé‡è°ƒæ•´åçš„è§†è§’æƒé‡
                # å¯¹äºæ‰€æœ‰äººç‰©åœºæ™¯ï¼Œé»˜è®¤æ·»åŠ æ­£é¢æœå‘æç¤ºï¼ˆé™¤éæ˜ç¡®è¦æ±‚èƒŒé¢ï¼‰
                viewpoint_explicit = viewpoint.get('explicit', False)
                # å¦‚æœè§†è§’ä¸æ˜¯èƒŒé¢ï¼Œéƒ½æ·»åŠ æ­£é¢æœå‘æç¤º
                if viewpoint_type != 'back':
                    use_chinese = not self.ascii_only_prompt
                    # å¦‚æœæ˜ç¡®è¦æ±‚æ­£é¢ï¼Œä½¿ç”¨æ›´é«˜æƒé‡ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤é«˜æƒé‡
                    if viewpoint_explicit and viewpoint_type == 'front':
                        final_weight = 2.0
                    elif viewpoint_type == 'front':
                        final_weight = max(viewpoint_weight, 1.8)  # è‡³å°‘1.8ï¼Œç¡®ä¿æ­£é¢æœå‘æ˜æ˜¾
                    else:
                        final_weight = 1.8  # é»˜è®¤é«˜æƒé‡ï¼Œç¡®ä¿æ­£é¢æœå‘
                    
                    facing_prompt = f"(æ­£é¢ï¼Œé¢å‘é•œå¤´ï¼Œäººç‰©é¢å‘è§‚ä¼—ï¼Œæ­£é¢è§†è§’:{final_weight:.2f})" if use_chinese else f"(facing camera, front view, face forward, character facing viewer, frontal view:{final_weight:.2f})"
                    # æ‰¾åˆ°è§’è‰²æè¿°çš„ä½ç½®ï¼Œåœ¨å…¶åæ’å…¥
                    insert_pos = len(priority_parts)
                    for i, part in enumerate(priority_parts):
                        if "han li" in part.lower() or "character" in part.lower() or "è§’è‰²" in part:
                            insert_pos = i + 1
                            break
                    priority_parts.insert(insert_pos, facing_prompt)
                    if viewpoint_explicit and viewpoint_type == 'front':
                        print(f"  âœ“ åŸºäºæ™ºèƒ½åˆ†ææ·»åŠ æ­£é¢æœå‘æç¤ºï¼ˆæ˜ç¡®è¦æ±‚ï¼Œæƒé‡{final_weight:.2f}ï¼Œä½ç½®{insert_pos}ï¼‰")
                    else:
                        print(f"  âœ“ åŸºäºæ™ºèƒ½åˆ†ææ·»åŠ æ­£é¢æœå‘æç¤ºï¼ˆé»˜è®¤æ­£é¢ï¼Œæƒé‡{final_weight:.2f}ï¼Œä½ç½®{insert_pos}ï¼‰")
                
                # å¦‚æœæœ‰å¤šä¸ªè§’è‰²ï¼Œæ·»åŠ å…¶ä»–è§’è‰²çš„æè¿°
                if len(identified_characters) > 1:
                    for char_id in identified_characters[1:]:
                        char_profile = self._get_character_profile(char_id)
                        if char_profile:
                            char_desc = self._build_character_description_prompt(char_profile, shot_type_for_prompt, compact=True)
                            if char_desc:
                                priority_parts.append(char_desc)
                                print(f"  âœ“ æ·»åŠ å…¶ä»–è§’è‰²æè¿°: {char_profile.get('character_name', char_id)}")
            else:
                # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°è§’è‰²ï¼Œä½†éœ€è¦è§’è‰²ï¼Œä½¿ç”¨é€šç”¨è§’è‰²æè¿°
                # ä»character_poseæˆ–descriptionä¸­æå–è§’è‰²ä¿¡æ¯
                visual = scene.get("visual", {}) or {}
                if isinstance(visual, dict):
                    character_pose = visual.get("character_pose", "")
                    if character_pose:
                        priority_parts.append(f"({character_pose}:1.5)")
                        print(f"  âœ“ ä½¿ç”¨ character_pose ä½œä¸ºè§’è‰²æè¿°: {character_pose[:50]}...")
        
        # ========== ç«‹å³æ·»åŠ åŠ¨ä½œ/å§¿åŠ¿æè¿°ï¼ˆç´§è·Ÿåœ¨è§’è‰²åé¢ï¼Œç¡®ä¿å…³é”®åŠ¨ä½œä¿¡æ¯åœ¨å‰ï¼‰==========
        # ä¼˜å…ˆä½¿ç”¨ä¸­æ–‡ description/promptï¼Œå¦‚æœå®ƒä»¬æ˜¯ä¸­æ–‡ï¼Œå°±ä¸ä½¿ç”¨ visual å­—æ®µä¸­çš„è‹±æ–‡å†…å®¹
        use_chinese_prompt = not self.ascii_only_prompt
        description_text = self._clean_prompt_text(scene.get("description") or "")
        prompt_text = self._clean_prompt_text(scene.get("prompt") or "")
        
        # æ£€æŸ¥ description æˆ– prompt æ˜¯å¦åŒ…å«ä¸­æ–‡
        import re
        has_chinese_desc = bool(re.search(r'[\u4e00-\u9fff]', description_text)) if description_text else False
        has_chinese_prompt = bool(re.search(r'[\u4e00-\u9fff]', prompt_text)) if prompt_text else False
        use_chinese = use_chinese_prompt and (has_chinese_desc or has_chinese_prompt)
        
        # è·å– visual å­—æ®µ
        visual = scene.get("visual") or {}
        # âš¡ v2 æ ¼å¼æ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨ character.poseï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ visual.character_pose
        character = scene.get("character", {}) or {}
        character_pose_v2 = character.get("pose", "")
        
        # å°† v2 æ ¼å¼çš„ pose å€¼è½¬æ¢ä¸ºå¯è¯»æè¿°
        # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sittingï¼ˆSDXL å¯¹ NOT ä¸æ•æ„Ÿï¼‰
        pose_map = {
            "lying_motionless": "body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position",
            "turning_head": "turning head, looking around, head movement",
            "recalling": "recalling, remembering, thoughtful expression",
            "focusing_gaze": "focusing gaze, looking intently, concentrated expression",
            "standing": "standing, upright position",
            "sitting": "sitting, seated position",
            "walking": "walking, moving forward",
        }
        
        if character_pose_v2 and character_pose_v2 in pose_map:
            character_pose_v2 = pose_map[character_pose_v2]
        
        if isinstance(visual, dict) and not use_chinese:
            # ä¼˜å…ˆä½¿ç”¨ character.poseï¼ˆv2 æ ¼å¼ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ visual.character_poseï¼ˆv1 æ ¼å¼ï¼‰
            character_pose = character_pose_v2 or self._clean_prompt_text(visual.get("character_pose") or "")
            if character_pose:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ­£é¢æœå‘å…³é”®è¯
                pose_lower = character_pose.lower()
                has_facing = any(kw in pose_lower for kw in ["facing", "front", "æ­£é¢", "é¢å‘", "forward", "toward camera", "facing camera"])
                has_back = any(kw in pose_lower for kw in ["back", "èƒŒé¢", "èƒŒå", "from behind", "rear"])
                
                # âš¡ ä¿®å¤ï¼šæ£€æµ‹è¡¨æƒ…ç›¸å…³æè¿°ï¼ˆgrim, dark, unpleasantç­‰ï¼‰ï¼Œæé«˜æƒé‡
                has_expression_keywords = any(kw in pose_lower for kw in [
                    "grim", "dark", "unpleasant", "gloomy", "serious", "stern", "frown", "scowl",
                    "é˜´æ²‰", "ä¸¥è‚ƒ", "ä¸æ‚¦", "çš±çœ‰", "è¡¨æƒ…", "expression"
                ])
                pose_weight = 1.8
                if has_expression_keywords:
                    pose_weight = 2.5  # è¡¨æƒ…æè¿°æé«˜æƒé‡
                    print(f"  âœ“ æ£€æµ‹åˆ°character_poseä¸­çš„è¡¨æƒ…æè¿°ï¼Œæé«˜æƒé‡åˆ°{pose_weight:.1f}")
                
                # åŸºäºæ„å›¾åˆ†æçš„åŠ¨ä½œç±»å‹ï¼ŒåŠ¨æ€è°ƒæ•´æƒé‡ï¼ˆé€šç”¨å¤„ç†ï¼‰
                action_type = intent['action_type']
                if action_type == 'static':
                    # é™æ€åŠ¨ä½œï¼Œä½¿ç”¨è¾ƒé«˜æƒé‡ç¡®ä¿å§¿åŠ¿å‡†ç¡®
                    if not has_back:  # å¦‚æœä¸æ˜¯æ˜ç¡®è¦æ±‚èƒŒé¢ï¼Œæ·»åŠ æ­£é¢æœå‘
                        priority_parts.append(f"({character_pose}, facing camera, front view:{pose_weight:.1f})")
                        print(f"  âœ“ ä½¿ç”¨ visual.character_poseï¼ˆé™æ€åŠ¨ä½œï¼Œå¢å¼ºæ­£é¢æœå‘ï¼Œæƒé‡{pose_weight:.1f}ï¼‰: {character_pose}")
                    else:
                        priority_parts.append(f"({character_pose}:{pose_weight:.1f})")
                        print(f"  âœ“ ä½¿ç”¨ visual.character_poseï¼ˆé™æ€åŠ¨ä½œï¼Œå¢å¼ºæƒé‡{pose_weight:.1f}ï¼‰: {character_pose}")
                else:
                    # åŠ¨æ€åŠ¨ä½œæˆ–å…¶ä»–ï¼Œæ ¹æ®æ˜¯å¦åŒ…å«æ­£é¢æœå‘è°ƒæ•´æƒé‡
                    if has_facing:
                        priority_parts.append(f"({character_pose}:{pose_weight:.1f})")
                        # é¢å¤–å¼ºè°ƒæ­£é¢æœå‘ï¼Œé˜²æ­¢è¢«å…¶ä»–æè¿°è¦†ç›–
                        priority_parts.append("(facing camera, front view, face forward, frontal view:1.8)")
                        print(f"  âœ“ ä½¿ç”¨ visual.character_poseï¼ˆæ­£é¢æœå‘ï¼Œå¢å¼ºæƒé‡{pose_weight:.1f}ï¼‰: {character_pose}")
                    elif has_back:
                        priority_parts.append(f"({character_pose}:{pose_weight:.1f})")
                        print(f"  âœ“ ä½¿ç”¨ visual.character_poseï¼ˆèƒŒé¢æœå‘ï¼Œæƒé‡{pose_weight:.1f}ï¼‰: {character_pose}")
                    else:
                        # å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šæœå‘ï¼Œé»˜è®¤æ·»åŠ æ­£é¢æœå‘
                        priority_parts.append(f"({character_pose}, facing camera, front view:1.8)")
                        print(f"  âœ“ ä½¿ç”¨ visual.character_poseï¼ˆé»˜è®¤æ­£é¢æœå‘ï¼Œå¢å¼ºæƒé‡1.8ï¼‰: {character_pose}")
        elif use_chinese and description_text:
            # å¦‚æœä½¿ç”¨ä¸­æ–‡ï¼Œä¼˜å…ˆä½¿ç”¨ description ä½œä¸ºåŠ¨ä½œ/å§¿åŠ¿æè¿°
            # å°† description æ·»åŠ åˆ° promptï¼ˆä½œä¸ºä¸»è¦æè¿°ï¼‰
            if description_text not in [p.split(':')[0].strip('()') for p in priority_parts]:
                priority_parts.append(f"({description_text}:1.6)")
                print(f"  âœ“ ä½¿ç”¨ä¸­æ–‡ descriptionï¼ˆä½œä¸ºåŠ¨ä½œ/å§¿åŠ¿æè¿°ï¼‰: {description_text[:50]}...")
        
        # ========== ç¬¬äºŒéƒ¨åˆ†ï¼šé•œå¤´å’Œæ„å›¾ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡è°ƒæ•´ï¼‰==========
        # å¦‚æœä½¿ç”¨ä¸­æ–‡ï¼Œä¸ä½¿ç”¨ visual å­—æ®µä¸­çš„è‹±æ–‡å†…å®¹ï¼›å¦åˆ™ä½¿ç”¨ visual.composition
        if not use_chinese and isinstance(visual, dict):
            # ä¼˜å…ˆä½¿ç”¨ visual.compositionï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œè¿™æ˜¯æœ€å‡†ç¡®çš„æ„å›¾æè¿°
            # ä½¿ç”¨ç»¼åˆæƒé‡è°ƒæ•´åçš„æ„å›¾æƒé‡
            weight_adjustments = intent.get('weight_adjustments', {})
            composition_weight = weight_adjustments.get('composition_weight', 1.4)
            composition = self._clean_prompt_text(visual.get("composition") or "")
            if composition:
                # âš¡ ä¼˜åŒ–ï¼šå¦‚æœcompositionåŒ…å«å…³é”®åŠ¨ä½œï¼ˆå¦‚"lying on"ã€"lying in"ï¼‰ï¼Œæé«˜æƒé‡
                composition_lower = composition.lower()
                if any(kw in composition_lower for kw in ["lying on", "lying in", "lying", "sitting on", "standing on"]):
                    # åŒ…å«å…³é”®åŠ¨ä½œå’Œç¯å¢ƒï¼Œæé«˜æƒé‡åˆ°1.8ï¼Œç¡®ä¿åŠ¨ä½œå’Œç¯å¢ƒéƒ½è¢«æ­£ç¡®ç”Ÿæˆ
                    composition_weight = max(composition_weight, 1.8)
                    print(f"  âœ“ æ£€æµ‹åˆ°å…³é”®åŠ¨ä½œï¼ˆlying/sitting/standing onï¼‰ï¼Œæé«˜compositionæƒé‡åˆ°{composition_weight:.2f}")
                
                # âš¡ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœcompositionåŒ…å«è¡¨æƒ…æè¿°ï¼ˆexpression darkens, grimç­‰ï¼‰æˆ–recallåŠ¨ä½œï¼Œæé«˜æƒé‡å¹¶å¼ºè°ƒ
                composition_lower = composition.lower()
                has_expression_in_composition = any(kw in composition_lower for kw in [
                    "expression darkens", "expression turning grim", "grim expression", "dark expression",
                    "expression darken", "face darkens", "expression turns", "è¡¨æƒ…", "é˜´æ²‰"
                ])
                has_recall_action = any(kw in composition_lower for kw in ["recall", "recalls", "recalling", "å›æƒ³", "å›å¿†"])
                
                if has_expression_in_composition:
                    composition_weight = 2.5  # å¤§å¹…æé«˜æƒé‡
                    # å¢å¼ºæè¿°ï¼Œæ˜ç¡®è¡¨æƒ…
                    enhanced_composition = composition
                    if "expression darkens" in composition_lower or "expression turning grim" in composition_lower:
                        enhanced_composition = f"{composition}, grim expression, dark expression, serious face, stern look, unpleasant expression"
                    priority_parts.append(f"({enhanced_composition}:{composition_weight:.2f})")
                    print(f"  âœ“ æ£€æµ‹åˆ°compositionä¸­çš„è¡¨æƒ…æè¿°ï¼Œå¤§å¹…æé«˜æƒé‡åˆ°{composition_weight:.2f}ï¼Œå¼ºè°ƒè¡¨æƒ…")
                elif has_recall_action:
                    composition_weight = max(composition_weight, 2.0)  # æé«˜æƒé‡
                    # å¢å¼ºæè¿°ï¼Œæ˜ç¡®recallåŠ¨ä½œå’Œè¡¨æƒ…
                    enhanced_composition = composition
                    if "expression darkens" in composition_lower or "expression turning grim" in composition_lower:
                        enhanced_composition = f"{composition}, grim expression, dark expression, serious face, stern look"
                    priority_parts.append(f"({enhanced_composition}:{composition_weight:.2f})")
                    print(f"  âœ“ æ£€æµ‹åˆ°recallåŠ¨ä½œï¼Œæé«˜compositionæƒé‡åˆ°{composition_weight:.2f}ï¼Œå¼ºè°ƒå›æƒ³å’Œè¡¨æƒ…")
                else:
                    # âš¡ ä½¿ç”¨é€šç”¨çš„promptå¢å¼ºæ–¹æ³•ï¼ˆåŸºäºè¯­ä¹‰åˆ†æï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç å…³é”®è¯ï¼‰
                    enhanced_composition = self.optimizer.enhance_prompt_part(composition, "composition")
                    
                    # å¦‚æœè¢«å¢å¼ºäº†ï¼Œæå–æ–°çš„æƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰
                    import re
                    weight_match = re.search(r':(\d+\.?\d*)', enhanced_composition)
                    if weight_match:
                        composition_weight = float(weight_match.group(1))
                    
                    priority_parts.append(f"({enhanced_composition}:{composition_weight:.2f})" if not enhanced_composition.startswith("(") else enhanced_composition)
                    if enhanced_composition != composition:
                        print(f"  âœ“ ä½¿ç”¨ visual.compositionï¼ˆå·²å¢å¼ºï¼Œæƒé‡{composition_weight:.2f}ï¼‰: {enhanced_composition[:80]}...")
                    else:
                        print(f"  âœ“ ä½¿ç”¨ visual.compositionï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡{composition_weight:.2f}ï¼‰: {composition}")
        
        # åŸºäºæ„å›¾åˆ†æå¤„ç†é•œå¤´ç±»å‹ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡è°ƒæ•´ï¼‰
        if camera_desc:
            camera_prompt = self._convert_camera_to_prompt(camera_desc)
            if camera_prompt:
                # ä½¿ç”¨ç»¼åˆæƒé‡è°ƒæ•´åçš„é•œå¤´æƒé‡
                weight_adjustments = intent.get('weight_adjustments', {})
                camera_weight = weight_adjustments.get('camera_weight', 1.3)
                viewpoint = intent.get('viewpoint', {})
                viewpoint_type = viewpoint.get('type', 'front')
                
                # æ ¹æ®è§†è§’ç±»å‹å’Œç»¼åˆæƒé‡è°ƒæ•´
                if viewpoint_type in ['close', 'wide']:
                    # ç‰¹å†™æˆ–è¿œæ™¯ï¼šä½¿ç”¨ç»¼åˆæƒé‡ï¼Œæ’å…¥åˆ°å‰é¢
                    priority_parts.insert(1, f"({camera_prompt}:{camera_weight:.2f})")  # æ’å…¥åˆ°ç¬¬2ä½
                    print(f"  âœ“ ä½¿ç”¨åœºæ™¯ camera æè¿°ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡{camera_weight:.2f}ï¼‰: {camera_desc} -> {camera_prompt}")
                else:
                    # å…¶ä»–é•œå¤´ç±»å‹ï¼šä½¿ç”¨ç»¼åˆæƒé‡
                    priority_parts.append(f"({camera_prompt}:{camera_weight:.2f})")
                    print(f"  âœ“ ä½¿ç”¨åœºæ™¯ camera æè¿°ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡{camera_weight:.2f}ï¼‰: {camera_desc} -> {camera_prompt}")
        
        # é•œå¤´æ„å›¾çº¦æŸï¼ˆæç®€ç‰ˆï¼Œåªä¿ç•™ä¸€ä¸ªï¼‰
        # æ·»åŠ å®½é«˜æ¯”ä¿æŠ¤ï¼Œé¿å…äººåƒè¢«æ¨ªå‘æ‹‰ä¼¸æˆ–çºµå‘æ‹‰ä¼¸ï¼ˆç˜¦é•¿è„¸ï¼‰
        use_chinese = not self.ascii_only_prompt
        
        # âš¡ ç«–å±æ¨¡å¼ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šé•œå¤´ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ™¯ï¼ˆé¿å…è¿‡è¿‘çš„é•œå¤´ï¼‰
        # ä½†éœ€è¦æ£€æŸ¥cameraå­—æ®µæ˜¯å¦åŒ…å«æ˜ç¡®çš„é•œå¤´æè¿°
        has_explicit_shot_type = (
            shot_type_for_prompt["is_wide"] or 
            shot_type_for_prompt["is_medium"] or 
            shot_type_for_prompt["is_close"] or 
            shot_type_for_prompt["is_full_body"]
        )
        
        # æ£€æŸ¥cameraå­—æ®µæ˜¯å¦åŒ…å«æ˜ç¡®çš„é•œå¤´å…³é”®è¯ï¼ˆå³ä½¿shot_type_for_promptæ²¡æœ‰æ ‡è®°ï¼‰
        camera_has_shot_type = False
        if camera_desc:
            camera_lower = camera_desc.lower()
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„é•œå¤´ç±»å‹å…³é”®è¯
            if any(kw in camera_lower for kw in [
                "wide shot", "wide pan", "long shot", "extreme wide", "establishing shot",
                "medium shot", "mid shot", "ä¸­æ™¯",
                "close-up", "closeup", "close up", "ç‰¹å†™", "è¿‘æ™¯",
                "full body", "å…¨èº«",
                "top-down", "ä¿¯è§†", "bird's eye",
                "eye close-up", "extreme eye", "çœ¼ç›ç‰¹å†™"
            ]):
                camera_has_shot_type = True
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šé•œå¤´ç±»å‹ï¼Œä¸”cameraå­—æ®µä¹Ÿæ²¡æœ‰æ˜ç¡®çš„é•œå¤´æè¿°ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ™¯
        if not has_explicit_shot_type and not camera_has_shot_type and include_character:
            # ç«–å±æ¨¡å¼é»˜è®¤ä¸­æ™¯ï¼Œé¿å…é•œå¤´è¿‡è¿‘
            shot_type_for_prompt["is_medium"] = True
            print(f"  âœ“ ç«–å±æ¨¡å¼ä¼˜åŒ–ï¼šæœªæŒ‡å®šé•œå¤´ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ™¯ï¼ˆé¿å…è¿‡è¿‘çš„é•œå¤´ï¼‰")
        elif has_explicit_shot_type or camera_has_shot_type:
            print(f"  âœ“ æ£€æµ‹åˆ°æ˜ç¡®çš„é•œå¤´ç±»å‹ï¼Œä¿æŒåŸå§‹é•œå¤´æè¿°ï¼ˆä¸å¼ºåˆ¶è½¬æ¢ä¸ºä¸­æ™¯ï¼‰")
        
        if shot_type_for_prompt["is_wide"] or shot_type_for_prompt["is_full_body"]:
            # è¿œæ™¯åœºæ™¯ï¼šå¼ºåˆ¶æ·»åŠ æ­£é¢æœå‘å’Œæ’é™¤èƒŒå½±ï¼Œé¿å…äººç‰©å¤ªå°å’ŒèƒŒå½±
            # âš¡ ä¿®å¤é•œå¤´å¤ªè¿‘ï¼šè¿œæ™¯åœºæ™¯æ˜ç¡®æ·»åŠ "distant view"ç¡®ä¿é•œå¤´è·ç¦»
            if use_chinese:
                priority_parts.append("(å•äººï¼Œæ­£é¢è§†è§’ï¼Œé¢å‘é•œå¤´ï¼Œè¿œæ™¯ï¼Œè¿œè·ç¦»:1.8)")
                priority_parts.append("(æ­£ç¡®å®½é«˜æ¯”ï¼Œè‡ªç„¶é¢éƒ¨æ¯”ä¾‹:1.3)")  # ä¿æŠ¤å®½é«˜æ¯”ï¼Œé˜²æ­¢ç˜¦é•¿è„¸
            else:
                priority_parts.append("(single person, front view, facing camera, distant view, far away, wide shot:1.8)")
                priority_parts.append("(correct aspect ratio, natural face proportions, no stretch:1.3)")  # ä¿æŠ¤å®½é«˜æ¯”ï¼Œé˜²æ­¢ç˜¦é•¿è„¸
        elif shot_type_for_prompt["is_medium"]:
            # ä¸­æ™¯åœºæ™¯ï¼šå¼ºåˆ¶æ·»åŠ æ­£é¢æœå‘ï¼Œé¿å…èƒŒå½±å’Œé•œå¤´è¿‡è¿‘
            if use_chinese:
                priority_parts.append("(ä¸­æ™¯ï¼Œæ­£é¢è§†è§’ï¼Œé¢å‘é•œå¤´ï¼Œè‡ªç„¶èº«ä½“æ¯”ä¾‹ï¼Œé€‚å½“è·ç¦»:1.8)")  # æé«˜æƒé‡ï¼Œå¼ºè°ƒæ­£é¢å’Œè‡ªç„¶æ¯”ä¾‹ï¼Œæ˜ç¡®é€‚å½“è·ç¦»
                priority_parts.append("(ä¿®é•¿èº«æï¼Œçª„è‚©ï¼Œè‡ªç„¶å§¿åŠ¿:1.3)")  # å¼ºè°ƒè‡ªç„¶å§¿åŠ¿
                priority_parts.append("(é¿å…è¿‡è¿‘é•œå¤´ï¼Œä¿æŒé€‚å½“è·ç¦»:1.2)")  # æ˜ç¡®æ’é™¤è¿‡è¿‘é•œå¤´
            else:
                priority_parts.append("(medium shot, front view, facing camera, natural body proportions, appropriate distance:1.8)")  # æé«˜æƒé‡ï¼Œå¼ºè°ƒæ­£é¢å’Œè‡ªç„¶æ¯”ä¾‹ï¼Œæ˜ç¡®é€‚å½“è·ç¦»
                priority_parts.append("(slim body, narrow shoulders, natural pose:1.3)")  # å¼ºè°ƒè‡ªç„¶å§¿åŠ¿
                priority_parts.append("(avoid too close, maintain appropriate distance:1.2)")  # æ˜ç¡®æ’é™¤è¿‡è¿‘é•œå¤´
        elif shot_type_for_prompt["is_close"]:
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœ¼ç›ç‰¹å†™æˆ–é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼ˆéœ€è¦ä¿æŒç‰¹å†™ï¼Œä¸è½¬æ¢ä¸ºä¸­æ™¯ï¼‰
            is_eye_closeup = shot_type_for_prompt.get("is_eye_closeup", False)
            camera_desc_check = scene.get("camera") if scene else ""
            # å¤„ç† v2 æ ¼å¼ï¼šå¦‚æœ camera æ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if isinstance(camera_desc_check, dict):
                camera_desc_check = self._convert_camera_v2_to_string(camera_desc_check)
            if not isinstance(camera_desc_check, str):
                camera_desc_check = str(camera_desc_check) if camera_desc_check else ""
            camera_desc_lower = (camera_desc_check or "").lower()
            # å¦‚æœæ²¡æœ‰æ ‡è®°ï¼Œæ£€æŸ¥cameraå­—æ®µæˆ–promptä¸­æ˜¯å¦æœ‰çœ¼ç›ç‰¹å†™æˆ–é¢éƒ¨ç‰¹å†™å…³é”®è¯
            if not is_eye_closeup:
                is_eye_closeup = any(kw in camera_desc_lower for kw in ['eye', 'eyes', 'pupil', 'pupils', 'çœ¼ç›', 'ç³å­”', 'extreme close'])
            is_face_closeup = any(kw in camera_desc_lower for kw in ['face', 'facial', 'portrait', 'headshot', 'é¢éƒ¨', 'è„¸éƒ¨', 'å¤´åƒ', 'close-up on face', 'closeup on face'])
            
            if is_eye_closeup:
                # çœ¼ç›ç‰¹å†™åœºæ™¯ï¼šä¿æŒç‰¹å†™æè¿°ï¼Œä¸è½¬æ¢ä¸ºä¸­æ™¯
                if use_chinese:
                    priority_parts.append("(çœ¼ç›ç‰¹å†™ï¼Œæè¿‘é•œå¤´:2.0)")
                    priority_parts.append("(è¯¦ç»†çš„çœ¼ç›ï¼Œç³å­”æ¸…æ™°å¯è§:1.8)")
                else:
                    priority_parts.append("(extreme close-up on eyes:2.0)")
                    priority_parts.append("(detailed eyes, pupils clearly visible:1.8)")
                print(f"  âœ“ æ£€æµ‹åˆ°çœ¼ç›ç‰¹å†™åœºæ™¯ï¼Œä¿æŒç‰¹å†™æè¿°ï¼ˆä¸è½¬æ¢ä¸ºä¸­æ™¯ï¼‰")
            elif is_face_closeup:
                # é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼šä¿æŒç‰¹å†™æè¿°ï¼Œä¸è½¬æ¢ä¸ºä¸­æ™¯
                if use_chinese:
                    priority_parts.append("(é¢éƒ¨ç‰¹å†™ï¼Œè¿‘æ™¯é•œå¤´:2.0)")
                    priority_parts.append("(æ¸…æ™°çš„é¢éƒ¨è¡¨æƒ…:1.8)")
                else:
                    priority_parts.append("(close-up on face:2.0)")
                    priority_parts.append("(portrait shot, headshot, clear facial expression:1.8)")
                print(f"  âœ“ æ£€æµ‹åˆ°é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼Œä¿æŒç‰¹å†™æè¿°ï¼ˆä¸è½¬æ¢ä¸ºä¸­æ™¯ï¼‰")
            else:
                # å…¶ä»–ç‰¹å†™åœºæ™¯ï¼šé¿å…å¤ªè¿‘çš„é•œå¤´ï¼Œä½¿ç”¨ä¸­æ™¯æè¿°ï¼ˆç«–å±æ¨¡å¼ä¼˜åŒ–ï¼‰
                if use_chinese:
                    priority_parts.append("(ä¸­æ™¯ï¼Œé€‚å½“è·ç¦»:1.5)")  # æé«˜æƒé‡ï¼Œæ˜ç¡®é€‚å½“è·ç¦»
                    priority_parts.append("(ä¿®é•¿èº«æï¼Œçª„è‚©:1.3)")
                    priority_parts.append("(é¿å…è¿‡è¿‘é•œå¤´:1.2)")  # æ˜ç¡®æ’é™¤è¿‡è¿‘é•œå¤´
                else:
                    priority_parts.append("(medium shot, appropriate distance:1.5)")  # æé«˜æƒé‡ï¼Œæ˜ç¡®é€‚å½“è·ç¦»
                    priority_parts.append("(slim body, narrow shoulders:1.3)")
                    priority_parts.append("(avoid too close, maintain distance:1.2)")  # æ˜ç¡®æ’é™¤è¿‡è¿‘é•œå¤´
                print(f"  âš  æ£€æµ‹åˆ°ç‰¹å†™é•œå¤´ï¼Œå·²è½¬æ¢ä¸ºä¸­æ™¯ä»¥é¿å…èº«ä½“è¿‡å®½å’Œæ¨¡ç³Šï¼ˆç«–å±æ¨¡å¼ä¼˜åŒ–ï¼šæ˜ç¡®é€‚å½“è·ç¦»ï¼‰")
        
        # ========== ç¬¬ä¸‰éƒ¨åˆ†ï¼šåœºæ™¯èƒŒæ™¯ï¼ˆå¢å¼ºç‰ˆï¼Œä¿ç•™å®Œæ•´ç»†èŠ‚ï¼‰==========
        # å¦‚æœå·²ç»ä½¿ç”¨äº†ä¸­æ–‡ descriptionï¼Œå°±ä¸å†æ·»åŠ  visual.environmentï¼ˆé¿å…é‡å¤å’Œæ··ç”¨ä¸­è‹±æ–‡ï¼‰
        # å¦‚æœè¿˜æ²¡æœ‰æ·»åŠ  descriptionï¼Œæ‰è€ƒè™‘ä½¿ç”¨ visual.environment
        # âš¡ v2 æ ¼å¼æ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨ visual_constraints.environmentï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ visual.environment
        if not use_chinese:
            # ä¼˜å…ˆä» visual_constraints.environment è¯»å–ï¼ˆv2 æ ¼å¼ï¼‰
            visual_constraints = scene.get("visual_constraints", {}) or {}
            environment_visual = self._clean_prompt_text(visual_constraints.get("environment") or "")
            
            # å¦‚æœæ²¡æœ‰ visual_constraints.environmentï¼Œåˆ™ä½¿ç”¨ visual.environmentï¼ˆv1 æ ¼å¼ï¼‰
            if not environment_visual and isinstance(visual, dict):
                environment_visual = self._clean_prompt_text(visual.get("environment") or "")
            
            if environment_visual:
                # ä¸å†è¿‡åº¦ç²¾ç®€ï¼Œä¿ç•™å®Œæ•´çš„ç¯å¢ƒæè¿°ä»¥å¢å¼ºåœºæ™¯è¡¨ç°
                # ç¯å¢ƒæè¿°åŒ…å«åœºæ™¯ä¸­çš„ç‰©ä½“ã€åœ°å½¢ã€å¤©æ°”ç­‰é‡è¦ä¿¡æ¯
                # æé«˜æƒé‡ä»1.4åˆ°1.8ï¼Œç¡®ä¿ç¯å¢ƒåœºæ™¯ï¼ˆå¦‚æ²™æ¼ ï¼‰è¢«æ­£ç¡®ç”Ÿæˆ
                # âš¡ ä¼˜åŒ–ï¼šå¯¹äºè¿œæ™¯åœºæ™¯ï¼Œè¿›ä¸€æ­¥æé«˜ç¯å¢ƒæƒé‡åˆ°2.0ï¼Œç¡®ä¿èƒŒæ™¯æ¸…æ™°å¯è§
                env_weight = 1.8
                if shot_type_for_prompt.get("is_wide") or shot_type_for_prompt.get("is_full_body"):
                    env_weight = 2.0
                    print(f"  âœ“ è¿œæ™¯åœºæ™¯ï¼šæé«˜ç¯å¢ƒæè¿°æƒé‡åˆ°{env_weight:.1f}ï¼Œç¡®ä¿èƒŒæ™¯æ¸…æ™°å¯è§")
                
                # âš¡ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç¯å¢ƒæè¿°åŒ…å«"three suns"æˆ–"lunar phantoms"ï¼Œå¤§å¹…æé«˜æƒé‡å¹¶å¼ºè°ƒå¯è§æ€§
                env_lower = environment_visual.lower()
                if "three" in env_lower and ("sun" in env_lower or "lunar" in env_lower or "moon" in env_lower):
                    env_weight = 2.5  # å¤§å¹…æé«˜æƒé‡
                    # å¢å¼ºæè¿°ï¼Œå¼ºè°ƒå¤ªé˜³å’Œæœˆäº®çš„å¯è§æ€§å’Œæ•°é‡
                    enhanced_env = environment_visual
                    if "three dazzling suns" in env_lower:
                        enhanced_env = f"Three large and prominent dazzling suns, clearly visible and bright, dominating the sky, {environment_visual}"
                    elif "three" in env_lower and "sun" in env_lower:
                        enhanced_env = f"Three large and prominent dazzling suns, clearly visible and bright, dominating the sky, {environment_visual}"
                    if "four" in env_lower and ("lunar" in env_lower or "moon" in env_lower):
                        enhanced_env = f"{enhanced_env}, four faint but clearly visible lunar phantoms, clearly distinguishable in the sky, not just one sun"
                    priority_parts.append(f"({enhanced_env}:{env_weight:.1f})")
                    print(f"  âœ“ æ£€æµ‹åˆ°å¤©ç©ºåœºæ™¯ï¼ˆå¤ªé˜³/æœˆäº®ï¼‰ï¼Œå¤§å¹…æé«˜æƒé‡åˆ°{env_weight:.1f}ï¼Œå¼ºè°ƒå¯è§æ€§å’Œæ•°é‡")
                else:
                    # âš¡ ä½¿ç”¨é€šç”¨çš„promptå¢å¼ºæ–¹æ³•ï¼ˆåŸºäºè¯­ä¹‰åˆ†æï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç å…³é”®è¯ï¼‰
                    enhanced_env = self.optimizer.enhance_prompt_part(environment_visual, "environment")
                    
                    # å¦‚æœè¢«å¢å¼ºäº†ï¼Œæå–æ–°çš„æƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰
                    import re
                    weight_match = re.search(r':(\d+\.?\d*)', enhanced_env)
                    if weight_match:
                        env_weight = float(weight_match.group(1))
                    
                    priority_parts.append(f"({enhanced_env}:{env_weight:.1f})" if not enhanced_env.startswith("(") else enhanced_env)
                    if enhanced_env != environment_visual:
                        print(f"  âœ“ ä½¿ç”¨ visual.environmentï¼ˆå·²å¢å¼ºï¼Œæƒé‡{env_weight:.1f}ï¼‰: {enhanced_env[:80]}...")
                # print(f"  âœ“ ä½¿ç”¨ visual.environmentï¼ˆå®Œæ•´ç‰ˆï¼Œæƒé‡{env_weight:.1f}ï¼‰: {environment_visual}")  # å‡å°‘æ—¥å¿—
        
        # ========== æ·»åŠ åŸå§‹åœºæ™¯ promptï¼ˆå…³é”®ä¿¡æ¯ï¼Œä¼˜å…ˆå¤„ç†ï¼‰==========
        # âš¡ Prompt ä¼˜åŒ–ï¼šåŸå§‹åœºæ™¯ prompt åº”è¯¥åœ¨é£æ ¼å’Œè§’è‰²ä¹‹åï¼Œç¯å¢ƒä¹‹å‰
        # é¡ºåºï¼šé£æ ¼(0) -> çº¦æŸ(1) -> è§’è‰²(2) -> åœºæ™¯prompt(3) -> ç¯å¢ƒ/èƒŒæ™¯ -> å…¶ä»–
        # æ³¨æ„ï¼šprompt_text åœ¨ç¬¬ 461 è¡Œå·²å®šä¹‰
        if prompt_text and not use_chinese:
            # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«åœ¨ priority_parts ä¸­ï¼ˆé¿å…é‡å¤ï¼‰
            prompt_already_included = any(
                prompt_text.lower() in part.lower() or 
                part.lower() in prompt_text.lower() or
                any(keyword in part.lower() for keyword in prompt_text.lower().split()[:3])  # æ£€æŸ¥å‰3ä¸ªå…³é”®è¯
                for part in priority_parts
            )
            if not prompt_already_included:
                # âš¡ ä¼˜åŒ–ï¼šåŸå§‹åœºæ™¯ prompt æ’å…¥åˆ°ç¬¬3ä½ï¼ˆé£æ ¼ã€çº¦æŸã€è§’è‰²ä¹‹åï¼‰
                # è¿™æ˜¯åœºæ™¯çš„æ ¸å¿ƒå†…å®¹ï¼Œåº”è¯¥åœ¨é£æ ¼å’Œè§’è‰²ä¹‹åç«‹å³å‡ºç°
                insert_pos = min(3, len(priority_parts))  # æœ€å¤šæ’å…¥åˆ°ç¬¬3ä½
                # å¦‚æœå·²ç»æœ‰é£æ ¼ã€çº¦æŸã€è§’è‰²ï¼Œæ’å…¥åˆ°ç¬¬3ä½ï¼›å¦åˆ™æ’å…¥åˆ°åˆé€‚ä½ç½®
                if len(priority_parts) >= 3:
                    insert_pos = 3
                elif len(priority_parts) >= 2:
                    insert_pos = 2
                elif len(priority_parts) >= 1:
                    insert_pos = 1
                else:
                    insert_pos = 0
                priority_parts.insert(insert_pos, prompt_text)
                # print(f"  âœ“ æ·»åŠ åŸå§‹åœºæ™¯ promptï¼ˆæ ¸å¿ƒå†…å®¹ï¼Œç¬¬{insert_pos}ä½ï¼Œé£æ ¼å’Œè§’è‰²ä¹‹åï¼‰: {prompt_text[:80]}...")  # å‡å°‘æ—¥å¿—
        
        # ========== æ·»åŠ åœºæ™¯èƒŒæ™¯æè¿°ï¼ˆç¡®ä¿æœ‰èƒŒæ™¯ï¼Œå³ä½¿æœ‰è§’è‰²ï¼‰==========
        # âš¡ Prompt ä¼˜åŒ–ï¼šåœºæ™¯èƒŒæ™¯åº”è¯¥åœ¨åŸå§‹åœºæ™¯ prompt ä¹‹å
        # é¡ºåºï¼šé£æ ¼(0) -> çº¦æŸ(1) -> è§’è‰²(2) -> åœºæ™¯prompt(3) -> èƒŒæ™¯(4) -> å…¶ä»–
        # å¯¹äºç§‘æ™®è§†é¢‘ï¼Œå³ä½¿æœ‰è§’è‰²ï¼Œä¹Ÿéœ€è¦åœºæ™¯èƒŒæ™¯
        scene_bg_compact = self._build_scene_background_prompt_compact(scene, script_data)
        if scene_bg_compact:
            # å°†èƒŒæ™¯æè¿°æ·»åŠ åˆ° priority_partsï¼ˆåœ¨åŸå§‹åœºæ™¯ prompt ä¹‹åï¼‰
            # æ‰¾åˆ°åŸå§‹åœºæ™¯ prompt çš„ä½ç½®ï¼Œåœ¨å…¶åæ’å…¥
            insert_pos = len(priority_parts)
            if prompt_text:
                for i, part in enumerate(priority_parts):
                    if prompt_text.lower() in part.lower():
                        insert_pos = i + 1  # åœ¨åŸå§‹åœºæ™¯ prompt ä¹‹å
                        break
            # å¦‚æœæ²¡æ‰¾åˆ°åŸå§‹åœºæ™¯ promptï¼Œæ’å…¥åˆ°è§’è‰²ä¹‹åï¼ˆç¬¬3ä½ï¼‰
            if insert_pos == len(priority_parts):
                insert_pos = min(4, len(priority_parts))  # é»˜è®¤æ’å…¥åˆ°ç¬¬4ä½ï¼ˆé£æ ¼ã€çº¦æŸã€è§’è‰²ã€åœºæ™¯promptä¹‹åï¼‰
            priority_parts.insert(insert_pos, scene_bg_compact)
            # print(f"  âœ“ åº”ç”¨åœºæ™¯èƒŒæ™¯æ¨¡æ¿ï¼ˆç²¾ç®€ç‰ˆï¼Œç¬¬{insert_pos}ä½ï¼Œåœºæ™¯promptä¹‹åï¼Œç¡®ä¿æœ‰èƒŒæ™¯ï¼‰: {scene_bg_compact}")  # å‡å°‘æ—¥å¿—
        
        # ========== ç¬¬äº”éƒ¨åˆ†ï¼šåŠ¨ä½œæè¿°ï¼ˆæ™ºèƒ½ç»¼åˆæƒé‡è°ƒæ•´ï¼‰==========
        # ä½¿ç”¨ç»¼åˆæƒé‡è°ƒæ•´åçš„åŠ¨ä½œæƒé‡
        weight_adjustments = intent.get('weight_adjustments', {})
        action_weight = weight_adjustments.get('action_weight', 1.2)
        
        # å¦‚æœå·²ç»æœ‰character_poseï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å……åŠ¨ä½œä¿¡æ¯
        use_chinese = not self.ascii_only_prompt
        # âš¡ v2 æ ¼å¼æ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨ character.pose
        character = scene.get("character", {}) or {}
        character_pose_v2 = character.get("pose", "")
        
        # å°† v2 æ ¼å¼çš„ pose å€¼è½¬æ¢ä¸ºå¯è¯»æè¿°
        pose_map = {
            "lying_motionless": "lying motionless",
            "turning_head": "turning head",
            "recalling": "recalling",
            "focusing_gaze": "focusing gaze",
        }
        if character_pose_v2 and character_pose_v2 in pose_map:
            character_pose_v2 = pose_map[character_pose_v2]
        
        # ä¼˜å…ˆä½¿ç”¨ character.poseï¼ˆv2 æ ¼å¼ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ visual.character_poseï¼ˆv1 æ ¼å¼ï¼‰
        character_pose_from_visual = visual.get("character_pose", "") if isinstance(visual, dict) else ""
        character_pose_combined = character_pose_v2 or character_pose_from_visual
        
        if character_pose_combined and not use_chinese:
            # å¦‚æœ character_pose å­˜åœ¨ä½†ä¸å¤Ÿè¯¦ç»†ï¼Œå¯ä»¥è¡¥å…… actionï¼ˆä»…è‹±æ–‡æ¨¡å¼ï¼‰
            character_pose_text = character_pose_combined.lower()
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„åŠ¨ä½œåŠ¨è¯
            has_action_verb = any(verb in character_pose_text for verb in 
                                 ["lying", "standing", "walking", "sitting", "running", 
                                  "flying", "attacking", "defending", "casting", "using"])
            if not has_action_verb:
                # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„åŠ¨ä½œï¼Œä» action å­—æ®µè¡¥å……
                raw_action = (scene.get("action") or "")
                if raw_action:
                    action_simple = raw_action.replace("_", " ").lower()
                    if "walk" in action_simple:
                        priority_parts.append(f"(walking:{action_weight:.2f})")
                    elif "stand" in action_simple or "detect" in action_simple:
                        priority_parts.append(f"(standing:{action_weight:.2f})")
                    elif "lie" in action_simple or "lying" in action_simple:
                        # âš¡ ä¼˜åŒ–ï¼šå¯¹äºlyingåŠ¨ä½œï¼Œæé«˜æƒé‡å¹¶æ˜ç¡®"lying on ground/sand"
                        # æ£€æŸ¥compositionæˆ–environmentä¸­æ˜¯å¦æœ‰"on sand/ground/desert"
                        composition_text = str(visual.get("composition", "")).lower() if isinstance(visual, dict) else ""
                        environment_text = str(visual.get("environment", "")).lower() if isinstance(visual, dict) else ""
                        
                        # å¦‚æœcompositionæˆ–environmentä¸­åŒ…å«"sand/ground/desert"ï¼Œæ˜ç¡®"lying on"
                        if "sand" in composition_text or "sand" in environment_text or "desert" in composition_text or "desert" in environment_text:
                            # âš¡ ä¿®å¤ï¼šå¤§å¹…æé«˜æƒé‡åˆ°2.5ï¼Œç¡®ä¿"lying on sand"è¢«æ­£ç¡®ç”Ÿæˆ
                            lying_weight = max(action_weight + 0.8, 2.8)  # âš¡ ä¿®å¤ï¼šæé«˜åˆ°2.8ï¼Œç¡®ä¿é«˜ä¼˜å…ˆçº§
                            # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sittingï¼ˆSDXL å¯¹ NOT ä¸æ•æ„Ÿï¼‰
                            lying_text = f"(body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:{lying_weight:.2f})"
                            # âš¡ ä½¿ç”¨é€šç”¨çš„promptå¢å¼ºæ–¹æ³•ï¼ˆè‡ªåŠ¨æ·»åŠ NOT standingç­‰æ’é™¤è¯ï¼‰
                            enhanced_lying = self.optimizer.enhance_prompt_part(lying_text, "action")
                            priority_parts.append(enhanced_lying)
                            print(f"  âœ“ æ£€æµ‹åˆ°lyingåŠ¨ä½œå’Œsand/desertç¯å¢ƒï¼Œå¼ºè°ƒ'lying on sand/ground/desert'ï¼Œæƒé‡{lying_weight:.2f}ï¼ˆé«˜ä¼˜å…ˆçº§ï¼Œæ’é™¤standingå’Œsittingï¼‰")
                        else:
                            # âš¡ ä¿®å¤ï¼šå³ä½¿æ²¡æœ‰æ˜ç¡®ç¯å¢ƒï¼Œä¹Ÿæ·»åŠ æ’é™¤è¯å’Œæé«˜æƒé‡
                            lying_weight = max(action_weight + 0.5, 2.5)  # è‡³å°‘2.5
                            # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sitting
                            lying_text = f"(body fully on the ground, legs fully extended, arms lying flat, no bent knees, horizontal position:{lying_weight:.2f})"
                            # âš¡ ä½¿ç”¨é€šç”¨çš„promptå¢å¼ºæ–¹æ³•
                            enhanced_lying = self.optimizer.enhance_prompt_part(lying_text, "action")
                            priority_parts.append(enhanced_lying)
                            print(f"  âœ“ æ£€æµ‹åˆ°lyingåŠ¨ä½œï¼Œå¼ºè°ƒ'lying down'ï¼Œæƒé‡{lying_weight:.2f}ï¼ˆæ’é™¤standingå’Œsittingï¼‰")
                    elif "use" in action_simple or "cast" in action_simple:
                        priority_parts.append(f"({action_simple}:{action_weight:.2f})")
        elif not use_chinese:
            # å¦‚æœæ²¡æœ‰ character_poseï¼Œä» action å­—æ®µæ·»åŠ åŠ¨ä½œæè¿°ï¼ˆä»…è‹±æ–‡æ¨¡å¼ï¼‰
            raw_action = (scene.get("action") or "")
            if raw_action:
                action_simple = raw_action.replace("_", " ").lower()
                if "walk" in action_simple:
                    priority_parts.append(f"(walking:{action_weight:.2f})")
                elif "stand" in action_simple or "detect" in action_simple:
                    priority_parts.append(f"(standing:{action_weight:.2f})")
                elif "lie" in action_simple or "lying" in action_simple:
                    # âš¡ ä¼˜åŒ–ï¼šå¯¹äºlyingåŠ¨ä½œï¼Œæé«˜æƒé‡å¹¶æ˜ç¡®"lying on ground/sand"
                    # æ£€æŸ¥compositionæˆ–environmentä¸­æ˜¯å¦æœ‰"on sand/ground/desert"
                    composition_text = str(visual.get("composition", "")).lower() if isinstance(visual, dict) else ""
                    environment_text = str(visual.get("environment", "")).lower() if isinstance(visual, dict) else ""
                    
                    # å¦‚æœcompositionæˆ–environmentä¸­åŒ…å«"sand/ground/desert"ï¼Œæ˜ç¡®"lying on"
                    if "sand" in composition_text or "sand" in environment_text or "desert" in composition_text or "desert" in environment_text:
                        # âš¡ ä¿®å¤ï¼šå¤§å¹…æé«˜æƒé‡åˆ°2.5ï¼Œç¡®ä¿"lying on sand"è¢«æ­£ç¡®ç”Ÿæˆ
                        lying_weight = max(action_weight + 0.8, 2.8)  # âš¡ ä¿®å¤ï¼šæé«˜åˆ°2.8ï¼Œç¡®ä¿é«˜ä¼˜å…ˆçº§
                        lying_text = f"(lying on sand, lying on ground, lying on desert, NOT standing, NOT sitting, horizontal position, prone, supine:{lying_weight:.2f})"
                        # âš¡ ä½¿ç”¨é€šç”¨çš„promptå¢å¼ºæ–¹æ³•ï¼ˆè‡ªåŠ¨æ·»åŠ NOT standingç­‰æ’é™¤è¯ï¼‰
                        enhanced_lying = self.optimizer.enhance_prompt_part(lying_text, "action")
                        priority_parts.append(enhanced_lying)
                        print(f"  âœ“ æ£€æµ‹åˆ°lyingåŠ¨ä½œå’Œsand/desertç¯å¢ƒï¼Œå¼ºè°ƒ'lying on sand/ground/desert'ï¼Œæƒé‡{lying_weight:.2f}ï¼ˆé«˜ä¼˜å…ˆçº§ï¼Œæ’é™¤standingå’Œsittingï¼‰")
                    else:
                        lying_text = f"(lying, lying down:{action_weight:.2f})"
                        # âš¡ ä½¿ç”¨é€šç”¨çš„promptå¢å¼ºæ–¹æ³•
                        enhanced_lying = self.optimizer.enhance_prompt_part(lying_text, "action")
                        priority_parts.append(enhanced_lying)
                elif "use" in action_simple or "cast" in action_simple:
                    priority_parts.append(f"({action_simple}:{action_weight:.2f})")
        
        # ========== ç¬¬å…­éƒ¨åˆ†ï¼šé£æ ¼æ³¨å…¥ï¼ˆSceneå±‚ï¼Œæ— æƒé‡æ ‡è®°ï¼‰==========
        # âš¡ æ ¸å¿ƒä¿®å¤ï¼šé£æ ¼åªåœ¨Sceneå±‚æ³¨å…¥ï¼Œä¸åœ¨äººç‰©å±‚
        # é£æ ¼æè¿°ç®€æ´ï¼Œæ— æƒé‡æ ‡è®°ï¼Œé¿å…å¹²æ‰°
        use_chinese = not self.ascii_only_prompt
        scene_style_text = None
        if not is_kepu_video:
            # ä»™ä¾ é£æ ¼ï¼šç®€æ´æè¿°ï¼Œæ— æƒé‡æ ‡è®°ï¼Œä½†æ›´æ˜ç¡®å¼ºè°ƒåŠ¨æ¼«é£æ ¼
            scene_style_text = "Chinese xianxia anime illustration, 3D rendered anime, anime cinematic style, cinematic lighting" if not use_chinese else "ä¸­å›½ä»™ä¾ åŠ¨æ¼«æ’ç”»ï¼Œ3Dæ¸²æŸ“åŠ¨æ¼«ï¼ŒåŠ¨æ¼«ç”µå½±é£æ ¼ï¼Œç”µå½±çº§å…‰ç…§"
            # æ·»åŠ åˆ°åœºæ™¯æè¿°ä¹‹åï¼ˆå¦‚æœæœ‰è§’è‰²ï¼Œåœ¨è§’è‰²ä¹‹åï¼‰
            priority_parts.append(scene_style_text)
            # print(f"  âœ“ Sceneå±‚é£æ ¼æ³¨å…¥ï¼ˆæ— æƒé‡æ ‡è®°ï¼Œå¢å¼ºåŠ¨æ¼«é£æ ¼ï¼‰: {scene_style_text}")  # å‡å°‘æ—¥å¿—
        
        # ========== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šèƒŒæ™¯ä¸€è‡´æ€§ï¼ˆä¿è¯åœºæ™¯è¿è´¯ï¼Œç²¾ç®€ï¼‰==========
        # å¼ºè°ƒèƒŒæ™¯ç¨³å®šï¼Œé¿å…è·³å¸§å’Œé£æ ¼æ¼‚ç§»
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰åœºæ™¯èƒŒæ™¯æè¿°
        has_scene_bg = any("desert" in p.lower() or "chamber" in p.lower() or "background" in p.lower() or "golden" in p.lower() or "æ²™æ¼ " in p or "é—è¿¹" in p or "èƒŒæ™¯" in p for p in priority_parts)
        # å¦‚æœæœ‰åœºæ™¯èƒŒæ™¯æ¨¡æ¿ï¼ŒèƒŒæ™¯ä¸€è‡´æ€§æç¤ºæ›´é‡è¦ï¼Œä¼˜å…ˆä¿ç•™
        if len(priority_parts) < 7 or has_scene_bg:
            # å¦‚æœå·²ç»æœ‰åœºæ™¯èƒŒæ™¯æè¿°ï¼Œä½¿ç”¨æ›´ç®€æ´çš„ä¸€è‡´æ€§æç¤º
            if has_scene_bg:
                if not self.ascii_only_prompt:
                    priority_parts.append("(èƒŒæ™¯ä¸€è‡´:1.2)")
                else:
                    priority_parts.append("(consistent background:1.2)")
            else:
                if not self.ascii_only_prompt:
                    priority_parts.append("(èƒŒæ™¯ä¸€è‡´ï¼Œç¯å¢ƒç¨³å®š:1.3)")
                else:
                    priority_parts.append("(consistent background, stable environment:1.3)")
        
        # ========== ç¬¬å…«éƒ¨åˆ†ï¼šç›¸é‚»åœºæ™¯è¿è´¯æ€§ï¼ˆæ–°å¢ï¼‰==========
        # å¦‚æœæœ‰å‰ä¸€ä¸ªåœºæ™¯ï¼Œå¼ºè°ƒåœºæ™¯è¿ç»­æ€§
        if previous_scene:
            # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€ç¯å¢ƒï¼ˆé€šè¿‡episodeã€titleæˆ–scene_nameåˆ¤æ–­ï¼‰
            current_env = scene.get("scene_name") or script_data.get("title", "") if script_data else ""
            prev_env = previous_scene.get("scene_name") or ""
            
            # å¦‚æœç¯å¢ƒç›¸åŒæˆ–ç›¸ä¼¼ï¼Œå¼ºè°ƒè¿ç»­æ€§
            use_chinese = not self.ascii_only_prompt
            if current_env and prev_env and (current_env == prev_env or 
                any(keyword in current_env.lower() and keyword in prev_env.lower() 
                    for keyword in ["desert", "chamber", "corridor", "é—è¿¹", "æ²™æ¼ "])):
                if use_chinese:
                    priority_parts.append("(ç›¸åŒä½ç½®ï¼Œè¿ç»­åœºæ™¯:1.2)")
                    priority_parts.append("(ç›¸åŒç¯å¢ƒé£æ ¼:1.1)")
                else:
                    priority_parts.append("(same location, continuous scene:1.2)")
                    priority_parts.append("(same environment style:1.1)")
                print(f"  âœ“ æ£€æµ‹åˆ°ç›¸é‚»åœºæ™¯åœ¨åŒä¸€ç¯å¢ƒï¼Œæ·»åŠ è¿è´¯æ€§æç¤º")
            
            # æ£€æŸ¥è§’è‰²æ˜¯å¦ç›¸åŒï¼ˆå¦‚æœéƒ½æœ‰è§’è‰²ï¼‰
            if include_character and self._needs_character and self._needs_character(previous_scene):
                if use_chinese:
                    priority_parts.append("(ç›¸åŒè§’è‰²å¤–è§‚:1.2)")
                else:
                    priority_parts.append("(same character appearance:1.2)")
                print(f"  âœ“ æ£€æµ‹åˆ°ç›¸é‚»åœºæ™¯éƒ½æœ‰è§’è‰²ï¼Œæ·»åŠ è§’è‰²ä¸€è‡´æ€§æç¤º")
        
        # ========== ç¬¬å››éƒ¨åˆ†ï¼šåœºæ™¯ç‰¹æ•ˆå’Œç»†èŠ‚ï¼ˆæå‡ä¼˜å…ˆçº§ï¼‰==========
        # å¦‚æœä½¿ç”¨ä¸­æ–‡ï¼Œä¸ä½¿ç”¨ visual.fx ä¸­çš„è‹±æ–‡å†…å®¹ï¼›å¦åˆ™ä½¿ç”¨ visual.fx
        # fx æè¿°äº†åœºæ™¯ä¸­çš„ç‰¹æ•ˆã€ç‰©ä½“ã€åŠ¨ä½œç­‰å…³é”®è§†è§‰å…ƒç´ ï¼Œåº”è¯¥æ”¾åœ¨ä¼˜å…ˆçº§éƒ¨åˆ†
        # å¢å¼ºï¼šå°† fx æå‡åˆ° priority_partsï¼Œç¡®ä¿åœºæ™¯ä¸­çš„ç‰©ä½“å’ŒåŠ¨ä½œèƒ½è¢«æ­£ç¡®è¡¨ç°
        if not use_chinese and isinstance(visual, dict):
            # åªæœ‰å½“ä¸ä½¿ç”¨ä¸­æ–‡æ—¶ï¼Œæ‰ä½¿ç”¨ visual.fx
            fx = self._clean_prompt_text(visual.get("fx") or "")
            if fx:
                # fx åŒ…å«åœºæ™¯ä¸­çš„ç‰¹æ•ˆã€ç‰©ä½“ã€ç²’å­ç­‰ç»†èŠ‚ï¼Œå¯¹åœºæ™¯è¡¨ç°å¾ˆé‡è¦
                # æ£€æŸ¥æ˜¯å¦æ˜¯çœ¼ç›ç‰¹å†™åœºæ™¯ï¼Œå¦‚æœæ˜¯ï¼Œæé«˜æƒé‡
                camera_desc_lower = (camera_desc or "").lower()
                fx_lower = fx.lower()
                is_eye_closeup = any(kw in camera_desc_lower for kw in ['close-up', 'closeup', 'close up', 'extreme close', 'eye', 'eyes', 'ç‰¹å†™', 'è¿‘æ™¯', 'çœ¼ç›'])
                has_eye_detail = any(kw in fx_lower for kw in ['eye', 'pupil', 'glint', 'glow', 'blue', 'light'])
                
                # å¦‚æœæ˜¯çœ¼ç›ç‰¹å†™æˆ–åŒ…å«çœ¼ç›ç»†èŠ‚ï¼Œä½¿ç”¨æ›´é«˜æƒé‡
                if is_eye_closeup or has_eye_detail:
                    priority_parts.append(f"({fx}:2.0)")
                    print(f"  âœ“ ä½¿ç”¨ visual.fxï¼ˆçœ¼ç›ç‰¹å†™/ç»†èŠ‚å¢å¼ºï¼Œæƒé‡2.0ï¼‰: {fx}")
                else:
                    priority_parts.append(f"({fx}:1.5)")
                    print(f"  âœ“ ä½¿ç”¨ visual.fxï¼ˆæå‡ä¼˜å…ˆçº§ï¼Œæƒé‡1.5ï¼‰: {fx}")
        
        # ========== æ¬¡è¦ä¿¡æ¯ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼Œä½†ä¿ç•™ç”¨äºå®Œæ•´æ€§ï¼‰==========
        # motion æè¿°é•œå¤´è¿åŠ¨ï¼Œä½œä¸ºè¡¥å……ä¿¡æ¯
        if isinstance(visual, dict):
            motion_desc = self._convert_motion_to_prompt(visual.get("motion"))
            if motion_desc:
                secondary_parts.append(f"({motion_desc}:1.0)")
        
        # face_style_autoï¼ˆæ¬¡è¦ï¼‰
        face_style = scene.get("face_style_auto") or {}
        if isinstance(face_style, dict):
            expression = self._clean_prompt_text(face_style.get("expression") or "")
            if expression:
                secondary_parts.append(f"({expression} expression:1.0)")
        
        # âš¡ æ ¸å¿ƒä¿®å¤ï¼šç§»é™¤è¿‡å¤šé£æ ¼æ ‡ç­¾ï¼Œé£æ ¼å·²åœ¨Sceneå±‚æ³¨å…¥ï¼ˆç¬¬845è¡Œï¼‰
        # secondary_partsä¸­çš„é£æ ¼æ ‡ç­¾å·²ç§»é™¤ï¼Œé¿å…ä¸Sceneå±‚é£æ ¼å†²çª
        # é£æ ¼åªåœ¨Sceneå±‚é€šè¿‡priority_partsæ³¨å…¥ï¼Œä¿æŒä¸€è‡´æ€§
        
        # åˆå¹¶ï¼šåªä½¿ç”¨ä¼˜å…ˆéƒ¨åˆ†ï¼Œç¡®ä¿å…³é”®ä¿¡æ¯åœ¨å‰ 77 tokens å†…
        # ä½¿ç”¨æ›´å‡†ç¡®çš„ token ä¼°ç®—ï¼ˆè€ƒè™‘æ‹¬å·å’Œæƒé‡æ ‡è®°ï¼‰
        # âš¡ Prompt ä¼˜åŒ–ï¼šç¡®ä¿é€—å·åˆ†éš”æ¸…æ™°ï¼ˆç¬¦åˆ Flux/SDXL æœ€ä½³å®è·µï¼‰
        # æ¸…ç†æ¯ä¸ªéƒ¨åˆ†ï¼Œç§»é™¤å¤šä½™çš„é€—å·å’Œç©ºæ ¼
        cleaned_parts = []
        for part in priority_parts:
            if part:
                # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„é€—å·å’Œç©ºæ ¼
                part = part.strip().strip(',').strip()
                if part:
                    cleaned_parts.append(part)
        priority_prompt = ", ".join(cleaned_parts)
        
        # å°è¯•ä½¿ç”¨CLIP tokenizerè¿›è¡Œå‡†ç¡®è®¡ç®—ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ä¿å®ˆä¼°ç®—
        estimated_tokens = self.token_estimator.estimate(priority_prompt)
        
        # âš¡ æ ¸å¿ƒä¿®å¤ï¼šé€šç”¨ä¿æŠ¤æœºåˆ¶ - ä¿æŠ¤æ‰€æœ‰é«˜æƒé‡å’Œå…³é”®å†…å®¹ä¸è¢«ä¼˜åŒ–å™¨ç§»é™¤
        # åœ¨ä¼˜åŒ–å‰ä¿å­˜å…³é”®å†…å®¹ï¼ˆåŸºäºæƒé‡å’Œé‡è¦æ€§ï¼Œè€Œéç¡¬ç¼–ç å…³é”®è¯ï¼‰
        protected_contents = []  # å­˜å‚¨éœ€è¦ä¿æŠ¤çš„å†…å®¹åŠå…¶å…ƒæ•°æ®
        
        for i, part in enumerate(priority_parts):
            part_lower = part.lower()
            
            # 1. ä¿æŠ¤è§’è‰²æ¨¡æ¿å†…å®¹ï¼ˆé€šè¿‡ç‰¹å¾è¯æ£€æµ‹ï¼‰
            if any(keyword in part_lower for keyword in ["young male cultivator", "chinese xianxia novel", "slim but resilient", "sharp calm eyes", "dark simple cultivator robe", "dark green simple"]):
                protected_contents.append({
                    "content": part,
                    "type": "character_template",
                    "priority": 1,  # æœ€é«˜ä¼˜å…ˆçº§
                    "keywords": ["young male cultivator", "chinese xianxia novel", "slim but resilient"]
                })
                # print(f"  ğŸ›¡ï¸ æ£€æµ‹åˆ°è§’è‰²æ¨¡æ¿å†…å®¹ï¼ˆä½ç½®{i}ï¼‰ï¼Œå°†åœ¨ä¼˜åŒ–åæ£€æŸ¥å¹¶ä¿æŠ¤")  # å‡å°‘æ—¥å¿—
            
            # 2. ä¿æŠ¤é«˜æƒé‡åŠ¨ä½œæè¿°ï¼ˆæƒé‡ >= 1.8 æˆ–åŒ…å«å…³é”®åŠ¨ä½œ+ç¯å¢ƒç»„åˆï¼‰
            # æå–æƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            import re
            weight_match = re.search(r':([\d.]+)\)', part)
            weight = float(weight_match.group(1)) if weight_match else 1.0
            
            # æ£€æµ‹å…³é”®åŠ¨ä½œ+ç¯å¢ƒç»„åˆï¼ˆå¦‚"lying on sand/desert/ground"ï¼‰
            key_action_patterns = [
                r"lying\s+on\s+(sand|desert|ground|floor|earth)",
                r"sitting\s+on\s+(sand|desert|ground|floor|rock|stone)",
                r"standing\s+on\s+(sand|desert|ground|floor|rock|stone|mountain)",
                r"walking\s+(in|on|through)\s+(sand|desert|forest|mountain|valley)",
            ]
            has_key_action_env = any(re.search(pattern, part_lower) for pattern in key_action_patterns)
            
            if weight >= 1.8 or has_key_action_env:
                protected_contents.append({
                    "content": part,
                    "type": "high_weight_action",
                    "priority": 2 if weight >= 2.0 else 3,
                    "keywords": [part_lower[:50]]  # ä½¿ç”¨å†…å®¹çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºå…³é”®è¯
                })
                # print(f"  ğŸ›¡ï¸ æ£€æµ‹åˆ°é«˜æƒé‡åŠ¨ä½œæè¿°ï¼ˆä½ç½®{i}ï¼Œæƒé‡{weight:.2f}ï¼‰ï¼Œå°†åœ¨ä¼˜åŒ–åæ£€æŸ¥å¹¶ä¿æŠ¤")  # å‡å°‘æ—¥å¿—
            
            # 3. ä¿æŠ¤é«˜æƒé‡ç¯å¢ƒæè¿°ï¼ˆæƒé‡ >= 1.8 æˆ–åŒ…å«å…³é”®ç¯å¢ƒè¯ï¼‰
            key_environment_keywords = ["desert", "sand", "forest", "mountain", "valley", "ocean", "sea", "river", "lake", "cave", "temple", "palace"]
            has_key_env = any(kw in part_lower for kw in key_environment_keywords)
            
            if (weight >= 1.8 or has_key_env) and "action" not in part_lower[:20]:  # æ’é™¤åŠ¨ä½œæè¿°ï¼ˆå·²åœ¨ä¸Šé¢å¤„ç†ï¼‰
                # æ£€æŸ¥æ˜¯å¦å·²ç»ä½œä¸ºåŠ¨ä½œ+ç¯å¢ƒç»„åˆè¢«ä¿æŠ¤
                is_already_protected = any(part == pc["content"] for pc in protected_contents)
                if not is_already_protected:
                    protected_contents.append({
                        "content": part,
                        "type": "high_weight_environment",
                        "priority": 2 if weight >= 2.0 else 3,
                        "keywords": [kw for kw in key_environment_keywords if kw in part_lower]
                    })
                    # print(f"  ğŸ›¡ï¸ æ£€æµ‹åˆ°é«˜æƒé‡ç¯å¢ƒæè¿°ï¼ˆä½ç½®{i}ï¼Œæƒé‡{weight:.2f}ï¼‰ï¼Œå°†åœ¨ä¼˜åŒ–åæ£€æŸ¥å¹¶ä¿æŠ¤")  # å‡å°‘æ—¥å¿—
        
        # å¦‚æœä¼°ç®—è¶…è¿‡ 60 tokensï¼ˆç•™å‡ºå®‰å…¨è¾¹ç•Œï¼Œç¡®ä¿ä¸è¶…è¿‡77ï¼‰ï¼Œä½¿ç”¨æ™ºèƒ½ä¼˜åŒ–
        # ä»70é™ä½åˆ°60ï¼Œå› ä¸ºå®é™…tokenizerè®¡ç®—å¯èƒ½æ¯”ä¼°ç®—å€¼é«˜ï¼Œéœ€è¦æ›´å¤šå®‰å…¨è¾¹ç•Œ
        if estimated_tokens > 60:
            # å°è¯•ä½¿ç”¨æ™ºèƒ½ä¼˜åŒ–ï¼ˆåŸºäºè¯­ä¹‰é‡è¦æ€§ï¼‰
            # print(f"  ğŸ§  Prompt è¿‡é•¿ ({estimated_tokens} tokens)ï¼Œå°è¯•æ™ºèƒ½ä¼˜åŒ–...")  # å‡å°‘æ—¥å¿—
            optimized_parts = self.optimizer.optimize(priority_parts, max_tokens=60)
            if len(optimized_parts) < len(priority_parts):
                # æ£€æŸ¥æ‰€æœ‰ä¿æŠ¤çš„å†…å®¹æ˜¯å¦ä»ç„¶å­˜åœ¨
                for protected in protected_contents:
                    content = protected["content"]
                    keywords = protected["keywords"]
                    content_type = protected["type"]
                    priority = protected["priority"]
                    
                    # æ£€æŸ¥æ˜¯å¦ä»ç„¶å­˜åœ¨ï¼ˆå®Œå…¨åŒ¹é…æˆ–åŒ…å«å…³é”®è¯ï¼‰
                    still_present = any(
                        content == part or 
                        any(kw in part.lower() for kw in keywords)
                        for part in optimized_parts
                    )
                    
                    if not still_present:
                        # æ ¹æ®ä¼˜å…ˆçº§å†³å®šæ’å…¥ä½ç½®
                        if priority == 1:  # è§’è‰²æ¨¡æ¿ï¼šæ’å…¥åˆ°å‰é¢
                            insert_pos = min(1, len(optimized_parts)) if len(optimized_parts) > 0 else 0
                            optimized_parts.insert(insert_pos, content)
                            # print(f"  âš  {content_type}è¢«ä¼˜åŒ–å™¨ç§»é™¤ï¼Œå·²å¼ºåˆ¶åŠ å›ï¼ˆä½ç½®{insert_pos}ï¼Œä¼˜å…ˆçº§{priority}ï¼‰")  # å‡å°‘æ—¥å¿—
                        elif priority == 2:  # é«˜ä¼˜å…ˆçº§ï¼šæ’å…¥åˆ°å‰é¢
                            insert_pos = min(2, len(optimized_parts)) if len(optimized_parts) > 0 else 0
                            optimized_parts.insert(insert_pos, content)
                            # print(f"  âš  {content_type}è¢«ä¼˜åŒ–å™¨ç§»é™¤ï¼Œå·²å¼ºåˆ¶åŠ å›ï¼ˆä½ç½®{insert_pos}ï¼Œä¼˜å…ˆçº§{priority}ï¼‰")  # å‡å°‘æ—¥å¿—
                        else:  # æ™®é€šä¼˜å…ˆçº§ï¼šè¿½åŠ åˆ°åé¢
                            optimized_parts.append(content)
                            # print(f"  âš  {content_type}è¢«ä¼˜åŒ–å™¨ç§»é™¤ï¼Œå·²å¼ºåˆ¶åŠ å›ï¼ˆä¼˜å…ˆçº§{priority}ï¼‰")  # å‡å°‘æ—¥å¿—
                
                # ä¿æŠ¤Sceneå±‚é£æ ¼
                style_still_present = scene_style_text and any(scene_style_text in part or "xianxia anime" in part.lower() for part in optimized_parts)
                if not style_still_present and scene_style_text:
                    optimized_parts.append(scene_style_text)
                    # print(f"  âš  Sceneå±‚é£æ ¼è¢«ä¼˜åŒ–å™¨ç§»é™¤ï¼Œå·²å¼ºåˆ¶åŠ å›")  # å‡å°‘æ—¥å¿—
                
                priority_parts = optimized_parts
                priority_prompt = ", ".join(filter(None, priority_parts))
                estimated_tokens = self.token_estimator.estimate(priority_prompt)
                # print(f"  âœ“ æ™ºèƒ½ä¼˜åŒ–å®Œæˆ: {len(optimized_parts)} ä¸ªéƒ¨åˆ†ï¼Œ{estimated_tokens} tokensï¼ˆå…³é”®å†…å®¹å·²ä¿æŠ¤ï¼‰")  # å‡å°‘æ—¥å¿—
            else:
                # å¦‚æœæ™ºèƒ½ä¼˜åŒ–æ²¡æœ‰æ•ˆæœï¼Œä½¿ç”¨ä¼ ç»Ÿç²¾ç®€æ–¹æ³•
                print(f"  âš  æ™ºèƒ½ä¼˜åŒ–æœªè¾¾åˆ°é¢„æœŸï¼Œä½¿ç”¨ä¼ ç»Ÿç²¾ç®€æ–¹æ³•...")
        
        # ç¡®ä¿ä»™ä¾ é£æ ¼æè¿°ä¸ä¼šè¢«ä¼˜åŒ–é˜¶æ®µå‰”é™¤ï¼ˆä»…å¯¹éç§‘æ™®è§†é¢‘ï¼‰
        # ä½†åªæ·»åŠ ç®€å•çš„é£æ ¼å…³é”®è¯ï¼Œå®Œæ•´çš„Sceneå±‚é£æ ¼åº”è¯¥åœ¨å‰é¢
        if not is_kepu_video:
            has_any_style = any(self._has_xianxia_keyword(part) or (scene_style_text and scene_style_text in part) for part in priority_parts)
            if not has_any_style:
                # å¦‚æœæ²¡æœ‰å®Œæ•´çš„Sceneå±‚é£æ ¼ï¼Œè‡³å°‘æ·»åŠ ç®€å•é£æ ¼å…³é”®è¯
                simple_style = "xianxia fantasy" if not use_chinese else "ä»™ä¾ é£æ ¼"
                priority_parts.insert(0, simple_style)
                priority_prompt = ", ".join(filter(None, priority_parts))
                estimated_tokens = self.token_estimator.estimate(priority_prompt)
                print("  âœ“ æ™ºèƒ½ä¼˜åŒ–åè¡¥å›ä»™ä¾ é£æ ¼æç¤ºï¼ˆç®€å•å…³é”®è¯ï¼‰ï¼Œç¡®ä¿é£æ ¼ä¸€è‡´")
        
        # æ³¨æ„ï¼šç”±äºå®Œæ•´è¿ç§»æ‰€æœ‰tokenä¼˜åŒ–å’Œç²¾ç®€é€»è¾‘éœ€è¦çº¦600è¡Œä»£ç ï¼Œè¿™é‡Œå…ˆå®ç°åŸºæœ¬é€»è¾‘
        # å®Œæ•´å®ç°éœ€è¦ä» ImageGenerator.build_prompt() ä¸­è¿ç§»ï¼ˆline 2960-3362ï¼‰
        # TODO: å®Œæ•´è¿ç§»tokenä¼˜åŒ–å’Œç²¾ç®€é€»è¾‘
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ä¸è¶…è¿‡ 77 tokens
        final_estimated = self.token_estimator.estimate(priority_prompt)
        
        # å¦‚æœ tokenizer å¯ç”¨ï¼Œä½¿ç”¨çœŸå®è®¡ç®—ï¼›å¦åˆ™ä½¿ç”¨ä¼°ç®—
        if self._clip_tokenizer is not None:
            try:
                tokens = self._clip_tokenizer(priority_prompt, truncation=False, return_tensors="pt")
                final_estimated = tokens.input_ids.shape[1]
                print(f"  âœ“ ä½¿ç”¨çœŸå® tokenizer è®¡ç®—: {final_estimated} tokens")
            except Exception as e:
                print(f"  âš  Tokenizer æœ€ç»ˆéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—: {e}")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœä»ç„¶è¶…è¿‡77 tokensï¼Œè¿›è¡Œå¼ºåˆ¶ç²¾ç®€
        if final_estimated > 77:
            print(f"  âš  è­¦å‘Š: Prompt æœ€ç»ˆé•¿åº¦ ({final_estimated} tokens) è¶…è¿‡ 77 tokens é™åˆ¶ï¼Œè¿›è¡Œå¼ºåˆ¶ç²¾ç®€...")
            # å¼ºåˆ¶ç²¾ç®€ï¼šåªä¿ç•™æœ€å…³é”®çš„éƒ¨åˆ†
            # 1. ä¿ç•™è§’è‰²æ¨¡æ¿ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # 2. ä¿ç•™é«˜æƒé‡åŠ¨ä½œ+ç¯å¢ƒç»„åˆï¼ˆæƒé‡ >= 2.0ï¼‰
            # 3. ä¿ç•™é«˜æƒé‡ç¯å¢ƒæè¿°ï¼ˆæƒé‡ >= 2.0ï¼‰
            # 4. ä¿ç•™é£æ ¼æè¿°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            essential_parts = []
            style_part = None
            single_person_part = None
            
            # æå–å¹¶ä¿ç•™æœ€å…³é”®çš„å†…å®¹
            for part in priority_parts:
                part_lower = part.lower()
                import re
                weight_match = re.search(r':([\d.]+)\)', part)
                weight = float(weight_match.group(1)) if weight_match else 1.0
                
                # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä¿ç•™é£æ ¼æè¿°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç¡®ä¿é£æ ¼æ­£ç¡®ï¼‰
                if any(kw in part_lower for kw in ["xianxia", "anime", "cinematic", "illustration", "ä»™ä¾ ", "åŠ¨æ¼«"]):
                    if style_part is None:  # åªä¿ç•™ç¬¬ä¸€ä¸ªé£æ ¼æè¿°
                        style_part = part
                        print(f"  âœ“ ä¿ç•™é£æ ¼æè¿°: {part[:60]}...")
                    continue
                
                # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä¿ç•™single personçº¦æŸï¼ˆç¬¬äºŒä¼˜å…ˆçº§ï¼Œç¡®ä¿å•äººï¼‰
                if "single person" in part_lower or "only one" in part_lower or "å•äºº" in part_lower:
                    if single_person_part is None:  # åªä¿ç•™ç¬¬ä¸€ä¸ªsingle personçº¦æŸ
                        single_person_part = part
                        print(f"  âœ“ ä¿ç•™single personçº¦æŸ: {part[:60]}...")
                    continue
                
                # ä¿ç•™è§’è‰²æ¨¡æ¿
                if any(kw in part_lower for kw in ["young male cultivator", "chinese xianxia novel", "slim but resilient", "cultivator", "robe", "dark green"]):
                    essential_parts.append(part)
                    continue
                
                # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä¿ç•™å…³é”®åŠ¨ä½œï¼ˆlying/sitting/standingï¼‰ï¼Œæ— è®ºæ˜¯å¦æœ‰ç¯å¢ƒæè¿°
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®åŠ¨ä½œå…³é”®è¯
                has_lying = any(kw in part_lower for kw in ["lying", "lie", "èºº", "horizontal position", "prone", "supine"])
                has_sitting = any(kw in part_lower for kw in ["sitting", "sit", "å", "seated"])
                has_standing = any(kw in part_lower for kw in ["standing", "stand", "ç«™", "upright"])
                
                # å¦‚æœåŒ…å«å…³é”®åŠ¨ä½œï¼Œå¿…é¡»ä¿ç•™ï¼ˆé™ä½æƒé‡é˜ˆå€¼åˆ°1.5ï¼Œç¡®ä¿lyingæè¿°è¢«ä¿ç•™ï¼‰
                if has_lying or has_sitting or has_standing:
                    if weight >= 1.5:  # é™ä½é˜ˆå€¼ï¼Œç¡®ä¿lyingæè¿°è¢«ä¿ç•™
                        essential_parts.append(part)
                        print(f"  âœ“ ä¿ç•™å…³é”®åŠ¨ä½œæè¿°ï¼ˆæƒé‡{weight:.2f}ï¼‰: {part[:60]}...")
                        continue
                
                # ä¿ç•™é«˜æƒé‡åŠ¨ä½œ+ç¯å¢ƒç»„åˆï¼ˆæƒé‡ >= 2.0ï¼‰
                key_action_patterns = [
                    r"lying\s+on\s+(sand|desert|ground)",
                    r"sitting\s+on\s+(sand|desert|ground|rock)",
                    r"standing\s+on\s+(sand|desert|ground|rock|mountain)",
                ]
                has_key_action_env = any(re.search(pattern, part_lower) for pattern in key_action_patterns)
                if has_key_action_env and weight >= 2.0:
                    essential_parts.append(part)
                    continue
                
                # ä¿ç•™é«˜æƒé‡ç¯å¢ƒæè¿°ï¼ˆæƒé‡ >= 2.0ï¼‰
                key_env_keywords = ["desert", "sand", "forest", "mountain", "valley"]
                has_key_env = any(kw in part_lower for kw in key_env_keywords)
                if has_key_env and weight >= 2.0:
                    essential_parts.append(part)
                    continue
                
                # å…¶ä»–éƒ¨åˆ†ç»§ç»­å¤„ç†ï¼ˆsingle personå·²åœ¨å‰é¢å¤„ç†ï¼‰
                continue
            
            # âš¡ å…³é”®ä¿®å¤ï¼šç¡®ä¿é£æ ¼å’Œsingle personçº¦æŸåœ¨æœ€å‰é¢ï¼ˆæŒ‰æ­£ç¡®é¡ºåºï¼‰
            # 1. é£æ ¼æè¿°ï¼ˆç¬¬0ä½ï¼‰
            if style_part:
                essential_parts.insert(0, style_part)
            elif not any("xianxia" in p.lower() or "anime" in p.lower() for p in essential_parts):
                essential_parts.insert(0, "Chinese xianxia anime illustration, anime cinematic style")
            
            # 2. single personçº¦æŸï¼ˆç¬¬1ä½ï¼Œé£æ ¼ä¹‹åï¼‰
            if single_person_part:
                essential_parts.insert(1, single_person_part)
            elif include_character:  # å¦‚æœæ˜¯äººç‰©åœºæ™¯ä½†æ²¡æœ‰single personçº¦æŸï¼Œå¼ºåˆ¶æ·»åŠ 
                essential_parts.insert(1, "(single person:2.5)")
                print(f"  âœ“ å¼ºåˆ¶æ·»åŠ single personçº¦æŸï¼ˆç¡®ä¿å•äººï¼‰")
            
            # é‡æ–°ç»„åˆ
            priority_prompt = ", ".join(filter(None, essential_parts))
            final_estimated = self.token_estimator.estimate(priority_prompt)
            
            # å¦‚æœä»ç„¶è¶…è¿‡ï¼Œè¿›ä¸€æ­¥ç²¾ç®€è§’è‰²æ¨¡æ¿
            if final_estimated > 77:
                print(f"  âš  å¼ºåˆ¶ç²¾ç®€åä»è¶…è¿‡é™åˆ¶ ({final_estimated} tokens)ï¼Œè¿›ä¸€æ­¥ç²¾ç®€è§’è‰²æ¨¡æ¿...")
                # ç²¾ç®€è§’è‰²æ¨¡æ¿ï¼šä¿ç•™å…³é”®ç‰¹å¾ï¼ˆæœé¥°ã€å‘å‹ã€è§’è‰²ç±»å‹ï¼‰
                simplified_parts = []
                style_part_simplified = None
                single_person_part_simplified = None
                
                for part in essential_parts:
                    part_lower = part.lower()
                    # âš¡ å…³é”®ä¿®å¤ï¼šä¿ç•™é£æ ¼æè¿°ï¼ˆä¸ç²¾ç®€ï¼Œæ”¾åœ¨æœ€å‰é¢ï¼‰
                    if any(kw in part_lower for kw in ["xianxia", "anime", "cinematic", "illustration"]):
                        if style_part_simplified is None:
                            style_part_simplified = part
                        continue
                    
                    # âš¡ å…³é”®ä¿®å¤ï¼šä¿ç•™single personçº¦æŸï¼ˆä¸ç²¾ç®€ï¼Œæ”¾åœ¨ç¬¬äºŒä½ï¼‰
                    if "single person" in part_lower or "only one" in part_lower or "å•äºº" in part_lower:
                        if single_person_part_simplified is None:
                            single_person_part_simplified = part
                        continue
                    
                    if any(kw in part_lower for kw in ["young male cultivator", "chinese xianxia novel", "slim but resilient"]):
                        # âš¡ å…³é”®ä¿®å¤ï¼šä¿ç•™æ›´å¤šå…³é”®ç‰¹å¾ï¼Œç¡®ä¿é£æ ¼æ­£ç¡®
                        # ä¿ç•™ï¼šè§’è‰²ç±»å‹ã€æœé¥°ã€å‘å‹ã€åŸºæœ¬ç‰¹å¾
                        simplified_parts.append("young male cultivator, (dark green simple cultivator robe:2.0), long black hair, slim build, calm expression")
                    else:
                        simplified_parts.append(part)
                
                # âš¡ ç¡®ä¿é£æ ¼å’Œsingle personçº¦æŸåœ¨æœ€å‰é¢ï¼ˆæŒ‰æ­£ç¡®é¡ºåºï¼‰
                # 1. é£æ ¼æè¿°ï¼ˆç¬¬0ä½ï¼‰
                if style_part_simplified:
                    simplified_parts.insert(0, style_part_simplified)
                elif not any("xianxia" in p.lower() or "anime" in p.lower() for p in simplified_parts):
                    simplified_parts.insert(0, "Chinese xianxia anime illustration, anime cinematic style")
                
                # 2. single personçº¦æŸï¼ˆç¬¬1ä½ï¼Œé£æ ¼ä¹‹åï¼‰
                if single_person_part_simplified:
                    simplified_parts.insert(1, single_person_part_simplified)
                elif include_character:  # å¦‚æœæ˜¯äººç‰©åœºæ™¯ä½†æ²¡æœ‰single personçº¦æŸï¼Œå¼ºåˆ¶æ·»åŠ 
                    simplified_parts.insert(1, "(single person:2.5)")
                
                priority_prompt = ", ".join(filter(None, simplified_parts))
                final_estimated = self.token_estimator.estimate(priority_prompt)
            
            # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœä»ç„¶è¶…è¿‡77ï¼Œè¿›è¡Œæœ€ç»ˆå¼ºåˆ¶ç²¾ç®€ï¼Œç¡®ä¿ä¸è¶…è¿‡77
            if final_estimated > 77:
                print(f"  âš  æœ€ç»ˆç²¾ç®€åä»è¶…è¿‡é™åˆ¶ ({final_estimated} tokens)ï¼Œè¿›è¡Œæœ€ç»ˆå¼ºåˆ¶ç²¾ç®€...")
                # æœ€ç»ˆç²¾ç®€ï¼šåªä¿ç•™æœ€æ ¸å¿ƒçš„å†…å®¹ï¼Œç¡®ä¿ä¸è¶…è¿‡77 tokens
                final_parts = []
                
                # 1. å¿…é¡»ä¿ç•™ï¼šé£æ ¼æè¿°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæ”¾åœ¨æœ€å‰é¢ï¼‰
                style_found = False
                for part in simplified_parts if 'simplified_parts' in locals() else essential_parts:
                    if any(kw in part.lower() for kw in ["xianxia", "anime", "cinematic", "illustration"]) and not style_found:
                        # ç²¾ç®€ä¸ºæœ€çŸ­å½¢å¼
                        final_parts.insert(0, "Chinese xianxia anime illustration, anime cinematic style")
                        style_found = True
                        continue
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é£æ ¼ï¼Œå¼ºåˆ¶æ·»åŠ 
                if not style_found:
                    final_parts.insert(0, "Chinese xianxia anime illustration, anime cinematic style")
                
                # 2. å¿…é¡»ä¿ç•™ï¼šsingle personçº¦æŸï¼ˆç¬¬äºŒä¼˜å…ˆçº§ï¼Œæ”¾åœ¨é£æ ¼ä¹‹åï¼‰
                single_person_found = False
                for part in simplified_parts if 'simplified_parts' in locals() else essential_parts:
                    if "single person" in part.lower() and not single_person_found:
                        # ç²¾ç®€ä¸ºæœ€çŸ­å½¢å¼ï¼Œä½†ä¿æŒé«˜æƒé‡
                        final_parts.insert(1, "(single person:2.5)")  # æé«˜æƒé‡åˆ°2.5ï¼Œæ”¾åœ¨é£æ ¼ä¹‹å
                        single_person_found = True
                        continue
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°single personï¼Œå¼ºåˆ¶æ·»åŠ 
                if not single_person_found:
                    final_parts.insert(1, "(single person:2.5)")
                
                # 3. âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä¿ç•™å…³é”®åŠ¨ä½œï¼ˆlying/sitting/standingï¼‰ï¼Œæ— è®ºæƒé‡
                # æ£€æŸ¥æ˜¯å¦æœ‰lying/sitting/standingç­‰å…³é”®åŠ¨ä½œ
                has_lying_action = False
                lying_action_text = None
                for part in simplified_parts if 'simplified_parts' in locals() else essential_parts:
                    part_lower = part.lower()
                    import re
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®åŠ¨ä½œ
                    if any(kw in part_lower for kw in ["lying", "lie", "èºº", "horizontal position", "prone", "supine"]):
                        has_lying_action = True
                        # æå–lyingç›¸å…³çš„æè¿°
                        if "lying on" in part_lower or "lie on" in part_lower:
                            # æå–å®Œæ•´çš„lyingæè¿°
                            lying_match = re.search(r'(lying\s+on\s+[^,\)]+|lie\s+on\s+[^,\)]+)', part_lower)
                            if lying_match:
                                lying_action_text = f"(lying on desert sand:2.5)"  # ä½¿ç”¨é«˜æƒé‡ç¡®ä¿ä¿ç•™
                            else:
                                lying_action_text = f"(lying on desert sand:2.5)"
                        else:
                            # âš¡ å…³é”®ä¿®å¤ï¼šå³ä½¿æ²¡æœ‰"lying on"æ ¼å¼ï¼Œåªè¦æœ‰"lying"å…³é”®è¯ï¼Œä¹Ÿè¦æ·»åŠ lyingæè¿°
                            # æ£€æŸ¥ç¯å¢ƒæè¿°ï¼Œç¡®å®šlyingçš„ä½ç½®
                            has_desert = any("desert" in p.lower() or "sand" in p.lower() for p in (simplified_parts if 'simplified_parts' in locals() else essential_parts))
                            if has_desert:
                                # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sitting
                                lying_action_text = "(body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:3.0)"
                            else:
                                # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sitting
                                lying_action_text = "(body fully on the ground, legs fully extended, arms lying flat, no bent knees, horizontal position:3.0)"
                        break
                
                # âš¡ ä¿®å¤ï¼šå¦‚æœæœ‰lyingåŠ¨ä½œï¼Œå¿…é¡»æ·»åŠ åˆ°final_partsçš„æœ€å‰é¢ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                if has_lying_action:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨lyingæè¿°
                    has_lying_in_final = any("lying" in str(p).lower() or "lie" in str(p).lower() for p in final_parts)
                    if not has_lying_in_final:
                        # æ’å…¥åˆ°æœ€å‰é¢ï¼Œç¡®ä¿æœ€é«˜ä¼˜å…ˆçº§
                        # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sitting
                        final_parts.insert(0, "(body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:3.0)")
                        print(f"  âœ“ å¼ºåˆ¶åœ¨promptæœ€å‰é¢æ·»åŠ lyingæè¿°ï¼ˆæƒé‡3.0ï¼Œæœ€é«˜ä¼˜å…ˆçº§ï¼‰")
                    else:
                        # å¦‚æœå·²å­˜åœ¨ï¼Œæ£€æŸ¥æƒé‡æ˜¯å¦è¶³å¤Ÿé«˜
                        for i, part in enumerate(final_parts):
                            if "lying" in str(part).lower() or "lie" in str(part).lower():
                                # æå–æƒé‡
                                import re
                                weight_match = re.search(r':([\d.]+)\)', str(part))
                                if weight_match:
                                    weight = float(weight_match.group(1))
                                    if weight < 3.0:
                                        # æ›¿æ¢ä¸ºé«˜æƒé‡ç‰ˆæœ¬
                                        # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ NOT sitting
                                        final_parts[i] = "(body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:3.0)"
                                        print(f"  âœ“ æå‡lyingæè¿°æƒé‡åˆ°3.0ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰")
                                break
                
                # 3. ä¿ç•™ï¼šé«˜æƒé‡åŠ¨ä½œ+ç¯å¢ƒç»„åˆï¼ˆæƒé‡ >= 1.8ï¼Œé™ä½é˜ˆå€¼ä»¥ä¿ç•™æ›´å¤šå…³é”®ä¿¡æ¯ï¼‰
                for part in simplified_parts if 'simplified_parts' in locals() else essential_parts:
                    part_lower = part.lower()
                    import re
                    weight_match = re.search(r':([\d.]+)\)', part)
                    weight = float(weight_match.group(1)) if weight_match else 1.0
                    
                    # è·³è¿‡single personï¼ˆå·²å¤„ç†ï¼‰
                    if "single person" in part_lower:
                        continue
                    
                    # è·³è¿‡lyingï¼ˆå·²å¤„ç†ï¼‰
                    if "lying" in part_lower or "lie" in part_lower:
                        continue
                    
                    # ä¿ç•™é«˜æƒé‡åŠ¨ä½œ+ç¯å¢ƒç»„åˆï¼ˆé™ä½é˜ˆå€¼åˆ°1.8ï¼‰
                    key_action_patterns = [
                        r"sitting\s+on\s+(sand|desert|ground)",
                        r"standing\s+on\s+(sand|desert|ground)",
                    ]
                    has_key_action_env = any(re.search(pattern, part_lower) for pattern in key_action_patterns)
                    if has_key_action_env and weight >= 1.8:
                        # ç²¾ç®€ä¸ºæœ€çŸ­å½¢å¼
                        if "(sitting on" not in str(final_parts) and "(standing on" not in str(final_parts):
                            if "sitting" in part_lower:
                                final_parts.append("(sitting on desert sand:2.0)")
                            elif "standing" in part_lower:
                                final_parts.append("(standing on desert sand:2.0)")
                        continue
                    
                    # ä¿ç•™é«˜æƒé‡ç¯å¢ƒæè¿°ï¼ˆæƒé‡ >= 1.8ï¼Œé™ä½é˜ˆå€¼ï¼‰
                    if any(kw in part_lower for kw in ["desert", "sand"]) and weight >= 1.8:
                        # ç²¾ç®€ä¸ºæœ€çŸ­å½¢å¼
                        if "desert" in part_lower and "(desert" not in str(final_parts) and "(gray-green desert" not in str(final_parts):
                            final_parts.append("(gray-green desert:2.0)")
                        continue
                
                # 4. âš¡ å…³é”®ä¿®å¤ï¼šå¿…é¡»ä¿ç•™è§’è‰²æè¿°ï¼ˆåŒ…æ‹¬æœé¥°ï¼‰ï¼Œç¡®ä¿ä¸ä¼šç”Ÿæˆå…‰ç€ä¸Šèº«çš„å›¾åƒ
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰è§’è‰²æè¿°
                has_character_desc = any("cultivator" in str(p).lower() or "robe" in str(p).lower() for p in final_parts)
                if not has_character_desc:
                    # å¿…é¡»æ·»åŠ è§’è‰²æè¿°ï¼ˆåŒ…æ‹¬æœé¥°ï¼‰ï¼Œè¿™æ˜¯æ ¸å¿ƒç‰¹å¾
                    final_parts.append("young male cultivator, (dark green simple cultivator robe:2.0), long black hair")
                else:
                    # å¦‚æœå·²æœ‰è§’è‰²æè¿°ï¼Œç¡®ä¿åŒ…å«æœé¥°
                    for i, part in enumerate(final_parts):
                        if "cultivator" in part.lower() and "robe" not in part.lower():
                            # åœ¨è§’è‰²æè¿°ä¸­æ·»åŠ æœé¥°
                            final_parts[i] = part + ", (dark green simple cultivator robe:2.0)"
                            break
                
                priority_prompt = ", ".join(filter(None, final_parts))
                final_estimated = self.token_estimator.estimate(priority_prompt)
                
                # å¦‚æœä»ç„¶è¶…è¿‡ï¼Œåªä¿ç•™æœ€æ ¸å¿ƒçš„ï¼ˆä½†å¿…é¡»åŒ…å«é£æ ¼å’Œæœé¥°ï¼‰
                if final_estimated > 77:
                    print(f"  âš  æœ€ç»ˆç²¾ç®€åä»è¶…è¿‡é™åˆ¶ ({final_estimated} tokens)ï¼Œåªä¿ç•™æœ€æ ¸å¿ƒå†…å®¹ï¼ˆå¿…é¡»åŒ…å«é£æ ¼å’Œæœé¥°ï¼‰...")
                    # æœ€ç²¾ç®€ç‰ˆæœ¬ï¼šå¿…é¡»åŒ…å«é£æ ¼ã€è§’è‰²ã€æœé¥°ã€åŠ¨ä½œã€ç¯å¢ƒ
                    # âš¡ å…³é”®ä¿®å¤ï¼šå¢å¼ºé£æ ¼æè¿°å’Œå•äººçº¦æŸï¼ˆwide + top_down + lying åœºæ™¯æ²¡æœ‰ LoRAï¼Œéœ€è¦æ›´å¼ºçš„é£æ ¼å’Œçº¦æŸï¼‰
                    # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ "lying on desert sand"ï¼ˆSDXL å¯¹ç‰©ç†æ¥è§¦æè¿°æ›´æ•æ„Ÿï¼‰
                    priority_prompt = "Chinese xianxia anime illustration, 3D rendered anime, anime cinematic style, cinematic lighting, (single person:3.0), (only one person:3.0), young male cultivator, (dark green simple cultivator robe:2.0), (body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:3.0), (gray-green desert:2.0)"
                    final_estimated = self.token_estimator.estimate(priority_prompt)
                    
                    # å¦‚æœä»ç„¶è¶…è¿‡ï¼Œè¿›ä¸€æ­¥ç²¾ç®€ï¼ˆä½†ä¿ç•™é£æ ¼å’Œæœé¥°ï¼‰
                    if final_estimated > 77:
                        print(f"  âš  æœ€ç²¾ç®€ç‰ˆæœ¬ä»è¶…è¿‡é™åˆ¶ ({final_estimated} tokens)ï¼Œä½¿ç”¨æç®€ç‰ˆæœ¬ï¼ˆä¿ç•™é£æ ¼å’Œæœé¥°ï¼‰...")
                        # âš¡ å…³é”®ä¿®å¤ï¼šå¢å¼ºé£æ ¼æè¿°å’Œå•äººçº¦æŸ
                        # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ "lying on desert sand"
                        priority_prompt = "Chinese xianxia anime illustration, 3D rendered anime, anime cinematic style, (single person:3.0), (only one person:3.0), young male cultivator, (dark green robe:2.0), (body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:3.0), (desert:2.0)"
                        final_estimated = self.token_estimator.estimate(priority_prompt)
                        
                        # å¦‚æœä»ç„¶è¶…è¿‡ï¼Œä½¿ç”¨æœ€æç®€ç‰ˆæœ¬ï¼ˆä½†å¿…é¡»åŒ…å«é£æ ¼å’Œæœé¥°ï¼‰
                        if final_estimated > 77:
                            print(f"  âš  æç®€ç‰ˆæœ¬ä»è¶…è¿‡é™åˆ¶ ({final_estimated} tokens)ï¼Œä½¿ç”¨æœ€æç®€ç‰ˆæœ¬ï¼ˆä¿ç•™é£æ ¼å’Œæœé¥°ï¼‰...")
                            # âš¡ å…³é”®ä¿®å¤ï¼šå¢å¼ºé£æ ¼æè¿°å’Œå•äººçº¦æŸ
                            # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°è€Œä¸æ˜¯ "lying on desert sand"
                            priority_prompt = "Chinese xianxia anime illustration, 3D rendered anime, anime cinematic style, (single person:3.0), (only one person:3.0), (dark green robe:2.0), (body fully on the ground, back touching the sand, legs fully extended on the ground, arms lying flat on the sand, no bent knees, horizontal position:3.0), (desert:2.0)"
                            final_estimated = self.token_estimator.estimate(priority_prompt)
            
            # print(f"  âœ“ å¼ºåˆ¶ç²¾ç®€å®Œæˆ: {final_estimated} tokensï¼ˆä¿ç•™æœ€å…³é”®ä¿¡æ¯ï¼‰")  # å‡å°‘æ—¥å¿—
        
        full_prompt = priority_prompt
        
        if not full_prompt:
            # é»˜è®¤fallback promptï¼Œä½¿ç”¨ä¸­æ–‡ï¼ˆå› ä¸ºç”¨æˆ·è¦æ±‚ä½¿ç”¨ä¸­æ–‡ï¼‰ï¼Œä¸é™å®šå…·ä½“åœºæ™¯
            if not self.ascii_only_prompt:
                full_prompt = "ä»™ä¾ é£æ ¼ï¼Œä¿®ä»™ä¸–ç•Œï¼Œçµæ°”èƒ½é‡ï¼Œè¯¦ç»†æ’ç”»"
            else:
                full_prompt = "xianxia fantasy, cultivation world, spiritual energy, detailed illustration"
        
        # ä½¿ç”¨å‡†ç¡®çš„tokenizerè®¡ç®—æœ€ç»ˆtokenæ•°ï¼ˆå¿…é¡»ä½¿ç”¨çœŸå®è®¡ç®—ï¼‰
        final_tokens = self.token_estimator.estimate(priority_prompt)
        # å¦‚æœ tokenizer å¯ç”¨ï¼Œå¼ºåˆ¶ä½¿ç”¨çœŸå®è®¡ç®—
        if self._clip_tokenizer is not None:
            try:
                tokens = self._clip_tokenizer(priority_prompt, truncation=False, return_tensors="pt")
                final_tokens = tokens.input_ids.shape[1]
                print(f"  âœ“ ä½¿ç”¨çœŸå® tokenizer è®¡ç®—: {final_tokens} tokens")
            except Exception as e:
                print(f"  âš  Tokenizer æœ€ç»ˆéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—: {e}")
        
        if final_tokens > 77:
            print(f"  âš  è­¦å‘Š: Prompt æœ€ç»ˆé•¿åº¦ ({final_tokens} tokens) è¶…è¿‡ 77 tokens é™åˆ¶ï¼Œå°†è¢« CLIP è‡ªåŠ¨æˆªæ–­")
            print(f"  âš  å»ºè®®è¿›ä¸€æ­¥ç²¾ç®€ prompt ä»¥é¿å…ä¿¡æ¯ä¸¢å¤±")
        
        # å¦‚æœä½¿ç”¨ä¸­æ–‡ä¸”SDXLæ¨¡å‹å¯¹ä¸­æ–‡æ”¯æŒä¸å¥½ï¼Œè€ƒè™‘ç¿»è¯‘æˆè‹±æ–‡
        # ä½†å…ˆæ£€æŸ¥é…ç½®ï¼Œå¦‚æœé…ç½®å…è®¸ä¸­æ–‡ï¼Œå°±ä½¿ç”¨ä¸­æ–‡
        if not self.ascii_only_prompt:
            # ä½¿ç”¨ä¸­æ–‡prompt
            final_prompt = priority_prompt
            print(f"  â„¹ ä½¿ç”¨ä¸­æ–‡ promptï¼ˆSDXLå¯èƒ½ç†è§£ä¸ä½³ï¼Œå¦‚æœç”Ÿæˆæ•ˆæœä¸å¥½ï¼Œå»ºè®®è®¾ç½® ascii_only_prompt: trueï¼‰")
        else:
            # ç¿»è¯‘æˆè‹±æ–‡
            final_prompt = self._translate_chinese_to_english(priority_prompt)
            print(f"  â„¹ å·²ç¿»è¯‘ä¸ºè‹±æ–‡ prompt")
        
        # é‡æ–°è®¡ç®—æœ€ç»ˆpromptçš„tokenæ•°ï¼ˆä½¿ç”¨çœŸå®tokenizerï¼‰
        if self._clip_tokenizer is not None:
            try:
                tokens = self._clip_tokenizer(final_prompt, truncation=False, return_tensors="pt")
                final_tokens = tokens.input_ids.shape[1]
                print(f"  âœ“ ä½¿ç”¨çœŸå® tokenizer è®¡ç®—æœ€ç»ˆprompt: {final_tokens} tokens")
            except Exception as e:
                print(f"  âš  Tokenizer æœ€ç»ˆéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—: {e}")
        
        if final_tokens > 77:
            print(f"  âš  è­¦å‘Š: Prompt æœ€ç»ˆé•¿åº¦ ({final_tokens} tokens) è¶…è¿‡ 77 tokens é™åˆ¶ï¼Œå°†è¢« CLIP è‡ªåŠ¨æˆªæ–­")
            print(f"  âš  å»ºè®®è¿›ä¸€æ­¥ç²¾ç®€ prompt ä»¥é¿å…ä¿¡æ¯ä¸¢å¤±")
        
        part_count = len(priority_parts)
        print(f"  ğŸ“Š Prompt æœ€ç»ˆé•¿åº¦: {final_tokens} tokens (å…³é”®éƒ¨åˆ†: {part_count} é¡¹)")
        print(f"  ğŸ“Š Promptæ–‡æœ¬é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
        # ä¿®å¤ä¸­æ–‡ç¼–ç é—®é¢˜ï¼šä½¿ç”¨repræˆ–ç¡®ä¿UTF-8ç¼–ç 
        try:
            # å°è¯•ç›´æ¥æ‰“å°ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨repr
            print(f"  ğŸ“ æœ€ç»ˆPromptæ–‡æœ¬: {final_prompt}")
        except UnicodeEncodeError:
            # å¦‚æœé‡åˆ°ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨å®‰å…¨çš„æ‰“å°æ–¹å¼
            print(f"  ğŸ“ æœ€ç»ˆPromptæ–‡æœ¬: {final_prompt.encode('utf-8', errors='replace').decode('utf-8')}")
        # æ‰“å°æ¯ä¸ªéƒ¨åˆ†çš„è¯¦ç»†ä¿¡æ¯
        print(f"  ğŸ“‹ Promptç»„æˆéƒ¨åˆ† ({len(priority_parts)} é¡¹):")
        for i, part in enumerate(priority_parts, 1):
            part_tokens = self.token_estimator.estimate(part)
            # ä½¿ç”¨çœŸå®tokenizerè®¡ç®—æ¯ä¸ªéƒ¨åˆ†çš„tokenæ•°
            if self._clip_tokenizer is not None:
                try:
                    tokens_obj = self._clip_tokenizer(part, truncation=False, return_tensors="pt")
                    part_tokens = tokens_obj.input_ids.shape[1]
                except:
                    pass
            print(f"    {i}. [{part_tokens} tokens] {part[:80]}{'...' if len(part) > 80 else ''}")
        return final_prompt
    
    def _build_semantic_prompt_for_flux(self, scene: Dict[str, Any], intent: Dict[str, Any]) -> str:
        """
        FLUX ä¸“ç”¨è¯­ä¹‰åŒ– prompt æ„å»ºï¼ˆwide + top_down + lying åœºæ™¯ï¼‰
        
        ä½¿ç”¨è‡ªç„¶è¯­è¨€å¥å­è€Œä¸æ˜¯æƒé‡æ ‡è®°ï¼ŒFLUX å¯¹è¯­ä¹‰ç†è§£æ›´å¼º
        âš¡ å…³é”®ä¿®å¤ï¼šFLUX ä½¿ç”¨ T5 tokenizerï¼Œæ”¯æŒ 512+ tokensï¼Œä¸éœ€è¦ 77 token é™åˆ¶
        âš¡ å…³é”®ä¿®å¤ï¼šç®€åŒ– promptï¼Œè®© IP-Adapter çš„å‚è€ƒå›¾å‘æŒ¥ä¸»è¦ä½œç”¨
        """
        character = scene.get("character", {}) or {}
        character_pose = character.get("pose", "")
        visual_constraints = scene.get("visual_constraints", {}) or {}
        environment = visual_constraints.get("environment", "")
        camera = scene.get("camera", {}) or {}
        
        # âš¡ å…³é”®ä¿®å¤ï¼šç®€åŒ– promptï¼Œè®© IP-Adapter çš„å‚è€ƒå›¾å‘æŒ¥ä¸»è¦ä½œç”¨
        # FLUX IP-Adapter ä¼šä»å‚è€ƒå›¾ä¸­æå–å½¢è±¡ç‰¹å¾ï¼Œprompt åªéœ€è¦æè¿°åœºæ™¯å’Œå§¿æ€
        prompt_parts = []
        
        # 1. å§¿æ€æè¿°ï¼ˆä½¿ç”¨ç‰©ç†æ¥è§¦æè¿°ï¼Œæœ€é‡è¦ï¼‰
        if character_pose in ["lying_motionless", "lying"]:
            prompt_parts.append("lies motionless on a vast desert")
            prompt_parts.append("body fully on the ground, back touching the sand, legs fully extended, arms lying flat, no bent knees, horizontal position")
        
        # 2. ç¯å¢ƒæè¿°
        if environment:
            prompt_parts.append(f"on {environment}")
        else:
            prompt_parts.append("on a vast gray-green desert")
        
        # 3. é•œå¤´æè¿°
        camera_shot = camera.get("shot", "wide")
        camera_angle = camera.get("angle", "top_down")
        if camera_shot == "wide" and camera_angle == "top_down":
            prompt_parts.append("Wide top-down cinematic shot")
        
        # 4. é£æ ¼æè¿°ï¼ˆç®€åŒ–ï¼‰
        prompt_parts.append("Chinese xianxia anime style")
        
        # 5. å•äººçº¦æŸï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        prompt_parts.append("one person only, single character")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šä¸æ·»åŠ "å½¢è±¡ä¸€è‡´æ€§"æç¤ºï¼Œè®© IP-Adapter çš„å‚è€ƒå›¾å‘æŒ¥ä¸»è¦ä½œç”¨
        # IP-Adapter ä¼šè‡ªåŠ¨ä»å‚è€ƒå›¾ä¸­æå–å½¢è±¡ç‰¹å¾ï¼Œprompt åªéœ€è¦æè¿°åœºæ™¯
        
        # ç»„åˆæˆå®Œæ•´çš„è¯­ä¹‰åŒ– prompt
        semantic_prompt = ". ".join(prompt_parts) + "."
        
        print(f"  âœ“ FLUX è¯­ä¹‰åŒ– prompt æ„å»ºå®Œæˆï¼ˆç®€åŒ–ç‰ˆï¼Œè®© IP-Adapter å‚è€ƒå›¾å‘æŒ¥ä¸»è¦ä½œç”¨ï¼‰")
        print(f"  ğŸ“ è¯­ä¹‰åŒ– Prompt: {semantic_prompt}")
        print(f"  â„¹ FLUX ä½¿ç”¨ T5 tokenizerï¼Œæ”¯æŒ 512+ tokensï¼Œå½“å‰ prompt é•¿åº¦: {len(semantic_prompt.split())} words")
        
        return semantic_prompt
    
    def _clean_prompt_text(self, text: str) -> str:
        """æ¸…ç† prompt æ–‡æœ¬ï¼Œæ”¯æŒä¸­æ–‡"""
        text = (text or "").strip().strip('"')
        if not text:
            return ""
        
        if self.ascii_only_prompt:
            text = "".join(ch if ord(ch) < 128 else " " for ch in text)
            text = " ".join(t for t in text.split() if t)
        else:
            import re
            text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    def _has_xianxia_keyword(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä»™ä¾ ç›¸å…³å…³é”®è¯"""
        if not text:
            return False
        lowered = str(text).lower()
        return (
            any(
                kw in lowered
                for kw in [
                    "xianxia",
                    "immortal cultivator",
                    "cultivation world",
                    "celestial aura",
                    "spiritual energy",
                ]
            )
            or ("ä»™ä¾ " in str(text))
            or ("ä¿®ä»™" in str(text))
        )
    
    def _load_character_template(self, template_name: str) -> Optional[str]:
        """åŠ è½½è§’è‰²Promptæ¨¡æ¿æ–‡ä»¶ï¼ˆæ— é£æ ¼è¯ï¼Œçº¯äººç‰©æè¿°ï¼‰
        
        Args:
            template_name: æ¨¡æ¿æ–‡ä»¶åï¼ˆä¸å«.promptæ‰©å±•åï¼‰ï¼Œå¦‚"HanLi"
            
        Returns:
            æ¨¡æ¿å†…å®¹å­—ç¬¦ä¸²ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºpromptæ¨¡å—ç›®å½•ï¼‰
            current_file = Path(__file__)
            template_dir = current_file.parent / "templates"
            template_path = template_dir / f"{template_name}.prompt"
            
            if template_path.exists():
                with open(template_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    print(f"  âœ“ åŠ è½½è§’è‰²æ¨¡æ¿æ–‡ä»¶: {template_path}")
                    return content
            else:
                print(f"  âš  è§’è‰²æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
                return None
        except Exception as e:
            print(f"  âš  åŠ è½½è§’è‰²æ¨¡æ¿å¤±è´¥: {e}")
            return None
    
    def _get_character_profile(self, character_id: str = "hanli") -> Dict[str, Any]:
        """è·å–è§’è‰²æ¨¡æ¿"""
        # å¤„ç†ç§‘æ™®ä¸»æŒäººçš„æ˜ å°„
        if character_id in ["kepu_gege", "ç§‘æ™®å“¥å“¥"]:
            character_id = "kepu_gege"
        elif character_id in ["weilai_jiejie", "æœªæ¥å§å§"]:
            character_id = "weilai_jiejie"
        
        return self.character_profiles.get(character_id, {})
    
    def _get_scene_profile(
        self,
        scene_name: str = None,
        episode: int = None,
        profile_key: str = None,
        is_kepu_video: bool = False,
    ) -> Dict[str, Any]:
        """æ ¹æ®åœºæ™¯ keyã€åç§°æˆ–é›†æ•°è·å–åœºæ™¯æ¨¡æ¿
        
        Args:
            scene_name: åœºæ™¯åç§°
            episode: é›†æ•°
            profile_key: åœºæ™¯æ¨¡æ¿ key
            is_kepu_video: æ˜¯å¦ä¸ºç§‘æ™®è§†é¢‘ï¼ˆç§‘æ™®è§†é¢‘ä¸ä½¿ç”¨åœºæ™¯æ¨¡æ¿ï¼‰
        """
        # ç§‘æ™®è§†é¢‘ä¸ä½¿ç”¨åœºæ™¯æ¨¡æ¿ï¼Œç›´æ¥è¿”å›ç©ºå­—å…¸
        if is_kepu_video:
            return {}
        
        # 1. è‹¥æ˜¾å¼æŒ‡å®šæ¨¡æ¿ keyï¼Œç›´æ¥ç²¾ç¡®åŒ¹é…
        if profile_key:
            profile = self.scene_profiles.get(profile_key)
            if profile:
                return profile
        
        # 2. ä½¿ç”¨åœºæ™¯åç§°æ¨¡ç³ŠåŒ¹é…
        if scene_name:
            scene_name_lower = scene_name.lower()
            
            for key, profile in self.scene_profiles.items():
                profile_scene_name = profile.get("scene_name", "").lower()
                if profile_scene_name and (profile_scene_name in scene_name_lower or scene_name_lower in profile_scene_name):
                    return profile
                if key.lower() in scene_name_lower or scene_name_lower in key.lower():
                    return profile
            
            # å…³é”®è¯åŒ¹é…
            if "æ²™æ¼ " in scene_name or "æ²™åœ°" in scene_name:
                for key, profile in self.scene_profiles.items():
                    profile_scene_name = profile.get("scene_name", "").lower()
                    if "æ²™æ¼ " in profile_scene_name or "desert" in key.lower():
                        return profile
        
        # 3. ä½¿ç”¨é›†æ•°åŒ¹é…
        if episode:
            for key, profile in self.scene_profiles.items():
                if profile.get("episode") == episode:
                    return profile
        
        # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ªåœºæ™¯æ¨¡æ¿
        if self.scene_profiles:
            return list(self.scene_profiles.values())[0]
        
        return {}
    
    def _translate_chinese_to_english(self, text: str) -> str:
        """å°†ä¸­æ–‡ prompt ç¿»è¯‘æˆè‹±æ–‡"""
        if not text:
            return ""
        
        translations = {
            "ä»™ä¾ é£æ ¼": "xianxia fantasy style",
            "ä»™ä¾ ": "xianxia",
            "å¤é£": "ancient Chinese style",
            "ä¿®ä»™": "cultivation",
            "ä¿®ä»™ä¸–ç•Œ": "cultivation world",
            "ä¸­å›½å¤é£": "ancient Chinese style",
            "é»‘è‰²é•¿å‘": "long black hair",
            "æ·±ç»¿é“è¢": "dark green robe",
            "å¹³é™çœ¼ç¥": "calm eyes",
            "ä¿®é•¿èº«æ": "slim body",
            "çª„è‚©": "narrow shoulders",
            "èºº": "lying",
            "æ²™åœ°": "sand ground",
            "é’ç°è‰²æ²™åœ°": "grayish sand ground",
            "ä¸€åŠ¨ä¸åŠ¨": "motionless",
            "æ„Ÿå—": "feeling",
            "ç‡¥çƒ­": "heat",
            "ä»™åŸŸ": "immortal realm",
            "å¤©ç©º": "sky",
            "å¤ªé˜³": "sun",
            "æœˆäº®": "moon",
            "è™šå½±": "phantom",
            "å‡ºç°": "appearing",
            "äº‘é›¾": "mist",
            "ç¼­ç»•": "swirling",
            "å·è½´": "scroll",
            "çµæ°”": "spiritual energy",
            "ç²’å­": "particles",
            "é£˜æµ®": "floating",
            "å¼€åœº": "opening",
            "è¿œæ™¯": "wide shot",
            "ä¿¯è§†": "aerial view",
            "é¸Ÿç°": "bird's eye view",
            "å…¨æ™¯": "panoramic view",
            "èƒŒæ™¯ä¸€è‡´": "consistent background",
        }
        
        result = text
        for chinese, english in sorted(translations.items(), key=lambda x: len(x[0]), reverse=True):
            result = result.replace(chinese, english)
        
        return result
    
    def _convert_camera_v2_to_string(self, camera_dict: Dict[str, Any]) -> str:
        """å°† v2 æ ¼å¼çš„ camera å­—å…¸è½¬æ¢ä¸ºå­—ç¬¦ä¸²æè¿°"""
        if not camera_dict or not isinstance(camera_dict, dict):
            return ""
        
        parts = []
        
        # shot å­—æ®µæ˜ å°„
        shot_map = {
            "wide": "è¿œæ™¯",
            "medium": "ä¸­æ™¯",
            "close_up": "ç‰¹å†™",
            "closeup": "ç‰¹å†™",
            "extreme_close": "æè¿‘ç‰¹å†™",
            "full_body": "å…¨èº«",
            "long": "é•¿é•œå¤´",
        }
        shot = camera_dict.get("shot", "")
        if shot:
            shot_str = shot_map.get(shot.lower(), shot)
            parts.append(shot_str)
        
        # angle å­—æ®µæ˜ å°„
        angle_map = {
            "eye_level": "å¹³è§†",
            "top_down": "ä¿¯æ‹",
            "bird_eye": "é¸Ÿç°",
            "low_angle": "ä»°æ‹",
            "worm_eye": "æä½è§’åº¦",
            "side": "ä¾§æ‹",
            "front": "æ­£é¢",
            "back": "èƒŒå",
        }
        angle = camera_dict.get("angle", "")
        if angle:
            angle_str = angle_map.get(angle.lower(), angle)
            parts.append(angle_str)
        
        # movement å­—æ®µæ˜ å°„
        # âš¡ å…³é”®ä¿®å¤ï¼šå•å¸§ç”Ÿæˆæ—¶ï¼Œå»æ‰è§†é¢‘è¯­ä¹‰ï¼ˆpan/tilt/push_in/pull_outï¼‰ï¼Œæ”¹ä¸º static
        # åŸå› ï¼šSDXL ä¼šå½“æˆ"äººç‰©åŠ¨æ€å§¿æ€"ï¼Œå¯¼è‡´å§¿æ€é”™è¯¯
        movement_map = {
            "static": "é™æ­¢",
            "pan": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œpan æ”¹ä¸ºé™æ­¢
            "tilt": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œtilt æ”¹ä¸ºé™æ­¢
            "push_in": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œpush_in æ”¹ä¸ºé™æ­¢
            "pull_out": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œpull_out æ”¹ä¸ºé™æ­¢
            "orbit": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œorbit æ”¹ä¸ºé™æ­¢
            "follow": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œfollow æ”¹ä¸ºé™æ­¢
            "shake": "é™æ­¢",  # å•å¸§ç”Ÿæˆæ—¶ï¼Œshake æ”¹ä¸ºé™æ­¢
        }
        movement = camera_dict.get("movement", "")
        if movement:
            movement_str = movement_map.get(movement.lower(), "é™æ­¢")  # é»˜è®¤æ”¹ä¸ºé™æ­¢
            if movement_str == "é™æ­¢":
                # åªåœ¨éé™æ­¢æ—¶æ‰æ·»åŠ ï¼Œé¿å…é‡å¤
                if "é™æ­¢" not in " ".join(parts):
                    parts.append(movement_str)
            else:
                parts.append(movement_str)
        
        return " ".join(parts) if parts else ""
    
    def _convert_camera_to_prompt(self, camera_desc: str) -> str:
        """å°†ä¸­æ–‡é•œå¤´æè¿°è½¬æ¢ä¸ºé•œå¤´å…³é”®è¯ï¼ˆæ ¹æ®é…ç½®è¿”å›ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰"""
        if not camera_desc:
            return ""
        
        use_chinese = not self.ascii_only_prompt
        camera_keywords = []
        
        # é•œå¤´è·ç¦»/æ™¯åˆ«
        if "è¿œæ™¯" in camera_desc or "å…¨æ™¯" in camera_desc or "å¹¿è§’" in camera_desc:
            if "ä¿¯æ‹" in camera_desc or "ä¿¯è§†" in camera_desc:
                if use_chinese:
                    camera_keywords.append("è¿œæ™¯ä¿¯æ‹ï¼Œé¸Ÿç°è§†è§’")
                else:
                    camera_keywords.append("extreme wide shot, aerial view")
            elif "ä»°æ‹" in camera_desc or "ä»°è§†" in camera_desc:
                if use_chinese:
                    camera_keywords.append("è¿œæ™¯ä»°æ‹ï¼Œä½è§’åº¦è§†è§’")
                else:
                    camera_keywords.append("extreme wide shot, low angle view")
            else:
                if use_chinese:
                    camera_keywords.append("è¿œæ™¯ï¼Œè¶…é•¿é•œå¤´")
                else:
                    camera_keywords.append("extreme wide shot, very long shot")
        elif "ä¸­æ™¯" in camera_desc or "ä¸­è·" in camera_desc:
            if use_chinese:
                camera_keywords.append("ä¸­æ™¯é•œå¤´")
            else:
                camera_keywords.append("medium shot, mid shot")
        elif "è¿‘æ™¯" in camera_desc or "ç‰¹å†™" in camera_desc or "close-up" in camera_desc.lower() or "closeup" in camera_desc.lower() or "close up" in camera_desc.lower():
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœ¼ç›ç‰¹å†™æˆ–é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼ˆéœ€è¦ä¿æŒç‰¹å†™ï¼‰
            camera_desc_lower = camera_desc.lower()
            is_eye_closeup = any(kw in camera_desc_lower for kw in ['eye', 'eyes', 'pupil', 'pupils', 'çœ¼ç›', 'ç³å­”', 'extreme close'])
            is_face_closeup = any(kw in camera_desc_lower for kw in ['face', 'facial', 'portrait', 'headshot', 'é¢éƒ¨', 'è„¸éƒ¨', 'å¤´åƒ', 'close-up on face', 'closeup on face'])
            
            if is_eye_closeup:
                # çœ¼ç›ç‰¹å†™åœºæ™¯ï¼šä¿æŒç‰¹å†™ï¼Œä¸è½¬æ¢ä¸ºä¸­æ™¯
                if use_chinese:
                    camera_keywords.append("çœ¼ç›ç‰¹å†™ï¼Œæè¿‘é•œå¤´")
                else:
                    camera_keywords.append("extreme close-up on eyes, eye close-up, detailed eyes")
                print(f"  âœ“ æ£€æµ‹åˆ°çœ¼ç›ç‰¹å†™åœºæ™¯ï¼Œä¿æŒç‰¹å†™é•œå¤´ï¼ˆä¸è½¬æ¢ä¸ºä¸­æ™¯ï¼‰")
            elif is_face_closeup:
                # é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼šä¿æŒç‰¹å†™ï¼Œä¸è½¬æ¢ä¸ºä¸­æ™¯
                if use_chinese:
                    camera_keywords.append("é¢éƒ¨ç‰¹å†™ï¼Œè¿‘æ™¯é•œå¤´")
                else:
                    camera_keywords.append("close-up on face, face close-up, portrait shot, headshot")
                print(f"  âœ“ æ£€æµ‹åˆ°é¢éƒ¨ç‰¹å†™åœºæ™¯ï¼Œä¿æŒç‰¹å†™é•œå¤´ï¼ˆä¸è½¬æ¢ä¸ºä¸­æ™¯ï¼‰")
            else:
                # å…¶ä»–ç‰¹å†™åœºæ™¯ï¼šé¿å…å¤ªè¿‘çš„é•œå¤´ï¼Œè½¬æ¢ä¸ºä¸­æ™¯
                print(f"  âš  æ£€æµ‹åˆ°ç‰¹å†™/è¿‘æ™¯é•œå¤´æè¿°ï¼Œä¸ºé¿å…èº«ä½“è¿‡å®½å’Œæ¨¡ç³Šï¼Œè½¬æ¢ä¸ºä¸­æ™¯")
                if use_chinese:
                    camera_keywords.append("ä¸­æ™¯é•œå¤´")
                else:
                    camera_keywords.append("medium shot, mid shot")  # è½¬æ¢ä¸ºä¸­æ™¯
        elif "å…¨èº«" in camera_desc or "å…¨è²Œ" in camera_desc:
            if use_chinese:
                camera_keywords.append("å…¨èº«é•œå¤´")
            else:
                camera_keywords.append("full body shot, full figure")
        elif "é•¿é•œå¤´" in camera_desc or "é•¿ç„¦" in camera_desc:
            if use_chinese:
                camera_keywords.append("é•¿ç„¦é•œå¤´")
            else:
                camera_keywords.append("long shot, telephoto")
        elif "çŸ­ç„¦" in camera_desc or "å¹¿è§’" in camera_desc:
            if use_chinese:
                camera_keywords.append("å¹¿è§’é•œå¤´")
            else:
                camera_keywords.append("wide angle shot")
        
        # é•œå¤´è¿åŠ¨
        if "æ¨è¿‘" in camera_desc or "æ¨è¿›" in camera_desc or "æ¨é•œ" in camera_desc:
            if use_chinese:
                camera_keywords.append("æ¨é•œ")
            else:
                camera_keywords.append("push in, dolly in")
        elif "æ‹‰è¿œ" in camera_desc or "æ‹‰é•œ" in camera_desc or "æ¨è¿œ" in camera_desc:
            if use_chinese:
                camera_keywords.append("æ‹‰é•œ")
            else:
                camera_keywords.append("pull out, dolly out")
        elif "è·Ÿéš" in camera_desc or "è·Ÿæ‹" in camera_desc:
            if use_chinese:
                camera_keywords.append("è·Ÿæ‹")
            else:
                camera_keywords.append("follow shot, tracking shot")
        elif "ç¯ç»•" in camera_desc or "æ—‹è½¬" in camera_desc:
            if use_chinese:
                camera_keywords.append("ç¯ç»•é•œå¤´")
            else:
                camera_keywords.append("orbital shot, rotating camera")
        elif "ä¸Šç§»" in camera_desc or "ä¸Šæ‰¬" in camera_desc:
            if use_chinese:
                camera_keywords.append("ä¸Šæ‘‡")
            else:
                camera_keywords.append("tilt up, camera tilt up")
        elif "ä¸‹ç§»" in camera_desc or "ä¸‹æ¨" in camera_desc:
            if use_chinese:
                camera_keywords.append("ä¸‹æ‘‡")
            else:
                camera_keywords.append("tilt down, camera tilt down")
        elif "æ¨ªç§»" in camera_desc or "å¹³ç§»" in camera_desc:
            # âš¡ å…³é”®ä¿®å¤ï¼šå•å¸§ç”Ÿæˆæ—¶ï¼Œå»æ‰è§†é¢‘è¯­ä¹‰ï¼ˆpan/lateralï¼‰ï¼Œæ”¹ä¸º static
            # åŸå› ï¼šSDXL ä¼šå½“æˆ"äººç‰©åŠ¨æ€å§¿æ€"ï¼Œå¯¼è‡´å§¿æ€é”™è¯¯
            if use_chinese:
                camera_keywords.append("é™æ­¢é•œå¤´")  # æ”¹ä¸ºé™æ­¢
            else:
                camera_keywords.append("static shot, still frame")  # æ”¹ä¸ºé™æ­¢
        elif "å®šæ ¼" in camera_desc or "é™æ­¢" in camera_desc:
            if use_chinese:
                camera_keywords.append("é™æ­¢é•œå¤´")
            else:
                camera_keywords.append("static shot, still frame")
        
        # é•œå¤´è§’åº¦
        if "ä¿¯æ‹" in camera_desc or "ä¿¯è§†" in camera_desc:
            if use_chinese:
                camera_keywords.append("ä¿¯è§†ï¼Œé¸Ÿç°")
            else:
                camera_keywords.append("aerial view, top down, bird's eye view")
        elif "ä»°æ‹" in camera_desc or "ä»°è§†" in camera_desc:
            if use_chinese:
                camera_keywords.append("ä»°è§†ï¼Œä½è§’åº¦")
            else:
                camera_keywords.append("low angle, worm's eye view")
        elif "ä¾§æ‹" in camera_desc or "ä¾§é¢" in camera_desc:
            if use_chinese:
                camera_keywords.append("ä¾§é¢è§†è§’")
            else:
                camera_keywords.append("side view, profile shot")
        elif "èƒŒå" in camera_desc or "èƒŒå½±" in camera_desc:
            if use_chinese:
                camera_keywords.append("èƒŒåè§†è§’")
            else:
                camera_keywords.append("back view, from behind")
        elif "æ­£é¢" in camera_desc:
            if use_chinese:
                camera_keywords.append("æ­£é¢è§†è§’")
            else:
                camera_keywords.append("front view, face forward")
        
        # ç‰¹æ®Šæ•ˆæœ
        if "æŠ–åŠ¨" in camera_desc or "éœ‡åŠ¨" in camera_desc:
            if use_chinese:
                camera_keywords.append("é•œå¤´æŠ–åŠ¨")
            else:
                camera_keywords.append("shaky camera, camera shake")
        elif "æ…¢åŠ¨ä½œ" in camera_desc or "æ…¢é•œ" in camera_desc:
            if use_chinese:
                camera_keywords.append("æ…¢åŠ¨ä½œ")
            else:
                camera_keywords.append("slow motion")
        elif "å¿«é€Ÿ" in camera_desc or "æ€¥é€Ÿ" in camera_desc:
            if use_chinese:
                camera_keywords.append("å¿«é€Ÿè¿åŠ¨")
            else:
                camera_keywords.append("fast movement, rapid camera")
        elif "ç¼“ç¼“" in camera_desc or "ç¼“æ…¢" in camera_desc:
            if use_chinese:
                camera_keywords.append("ç¼“æ…¢è¿åŠ¨")
            else:
                camera_keywords.append("slow movement, gentle camera")
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•åŒ¹é…ï¼Œå°è¯•ç›´æ¥ç¿»è¯‘å…³é”®è¯
        if not camera_keywords:
            if use_chinese:
                camera_keywords.append("ç”µå½±çº§é•œå¤´")
            else:
                camera_keywords.append("cinematic shot")
        
        return ", ".join(camera_keywords)
    
    def _convert_motion_to_prompt(self, motion: Any) -> str:
        """å°† visual.motion è½¬æ¢ä¸º prompt æè¿°"""
        if not motion:
            return ""
        
        if isinstance(motion, str):
            return motion
        
        if isinstance(motion, dict):
            motion_type = motion.get("type", "")
            direction = motion.get("direction", "")
            speed = motion.get("speed", "medium")
            
            motion_keywords = []
            
            # ç±»å‹è½¬æ¢
            type_map = {
                "static": "static shot",
                "pan": "pan shot",
                "tilt": "tilt shot",
                "push_in": "push in, dolly in",
                "pull_out": "pull out, dolly out",
                "orbit": "orbital shot, rotating camera",
                "shake": "shaky camera, camera shake",
                "follow": "follow shot, tracking shot",
            }
            
            if motion_type in type_map:
                motion_keywords.append(type_map[motion_type])
            elif motion_type:
                motion_keywords.append(motion_type)
            
            # æ–¹å‘è½¬æ¢
            if direction:
                direction_map = {
                    "left_to_right": "left to right",
                    "right_to_left": "right to left",
                    "up": "tilt up",
                    "down": "tilt down",
                    "forward": "forward",
                    "backward": "backward",
                    "around": "around subject",
                }
                if direction in direction_map:
                    motion_keywords.append(direction_map[direction])
            
            # é€Ÿåº¦
            if speed and speed != "medium":
                motion_keywords.append(f"{speed} movement")
            
            return ", ".join(motion_keywords)
        
        return ""
    
    def _looks_like_camera_prompt(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦çœ‹èµ·æ¥åƒç›¸æœºæè¿°"""
        if not text:
            return False
        lowered = text.lower()
        keywords = [
            "è¿œæ™¯", "å…¨æ™¯", "è¿‘æ™¯", "ä¸­æ™¯", "ç‰¹å†™", "é•œå¤´", "ä¿¯æ‹", "ä¿¯è§†", "ä»°æ‹", "ä»°è§†", "æ¨è¿‘", "æ‹‰è¿œ",
            "è·Ÿæ‹", "ç¯ç»•", "æ¨ªç§»", "æ¨é•œ", "é•œå¤´ç¼“ç¼“", "é•œå¤´å¿«é€Ÿ", "slow motion", "close-up", "wide shot",
            "shot", "pan", "tilt", "dolly", "camera"
        ]
        return any(kw in lowered for kw in keywords)
    
    def _build_character_prompt(self, character_id: str = "hanli") -> str:
        """æ ¹æ®è§’è‰²æ¨¡æ¿æ„å»ºè§’è‰²æè¿° promptï¼ˆå®Œæ•´ç‰ˆï¼‰"""
        profile = self._get_character_profile(character_id)
        if not profile:
            return ""
        
        parts = []
        
        # å‘å‹æè¿°ï¼ˆæœ€é«˜æƒé‡ï¼Œç¡®ä¿å‘å‹æ­£ç¡®ï¼‰
        if profile.get("hair", {}).get("prompt_keywords"):
            parts.append(profile["hair"]["prompt_keywords"])
        
        # æœé¥°æè¿°ï¼ˆæœ€é«˜æƒé‡ï¼Œå¼ºè°ƒä¿®ä»™é£æ ¼ï¼Œæ’é™¤é“ ç”²ï¼‰
        if profile.get("clothes", {}).get("prompt_keywords"):
            parts.append(profile["clothes"]["prompt_keywords"])
        
        # ä¿®ä»™æ°”è´¨ç‰¹å¾
        parts.append("(xianxia cultivator aura:1.3)")
        parts.append("(elegant immortal style:1.2)")
        parts.append("(refined scholar-warrior appearance:1.2)")
        
        # é¢éƒ¨ç‰¹å¾
        if profile.get("face_keywords"):
            parts.append(f"({profile['face_keywords']}:1.2)")
        
        # èº«ä½“ç‰¹å¾ï¼ˆå¼ºè°ƒç˜¦å‰Šï¼Œé¿å…è¿‡å®½ï¼‰
        body = profile.get("body", {})
        if body.get("build"):
            parts.append(f"({body['build']}:1.2)")
        parts.append("(slim physique, lean body:1.2)")  # å¼ºè°ƒç˜¦å‰Šèº«æ
        if body.get("posture"):
            parts.append(f"({body['posture']}:1.1)")
        
        # è§’è‰²ä¸€è‡´æ€§æ ‡è®°
        parts.append("(consistent character appearance:1.3)")
        parts.append("(correct hairstyle, correct clothing:1.3)")
        
        return ", ".join(parts)
    
    def _build_character_prompt_compact(self, character_id: str = "hanli", shot_type: Dict[str, bool] = None) -> str:
        """æ ¹æ®è§’è‰²æ¨¡æ¿æ„å»ºæç®€ç‰ˆè§’è‰²æè¿° promptï¼ˆç¡®ä¿åœ¨å‰ 77 tokens å†…ï¼‰"""
        profile = self._get_character_profile(character_id)
        if not profile:
            return ""
        
        use_chinese = not self.ascii_only_prompt
        parts = []
        
        # 0. æ€§åˆ«ç‰¹å¾ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œä» identity å­—æ®µæå–ï¼Œé¿å…ç”Ÿæˆé”™è¯¯æ€§åˆ«ï¼‰
        identity = profile.get("identity", "")
        if identity:
            identity_lower = identity.lower()
            if "male" in identity_lower or "ç”·" in identity:
                # âš¡ ä¿®å¤æ€§åˆ«é”™è¯¯ï¼šæé«˜æƒé‡åˆ°2.5ï¼Œç¡®ä¿æ€§åˆ«æ­£ç¡®
                if use_chinese:
                    parts.append("(ç”·æ€§ï¼Œç”·ï¼Œç”·äºº:2.5)")
                else:
                    parts.append("(male, man, masculine:2.5)")
            elif "female" in identity_lower or "å¥³" in identity:
                if use_chinese:
                    parts.append("(å¥³æ€§ï¼Œå¥³:1.8)")
                else:
                    parts.append("(female, woman:1.8)")
        else:
            # å‘åå…¼å®¹ï¼šå¯¹äºéŸ©ç«‹ï¼Œé»˜è®¤æ˜¯ç”·æ€§
            # âš¡ ä¿®å¤æ€§åˆ«é”™è¯¯ï¼šæé«˜æƒé‡åˆ°2.5ï¼Œç¡®ä¿æ€§åˆ«æ­£ç¡®
            if character_id == "hanli":
                if use_chinese:
                    parts.append("(ç”·æ€§ï¼Œç”·ï¼Œç”·äºº:2.5)")
                else:
                    parts.append("(male, man, masculine:2.5)")
        
        # 1. å‘å‹å’Œæœé¥°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œåˆå¹¶æè¿°ï¼‰
        if use_chinese:
            parts.append("(é»‘è‰²é•¿å‘ï¼Œæ·±ç»¿é“è¢:1.7)")
        else:
            parts.append("(long black hair, dark green robe:1.7)")
        
        # 2. é¢éƒ¨ç‰¹å¾ï¼ˆæç®€ï¼‰
        if use_chinese:
            parts.append("(å¹³é™çœ¼ç¥:1.2)")
        else:
            parts.append("(calm eyes:1.2)")
        
        # 3. èº«ä½“ç‰¹å¾ï¼ˆæ ¹æ®é•œå¤´ç±»å‹ï¼Œæç®€ï¼‰
        if shot_type and (shot_type.get("is_medium") or shot_type.get("is_close")):
            if use_chinese:
                parts.append("(ä¿®é•¿èº«æï¼Œçª„è‚©:1.3)")
            else:
                parts.append("(slim body, narrow shoulders:1.3)")
        
        return ", ".join(parts)
    
    def _build_character_description_prompt(self, profile: Dict[str, Any], shot_type: Dict[str, bool] = None, compact: bool = False) -> str:
        """æ ¹æ®è§’è‰²æè¿°æ„å»º promptï¼ˆç”¨äºæ ¹æ®æè¿°ç”Ÿæˆå›¾åƒï¼Œä¸ä½¿ç”¨å‚è€ƒç…§ç‰‡ï¼‰"""
        if not profile:
            return ""
        
        use_chinese = not self.ascii_only_prompt
        parts = []
        
        # 0. èº«ä»½å’Œæ€§åˆ«ï¼ˆç²¾ç®€ç‰ˆï¼Œé¿å…ä¸single personé‡å¤ï¼‰
        # æ³¨æ„ï¼šå¦‚æœå·²ç»æœ‰single personçº¦æŸï¼Œå°±ä¸éœ€è¦å†å¼ºè°ƒmale/manï¼ˆé¿å…é‡å¤ï¼‰
        # å¯¹äºç§‘æ™®ä¸»æŒäººï¼Œæ€§åˆ«ä¿¡æ¯å·²ç»åœ¨è§’è‰²åç§°ä¸­ä½“ç°ï¼Œä¸éœ€è¦é¢å¤–æ·»åŠ 
        identity = profile.get("identity", "")
        character_id = profile.get("character_id", "").lower() or profile.get("id", "").lower()
        character_name = str(profile.get("character_name", "")).lower()
        
        # å¯¹äºç§‘æ™®ä¸»æŒäººï¼Œä¸æ·»åŠ æ€§åˆ«æ ‡è®°ï¼ˆè§’è‰²åç§°å·²ä½“ç°ï¼‰
        if "kepu" in character_id or "weilai" in character_id or "ç§‘æ™®" in character_name or "æœªæ¥" in character_name:
            # ç§‘æ™®ä¸»æŒäººä¸éœ€è¦é¢å¤–æ€§åˆ«æ ‡è®°
            pass
        elif identity:
            # å…¶ä»–è§’è‰²ï¼šåªä½¿ç”¨ä¸€ä¸ªè¯ï¼Œé¿å…é‡å¤
            identity_lower = identity.lower()
            if "male" in identity_lower or "ç”·" in identity:
                # âš¡ ä¿®å¤æ€§åˆ«é”™è¯¯ï¼šæé«˜æƒé‡åˆ°2.5ï¼Œç¡®ä¿æ€§åˆ«æ­£ç¡®
                if use_chinese:
                    parts.append("(ç”·æ€§ï¼Œç”·ï¼Œç”·äºº:2.5)")
                else:
                    parts.append("(male, man, masculine:2.5)")
            elif "female" in identity_lower or "å¥³" in identity:
                if use_chinese:
                    parts.append("(å¥³æ€§:1.5)")
                else:
                    parts.append("(female:1.5)")
        
        # 1. è§’è‰²åç§°ï¼ˆå¿…é¡»åŒ…å«ï¼Œç¡®ä¿è§’è‰²è¯†åˆ«ï¼‰
        character_name = profile.get("character_name", "")
        if character_name:
            parts.append(character_name)
        
        # 2. å‘å‹æè¿°ï¼ˆç²¾ç®€ç‰ˆï¼Œåªä¿ç•™æ ¸å¿ƒæè¿°ï¼‰
        hair = profile.get("hair", {})
        if hair.get("prompt_keywords"):
            # å¤§å¹…ç®€åŒ–ï¼šåªæå–ç¬¬ä¸€ä¸ªæ ¸å¿ƒæè¿°
            import re
            hair_keywords = hair["prompt_keywords"]
            matches = re.findall(r'\(([^)]+)\)', hair_keywords)
            if matches:
                # åªä½¿ç”¨ç¬¬ä¸€ä¸ªæè¿°ï¼Œç®€åŒ–æƒé‡
                core_desc = matches[0].split(':')[0].strip()
                parts.append(f"({core_desc}:1.5)")
            else:
                # å¦‚æœæ²¡æœ‰æ‹¬å·ï¼Œç®€åŒ–æƒé‡
                hair_keywords = re.sub(r':\d+\.\d+', ':1.5', hair_keywords)
                parts.append(hair_keywords)
        elif hair.get("style"):
            # åªä½¿ç”¨styleï¼Œä¸æ·»åŠ colorï¼ˆå‡å°‘tokenï¼‰
            parts.append(f"({hair.get('style')}:1.5)")
        
        # 3. æœé¥°æè¿°ï¼ˆç²¾ç®€ç‰ˆï¼Œåªä¿ç•™æ ¸å¿ƒæè¿°ï¼‰
        clothes = profile.get("clothes", {})
        if clothes.get("prompt_keywords"):
            # å¤§å¹…ç®€åŒ–ï¼šåªæå–ç¬¬ä¸€ä¸ªæ ¸å¿ƒæè¿°
            import re
            clothes_keywords = clothes["prompt_keywords"]
            matches = re.findall(r'\(([^)]+)\)', clothes_keywords)
            if matches:
                # åªä½¿ç”¨ç¬¬ä¸€ä¸ªæè¿°ï¼ˆæœ€é‡è¦çš„ï¼‰ï¼Œè¿›ä¸€æ­¥ç²¾ç®€ï¼šåªä¿ç•™å‰3ä¸ªå…³é”®è¯
                core_desc = matches[0].split(':')[0].strip()
                core_words = core_desc.split(',')[:3]
                parts.append(f"({', '.join(core_words)}:1.6)")
            else:
                # å¦‚æœæ²¡æœ‰æ‹¬å·ï¼Œç®€åŒ–æƒé‡ï¼Œåªä¿ç•™å‰50ä¸ªå­—ç¬¦
                clothes_keywords = re.sub(r':\d+\.\d+', ':1.6', clothes_keywords)
                if len(clothes_keywords) > 50:
                    clothes_keywords = clothes_keywords[:50] + "..."
                parts.append(clothes_keywords)
        elif clothes.get("style"):
            # åªä½¿ç”¨styleï¼Œä¸æ·»åŠ colorï¼ˆå‡å°‘tokenï¼‰
            parts.append(f"({clothes.get('style')}:1.6)")
        
        # 4. é¢éƒ¨ç‰¹å¾ï¼ˆç²¾ç®€ç‰ˆï¼Œåªä¿ç•™å‰2ä¸ªå…³é”®è¯ï¼‰
        if profile.get("face_keywords"):
            face_keywords = profile["face_keywords"]
            # å¤§å¹…ç®€åŒ–ï¼šåªä¿ç•™å‰2ä¸ªå…³é”®è¯
            face_parts = [p.strip() for p in face_keywords.split(",")][:2]
            if face_parts:
                parts.append(f"({', '.join(face_parts)}:1.3)")
        
        # 6. èº«ä½“ç‰¹å¾ï¼ˆæ ¹æ®é•œå¤´ç±»å‹ï¼‰
        body = profile.get("body", {})
        if shot_type and (shot_type.get("is_medium") or shot_type.get("is_close")):
            if body.get("build"):
                parts.append(f"({body['build']}:1.2)")
        
        # å¦‚æœæ˜¯ç²¾ç®€ç‰ˆï¼Œåªä¿ç•™æœ€æ ¸å¿ƒçš„ç‰¹å¾ï¼ˆæ€§åˆ«ã€å‘å‹ã€æœé¥°ã€ä¿®ä»™æ°”è´¨ï¼‰
        if compact:
            # ä¿ç•™ï¼šæ€§åˆ«ã€è§’è‰²åç§°ã€å‘å‹ã€æœé¥°ã€ä¿®ä»™æ°”è´¨
            essential_parts = []
            for part in parts:
                if any(kw in part.lower() for kw in ["male", "female", "ç”·", "å¥³", "han li", "éŸ©ç«‹", "hair", "é•¿å‘", "robe", "é“è¢", "cultivator", "ä¿®ä»™"]):
                    essential_parts.append(part)
            if essential_parts:
                parts = essential_parts[:5]  # æœ€å¤šä¿ç•™5ä¸ªæ ¸å¿ƒç‰¹å¾
        
        return ", ".join(parts) if parts else ""
    
    def _build_scene_background_prompt_compact(self, scene: Dict[str, Any], script_data: Dict[str, Any] = None) -> str:
        """æ„å»ºç²¾ç®€ç‰ˆåœºæ™¯èƒŒæ™¯ prompt"""
        # v2 å…¼å®¹ï¼šä¼˜å…ˆ scene_idï¼Œå…¶æ¬¡ id
        scene_id = scene.get("scene_id", scene.get("id"))
        is_opening_ending = scene_id in [0, 999]
        
        if is_opening_ending:
            if not self.ascii_only_prompt:
                return "(ä»™åŸŸå¤©ç©ºï¼Œçµæ°”ç¼­ç»•:1.3)"
            else:
                return "(immortal realm sky, spiritual mist:1.3)"
        
        # é¦–å…ˆæ£€æŸ¥åœºæ™¯æè¿°ä¸­çš„å®é™…é¢œè‰²å’Œåœ°å½¢
        # âš¡ v2 æ ¼å¼æ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨ visual_constraintsï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ visual
        visual_constraints = scene.get("visual_constraints", {}) or {}
        visual = scene.get("visual", {}) or {}
        
        # ä¼˜å…ˆä» visual_constraints è¯»å–ï¼ˆv2 æ ¼å¼ï¼‰
        environment = self._clean_prompt_text(visual_constraints.get("environment", "") or "")
        if not environment:
            environment = self._clean_prompt_text(visual.get("environment", "") if isinstance(visual, dict) else "")
        
        composition = self._clean_prompt_text(visual.get("composition", "") if isinstance(visual, dict) else "")
        description = self._clean_prompt_text(scene.get("description", ""))
        
        # ä»åœºæ™¯æè¿°ä¸­æå–é¢œè‰²ä¿¡æ¯
        scene_text = f"{environment} {composition} {description}".lower()
        
        # æ£€æµ‹åœºæ™¯æè¿°ä¸­çš„é¢œè‰²
        detected_colors = []
        color_keywords = {
            "gray-green": "gray-green",
            "grey-green": "gray-green",
            "gray green": "gray-green",
            "grey green": "gray-green",
            "é’ç°": "gray-green",
            "é’ç°è‰²": "gray-green",
            "golden": "golden",
            "é‡‘è‰²": "golden",
            "warm orange": "warm orange",
            "æš–æ©™": "warm orange",
            "orange": "warm orange",
            "blue": "blue",
            "è“è‰²": "blue",
            "red": "red",
            "çº¢è‰²": "red"
        }
        
        for keyword, color_name in color_keywords.items():
            if keyword in scene_text:
                detected_colors.append(color_name)
                break  # åªå–ç¬¬ä¸€ä¸ªåŒ¹é…çš„é¢œè‰²
        
        # æ£€æµ‹åœºæ™¯æè¿°ä¸­çš„åœ°å½¢
        detected_terrain = None
        terrain_keywords = {
            "desert": "desert",
            "sand": "desert",
            "æ²™æ¼ ": "desert",
            "æ²™åœ°": "desert",
            "gravel": "gravel",
            "æ²™ç ¾": "gravel",
            "chamber": "chamber",
            "é—è¿¹": "chamber",
            "corridor": "corridor",
            "èµ°å»Š": "corridor"
        }
        
        for keyword, terrain_name in terrain_keywords.items():
            if keyword in scene_text:
                detected_terrain = terrain_name
                break
        
        profile_key = scene.get("scene_profile") or scene.get("scene_template") or scene.get("scene_key")
        scene_name = scene.get("scene_name") or scene.get("title", "")
        if not scene_name and script_data:
            scene_name = script_data.get("title", "")
        
        episode = scene.get("episode")
        if not episode and script_data:
            episode = script_data.get("episode")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç§‘æ™®è§†é¢‘ï¼ˆç§‘æ™®è§†é¢‘ä¸ä½¿ç”¨åœºæ™¯æ¨¡æ¿ï¼‰
        is_kepu_video = False
        if script_data:
            category = script_data.get("category", "")
            if category in ["universe", "quantum", "earth", "energy", "city", "biology", "ai"]:
                is_kepu_video = True
        
        profile = self._get_scene_profile(scene_name, episode, profile_key=profile_key, is_kepu_video=is_kepu_video)
        
        # å¦‚æœæ˜¯ç§‘æ™®è§†é¢‘ï¼Œä¸ä½¿ç”¨åœºæ™¯æ¨¡æ¿ï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
        if is_kepu_video:
            return ""
        
        parts = []
        
        # ä¼˜å…ˆä½¿ç”¨åœºæ™¯æè¿°ä¸­æ£€æµ‹åˆ°çš„é¢œè‰²ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ¨¡æ¿
        if detected_colors:
            color = detected_colors[0]
            if color == "gray-green":
                parts.append("(gray-green tones:1.2)")
            elif color == "golden":
                parts.append("(golden sand:1.4)")
            elif color == "warm orange":
                parts.append("(warm orange tones:1.2)")
        elif profile and profile.get("color_palette", {}).get("prompt"):
            color_prompt = profile["color_palette"]["prompt"]
            if "golden sand" in color_prompt.lower():
                parts.append("(golden sand:1.4)")
            elif "warm orange" in color_prompt.lower():
                parts.append("(warm orange tones:1.2)")
        
        # ä¼˜å…ˆä½¿ç”¨åœºæ™¯æè¿°ä¸­æ£€æµ‹åˆ°çš„åœ°å½¢ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ¨¡æ¿
        if detected_terrain:
            if detected_terrain == "desert":
                # æ ¹æ®é¢œè‰²è°ƒæ•´æ²™æ¼ æè¿°
                if detected_colors and detected_colors[0] == "gray-green":
                    parts.append("(gray-green desert:1.3)")
                else:
                    parts.append("(vast golden desert:1.3)")
            elif detected_terrain == "gravel":
                parts.append("(gray-green gravel plain:1.3)")
            elif detected_terrain == "chamber":
                parts.append("(ancient stone chamber:1.3)")
            elif detected_terrain == "corridor":
                parts.append("(stone corridor:1.3)")
        elif profile and profile.get("terrain", {}).get("prompt"):
            terrain_prompt = profile["terrain"]["prompt"]
            if "desert" in terrain_prompt.lower() or "sand" in terrain_prompt.lower():
                parts.append("(vast golden desert:1.3)")
            elif "chamber" in terrain_prompt.lower() or "corridor" in terrain_prompt.lower():
                parts.append("(ancient stone chamber:1.3)")
        
        # é»˜è®¤å€¼
        if not parts:
            if "æ²™æ¼ " in scene_name or "desert" in scene_name.lower():
                if not self.ascii_only_prompt:
                    return "(é‡‘è‰²æ²™æ¼ :1.3)"
                else:
                    return "(golden desert:1.3)"
            elif "é—è¿¹" in scene_name or "chamber" in scene_name.lower():
                if not self.ascii_only_prompt:
                    return "(å¤ä»£çŸ³å®¤:1.3)"
                else:
                    return "(ancient stone chamber:1.3)"
            else:
                if not self.ascii_only_prompt:
                    return "(èƒŒæ™¯ä¸€è‡´:1.2)"
                else:
                    return "(consistent background:1.2)"
        
        return ", ".join(parts)
    
    def _build_scene_background_prompt(self, scene: Dict[str, Any], script_data: Dict[str, Any] = None) -> str:
        """æ ¹æ®åœºæ™¯æ¨¡æ¿æ„å»ºèƒŒæ™¯æè¿° prompt"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºç§‘æ™®è§†é¢‘ï¼ˆç§‘æ™®è§†é¢‘ä¸ä½¿ç”¨åœºæ™¯æ¨¡æ¿ï¼‰
        is_kepu_video = False
        if script_data:
            category = script_data.get("category", "")
            if category in ["universe", "quantum", "earth", "energy", "city", "biology", "ai"]:
                is_kepu_video = True
        
        # å¦‚æœæ˜¯ç§‘æ™®è§†é¢‘ï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
        if is_kepu_video:
            return ""
        
        profile_key = scene.get("scene_profile") or scene.get("scene_template") or scene.get("scene_key")
        scene_name = scene.get("scene_name") or scene.get("title", "")
        if not scene_name and script_data:
            scene_name = script_data.get("title", "")
        
        episode = scene.get("episode")
        if not episode and script_data:
            episode = script_data.get("episode")
        
        profile = self._get_scene_profile(scene_name, episode, profile_key=profile_key, is_kepu_video=is_kepu_video)
        if not profile:
            return ""
        
        parts = []
        
        # é¢œè‰²è°ƒè‰²æ¿
        if profile.get("color_palette", {}).get("prompt"):
            parts.append(profile["color_palette"]["prompt"])
        
        # åœ°å½¢åœ°è²Œ
        if profile.get("terrain", {}).get("prompt"):
            parts.append(profile["terrain"]["prompt"])
        
        # å…‰ç…§
        if profile.get("lighting", {}).get("prompt"):
            parts.append(profile["lighting"]["prompt"])
        
        return ", ".join(parts)


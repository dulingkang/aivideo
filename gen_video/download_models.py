#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹ä¸‹è½½è„šæœ¬ï¼ˆPythonç‰ˆæœ¬ï¼‰
æ”¯æŒä½¿ç”¨ proxychains4 å’Œè™šæ‹Ÿç¯å¢ƒ
"""

import os
import sys
from pathlib import Path
from typing import Optional
import argparse


def download_model(
    model_id: str,
    local_dir: Path,
    resume: bool = True,
    use_proxy: bool = False,
    max_retries: int = 3,
    retry_delay: int = 10
) -> bool:
    """
    ä¸‹è½½æ¨¡å‹
    
    Args:
        model_id: HuggingFace æ¨¡å‹ID
        local_dir: æœ¬åœ°ä¿å­˜ç›®å½•
        resume: æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰
    
    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    try:
        from huggingface_hub import snapshot_download
        
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {model_id}")
        print(f"   ä¿å­˜åˆ°: {local_dir}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦çœŸçš„å®Œæ•´ï¼ˆä¸åªæ˜¯ç›®å½•å­˜åœ¨ï¼‰
        if local_dir.exists():
            # æ£€æŸ¥æ˜¯å¦æœ‰æƒé‡æ–‡ä»¶ï¼ˆ.safetensors, .bin, .ptï¼‰
            weight_files = list(local_dir.rglob("*.safetensors")) + \
                         list(local_dir.rglob("*.bin")) + \
                         list(local_dir.rglob("*.pt"))
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ model_index.json æˆ– config.json
            has_config = (local_dir / "model_index.json").exists() or \
                        any(local_dir.rglob("config.json"))
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤§æ–‡ä»¶ï¼ˆè‡³å°‘ > 100MBï¼‰
            large_files = [f for f in local_dir.rglob("*") 
                          if f.is_file() and f.stat().st_size > 100 * 1024 * 1024]
            
            # å¦‚æœæœ‰æƒé‡æ–‡ä»¶æˆ–å¤§æ–‡ä»¶ï¼Œä¸”å¤§å°åˆç†ï¼Œè®¤ä¸ºå·²ä¸‹è½½
            if (weight_files or large_files) and has_config:
                total_size = sum(f.stat().st_size for f in local_dir.rglob("*") if f.is_file())
                size_gb = total_size / (1024 * 1024 * 1024)
                if size_gb > 0.5:  # è‡³å°‘ 500MB
                    print(f"   âœ“ æ¨¡å‹å·²å­˜åœ¨ï¼ˆ{size_gb:.2f} GBï¼‰ï¼Œè·³è¿‡ä¸‹è½½")
                    return True
                else:
                    print(f"   âš ï¸  æ¨¡å‹ç›®å½•å­˜åœ¨ä½†æ–‡ä»¶è¿‡å°ï¼ˆ{size_gb:.2f} GBï¼‰ï¼Œé‡æ–°ä¸‹è½½...")
            elif weight_files or large_files:
                # æœ‰æƒé‡æ–‡ä»¶ä½†ç¼ºå°‘é…ç½®æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯éƒ¨åˆ†ä¸‹è½½
                total_size = sum(f.stat().st_size for f in local_dir.rglob("*") if f.is_file())
                size_gb = total_size / (1024 * 1024 * 1024)
                if size_gb > 1.0:  # è‡³å°‘ 1GB
                    print(f"   âš ï¸  æ¨¡å‹éƒ¨åˆ†å­˜åœ¨ï¼ˆ{size_gb:.2f} GBï¼‰ï¼Œä½†ç¼ºå°‘é…ç½®æ–‡ä»¶ï¼Œç»§ç»­ä¸‹è½½...")
                else:
                    print(f"   âš ï¸  æ¨¡å‹ç›®å½•å­˜åœ¨ä½†æ–‡ä»¶ä¸å®Œæ•´ï¼ˆ{size_gb:.2f} GBï¼‰ï¼Œé‡æ–°ä¸‹è½½...")
            else:
                # åªæœ‰å…ƒæ•°æ®æ–‡ä»¶ï¼Œæ²¡æœ‰å®é™…æ¨¡å‹
                print(f"   âš ï¸  ç›®å½•å­˜åœ¨ä½†æ— æ¨¡å‹æ–‡ä»¶ï¼Œé‡æ–°ä¸‹è½½...")
        
        # åˆ›å»ºç›®å½•
        local_dir.mkdir(parents=True, exist_ok=True)
        
        # å¸¦é‡è¯•çš„ä¸‹è½½
        import time
        for attempt in range(1, max_retries + 1):
            try:
                if attempt > 1:
                    print(f"   â³ é‡è¯• {attempt}/{max_retries}...")
                    time.sleep(retry_delay)
                else:
                    print(f"   â³ å¼€å§‹ä¸‹è½½ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰...")
                
                snapshot_download(
                    repo_id=model_id,
                    local_dir=str(local_dir),
                    local_dir_use_symlinks=False,
                    resume_download=resume,
                    max_workers=2,  # å‡å°‘å¹¶å‘ï¼Œé¿å…è¿æ¥é—®é¢˜
                )
                
                print(f"   âœ“ ä¸‹è½½å®Œæˆ")
                return True
                
            except Exception as e:
                error_msg = str(e)
                if "timeout" in error_msg.lower() or "socket error" in error_msg.lower():
                    if attempt < max_retries:
                        print(f"   âš ï¸  è¿æ¥è¶…æ—¶ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                        continue
                elif attempt < max_retries:
                    print(f"   âš ï¸  ä¸‹è½½å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡è¯•: {error_msg[:80]}")
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    raise
        
        print(f"   âœ“ ä¸‹è½½å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"   âœ— ä¸‹è½½å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="ä¸‹è½½å¤šæ¨¡å‹ç»„åˆæ–¹æ¡ˆæ‰€éœ€æ¨¡å‹")
    parser.add_argument(
        "--use-proxy",
        action="store_true",
        help="ä½¿ç”¨ proxychains4ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰"
    )
    parser.add_argument(
        "--model",
        choices=["all", "sd3-turbo", "flux", "flux1", "flux2", "hunyuan-dit", "kolors"],
        default="all",
        help="é€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹ï¼ˆé»˜è®¤: allï¼‰"
    )
    parser.add_argument(
        "--base-dir",
        type=str,
        default="/vepfs-dev/shawn/vid/fanren/gen_video/models",
        help="æ¨¡å‹ä¿å­˜åŸºç¡€ç›®å½•"
    )
    
    args = parser.parse_args()
    
    base_dir = Path(args.base_dir)
    base_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    print("ğŸš€ å¤šæ¨¡å‹ä¸‹è½½è„šæœ¬")
    print("=" * 60)
    print(f"åŸºç¡€ç›®å½•: {base_dir}")
    print(f"ä½¿ç”¨ä»£ç†: {args.use_proxy}")
    print("=" * 60)
    
    # æ¨¡å‹é…ç½®
    models = {
        "sd3-turbo": {
            "id": "stabilityai/stable-diffusion-3.5-large-turbo",  # ä½¿ç”¨æ ‡å‡† diffusers æ ¼å¼
            "dir": base_dir / "sd3-turbo",
            "description": "SD3.5 Large Turboï¼ˆæé€Ÿæ‰¹é‡ç”Ÿæˆï¼Œæ ‡å‡† diffusers æ ¼å¼ï¼‰"
        },
        "flux1": {
            "id": "black-forest-labs/FLUX.1-dev",
            "dir": base_dir / "flux1-dev",
            "description": "Flux.1ï¼ˆä¸»æŒäººè„¸+FaceIDï¼Œå®éªŒå®¤/åŒ»å­¦åœºæ™¯ï¼Œçº¦24GBï¼‰"
        },
        "flux2": {
            "id": "black-forest-labs/FLUX.1-schnell",  # æ³¨æ„ï¼šFlux.2 çš„å®é™…æ¨¡å‹IDéœ€è¦ç¡®è®¤
            "dir": base_dir / "flux2-dev",
            "description": "Flux.2ï¼ˆç§‘å­¦èƒŒæ™¯å›¾ã€å¤ªç©º/ç²’å­/é‡å­ç±»ï¼Œå†²å‡»åŠ›å¼ºï¼Œçº¦24GBï¼‰"
        },
        "flux": {  # å…¼å®¹æ—§å‚æ•°ï¼Œä¸‹è½½ flux1 å’Œ flux2
            "id": None,
            "dir": None,
            "description": "Fluxï¼ˆä¸‹è½½ Flux.1 å’Œ Flux.2ï¼‰",
            "is_alias": True
        },
        "hunyuan-dit": {
            "id": "Tencent-Hunyuan/HunyuanDiT",
            "dir": base_dir / "hunyuan-dit",
            "description": "Hunyuan-DiTï¼ˆä¸­æ–‡åœºæ™¯ï¼Œå¯èƒ½éœ€è¦æˆæƒï¼‰"
        },
        "kolors": {
            "id": "Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus",  # ä½¿ç”¨ IP-Adapter FaceID Plus ç‰ˆæœ¬
            "dir": base_dir / "kolors",
            "description": "Kolorsï¼ˆçœŸå®æ„Ÿåœºæ™¯ï¼Œå¿«æ‰‹å¯å›¾å›¢é˜Ÿå¼€å‘ï¼ŒçœŸäººè´¨æ„Ÿå¼ºï¼Œä¸­æ–‡ prompt ç†è§£ä¼˜ç§€ï¼‰",
            "note": "ä½¿ç”¨ Kolors-IP-Adapter-FaceID-Plus ç‰ˆæœ¬ï¼Œå¯ç›´æ¥ç”¨ diffusers åŠ è½½"
        }
    }
    
    # é€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹
    if args.model == "all":
        models_to_download = [k for k in models.keys() if not models[k].get("is_alias", False)]
    elif args.model == "flux":
        # flux æ˜¯åˆ«åï¼Œä¸‹è½½ flux1 å’Œ flux2
        models_to_download = ["flux1", "flux2"]
    else:
        models_to_download = [args.model]
    
    # ä¸‹è½½æ¨¡å‹
    success_count = 0
    fail_count = 0
    skipped_count = 0
    
    for i, model_key in enumerate(models_to_download, 1):
        model_info = models[model_key]
        print(f"\n[{i}/{len(models_to_download)}] {model_info['description']}")
        print("-" * 60)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ«å
        if model_info.get("is_alias", False):
            print(f"   â„¹ï¸  {model_key} æ˜¯åˆ«åï¼Œå·²å¤„ç†")
            skipped_count += 1
            continue
        
        # æ£€æŸ¥æ¨¡å‹IDæ˜¯å¦å­˜åœ¨
        if model_info["id"] is None:
            print(f"   âš  {model_key} æ¨¡å‹ä¸å¯ç”¨")
            if "alternative" in model_info:
                print(f"   ğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ: å¯ä»¥ä½¿ç”¨ {model_info['alternative']} æˆ–å…¶ä»–çœŸå®æ„Ÿæ¨¡å‹")
                print(f"   ğŸ’¡ å»ºè®®: ä½¿ç”¨ SDXL æˆ– Flux é…åˆçœŸå®æ„Ÿ LoRA å®ç°ç±»ä¼¼æ•ˆæœ")
            skipped_count += 1
            continue
        
        # ç‰¹æ®Šå¤„ç†ï¼šæ˜¾ç¤º Kolors çš„è¯´æ˜
        if model_key == "kolors" and "note" in model_info:
            print(f"   â„¹ï¸  {model_info['note']}")
        
        if download_model(
            model_id=model_info["id"],
            local_dir=model_info["dir"],
            resume=True,
            use_proxy=args.use_proxy,
            max_retries=5,  # é»˜è®¤é‡è¯•5æ¬¡
            retry_delay=10  # é»˜è®¤å»¶è¿Ÿ10ç§’
        ):
            success_count += 1
        else:
            fail_count += 1
            # å¯¹äºæŸäº›æ¨¡å‹ï¼Œå¤±è´¥ä¸é˜»æ­¢ç»§ç»­ä¸‹è½½
            if model_key == "kolors":
                print("   âš  Kolors ä¸‹è½½å¤±è´¥")
                print("   ğŸ’¡ æç¤º: Kolors å¯èƒ½éœ€è¦ç‰¹æ®Šæˆæƒï¼Œè¯·è®¿é—® https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus")
                print("   ğŸ’¡ æ³¨æ„: ç¡®ä¿å·²å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ diffusers: pip install -U diffusers transformers accelerate")
            else:
                print(f"   âš  {model_key} ä¸‹è½½å¤±è´¥")
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¸‹è½½æ€»ç»“")
    print("=" * 60)
    print(f"æˆåŠŸ: {success_count}/{len(models_to_download)}")
    print(f"å¤±è´¥: {fail_count}/{len(models_to_download)}")
    
    if fail_count > 0:
        print("\nâš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("  1. HuggingFace è®¿é—®æƒé™")
        print("  2. ç½‘ç»œè¿æ¥å’Œä»£ç†é…ç½®")
        print("  3. æ¨¡å‹æ˜¯å¦éœ€è¦ç‰¹æ®Šæˆæƒ")
        print("  4. å­˜å‚¨ç©ºé—´æ˜¯å¦å……è¶³ï¼ˆçº¦ 50-60GBï¼‰")
    
    print("\nâœ… ä¸‹è½½å®Œæˆï¼")


if __name__ == "__main__":
    main()


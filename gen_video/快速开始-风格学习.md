# å¿«é€Ÿå¼€å§‹ï¼šæ•´ä½“é£æ ¼å­¦ä¹ 

## ğŸ“‹ å‰ææ¡ä»¶

- âœ… processedç›®å½•ä¸­å·²æœ‰5500+å¼ å…³é”®å¸§å›¾ç‰‡
- âœ… å·²å®‰è£…è®­ç»ƒç¯å¢ƒï¼ˆaccelerate, diffusers, peftç­‰ï¼‰
- âœ… æœ‰è¶³å¤Ÿçš„GPUæ˜¾å­˜ï¼ˆæ¨è16GB+ï¼‰

## ğŸš€ ä¸‰æ­¥å®Œæˆé£æ ¼å­¦ä¹ 

### æ­¥éª¤1ï¼šæ”¶é›†é£æ ¼å‚è€ƒå›¾åƒï¼ˆ5åˆ†é’Ÿï¼‰

ä»processedç›®å½•ä¸­æ”¶é›†30-50å¼ ä»£è¡¨æ€§å…³é”®å¸§ï¼š

```bash
cd /vepfs-dev/shawn/vid/fanren

python gen_video/tools/collect_style_reference_frames.py \
    --base-dir . \
    --output gen_video/reference_materials/style_frames \
    --num-frames 30 \
    --method diverse \
    --rename
```

**å‚æ•°è¯´æ˜ï¼š**
- `--num-frames 30`: é€‰æ‹©30å¼ å¸§ï¼ˆæ¨è30-50å¼ ï¼‰
- `--method diverse`: ç¡®ä¿å¤šæ ·æ€§ï¼Œä»ä¸åŒåœºæ™¯é€‰æ‹©
- `--rename`: é‡å‘½åä¸º style_ref_001.jpg æ ¼å¼

**è¾“å‡ºï¼š**
- `gen_video/reference_materials/style_frames/`: 30å¼ é£æ ¼å‚è€ƒå›¾åƒ
- `metadata.json`: å…ƒæ•°æ®æ–‡ä»¶ï¼ˆåŒ…å«åŸå§‹è·¯å¾„ç­‰ä¿¡æ¯ï¼‰

### æ­¥éª¤2ï¼šè®­ç»ƒé£æ ¼LoRAï¼ˆ1-2å°æ—¶ï¼‰

ä½¿ç”¨æ”¶é›†çš„å‚è€ƒå›¾åƒè®­ç»ƒé£æ ¼LoRAï¼š

```bash
python scripts/train_style_lora_sdxl.py \
    --pretrained_model_name_or_path stabilityai/stable-diffusion-xl-base-1.0 \
    --instance_data_dir gen_video/reference_materials/style_frames \
    --output_dir gen_video/models/lora/anime_style \
    --instance_prompt "anime style, xianxia animation style, å‡¡äººä¿®ä»™ä¼  style" \
    --resolution 1024 \
    --train_batch_size 1 \
    --gradient_accumulation_steps 4 \
    --learning_rate 1e-4 \
    --max_train_steps 1000 \
    --checkpointing_steps 200
```

**è®­ç»ƒå‚æ•°è¯´æ˜ï¼š**
- `--max_train_steps 1000`: è®­ç»ƒæ­¥æ•°ï¼ˆæ¨è800-1200ï¼‰
- `--learning_rate 1e-4`: å­¦ä¹ ç‡ï¼ˆæ¨è1e-4ï¼‰
- `--resolution 1024`: è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆ1024æˆ–512ï¼‰

**è®­ç»ƒæ—¶é—´ï¼š**
- 30å¼ å›¾ç‰‡ï¼Œ1000æ­¥ï¼šçº¦1-2å°æ—¶ï¼ˆå–å†³äºGPUï¼‰

### æ­¥éª¤3ï¼šé…ç½®ä½¿ç”¨ï¼ˆ5åˆ†é’Ÿï¼‰

åœ¨ `gen_video/config.yaml` ä¸­é…ç½®é£æ ¼LoRAï¼š

```yaml
image:
  lora:
    enabled: true
    # è§’è‰²LoRAï¼ˆå·²æœ‰ï¼‰
    weights_path: gen_video/models/lora/hanli/pytorch_lora_weights.safetensors
    adapter_name: hanli
    alpha: 0.60
    
    # é£æ ¼LoRAï¼ˆæ–°å¢ï¼‰
    style_lora:
      enabled: true
      weights_path: gen_video/models/lora/anime_style/pytorch_lora_weights.safetensors
      adapter_name: anime_style
      alpha: 0.7  # é£æ ¼æƒé‡ï¼Œå¯è°ƒèŠ‚ï¼ˆ0.5-0.8ï¼‰
```

### æ­¥éª¤4ï¼šæµ‹è¯•ç”Ÿæˆ

```bash
# ä½¿ç”¨é£æ ¼LoRAç”Ÿæˆæµ‹è¯•å›¾åƒ
python gen_video/main.py --script test_scene.json --output test_style
```

## ğŸ¯ æ•ˆæœå¯¹æ¯”

**ä½¿ç”¨å‰ï¼ˆæ— é£æ ¼LoRAï¼‰ï¼š**
- é£æ ¼å¯èƒ½ä¸ä¸€è‡´
- ä¸åŒåœºæ™¯é£æ ¼å·®å¼‚å¤§
- éœ€è¦æ¯å¼ å›¾ç‰‡å•ç‹¬å‚è€ƒ

**ä½¿ç”¨åï¼ˆæœ‰é£æ ¼LoRAï¼‰ï¼š**
- âœ… æ‰€æœ‰åœºæ™¯ä¿æŒç»Ÿä¸€çš„åŸåŠ¨æ¼«é£æ ¼
- âœ… æ— éœ€æ¯å¼ å›¾ç‰‡å•ç‹¬å‚è€ƒ
- âœ… é£æ ¼ç¨³å®šï¼Œè´¨é‡é«˜

## ğŸ”§ é«˜çº§é…ç½®

### å¤šLoRAç»„åˆä½¿ç”¨

åŒæ—¶ä½¿ç”¨è§’è‰²LoRAå’Œé£æ ¼LoRAï¼š

```python
# åœ¨image_generator.pyä¸­
# åŠ è½½å¤šä¸ªLoRA
pipeline.load_lora_weights([
    "models/lora/hanli/pytorch_lora_weights.safetensors",      # è§’è‰²
    "models/lora/anime_style/pytorch_lora_weights.safetensors"  # é£æ ¼
], adapter_names=["hanli", "anime_style"])

# è®¾ç½®æƒé‡
pipeline.set_adapters(["hanli", "anime_style"], adapter_weights=[0.6, 0.7])
```

### åŠ¨æ€æƒé‡è°ƒæ•´

æ ¹æ®åœºæ™¯ç±»å‹è°ƒæ•´æƒé‡ï¼š

```python
# è¿œæ™¯åœºæ™¯ï¼šé™ä½è§’è‰²LoRAï¼Œæé«˜é£æ ¼LoRA
if scene_type == "wide_shot":
    character_weight = 0.4
    style_weight = 0.8
# ç‰¹å†™åœºæ™¯ï¼šæé«˜è§’è‰²LoRAï¼Œé™ä½é£æ ¼LoRA
elif scene_type == "close_up":
    character_weight = 0.8
    style_weight = 0.5
```

## ğŸ“Š è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥ï¼š
1. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
2. å®šæœŸæ£€æŸ¥checkpointï¼ˆæ¯200æ­¥ï¼‰
3. ä½¿ç”¨tensorboardç›‘æ§ï¼ˆå¦‚æœå¯ç”¨ï¼‰

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f training.log

# ä½¿ç”¨tensorboardï¼ˆå¦‚æœå¯ç”¨ï¼‰
tensorboard --logdir gen_video/models/lora/anime_style/logs
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ˜¾å­˜ä¸è¶³ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- é™ä½ `--resolution` åˆ° 512
- é™ä½ `--train_batch_size` åˆ° 1
- å¯ç”¨ `--gradient_checkpointing`
- ä½¿ç”¨ `--enable_cpu_offload`

### Q2: é£æ ¼å­¦ä¹ æ•ˆæœä¸å¥½ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
- å‚è€ƒå›¾åƒè´¨é‡ä¸é«˜
- å‚è€ƒå›¾åƒé£æ ¼ä¸ä¸€è‡´
- è®­ç»ƒæ­¥æ•°ä¸å¤Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- é‡æ–°é€‰æ‹©é«˜è´¨é‡çš„å‚è€ƒå›¾åƒ
- ç¡®ä¿å‚è€ƒå›¾åƒé£æ ¼ç»Ÿä¸€
- å¢åŠ è®­ç»ƒæ­¥æ•°åˆ°1200-1500

### Q3: é£æ ¼LoRAä¸è§’è‰²LoRAå†²çªï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- é™ä½é£æ ¼LoRAæƒé‡ï¼ˆ0.5-0.6ï¼‰
- é™ä½è§’è‰²LoRAæƒé‡ï¼ˆ0.5-0.6ï¼‰
- è°ƒæ•´è®­ç»ƒæ—¶çš„instance_prompt

## ğŸ‰ å®Œæˆï¼

è®­ç»ƒå®Œæˆåï¼Œæ‰€æœ‰ç”Ÿæˆçš„å›¾åƒéƒ½ä¼šè‡ªåŠ¨ä½¿ç”¨é£æ ¼LoRAï¼Œä¿æŒç»Ÿä¸€çš„åŸåŠ¨æ¼«é£æ ¼ï¼


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PuLID-FLUX å¼•æ“ - èº«ä»½ä¿æŒä¸ç¯å¢ƒèåˆ

æ¯” InstantID æ›´å¥½çš„èº«ä»½-ç¯å¢ƒå¹³è¡¡ï¼š
- ä½¿ç”¨ PuLID-FLUX v0.9.1 è¿›è¡Œèº«ä»½åµŒå…¥
- æ”¯æŒå‚è€ƒå¼ºåº¦æ§åˆ¶ (0-100)
- æ›´å¥½çš„ç¯å¢ƒè¡¨è¾¾èƒ½åŠ›

å‚è€ƒæ¶æ„ï¼š
- è±†åŒ… Seedream 2.0 çš„å‚è€ƒå¼ºåº¦æ§åˆ¶
- å¯çµ Element Library çš„å¤šå‚è€ƒå›¾ç³»ç»Ÿ
"""

import os
# âš¡ å…³é”®ä¿®å¤ï¼šåœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒæŠ‘åˆ¶ transformers çš„è­¦å‘Šè¾“å‡º
os.environ.setdefault("TRANSFORMERS_VERBOSITY", "error")  # è®¾ç½®ä¸º error çº§åˆ«ï¼Œåªæ˜¾ç¤ºé”™è¯¯
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")  # ç¦ç”¨ tokenizers çš„å¹¶è¡Œè­¦å‘Š

import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Tuple
from PIL import Image
import logging
import warnings
import sys
from contextlib import contextmanager

# âš¡ æŠ‘åˆ¶ EVA02-CLIP çš„ rope keys ç¼ºå¤±è­¦å‘Šï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸å½±å“åŠŸèƒ½ï¼‰
warnings.filterwarnings("ignore", message=".*incompatible_keys.missing_keys.*rope.*")
warnings.filterwarnings("ignore", message=".*missing_keys.*rope.*")

# âš¡ æŠ‘åˆ¶ CLIP tokenizer çš„ 77 token è­¦å‘Šï¼ˆFlux ä½¿ç”¨ T5 ä½œä¸ºä¸»ç¼–ç å™¨ï¼Œæ”¯æŒ 512 tokensï¼ŒCLIP åªæ˜¯è¾…åŠ©ç¼–ç å™¨ï¼‰
warnings.filterwarnings("ignore", message=".*Token indices sequence length is longer than the specified maximum sequence length.*")
warnings.filterwarnings("ignore", message=".*The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens.*")

# âš¡ å…³é”®ä¿®å¤ï¼šåˆ›å»ºä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥æŠ‘åˆ¶ CLIP tokenizer çš„ç›´æ¥ stderr è¾“å‡º
@contextmanager
def suppress_clip_tokenizer_warnings():
    """æŠ‘åˆ¶ CLIP tokenizer ç›´æ¥æ‰“å°åˆ° stderr çš„è­¦å‘Š"""
    import sys
    from io import StringIO
    
    # ä¿å­˜åŸå§‹çš„ stderr
    original_stderr = sys.stderr
    
    try:
        # åˆ›å»ºä¸€ä¸ªè¿‡æ»¤å™¨æ¥è¿‡æ»¤ CLIP tokenizer çš„è­¦å‘Š
        class FilteredStderr:
            def __init__(self, original):
                self.original = original
                self.buffer = []
            
            def write(self, text):
                # è¿‡æ»¤æ‰ CLIP tokenizer çš„ 77 token è­¦å‘Š
                if "Token indices sequence length is longer" in text:
                    return
                if "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens" in text:
                    return
                # å…¶ä»–å†…å®¹æ­£å¸¸è¾“å‡º
                self.original.write(text)
            
            def flush(self):
                self.original.flush()
            
            def __getattr__(self, name):
                return getattr(self.original, name)
        
        # æ›¿æ¢ stderr
        sys.stderr = FilteredStderr(original_stderr)
        yield
    finally:
        # æ¢å¤åŸå§‹çš„ stderr
        sys.stderr = original_stderr

import logging
import gc

# âš¡ æ·»åŠ  logging filter æ¥è¿‡æ»¤ EVA02-CLIP çš„ rope keys ç¼ºå¤±æ—¥å¿—
class EVA02CLIPRopeFilter(logging.Filter):
    """è¿‡æ»¤ EVA02-CLIP çš„ rope keys ç¼ºå¤±æ—¥å¿—ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸å½±å“åŠŸèƒ½ï¼‰"""
    def filter(self, record):
        # è¿‡æ»¤åŒ…å« rope.freqs ç›¸å…³çš„æ—¥å¿—
        if "rope.freqs" in record.getMessage() or "missing_keys" in record.getMessage():
            if "rope" in record.getMessage().lower():
                return False  # ä¸æ˜¾ç¤ºè¿™äº›æ—¥å¿—
        return True  # æ˜¾ç¤ºå…¶ä»–æ—¥å¿—

# åº”ç”¨ filter åˆ° root loggerï¼ˆå› ä¸º EVA02-CLIP ä½¿ç”¨ root loggerï¼‰
logging.getLogger().addFilter(EVA02CLIPRopeFilter())

logger = logging.getLogger(__name__)

def log_memory(stage: str):
    """è®°å½•æ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        logger.info(f"Memory [{stage}]: Allocated {allocated:.2f} GB, Reserved {reserved:.2f} GB")



class PuLIDEngine:
    """
    PuLID-FLUX å¼•æ“
    
    åŠŸèƒ½ï¼š
    - äººè„¸èº«ä»½åµŒå…¥ (æ¯”InstantIDæ›´å¥½çš„ç¯å¢ƒèåˆ)
    - å‚è€ƒå¼ºåº¦æ§åˆ¶ (0-100, ç±»ä¼¼å¯çµçš„å‚è€ƒå¼ºåº¦)
    - å¤šè§’åº¦å‚è€ƒå›¾æ”¯æŒ
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ– PuLID å¼•æ“
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹è·¯å¾„ç­‰
        """
        self.config = config
        self.device = config.get("device", "cuda")
        self.dtype = torch.bfloat16 if config.get("quantization", "bfloat16") == "bfloat16" else torch.float16
        
        # æ¨¡å‹è·¯å¾„é…ç½®
        self.model_base_path = config.get("model_dir", "/vepfs-dev/shawn/vid/fanren/gen_video/models")
        # æ³¨æ„ï¼šæ–‡ä»¶åæ˜¯å°å†™çš„ pulid_flux_v0.9.1.safetensors
        self.pulid_path = os.path.join(self.model_base_path, "pulid", "pulid_flux_v0.9.1.safetensors")
        self.flux_path = os.path.join(self.model_base_path, "flux1-dev")
        self.antelopev2_path = os.path.join(self.model_base_path, "antelopev2")
        self.eva_clip_path = os.path.join(self.model_base_path, "clip", "EVA02_CLIP_L_336_psz14_s6B.pt")
        
        # PuLID åŸç”Ÿæ¨¡å‹è·¯å¾„
        self.flux_native_path = os.path.join(self.model_base_path, "flux1-dev.safetensors")
        self.ae_path = os.path.join(self.model_base_path, "ae.safetensors")
        
        # Pipeline çŠ¶æ€
        self.pipeline = None
        self.face_analyzer = None
        self.pulid_loaded = False
        
        # PuLID åŸç”Ÿç»„ä»¶
        self.flux_model = None  # åŸç”Ÿ Flux æ¨¡å‹
        self.ae = None  # AutoEncoder
        self.t5 = None  # T5 ç¼–ç å™¨
        self.clip = None  # CLIP ç¼–ç å™¨
        self.pulid_model = None
        self.id_embedding = None
        self.use_native = False  # æ˜¯å¦ä½¿ç”¨åŸç”Ÿæ¨¡å¼
        
        # ç¼“å­˜
        self.face_embedding_cache = {}
        
        logger.info(f"PuLID Engine åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  PuLID æ¨¡å‹: {self.pulid_path}")
        logger.info(f"  Flux æ¨¡å‹: {self.flux_path}")
        logger.info(f"  Flux åŸç”Ÿ: {self.flux_native_path}")
    
    def load_pipeline(self):
        """
        åŠ è½½ PuLID-FLUX pipeline
        
        ä¼˜å…ˆä½¿ç”¨åŸç”Ÿæ¨¡å¼ï¼ˆflux.modelï¼‰ï¼Œå›é€€åˆ° diffusers æ¨¡å¼
        """
        if self.pulid_loaded:
            logger.info("PuLID pipeline å·²åŠ è½½ï¼Œè·³è¿‡")
            return
        
        logger.info("å¼€å§‹åŠ è½½ PuLID-FLUX pipeline...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŸç”Ÿæ¨¡å‹
        has_native_flux = os.path.exists(self.flux_native_path)
        has_ae = os.path.exists(self.ae_path)
        # æ£€æŸ¥æ˜¯å¦æœ‰åŸç”Ÿ Flux æ¨¡å‹
        # æ³¨æ„ï¼šæš‚æ—¶ç¦ç”¨åŸç”Ÿæ¨¡å¼ï¼Œå› ä¸ºæ˜¾å­˜å ç”¨å¤ªå¤§
        # TODO: åç»­ä¼˜åŒ–åŸç”Ÿæ¨¡å¼çš„æ˜¾å­˜ç®¡ç†
        if os.path.exists(self.flux_native_path) and os.path.exists(self.ae_path):
            logger.info("æ£€æµ‹åˆ°åŸç”Ÿ Flux æ¨¡å‹ï¼Œå¯ç”¨åŸç”Ÿæ¨¡å¼...")
            # logger.info("ä½¿ç”¨ diffusers æ¨¡å¼ï¼ˆæ”¯æŒæ›´å¥½çš„æ˜¾å­˜ç®¡ç†ï¼‰...") # Removed misleading log
            try:
                self._load_native_pipeline()
                self.use_native = True
                self.pulid_loaded = True
                logger.info("PuLID åŸç”Ÿæ¨¡å¼åŠ è½½å®Œæˆ!")
                return
            except Exception as e:
                logger.warning(f"åŸç”Ÿæ¨¡å¼åŠ è½½å¤±è´¥: {e}")
                logger.info("å›é€€åˆ° diffusers æ¨¡å¼...")
                try:
                    self.use_native = False
                    self._load_diffusers_pipeline()
                    self.pulid_loaded = True
                    logger.info("PuLID diffusers æ¨¡å¼åŠ è½½å®Œæˆï¼ˆåŸç”Ÿå¤±è´¥å›é€€ï¼‰")
                    return
                except Exception as e2:
                    logger.error(f"diffusers å›é€€åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
                    raise

        # æ²¡æœ‰åŸç”Ÿæƒé‡æ—¶ï¼Œç›´æ¥ä½¿ç”¨ diffusers æ¨¡å¼
        logger.info("æœªæ£€æµ‹åˆ°å¯ç”¨çš„åŸç”Ÿ Flux æƒé‡ï¼Œä½¿ç”¨ diffusers æ¨¡å¼åŠ è½½ PuLID...")
        self.use_native = False
        self._load_diffusers_pipeline()
        self.pulid_loaded = True
        logger.info("PuLID diffusers æ¨¡å¼åŠ è½½å®Œæˆ")
        return

    def _load_native_pipeline(self):
        """åŠ è½½ PuLID åŸç”Ÿ Flux æ¨¡å‹ï¼ˆæ˜¾å­˜ä¼˜åŒ–ç‰ˆï¼‰"""
        log_memory("Start Native Load")
        logger.info("åŠ è½½ PuLID åŸç”Ÿ Flux æ¨¡å‹...")
        
        # æ£€æŸ¥å¯ç”¨æ˜¾å­˜
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            free = total - reserved
            logger.info(f"æ˜¾å­˜çŠ¶æ€: æ€»è®¡={total:.2f}GB, å·²åˆ†é…={allocated:.2f}GB, å·²ä¿ç•™={reserved:.2f}GB, å¯ç”¨={free:.2f}GB")
            
            # å¦‚æœå¯ç”¨æ˜¾å­˜å°‘äº 25GBï¼Œè­¦å‘Š
            if free < 25:
                logger.warning(f"å¯ç”¨æ˜¾å­˜è¾ƒå°‘ ({free:.2f}GB)ï¼Œå¯èƒ½ä¼šè¶…å‡ºæ˜¾å­˜é™åˆ¶")
                logger.warning("å»ºè®®ï¼š1) å…³é—­å…¶ä»–å ç”¨æ˜¾å­˜çš„ç¨‹åº 2) ä½¿ç”¨æ›´æ¿€è¿›çš„ CPU offload")
        
        # å¯¼å…¥åŸç”Ÿæ¨¡å—
        # æ·»åŠ  PuLID åˆ° Python è·¯å¾„ï¼ˆPuLID å­æ¨¡å—ä½äº fanren/PuLIDï¼Œä¸ gen_video å¹³çº§ï¼‰
        import sys
        from pathlib import Path
        pulid_path = Path(__file__).parent.parent / "PuLID"
        if pulid_path.exists() and str(pulid_path) not in sys.path:
            sys.path.insert(0, str(pulid_path))
        
        from flux.util import load_t5, load_clip, load_ae
        from pulid.pipeline_flux import PuLIDPipeline
        
        # âš¡ å…³é”®ä¿®å¤ï¼šè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© PuLIDPipeline ä½¿ç”¨æœ¬åœ° EVA-CLIP æ¨¡å‹
        if os.path.exists(self.eva_clip_path):
            os.environ['EVA_CLIP_PATH'] = self.eva_clip_path
            logger.info(f"  âœ“ è®¾ç½® EVA_CLIP_PATH ç¯å¢ƒå˜é‡: {self.eva_clip_path}")
        else:
            logger.warning(f"  âš  æœ¬åœ° EVA-CLIP æ¨¡å‹ä¸å­˜åœ¨: {self.eva_clip_path}")
        
        # åŠ è½½ Flux DiT æ¨¡å‹ (ä¸»è¦æ¨¡å‹ï¼Œä¿æŒåœ¨ GPU)
        logger.info(f"  åŠ è½½ Flux DiT: {self.flux_native_path}")
        self.flux_model = self._optimized_load_flux("flux-dev", device=self.device)
        log_memory("After Flux Load")
        
        # åŠ è½½ AutoEncoder (è§£ç å™¨ï¼Œä¿æŒåœ¨ GPU)
        logger.info(f"  åŠ è½½ AutoEncoder: {self.ae_path}")
        # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ¬åœ° AE æ¨¡å‹æ–‡ä»¶ï¼Œé¿å…ä¸‹è½½
        # load_ae ä½¿ç”¨ configs[name].ae_pathï¼Œæˆ‘ä»¬éœ€è¦ä¸´æ—¶ä¿®æ”¹ configs æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
        from flux.util import configs, load_sft, AutoEncoder
        # âš¡ å…³é”®ä¿®å¤ï¼štorch å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œä¸éœ€è¦å†æ¬¡å¯¼å…¥
        # import torch  # åˆ é™¤è¿™è¡Œï¼Œä½¿ç”¨æ–‡ä»¶é¡¶éƒ¨çš„ torch
        
        if os.path.exists(self.ae_path):
            logger.info(f"  âœ“ æ£€æµ‹åˆ°æœ¬åœ° AE æ¨¡å‹æ–‡ä»¶: {self.ae_path}")
            try:
                # ä¿å­˜åŸå§‹è·¯å¾„
                original_ae_path = configs["flux-dev"].ae_path
                # ä¸´æ—¶ä¿®æ”¹ configs ä½¿ç”¨æœ¬åœ°è·¯å¾„
                configs["flux-dev"].ae_path = self.ae_path
                logger.info(f"  âœ“ ä½¿ç”¨æœ¬åœ° AE è·¯å¾„: {self.ae_path}")
                
                # è°ƒç”¨ load_aeï¼Œç°åœ¨å®ƒä¼šä½¿ç”¨æˆ‘ä»¬è®¾ç½®çš„æœ¬åœ°è·¯å¾„
                self.ae = load_ae("flux-dev", device=self.device, hf_download=False)
                logger.info(f"  âœ… æˆåŠŸä»æœ¬åœ°åŠ è½½ AE æ¨¡å‹ï¼ˆæœªä¸‹è½½ï¼‰")
                
                # æ¢å¤åŸå§‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œå› ä¸ºå·²ç»åŠ è½½å®Œæˆï¼‰
                # configs["flux-dev"].ae_path = original_ae_path
            except Exception as e:
                logger.warning(f"  âš  ä½¿ç”¨æœ¬åœ° AE æ–‡ä»¶å¤±è´¥: {e}")
                logger.info(f"  â„¹ å›é€€åˆ°é»˜è®¤åŠ è½½æ–¹å¼ï¼ˆå¯èƒ½ä¼šä¸‹è½½ï¼‰")
                # æ¢å¤åŸå§‹è·¯å¾„
                if 'original_ae_path' in locals():
                    configs["flux-dev"].ae_path = original_ae_path
                self.ae = load_ae("flux-dev", device=self.device)
        else:
            logger.warning(f"  âš  æœ¬åœ° AE æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.ae_path}")
            logger.info(f"  â„¹ å°†ä½¿ç”¨é»˜è®¤åŠ è½½æ–¹å¼ï¼ˆå¯èƒ½ä¼šä¸‹è½½ï¼‰")
            self.ae = load_ae("flux-dev", device=self.device)
        log_memory("After AE Load")
        
        # åŠ è½½ T5 å’Œ CLIP (å…ˆåŠ è½½åˆ° CPUï¼Œä½¿ç”¨æ—¶å†ç§»åˆ° GPU)
        # æ³¨æ„ï¼šFlux ä½¿ç”¨åŒç¼–ç å™¨æ¶æ„ï¼š
        #   - T5 ç¼–ç å™¨ï¼ˆä¸»è¦ï¼‰ï¼šæ”¯æŒ 128/256/512 tokensï¼Œå½“å‰é…ç½®ä¸º 256
        #   - CLIP ç¼–ç å™¨ï¼ˆè¾…åŠ©ï¼‰ï¼šå›ºå®š 77 tokensï¼ˆç”¨äºè¾…åŠ©è¯­ä¹‰ï¼Œä¸æ˜¯ä¸»è¦é™åˆ¶ï¼‰
        # âš¡ é‡è¦ï¼šCLIP çš„ 77 token è­¦å‘Šæ˜¯æ­£å¸¸çš„ï¼Œä¸å½±å“ç”Ÿæˆè´¨é‡ï¼ˆT5 æ˜¯ä¸»è¦ç¼–ç å™¨ï¼‰
        # å¦‚æœéœ€è¦æ”¯æŒæ›´é•¿çš„ promptï¼Œå¯ä»¥å°† T5 max_length æé«˜åˆ° 512
        t5_max_length = self.config.get("t5_max_length", 256)  # é»˜è®¤ 256ï¼Œå¯é…ç½®ä¸º 512
        logger.info(f"  åŠ è½½ T5 ç¼–ç å™¨ (CPU offload, max_length={t5_max_length})...")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ¬åœ° T5 æ¨¡å‹ï¼Œé¿å…é‡å¤ä¸‹è½½
        local_t5_path = os.path.join(self.model_base_path, "xflux_text_encoders")
        if os.path.exists(local_t5_path):
            logger.info(f"  âœ“ ä½¿ç”¨æœ¬åœ° T5 æ¨¡å‹: {local_t5_path}")
            # ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½ T5ï¼ˆHFEmbedder çš„ from_pretrained æ”¯æŒæœ¬åœ°è·¯å¾„ï¼‰
            from flux.modules.conditioner import HFEmbedder
            # âš¡ ä¿®å¤ï¼šä¸è¦åœ¨è¿™é‡Œé‡æ–°å¯¼å…¥ torchï¼Œä½¿ç”¨æ–‡ä»¶é¡¶éƒ¨å·²å¯¼å…¥çš„ torch
            # import torch  # åˆ é™¤è¿™è¡Œï¼Œå› ä¸ºæ–‡ä»¶é¡¶éƒ¨å·²ç»å¯¼å…¥äº† torch
            try:
                # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œå¹¶æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                abs_t5_path = os.path.abspath(local_t5_path)
                # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                required_files = [
                    "model-00001-of-00002.safetensors",
                    "model-00002-of-00002.safetensors",
                    "config.json"
                ]
                missing_files = []
                for file in required_files:
                    file_path = os.path.join(abs_t5_path, file)
                    if not os.path.exists(file_path):
                        missing_files.append(file)
                
                if missing_files:
                    logger.warning(f"  âš  æœ¬åœ° T5 æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œç¼ºå°‘: {missing_files}")
                    raise FileNotFoundError(f"T5 æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´: {missing_files}")
                
                # ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼ŒHFEmbedder åº”è¯¥ä¼šè‡ªåŠ¨è¯†åˆ«
                # å¦‚æœ HFEmbedder å†…éƒ¨ä½¿ç”¨ transformersï¼Œå®ƒä¼šè‡ªåŠ¨è¯†åˆ«æœ¬åœ°è·¯å¾„
                # âš¡ å…³é”®ä¿®å¤ï¼šä¼ é€’ local_files_only=True å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                logger.info(f"  âœ“ T5 æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„: {abs_t5_path}")
                self.t5 = HFEmbedder(
                    abs_t5_path, 
                    max_length=t5_max_length, 
                    torch_dtype=torch.bfloat16,
                    local_files_only=True  # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œé¿å…ä¸‹è½½
                ).to("cpu")
                logger.info(f"  âœ… æœ¬åœ° T5 æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆæœªä¸‹è½½ï¼‰")
            except Exception as e:
                logger.warning(f"  âš  æœ¬åœ° T5 æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ HuggingFace ç¼“å­˜")
                import traceback
                traceback.print_exc()
                # å›é€€åˆ°åŸå§‹æ–¹æ³•ï¼ˆä¼šå°è¯•ä½¿ç”¨ HuggingFace ç¼“å­˜ï¼‰
                # âš¡ å…³é”®ä¿®å¤ï¼šè®¾ç½® local_files_only=Trueï¼ˆå¦‚æœ HFEmbedder æ”¯æŒï¼‰
                try:
                    # å°è¯•ä½¿ç”¨ local_files_onlyï¼ˆå¦‚æœæ”¯æŒï¼‰
                    from transformers import AutoModel, AutoTokenizer
                    # æ£€æŸ¥ HuggingFace ç¼“å­˜
                    hf_home = os.environ.get("HF_HOME", os.path.expanduser("~/.cache/huggingface"))
                    hf_cache_path = os.path.join(hf_home, "hub", "models--xlabs-ai--xflux_text_encoders")
                    if os.path.exists(hf_cache_path):
                        logger.info(f"  â„¹ å°è¯•ä» HuggingFace ç¼“å­˜åŠ è½½ T5: {hf_cache_path}")
                        self.t5 = load_t5(device="cpu", max_length=t5_max_length)
                    else:
                        logger.error(f"  âŒ T5 æ¨¡å‹ä¸å­˜åœ¨ï¼ˆæœ¬åœ°å’Œç¼“å­˜éƒ½æ²¡æœ‰ï¼‰")
                        raise FileNotFoundError(f"T5 æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½åˆ°: {local_t5_path} æˆ– {hf_cache_path}")
                except Exception as e2:
                    logger.error(f"  âŒ T5 åŠ è½½å¤±è´¥: {e2}")
                    raise
        else:
            # å›é€€åˆ°åŸå§‹æ–¹æ³•ï¼ˆä¼šä» HuggingFace ä¸‹è½½æˆ–ä½¿ç”¨ç¼“å­˜ï¼‰
            logger.warning(f"  âš  æœ¬åœ° T5 æ¨¡å‹ä¸å­˜åœ¨: {local_t5_path}ï¼Œå°†ä½¿ç”¨ HuggingFace")
            # âš¡ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ HuggingFace ç¼“å­˜ï¼Œé¿å…ä¸‹è½½
            hf_home = os.environ.get("HF_HOME", os.path.expanduser("~/.cache/huggingface"))
            hf_cache_path = os.path.join(hf_home, "hub", "models--xlabs-ai--xflux_text_encoders")
            if os.path.exists(hf_cache_path):
                logger.info(f"  â„¹ ä½¿ç”¨ HuggingFace ç¼“å­˜: {hf_cache_path}")
                self.t5 = load_t5(device="cpu", max_length=t5_max_length)
            else:
                logger.error(f"  âŒ T5 æ¨¡å‹ä¸å­˜åœ¨ï¼ˆæœ¬åœ°å’Œç¼“å­˜éƒ½æ²¡æœ‰ï¼‰")
                logger.error(f"  ğŸ’¡ è¯·å…ˆä¸‹è½½ T5 æ¨¡å‹åˆ°: {local_t5_path}")
                raise FileNotFoundError(f"T5 æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½åˆ°: {local_t5_path}")
        
        logger.info("  åŠ è½½ CLIP ç¼–ç å™¨ (CPU offload)...")
        # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ¬åœ° CLIP æ¨¡å‹æˆ–ç¼“å­˜ï¼Œé¿å…ç½‘ç»œä¸‹è½½
        # âš¡ å…³é”®ä¿®å¤ï¼šåœ¨åŠ è½½ CLIP æ—¶æŠ‘åˆ¶ 77 token è­¦å‘Š
        with suppress_clip_tokenizer_warnings():
            try:
                from flux.modules.conditioner import HFEmbedder
                # æ£€æŸ¥æœ¬åœ° CLIP æ¨¡å‹è·¯å¾„
                local_clip_path = os.path.join(self.model_base_path, "clip", "openai-clip-vit-large-patch14")
                
                # æ£€æŸ¥ HuggingFace ç¼“å­˜è·¯å¾„
                hf_home = os.environ.get("HF_HOME", os.path.expanduser("~/.cache/huggingface"))
                # å¦‚æœé»˜è®¤è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨é¡¹ç›®é…ç½®çš„ç¼“å­˜ç›®å½•
                if not os.path.exists(hf_home):
                    hf_home = "/vepfs-dev/shawn/.cache/huggingface"
                    os.environ["HF_HOME"] = hf_home
                hf_cache_path = os.path.join(hf_home, "hub", "models--openai--clip-vit-large-patch14")
                
                # å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½
                if os.path.exists(local_clip_path):
                    logger.info(f"  âœ“ ä½¿ç”¨æœ¬åœ° CLIP æ¨¡å‹: {local_clip_path}")
                    try:
                        # âš¡ å…³é”®ä¿®å¤ï¼šç¡®ä¿è·¯å¾„æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå¹¶æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        abs_clip_path = os.path.abspath(local_clip_path)
                        # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆtransformers æ”¯æŒ safetensors æˆ– pytorch_model.binï¼‰
                        required_config_file = "config.json"
                        model_files = ["model.safetensors", "pytorch_model.bin"]
                        
                        config_exists = os.path.exists(os.path.join(abs_clip_path, required_config_file))
                        has_model_file = any(os.path.exists(os.path.join(abs_clip_path, f)) for f in model_files)
                        
                        if not config_exists:
                            logger.warning(f"  âš  æœ¬åœ° CLIP æ¨¡å‹ç¼ºå°‘é…ç½®æ–‡ä»¶: {required_config_file}")
                            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ ¼å¼çš„æ–‡ä»¶
                            all_files = os.listdir(abs_clip_path)
                            logger.info(f"  â„¹ CLIP ç›®å½•ä¸­çš„æ–‡ä»¶: {all_files[:10]}")
                            # å¦‚æœç¼ºå°‘é…ç½®æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨ HuggingFace ç¼“å­˜
                            if os.path.exists(hf_cache_path):
                                logger.info(f"  â„¹ å°è¯•ä» HuggingFace ç¼“å­˜åŠ è½½ CLIP: {hf_cache_path}")
                                self.clip = HFEmbedder("openai/clip-vit-large-patch14", max_length=77, torch_dtype=torch.bfloat16, local_files_only=True).to("cpu")
                                logger.info(f"  âœ… ä» HuggingFace ç¼“å­˜åŠ è½½ CLIP æˆåŠŸ")
                            else:
                                raise FileNotFoundError(f"CLIP æ¨¡å‹ç¼ºå°‘é…ç½®æ–‡ä»¶: {required_config_file}")
                        elif not has_model_file:
                            logger.warning(f"  âš  æœ¬åœ° CLIP æ¨¡å‹ç¼ºå°‘æ¨¡å‹æ–‡ä»¶ï¼ˆéœ€è¦ {model_files} ä¹‹ä¸€ï¼‰")
                            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ ¼å¼çš„æ–‡ä»¶
                            all_files = os.listdir(abs_clip_path)
                            logger.info(f"  â„¹ CLIP ç›®å½•ä¸­çš„æ–‡ä»¶: {all_files[:10]}")
                            # å¦‚æœç¼ºå°‘æ¨¡å‹æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨ HuggingFace ç¼“å­˜
                            if os.path.exists(hf_cache_path):
                                logger.info(f"  â„¹ å°è¯•ä» HuggingFace ç¼“å­˜åŠ è½½ CLIP: {hf_cache_path}")
                                self.clip = HFEmbedder("openai/clip-vit-large-patch14", max_length=77, torch_dtype=torch.bfloat16, local_files_only=True).to("cpu")
                                logger.info(f"  âœ… ä» HuggingFace ç¼“å­˜åŠ è½½ CLIP æˆåŠŸ")
                            else:
                                raise FileNotFoundError(f"CLIP æ¨¡å‹ç¼ºå°‘æ¨¡å‹æ–‡ä»¶ï¼ˆéœ€è¦ {model_files} ä¹‹ä¸€ï¼‰")
                        else:
                            # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„å­—ç¬¦ä¸²ï¼Œå¹¶ä¼ é€’ local_files_only=True
                            # transformers ä¼šè‡ªåŠ¨è¯†åˆ« safetensors æˆ– pytorch_model.bin
                            # âš¡ å…³é”®ä¿®å¤ï¼šHFEmbedder ç°åœ¨å¯ä»¥è¯†åˆ«æœ¬åœ° CLIP è·¯å¾„ï¼ˆåŒ…å« "clip" å…³é”®å­—ï¼‰
                            logger.info(f"  âœ“ CLIP æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼ˆconfig.json + æ¨¡å‹æ–‡ä»¶ï¼‰ï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„: {abs_clip_path}")
                            self.clip = HFEmbedder(
                                abs_clip_path,  # ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼ŒHFEmbedder ä¼šè¯†åˆ«ä¸º CLIP
                                max_length=77, 
                                torch_dtype=torch.bfloat16,
                                local_files_only=True  # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œé¿å…ä¸‹è½½
                            ).to("cpu")
                            logger.info(f"  âœ… æœ¬åœ° CLIP æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆæœªä¸‹è½½ï¼‰")
                    except Exception as e:
                        logger.warning(f"  âš  æœ¬åœ° CLIP æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ HuggingFace ç¼“å­˜")
                        import traceback
                        traceback.print_exc()
                        # å›é€€åˆ°ä½¿ç”¨ HuggingFace ç¼“å­˜ï¼ˆlocal_files_only=Trueï¼‰
                        if os.path.exists(hf_cache_path):
                            try:
                                self.clip = HFEmbedder("openai/clip-vit-large-patch14", max_length=77, torch_dtype=torch.bfloat16, local_files_only=True).to("cpu")
                                logger.info(f"  âœ… ä» HuggingFace ç¼“å­˜åŠ è½½ CLIP æˆåŠŸ")
                            except Exception as e2:
                                logger.error(f"  âŒ ä»ç¼“å­˜åŠ è½½ CLIP å¤±è´¥: {e2}")
                                raise
                        else:
                            logger.error(f"  âŒ HuggingFace ç¼“å­˜ä¸å­˜åœ¨: {hf_cache_path}")
                            logger.error(f"  ğŸ’¡ è¯·å…ˆä¸‹è½½ CLIP æ¨¡å‹ï¼Œè¿è¡Œ: python3 -c \"from transformers import CLIPTokenizer, CLIPTextModel; CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14'); CLIPTextModel.from_pretrained('openai/clip-vit-large-patch14')\"")
                            raise FileNotFoundError(f"CLIP æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½")
                else:
                    # æ£€æŸ¥ HuggingFace ç¼“å­˜
                    if os.path.exists(hf_cache_path):
                        logger.info(f"  â„¹ æœ¬åœ° CLIP æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨ HuggingFace ç¼“å­˜: {hf_cache_path}")
                        try:
                            self.clip = HFEmbedder("openai/clip-vit-large-patch14", max_length=77, torch_dtype=torch.bfloat16, local_files_only=True).to("cpu")
                            logger.info(f"  âœ… ä» HuggingFace ç¼“å­˜åŠ è½½ CLIP æˆåŠŸ")
                        except Exception as e:
                            logger.error(f"  âŒ ä»ç¼“å­˜åŠ è½½ CLIP å¤±è´¥: {e}")
                            raise
                    else:
                        logger.error(f"  âŒ CLIP æ¨¡å‹ä¸å­˜åœ¨ï¼ˆæœ¬åœ°å’Œç¼“å­˜éƒ½æ²¡æœ‰ï¼‰")
                        logger.error(f"  ğŸ’¡ è¯·å…ˆä¸‹è½½ CLIP æ¨¡å‹ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤:")
                        logger.error(f"     python3 -c \"from transformers import CLIPTokenizer, CLIPTextModel; CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14'); CLIPTextModel.from_pretrained('openai/clip-vit-large-patch14')\"")
                        raise FileNotFoundError(f"CLIP æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½åˆ°: {hf_cache_path}")
            except ImportError:
                logger.warning(f"  âš  æ— æ³•å¯¼å…¥ HFEmbedderï¼Œä½¿ç”¨ load_clipï¼ˆå¯èƒ½å°è¯•ç½‘ç»œä¸‹è½½ï¼‰")
                self.clip = load_clip(device="cpu")
            except FileNotFoundError:
                # å¦‚æœæ˜ç¡®æ˜¯æ–‡ä»¶ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºå¼‚å¸¸ï¼Œä¸è¦å°è¯•ç½‘ç»œä¸‹è½½
                raise
            except Exception as e:
                logger.error(f"  âŒ CLIP åŠ è½½å¤±è´¥: {e}")
                logger.error(f"  ğŸ’¡ å¦‚æœç½‘ç»œä¸å¯ç”¨ï¼Œè¯·å…ˆä¸‹è½½ CLIP æ¨¡å‹åˆ°ç¼“å­˜")
                raise
        log_memory("After Encoders Load")
        
        # åˆ›å»º PuLID Pipeline
        logger.info("  åˆ›å»º PuLID Pipeline...")
        self.pulid_model = PuLIDPipeline(
            dit=self.flux_model,
            device=self.device,
            weight_dtype=self.dtype
        )
        
        # åŠ è½½ PuLID æƒé‡
        logger.info(f"  åŠ è½½ PuLID æƒé‡: {self.pulid_path}")
        # âš¡ å…³é”®ä¿®å¤ï¼šä¼ é€’æ­£ç¡®çš„ç‰ˆæœ¬å·ï¼Œé¿å…ä¸‹è½½é”™è¯¯ç‰ˆæœ¬
        # ä»è·¯å¾„ä¸­æå–ç‰ˆæœ¬å·ï¼ˆä¾‹å¦‚ï¼špulid_flux_v0.9.1.safetensors -> v0.9.1ï¼‰
        import re
        version_match = re.search(r'v(\d+\.\d+\.\d+)', self.pulid_path)
        if version_match:
            pulid_version = version_match.group(1)
            logger.info(f"  âœ“ æ£€æµ‹åˆ° PuLID ç‰ˆæœ¬: v{pulid_version}")
            self.pulid_model.load_pretrain(pretrain_path=self.pulid_path, version=pulid_version)
        else:
            # é»˜è®¤ä½¿ç”¨ v0.9.1ï¼ˆä¸é…ç½®ä¸­çš„æ–‡ä»¶ååŒ¹é…ï¼‰
            logger.info(f"  â„¹ ä½¿ç”¨é»˜è®¤ PuLID ç‰ˆæœ¬: v0.9.1")
            self.pulid_model.load_pretrain(pretrain_path=self.pulid_path, version='v0.9.1')
        log_memory("After PuLID Load")
        
        # è®¾ç½®æ ‡å¿—
        self.use_pulid = True
        self.use_native = True
        self.use_cpu_offload = True  # æ ‡è®°ä½¿ç”¨ CPU offload
        
        logger.info("åŸç”Ÿæ¨¡å¼åŠ è½½å®Œæˆ! (CPU offload æ¨¡å¼)")

    def _optimized_load_flux(self, name: str, device: str = "cuda", hf_download: bool = True):
        """
        ä¼˜åŒ–çš„ Flux åŠ è½½å‡½æ•°
        
        åŸç”Ÿ util.load_flow_model ä¼šå°† checkpoint ç›´æ¥åŠ è½½åˆ° GPUï¼Œ
        åŠ ä¸Šå·²ç»åˆå§‹åŒ–çš„æ¨¡å‹ï¼Œä¼šå¯¼è‡´æ˜¾å­˜å ç”¨ç¿»å€ (23GB * 2 = 46GB)ã€‚
        æ­¤å‡½æ•°å¼ºåˆ¶å…ˆåŠ è½½åˆ° CPUï¼Œå†åŠ è½½è¿›æ¨¡å‹ã€‚
        """
        # âš¡ å…³é”®ä¿®å¤ï¼štorch å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œä¸éœ€è¦å†æ¬¡å¯¼å…¥
        # import torch  # åˆ é™¤è¿™è¡Œï¼Œä½¿ç”¨æ–‡ä»¶é¡¶éƒ¨çš„ torch
        
        from flux.model import Flux
        from flux.util import configs, load_sft, print_load_warning
        from huggingface_hub import hf_hub_download
        
        # Loading Flux
        logger.info("Init model (Optimized)")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆself.flux_native_pathï¼‰
        # å¦‚æœæœ¬åœ°æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨ï¼Œé¿å…ä¸‹è½½
        ckpt_path = None
        if hasattr(self, 'flux_native_path') and os.path.exists(self.flux_native_path):
            ckpt_path = self.flux_native_path
            logger.info(f"  âœ“ ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶: {ckpt_path}")
        else:
            # å›é€€åˆ°ä½¿ç”¨ configs ä¸­çš„è·¯å¾„
            ckpt_path = configs[name].ckpt_path
            logger.info(f"  â„¹ ä½¿ç”¨ configs è·¯å¾„: {ckpt_path}")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šåªæœ‰åœ¨æ–‡ä»¶ä¸å­˜åœ¨ä¸”æ˜ç¡®å…è®¸ä¸‹è½½æ—¶æ‰ä¸‹è½½
            if (
                not os.path.exists(ckpt_path)
                and configs[name].repo_id is not None
                and configs[name].repo_flow is not None
                and hf_download
            ):
                logger.warning(f"  âš  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ckpt_path}")
                logger.warning(f"  âš  å°†å°è¯•ä» HuggingFace ä¸‹è½½: {configs[name].repo_id}/{configs[name].repo_flow}")
                logger.warning(f"  âš  å¦‚æœæœ¬åœ°å·²æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®")
                ckpt_path = hf_hub_download(configs[name].repo_id, configs[name].repo_flow, local_dir='models')
            elif not os.path.exists(ckpt_path):
                logger.error(f"  âœ— æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ä¸”ä¸å…è®¸ä¸‹è½½: {ckpt_path}")
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ckpt_path}ï¼Œä¸” hf_download=False")

        # 1. åˆå§‹åŒ–æ¨¡å‹ç»“æ„ (å ç”¨æ˜¾å­˜)
        # âš¡ ä¿®å¤ï¼šä½¿ç”¨ torch.device å¯¹è±¡è€Œä¸æ˜¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        # æ³¨æ„ï¼štorch.device ä¸Šä¸‹æ–‡ç®¡ç†å™¨åœ¨æŸäº› PyTorch ç‰ˆæœ¬ä¸­å¯èƒ½ä¸å¯ç”¨
        # ç›´æ¥åˆ›å»ºæ¨¡å‹å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        model = Flux(configs[name].params)
        model = model.to(device).to(torch.bfloat16)

        if ckpt_path is not None:
            logger.info(f"Loading checkpoint: {ckpt_path}")
            logger.info("  Step 1: Loading state dict to CPU RAM...")
            # 2. åŠ è½½æƒé‡åˆ° CPU å†…å­˜ (ä¸å ç”¨æ˜¾å­˜)
            # load_sft å†…éƒ¨é€šå¸¸ä½¿ç”¨ safetensorsï¼Œæ”¯æŒ device å‚æ•°
            # å¼ºåˆ¶æŒ‡å®šä¸º cpu
            sd = load_sft(ckpt_path, device="cpu")
            
            logger.info("  Step 2: Loading state dict into Model (GPU)...")
            # 3. å°†æƒé‡åŠ è½½åˆ° GPU æ¨¡å‹ä¸­
            missing, unexpected = model.load_state_dict(sd, strict=False)
            print_load_warning(missing, unexpected)
            
            # 4. é‡Šæ”¾ CPU å†…å­˜
            del sd
            import gc
            gc.collect()
            torch.cuda.empty_cache()
            
        return model
    
    def _load_diffusers_pipeline(self):
        """ä½¿ç”¨ diffusers åŠ è½½ï¼ˆå›é€€æ¨¡å¼ï¼‰"""
        from diffusers import FluxPipeline
        
        logger.info("åŠ è½½ Flux pipeline (diffusers æ¨¡å¼)...")
        logger.info(f"  Flux æ¨¡å‹è·¯å¾„: {self.flux_path}")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šåœ¨åŠ è½½ pipeline æ—¶æŠ‘åˆ¶ CLIP tokenizer çš„ 77 token è­¦å‘Š
        with suppress_clip_tokenizer_warnings():
            # âš¡ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼Œé¿å…é‡æ–°ä¸‹è½½
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if os.path.exists(self.flux_path):
                logger.info(f"  âœ“ æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å‹")
                # âš¡ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                required_files = [
                    "model_index.json",
                    "flux1-dev.safetensors",
                    "transformer",
                    "vae",
                    "text_encoder",
                    "text_encoder_2"
                ]
                missing_files = []
                for file_or_dir in required_files:
                    path = os.path.join(self.flux_path, file_or_dir)
                    if not os.path.exists(path):
                        missing_files.append(file_or_dir)
                
                if missing_files:
                    logger.warning(f"  âš  æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œç¼ºå°‘: {missing_files}")
                    logger.info(f"  â„¹ å°†ä» HuggingFace ä¸‹è½½ç¼ºå¤±æ–‡ä»¶")
                    # å¦‚æœç¼ºå°‘å…³é”®æ–‡ä»¶ï¼Œå…è®¸ç½‘ç»œä¸‹è½½
                    self.pipeline = FluxPipeline.from_pretrained(
                        self.flux_path,
                        torch_dtype=self.dtype
                    )
                else:
                    # æ‰€æœ‰å…³é”®æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                    logger.info(f"  âœ“ æœ¬åœ°æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼ˆlocal_files_only=Trueï¼‰")
                    try:
                        self.pipeline = FluxPipeline.from_pretrained(
                            self.flux_path,
                            torch_dtype=self.dtype,
                            local_files_only=True
                        )
                        logger.info(f"  âœ… æˆåŠŸä»æœ¬åœ°åŠ è½½æ¨¡å‹ï¼ˆæœªä¸‹è½½ä»»ä½•æ–‡ä»¶ï¼‰")
                    except Exception as e:
                        logger.error(f"  âœ— ä½¿ç”¨ local_files_only åŠ è½½å¤±è´¥: {e}")
                        logger.warning(f"  âš  å³ä½¿æ–‡ä»¶å­˜åœ¨ï¼ŒåŠ è½½ä»å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸å…¼å®¹")
                        logger.info(f"  â„¹ å°è¯•ä¸ä½¿ç”¨ local_files_onlyï¼ˆå¯èƒ½ä¼šæ£€æŸ¥ç½‘ç»œä½†ä¸ä¼šä¸‹è½½ï¼Œå› ä¸ºæ–‡ä»¶å·²å­˜åœ¨ï¼‰")
                        # æœ€åä¸€æ¬¡å°è¯•ï¼šä¸ä½¿ç”¨ local_files_onlyï¼Œä½†æ–‡ä»¶å·²å­˜åœ¨ï¼Œåº”è¯¥ä¸ä¼šä¸‹è½½
                        self.pipeline = FluxPipeline.from_pretrained(
                            self.flux_path,
                            torch_dtype=self.dtype
                        )
            else:
                logger.warning(f"  âš  æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.flux_path}")
                logger.info(f"  â„¹ å°†ä» HuggingFace ä¸‹è½½æ¨¡å‹")
                self.pipeline = FluxPipeline.from_pretrained(
                    self.flux_path,
                    torch_dtype=self.dtype
                )
        self.pipeline.enable_model_cpu_offload()
        
        # å°è¯•åŠ è½½ PuLID
        try:
            # æ·»åŠ  PuLID åˆ° Python è·¯å¾„ï¼ˆPuLID å­æ¨¡å—ä½äº fanren/PuLIDï¼Œä¸ gen_video å¹³çº§ï¼‰
            import sys
            from pathlib import Path
            pulid_path = Path(__file__).parent.parent / "PuLID"
            if pulid_path.exists() and str(pulid_path) not in sys.path:
                sys.path.insert(0, str(pulid_path))
            
            from pulid.pipeline_flux import PuLIDPipeline
            
            dit = self.pipeline.transformer
            self.pulid_model = PuLIDPipeline(
                dit=dit,
                device=self.device,
                weight_dtype=self.dtype
            )
            # âš¡ å…³é”®ä¿®å¤ï¼šä¼ é€’æ­£ç¡®çš„ç‰ˆæœ¬å·ï¼Œé¿å…ä¸‹è½½é”™è¯¯ç‰ˆæœ¬
            # ä»è·¯å¾„ä¸­æå–ç‰ˆæœ¬å·ï¼ˆä¾‹å¦‚ï¼špulid_flux_v0.9.1.safetensors -> v0.9.1ï¼‰
            import re
            version_match = re.search(r'v(\d+\.\d+\.\d+)', self.pulid_path)
            if version_match:
                pulid_version = version_match.group(1)
                logger.info(f"  âœ“ æ£€æµ‹åˆ° PuLID ç‰ˆæœ¬: v{pulid_version}")
                self.pulid_model.load_pretrain(pretrain_path=self.pulid_path, version=pulid_version)
            else:
                # é»˜è®¤ä½¿ç”¨ v0.9.1ï¼ˆä¸é…ç½®ä¸­çš„æ–‡ä»¶ååŒ¹é…ï¼‰
                logger.info(f"  â„¹ ä½¿ç”¨é»˜è®¤ PuLID ç‰ˆæœ¬: v0.9.1")
                self.pulid_model.load_pretrain(pretrain_path=self.pulid_path, version='v0.9.1')
            self.use_pulid = True  # æ ‡è®° PuLID å¯ç”¨
            logger.info("PuLID æ¨¡å‹åŠ è½½å®Œæˆ (diffusers æ¨¡å¼)")
            
        except Exception as e:
            logger.warning(f"PuLID åŠ è½½å¤±è´¥: {e}")
            self.pulid_model = None
            self.use_pulid = False
        
        # åŠ è½½ InsightFace
        self._load_face_analyzer()
        # æ ‡è®°åŠ è½½å®Œæˆ
        self.pulid_loaded = True
    
    def _load_pulid_with_diffusers(self):
        """
        ä½¿ç”¨ diffusers æ–¹å¼åŠ è½½ Flux + PuLID
        
        è¿™æ˜¯å¤‡ç”¨æ–¹æ¡ˆï¼Œå½“ pulid åŒ…ä¸å¯ç”¨æ—¶ä½¿ç”¨
        """
        try:
            from diffusers import FluxPipeline
            
            logger.info("åŠ è½½ Flux pipeline (diffusers æ–¹å¼)...")
            logger.info(f"  Flux æ¨¡å‹è·¯å¾„: {self.flux_path}")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šåœ¨åŠ è½½ pipeline æ—¶æŠ‘åˆ¶ CLIP tokenizer çš„ 77 token è­¦å‘Š
            with suppress_clip_tokenizer_warnings():
                # åŠ è½½åŸºç¡€ Flux pipeline
                self.pipeline = FluxPipeline.from_pretrained(
                    self.flux_path,
                    torch_dtype=self.dtype
                )
            
            # å¯ç”¨ä¼˜åŒ–
            self.pipeline.enable_model_cpu_offload()
            
            # åŠ è½½ InsightFace ç”¨äºäººè„¸æ£€æµ‹
            self._load_face_analyzer()
            
            # æ³¨æ„ï¼šä½¿ç”¨ diffusers æ–¹å¼æ—¶ï¼ŒPuLID æƒé‡éœ€è¦æ‰‹åŠ¨æ³¨å…¥
            # è¿™æ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´ç‰ˆæœ¬éœ€è¦å®ç° PuLID çš„ attention injection
            logger.warning("ä½¿ç”¨ diffusers ç®€åŒ–æ¨¡å¼ï¼ŒPuLID èº«ä»½æ³¨å…¥åŠŸèƒ½å—é™")
            
            self.pulid_loaded = True
            self.use_pulid = False
            logger.info("Flux pipeline åŠ è½½å®Œæˆ (ç®€åŒ–æ¨¡å¼)")
            
        except Exception as e:
            logger.error(f"diffusers æ–¹å¼åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _load_face_analyzer(self):
        """åŠ è½½äººè„¸åˆ†æå™¨ (InsightFace)"""
        if self.face_analyzer is not None:
            return
        
        try:
            from insightface.app import FaceAnalysis
            
            logger.info("åŠ è½½ InsightFace FaceAnalysis...")
            
            # InsightFace çš„ root å‚æ•°ä¼šåœ¨å…¶ä¸‹å¯»æ‰¾ models/{name} ç›®å½•
            # antelopev2_path = /path/to/gen_video/models/antelopev2
            # éœ€è¦è®¾ç½® root = /path/to/gen_videoï¼Œè¿™æ · InsightFace ä¼šæ‰¾ {root}/models/antelopev2
            insightface_root = os.path.dirname(os.path.dirname(self.antelopev2_path))
            
            logger.info(f"  InsightFace root: {insightface_root}")
            logger.info(f"  æ¨¡å‹ç›®å½•: {self.antelopev2_path}")
            
            self.face_analyzer = FaceAnalysis(
                name='antelopev2',
                root=insightface_root,
                providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
            )
            self.face_analyzer.prepare(ctx_id=0, det_size=(640, 640))
            
            logger.info("InsightFace åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"InsightFace åŠ è½½å¤±è´¥: {e}")
            raise
    
    def extract_face_embedding(
        self,
        image: Union[str, Image.Image, np.ndarray]
    ) -> Optional[np.ndarray]:
        """
        æå–äººè„¸åµŒå…¥å‘é‡
        
        Args:
            image: è¾“å…¥å›¾åƒ (è·¯å¾„/PIL Image/numpy array)
            
        Returns:
            äººè„¸åµŒå…¥å‘é‡ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸åˆ™è¿”å› None
        """
        # ç¡®ä¿äººè„¸åˆ†æå™¨å·²åŠ è½½
        self._load_face_analyzer()
        
        # è½¬æ¢å›¾åƒæ ¼å¼
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # æ£€æµ‹äººè„¸
        faces = self.face_analyzer.get(image)
        
        if not faces:
            logger.warning("æœªæ£€æµ‹åˆ°äººè„¸")
            return None
        
        # è¿”å›æœ€å¤§äººè„¸çš„åµŒå…¥
        main_face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])
        return main_face.embedding
    
    def generate_with_identity(
        self,
        prompt: str,
        face_reference: Union[str, Image.Image],
        reference_strength: int = 60,
        width: int = 768,
        height: int = 1152,
        num_inference_steps: int = 28,
        guidance_scale: float = 3.5,
        seed: Optional[int] = None,
        **kwargs
    ) -> Image.Image:
        """
        ä½¿ç”¨èº«ä»½å‚è€ƒç”Ÿæˆå›¾åƒ
        
        Args:
            prompt: ç”Ÿæˆæç¤ºè¯ (åº”è¯¥åŒ…å«è¯¦ç»†çš„ç¯å¢ƒæè¿°)
            face_reference: äººè„¸å‚è€ƒå›¾åƒ
            reference_strength: å‚è€ƒå¼ºåº¦ (0-100)
                - 0-30: è½»å¾®å‚è€ƒï¼Œç¯å¢ƒä¼˜å…ˆ (é€‚åˆè¿œæ™¯)
                - 30-60: å¹³è¡¡æ¨¡å¼ (é€‚åˆä¸­æ™¯)
                - 60-90: å¼ºå‚è€ƒï¼Œäººè„¸ä¼˜å…ˆ (é€‚åˆç‰¹å†™)
            width: è¾“å‡ºå®½åº¦
            height: è¾“å‡ºé«˜åº¦
            num_inference_steps: æ¨ç†æ­¥æ•°
            guidance_scale: å¼•å¯¼å¼ºåº¦
            seed: éšæœºç§å­
            
        Returns:
            ç”Ÿæˆçš„å›¾åƒ
        """
        # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰å‚è€ƒå›¾åƒï¼Œç›´æ¥ä½¿ç”¨æ— èº«ä»½æ³¨å…¥æ¨¡å¼
        if face_reference is None:
            logger.info("æ²¡æœ‰å‚è€ƒå›¾åƒï¼Œä½¿ç”¨æ— èº«ä»½æ³¨å…¥æ¨¡å¼ç”Ÿæˆ")
            # ç¡®ä¿ pipeline å·²åŠ è½½
            self.load_pipeline()
            if self.pipeline is None:
                raise RuntimeError("Pipeline æœªåŠ è½½ï¼Œæ— æ³•ç”Ÿæˆå›¾åƒ")
            
            # è®¾ç½®éšæœºç§å­
            generator = None
            if seed is not None:
                generator = torch.Generator(device=self.device).manual_seed(seed)
            
            # âš¡ å…³é”®ä¿®å¤ï¼šåœ¨ç”Ÿæˆå›¾åƒæ—¶æŠ‘åˆ¶ CLIP tokenizer çš„ 77 token è­¦å‘Š
            with suppress_clip_tokenizer_warnings():
                result = self.pipeline(
                    prompt=prompt,
                    width=width,
                    height=height,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    generator=generator,
                ).images[0]
            return result
        
        # ç¡®ä¿ pipeline å·²åŠ è½½
        self.load_pipeline()
        
        # âš¡ å…³é”®ä¿®å¤ï¼šåŠ è½½ LoRAï¼ˆå¦‚æœæä¾›ï¼‰
        lora_config = kwargs.get('lora_config', None)
        character_id = kwargs.get('character_id', None)
        lora_loaded = False
        
        if lora_config:
            lora_path = lora_config.get('lora_path', '')
            lora_weight = lora_config.get('weight', 0.9)
            
            # æ£€æŸ¥è·¯å¾„ï¼ˆæ”¯æŒç›¸å¯¹è·¯å¾„ï¼‰
            if lora_path:
                lora_path_obj = Path(lora_path)
                if not lora_path_obj.is_absolute():
                    # ç›¸å¯¹è·¯å¾„ï¼šä» gen_video ç›®å½•å¼€å§‹ï¼ˆpulid_engine.py åœ¨ gen_video ç›®å½•ä¸‹ï¼‰
                    base_path = Path(__file__).parent  # gen_video ç›®å½•
                    lora_path_obj = base_path / lora_path
                lora_path = str(lora_path_obj)
            
            if lora_path and Path(lora_path).exists():
                try:
                    adapter_name = character_id if character_id else "character_lora"
                    logger.info(f"  åŠ è½½ LoRA: {lora_path} (æƒé‡: {lora_weight}, é€‚é…å™¨: {adapter_name})")
                    print(f"  [è°ƒè¯•] å°è¯•åŠ è½½ LoRA: {lora_path}")
                    
                    # âš¡ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ LoRA æƒé‡æ ¼å¼ï¼Œåªåœ¨éœ€è¦æ—¶è½¬æ¢
                    # å¦‚æœæƒé‡å·²ç»æ˜¯ diffusers æ ¼å¼ï¼ˆunet.xxx æˆ– transformer.xxxï¼‰ï¼Œç›´æ¥ä½¿ç”¨
                    # å¦‚æœæ˜¯ PEFT æ ¼å¼ï¼ˆbase_model.model.xxx æˆ– single_transformer_blocksï¼‰ï¼Œéœ€è¦è½¬æ¢
                    from safetensors import safe_open
                    import tempfile
                    import os
                    
                    lora_path_obj = Path(lora_path)
                    actual_lora_path = lora_path  # é»˜è®¤ä½¿ç”¨åŸå§‹è·¯å¾„
                    converted_lora_path = None
                    needs_conversion = False
                    is_unet_lora = False  # æ ‡è®°æ˜¯å¦ä¸ºUNetæ ¼å¼çš„LoRAï¼ˆåœ¨æ•´ä¸ªtryå—å†…éƒ½å¯ç”¨ï¼‰
                    
                    # æ£€æŸ¥æƒé‡æ ¼å¼
                    try:
                        with safe_open(str(lora_path_obj), framework="pt") as f:
                            sample_keys = list(f.keys())[:10]  # æ£€æŸ¥å‰10ä¸ªé”®
                            # æ£€æŸ¥æ˜¯å¦ä¸ºUNetæ ¼å¼
                            is_unet_lora = any(key.startswith("unet.") for key in sample_keys)
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢ï¼šå¦‚æœåŒ…å« PEFT æ ¼å¼ç‰¹å¾ï¼Œéœ€è¦è½¬æ¢
                            for key in sample_keys:
                                if key.startswith("base_model.model.") or "single_transformer_blocks" in key:
                                    needs_conversion = True
                                    break
                        
                        if needs_conversion:
                            logger.info(f"  ğŸ”§ æ£€æµ‹åˆ° PEFT æ ¼å¼ï¼Œè½¬æ¢ LoRA æƒé‡: {lora_path_obj.name}")
                            print(f"  [è°ƒè¯•] æ£€æµ‹åˆ° PEFT æ ¼å¼ï¼Œè½¬æ¢ LoRA æƒé‡")
                            
                            # è¯»å–å¹¶è½¬æ¢ LoRA æƒé‡ï¼ˆPEFT â†’ diffusersï¼‰
                            lora_state_dict = {}
                            with safe_open(str(lora_path_obj), framework="pt") as f:
                                for key in f.keys():
                                    new_key = key
                                    # æ­¥éª¤ 1ï¼šç§»é™¤ base_model.model. å‰ç¼€ï¼ˆPEFT æ ¼å¼ï¼‰
                                    if key.startswith("base_model.model."):
                                        new_key = key.replace("base_model.model.", "")
                                    
                                    # æ­¥éª¤ 2ï¼šå°† single_transformer_blocks æ›¿æ¢ä¸º transformer_blocks
                                    if "single_transformer_blocks" in new_key:
                                        new_key = new_key.replace("single_transformer_blocks", "transformer_blocks")
                                    
                                    # æ­¥éª¤ 3ï¼šç§»é™¤ .default éƒ¨åˆ†ï¼ˆPEFT æ ¼å¼ï¼‰
                                    if ".default." in new_key:
                                        new_key = new_key.replace(".default.", ".")
                                    
                                    # æ­¥éª¤ 4ï¼šæ·»åŠ  transformer. å‰ç¼€ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼Œä¸”æ˜¯ transformer_blocks ç›¸å…³çš„é”®ï¼‰
                                    if "transformer_blocks" in new_key and not new_key.startswith("transformer."):
                                        new_key = f"transformer.{new_key}"
                                    
                                    lora_state_dict[new_key] = f.get_tensor(key)
                            
                            # ä¿å­˜è½¬æ¢åçš„æƒé‡åˆ°ä¸´æ—¶æ–‡ä»¶
                            with tempfile.NamedTemporaryFile(suffix=".safetensors", delete=False) as tmp_file:
                                from safetensors.torch import save_file
                                save_file(lora_state_dict, tmp_file.name)
                                converted_lora_path = tmp_file.name
                            
                            actual_lora_path = converted_lora_path
                            logger.info(f"  âœ“ LoRA æƒé‡æ ¼å¼è½¬æ¢æˆåŠŸ")
                            print(f"  [è°ƒè¯•] LoRA æƒé‡æ ¼å¼è½¬æ¢æˆåŠŸ")
                        else:
                            if is_unet_lora:
                                logger.info(f"  â„¹ LoRA æƒé‡æ˜¯ UNet æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨: {lora_path_obj.name}")
                                print(f"  [è°ƒè¯•] LoRA æƒé‡æ˜¯ UNet æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ (is_unet_lora=True)")
                            else:
                                logger.info(f"  â„¹ LoRA æƒé‡å·²æ˜¯ diffusers æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨: {lora_path_obj.name}")
                                print(f"  [è°ƒè¯•] LoRA æƒé‡å·²æ˜¯ diffusers æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ (is_unet_lora=False)")
                            
                    except Exception as check_e:
                        logger.warning(f"  âš  æ£€æŸ¥ LoRA æ ¼å¼å¤±è´¥: {check_e}ï¼Œå°è¯•ç›´æ¥åŠ è½½")
                        print(f"  [è°ƒè¯•] æ£€æŸ¥ LoRA æ ¼å¼å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡ä»¶: {check_e} (is_unet_lora={is_unet_lora})")
                    
                    # 1. ä¼˜å…ˆå°è¯•åœ¨ pipeline ä¸ŠåŠ è½½ï¼ˆdiffusers æ¨¡å¼ï¼Œæ”¯æŒ LoRAï¼‰
                    if self.pipeline is not None:
                        # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ adapter_name åŠ è½½ï¼ˆUNetæ ¼å¼çš„LoRAåº”è¯¥èƒ½ç›´æ¥åŠ è½½ï¼‰
                        try:
                            # âš¡ å…³é”®ä¿®å¤ï¼šå¯¹äºUNetæ ¼å¼çš„LoRAï¼Œload_lora_weightsä¼šè‡ªåŠ¨å¤„ç†
                            # è­¦å‘Š"No LoRA keys associated to FluxTransformer2DModel"æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºè¿™æ˜¯UNetçš„LoRA
                            self.pipeline.load_lora_weights(actual_lora_path, adapter_name=adapter_name, weight_name=None)
                            
                            # âš¡ ä¿®å¤ï¼šæ£€æŸ¥ adapter æ˜¯å¦å·²æˆåŠŸåŠ è½½
                            if hasattr(self.pipeline, 'set_adapters'):
                                # ç­‰å¾…ä¸€ä¸‹ï¼Œè®©load_lora_weightså®Œæˆæ³¨å†Œ
                                import time
                                time.sleep(0.1)
                                
                                # æ£€æŸ¥ adapter æ˜¯å¦å·²åŠ è½½
                                adapter_to_use = None
                                if hasattr(self.pipeline, 'get_list_adapters'):
                                    try:
                                        list_adapters = self.pipeline.get_list_adapters()
                                        all_adapters = {adapter for adapters in list_adapters.values() for adapter in adapters}
                                        if adapter_name in all_adapters:
                                            adapter_to_use = adapter_name
                                        elif all_adapters:
                                            # å¦‚æœæŒ‡å®šçš„ adapter_name ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œä½†å·²æœ‰å…¶ä»– adapterï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
                                            adapter_to_use = list(all_adapters)[0]
                                            logger.info(f"  â„¹ ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„ adapter: {adapter_to_use} (è€ŒéæŒ‡å®šçš„ {adapter_name})")
                                        else:
                                            # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½• adapterï¼Œå¯¹äºUNet LoRAï¼Œç›´æ¥è®¤ä¸ºå·²åŠ è½½
                                            if is_unet_lora:
                                                logger.info(f"  âœ“ UNet LoRA å·²åŠ è½½ï¼ˆload_lora_weightsæˆåŠŸï¼Œget_list_adaptersè¿”å›ç©ºä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                                print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆget_list_adaptersè¿”å›ç©ºä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                                lora_loaded = True
                                                # è·³è¿‡åç»­çš„ set_adapters å°è¯•
                                                adapter_to_use = None
                                    except Exception as check_e:
                                        logger.warning(f"  âš  æ£€æŸ¥ adapter åˆ—è¡¨å¤±è´¥: {check_e}")
                                        # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œå¯¹äºUNet LoRAï¼Œç›´æ¥è®¤ä¸ºå·²åŠ è½½
                                        if is_unet_lora:
                                            logger.info(f"  âœ“ UNet LoRA å·²åŠ è½½ï¼ˆload_lora_weightsæˆåŠŸï¼Œæ£€æŸ¥adapteråˆ—è¡¨å¤±è´¥ä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                            print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆæ£€æŸ¥adapteråˆ—è¡¨å¤±è´¥ä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                            lora_loaded = True
                                            adapter_to_use = None
                                        else:
                                            # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä»ç„¶å°è¯•ä½¿ç”¨æŒ‡å®šçš„ adapter_name
                                            adapter_to_use = adapter_name
                                else:
                                    # âš¡ å…³é”®ä¿®å¤ï¼šæ²¡æœ‰ get_list_adapters æ–¹æ³•ï¼Œå¯¹äºUNet LoRAï¼Œç›´æ¥è®¤ä¸ºå·²åŠ è½½
                                    if is_unet_lora:
                                        logger.info(f"  âœ“ UNet LoRA å·²åŠ è½½ï¼ˆload_lora_weightsæˆåŠŸï¼Œæ— get_list_adaptersæ–¹æ³•ä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                        print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆæ— get_list_adaptersæ–¹æ³•ä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                        lora_loaded = True
                                        adapter_to_use = None
                                    else:
                                        # æ²¡æœ‰ get_list_adapters æ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨æŒ‡å®šçš„ adapter_name
                                        adapter_to_use = adapter_name
                                
                                if adapter_to_use:
                                    try:
                                        self.pipeline.set_adapters([adapter_to_use], adapter_weights=[lora_weight])
                                        logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (pipeline, adapter: {adapter_to_use}, weight: {lora_weight})")
                                        print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (pipeline, adapter: {adapter_to_use}, weight: {lora_weight})")
                                        lora_loaded = True
                                    except Exception as set_e:
                                        # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœset_adapterså¤±è´¥ï¼Œå¯¹äºUNet LoRAï¼Œload_lora_weightså¯èƒ½å·²ç»ç›´æ¥åº”ç”¨äº†æƒé‡
                                        logger.warning(f"  âš  è®¾ç½® adapter {adapter_to_use} å¤±è´¥: {set_e}")
                                        if is_unet_lora:
                                            # UNet LoRAä¸éœ€è¦set_adaptersï¼Œload_lora_weightså·²ç»ç›´æ¥åº”ç”¨äº†æƒé‡
                                            logger.info(f"  âœ“ UNet LoRA å·²åŠ è½½ï¼ˆload_lora_weightsæˆåŠŸï¼Œset_adapterså¤±è´¥ä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                            print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆload_lora_weightsæˆåŠŸï¼Œset_adapterså¤±è´¥ä½†æ— éœ€adapteræœºåˆ¶ï¼‰")
                                            lora_loaded = True
                                        else:
                                            # å¯¹äºéUNet LoRAï¼Œå°è¯•å…¶ä»–æ–¹å¼éªŒè¯
                                            logger.info(f"  â„¹ å°è¯•ç»§ç»­ä½¿ç”¨ï¼ˆLoRAå¯èƒ½å·²ç›´æ¥åº”ç”¨ï¼‰")
                                            try:
                                                # å°è¯•è·å–å·²åŠ è½½çš„adaptersï¼ˆå¯èƒ½ä½¿ç”¨ä¸åŒçš„æ–¹æ³•ï¼‰
                                                if hasattr(self.pipeline, 'get_active_adapters'):
                                                    active = list(self.pipeline.get_active_adapters())
                                                    if active:
                                                        logger.info(f"  âœ“ LoRA å¯èƒ½å·²é€šè¿‡å…¶ä»–æ–¹å¼åŠ è½½ (active adapters: {active})")
                                                        lora_loaded = True
                                                    else:
                                                        logger.warning(f"  âš  æœªæ£€æµ‹åˆ°active adapters")
                                                        lora_loaded = False
                                                else:
                                                    lora_loaded = False
                                            except:
                                                logger.warning(f"  âš  æ— æ³•éªŒè¯LoRAæ˜¯å¦å·²åŠ è½½")
                                                lora_loaded = False
                                else:
                                    # âš¡ å…³é”®ä¿®å¤ï¼šå¯¹äºUNetæ ¼å¼çš„LoRAï¼Œå³ä½¿get_list_adaptersè¿”å›ç©ºï¼Œload_lora_weightsä¹Ÿå¯èƒ½å·²æˆåŠŸ
                                    # UNet LoRAæ˜¯ç›´æ¥åº”ç”¨åˆ°UNetçš„ï¼Œä¸éœ€è¦é€šè¿‡adapteræœºåˆ¶
                                    # âš  æ³¨æ„ï¼šload_lora_weights é»˜è®¤ä½¿ç”¨æƒé‡ 1.0ï¼Œå¯¹äº UNet LoRAï¼Œæƒé‡å·²ç»åœ¨åŠ è½½æ—¶ç›´æ¥åº”ç”¨
                                    # å¦‚æœéœ€è¦è°ƒæ•´æƒé‡ï¼Œéœ€è¦åœ¨åŠ è½½å‰æ‰‹åŠ¨ç¼©æ”¾ LoRA æƒé‡æ–‡ä»¶ï¼Œæˆ–è€…ä½¿ç”¨ fuse_lora æ–¹æ³•
                                    logger.debug(f"  [è°ƒè¯•] adapter_to_use=None, is_unet_lora={is_unet_lora}")
                                    if is_unet_lora:
                                        # âš¡ å…³é”®ä¿®å¤ï¼šå¯¹äº UNet LoRAï¼Œload_lora_weights å·²ç»ç›´æ¥åº”ç”¨äº†æƒé‡ï¼ˆé»˜è®¤ 1.0ï¼‰
                                        # å¦‚æœéœ€è¦ä½¿ç”¨è‡ªå®šä¹‰æƒé‡ï¼ˆlora_weightï¼‰ï¼Œæˆ‘ä»¬éœ€è¦åœ¨åŠ è½½æ—¶æ‰‹åŠ¨ç¼©æ”¾
                                        if lora_weight != 1.0:
                                            logger.warning(f"  âš  UNet LoRA æƒé‡è®¾ç½®ä¸º {lora_weight}ï¼Œä½† load_lora_weights é»˜è®¤ä½¿ç”¨ 1.0")
                                            logger.warning(f"  âš  å»ºè®®ï¼šå¦‚æœ LoRA æ•ˆæœè¿‡å¼ºï¼Œå¯ä»¥é™ä½ lora_weightï¼›å¦‚æœæ•ˆæœè¿‡å¼±ï¼Œå¯ä»¥æé«˜ lora_weight")
                                            print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆé»˜è®¤æƒé‡ 1.0ï¼Œé…ç½®æƒé‡ {lora_weight} æœªåº”ç”¨ï¼‰")
                                        else:
                                            logger.info(f"  âœ“ UNet LoRA å·²åŠ è½½ï¼ˆæƒé‡: 1.0ï¼‰")
                                            print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆæƒé‡: 1.0ï¼‰")
                                        lora_loaded = True
                                    else:
                                        # adapter æœªåŠ è½½ï¼Œå°è¯•æ–¹æ³•2
                                        logger.warning(f"  âš  Adapter {adapter_name} æœªæˆåŠŸåŠ è½½ï¼Œå°è¯•ä¸ä½¿ç”¨ adapter_name")
                                        print(f"  [è°ƒè¯•] is_unet_lora={is_unet_lora}ï¼Œå°†å°è¯•æ–¹æ³•2")
                                        lora_loaded = False
                            else:
                                # æ²¡æœ‰ set_adapters æ–¹æ³•ï¼Œä½† load_lora_weights å¯èƒ½å·²æˆåŠŸï¼ˆUNet LoRAï¼‰
                                logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (pipeline, æ—  set_adapters æ–¹æ³•ï¼ŒUNet LoRAå·²ç›´æ¥åº”ç”¨)")
                                print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (pipeline, UNet LoRAå·²ç›´æ¥åº”ç”¨)")
                                lora_loaded = True
                        except Exception as e:
                            logger.warning(f"  âš  Pipeline LoRA åŠ è½½å¤±è´¥ï¼ˆæ–¹æ³•1ï¼‰: {e}")
                            lora_loaded = False
                        
                        # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ä¸ä½¿ç”¨ adapter_nameï¼ˆè®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ï¼‰
                        if not lora_loaded:
                            try:
                                logger.info(f"  å°è¯•æ–¹æ³•2ï¼šä¸ä½¿ç”¨ adapter_name åŠ è½½ LoRA...")
                                self.pipeline.load_lora_weights(actual_lora_path)  # ä¸ä½¿ç”¨ adapter_name
                                # è·å–å®é™…åŠ è½½çš„ adapter åç§°
                                if hasattr(self.pipeline, 'get_list_adapters'):
                                    try:
                                        list_adapters = self.pipeline.get_list_adapters()
                                        all_adapters = {adapter for adapters in list_adapters.values() for adapter in adapters}
                                        if all_adapters:
                                            actual_adapter = list(all_adapters)[0]
                                            if hasattr(self.pipeline, 'set_adapters'):
                                                self.pipeline.set_adapters([actual_adapter], adapter_weights=[lora_weight])
                                            logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (pipeline, æ–¹æ³•2, adapter: {actual_adapter})")
                                            print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (pipeline, æ–¹æ³•2, adapter: {actual_adapter})")
                                            lora_loaded = True
                                        else:
                                            # âš¡ å…³é”®ä¿®å¤ï¼šå¯¹äºUNetæ ¼å¼çš„LoRAï¼Œå³ä½¿get_list_adaptersè¿”å›ç©ºï¼Œload_lora_weightsä¹Ÿå¯èƒ½å·²æˆåŠŸ
                                            if is_unet_lora:
                                                logger.info(f"  âœ“ UNet LoRA å·²åŠ è½½ï¼ˆæ–¹æ³•2ï¼Œload_lora_weightsæˆåŠŸï¼Œæ— éœ€adapteræœºåˆ¶ï¼‰")
                                                print(f"  [è°ƒè¯•] UNet LoRA å·²åŠ è½½ï¼ˆæ–¹æ³•2ï¼Œload_lora_weightsæˆåŠŸï¼Œæ— éœ€adapteræœºåˆ¶ï¼‰")
                                                lora_loaded = True
                                            else:
                                                logger.warning(f"  âš  æ–¹æ³•2ï¼šæœªæ£€æµ‹åˆ°ä»»ä½• adapter")
                                    except Exception as check_e2:
                                        logger.warning(f"  âš  æ–¹æ³•2ï¼šæ£€æŸ¥ adapter åˆ—è¡¨å¤±è´¥: {check_e2}")
                                elif hasattr(self.pipeline, 'get_active_adapters'):
                                    # ä½¿ç”¨ get_active_adapters ä½œä¸ºå¤‡é€‰
                                    try:
                                        active_adapters = list(self.pipeline.get_active_adapters())
                                        if active_adapters:
                                            if hasattr(self.pipeline, 'set_adapters'):
                                                self.pipeline.set_adapters(active_adapters, adapter_weights=[lora_weight])
                                            logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (pipeline, æ–¹æ³•2, adapter: {active_adapters[0]})")
                                            print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (pipeline, æ–¹æ³•2, adapter: {active_adapters[0]})")
                                            lora_loaded = True
                                    except Exception as active_e:
                                        logger.warning(f"  âš  æ–¹æ³•2ï¼šè·å– active adapters å¤±è´¥: {active_e}")
                                else:
                                    # æ²¡æœ‰æ£€æŸ¥æ–¹æ³•ï¼Œå‡è®¾åŠ è½½æˆåŠŸ
                                    logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (pipeline, æ–¹æ³•2, æ— æ³•éªŒè¯)")
                                    print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (pipeline, æ–¹æ³•2)")
                                    lora_loaded = True
                            except Exception as e2:
                                logger.warning(f"  âš  Pipeline LoRA åŠ è½½å¤±è´¥ï¼ˆæ–¹æ³•2ï¼‰: {e2}")
                    
                    # 2. å¦‚æœ pipeline ä¸å­˜åœ¨ä½†éœ€è¦ LoRAï¼Œå°è¯•åŠ è½½ pipeline
                    if not lora_loaded and self.pipeline is None:
                        try:
                            logger.info(f"  Pipeline ä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½ diffusers pipeline ä»¥æ”¯æŒ LoRA...")
                            self._load_diffusers_pipeline()
                            if self.pipeline is not None:
                                # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ adapter_name å’Œ prefix=Noneï¼ˆä¿®å¤æƒé‡æ ¼å¼ä¸åŒ¹é…é—®é¢˜ï¼‰
                                try:
                                    self.pipeline.load_lora_weights(actual_lora_path, adapter_name=adapter_name, weight_name=None)
                                    # âš¡ ä¿®å¤ï¼šåœ¨è®¾ç½® adapter ä¹‹å‰ï¼Œå…ˆæ£€æŸ¥ adapter æ˜¯å¦å·²æˆåŠŸåŠ è½½
                                    if hasattr(self.pipeline, 'set_adapters'):
                                        # æ£€æŸ¥ adapter æ˜¯å¦å·²åŠ è½½
                                        adapter_to_use = None
                                        if hasattr(self.pipeline, 'get_list_adapters'):
                                            try:
                                                list_adapters = self.pipeline.get_list_adapters()
                                                all_adapters = {adapter for adapters in list_adapters.values() for adapter in adapters}
                                                if adapter_name in all_adapters:
                                                    adapter_to_use = adapter_name
                                                elif all_adapters:
                                                    # å¦‚æœæŒ‡å®šçš„ adapter_name ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œä½†å·²æœ‰å…¶ä»– adapterï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
                                                    adapter_to_use = list(all_adapters)[0]
                                                    logger.info(f"  â„¹ ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„ adapter: {adapter_to_use} (è€ŒéæŒ‡å®šçš„ {adapter_name})")
                                            except Exception as check_e:
                                                logger.warning(f"  âš  æ£€æŸ¥ adapter åˆ—è¡¨å¤±è´¥: {check_e}")
                                                # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä»ç„¶å°è¯•ä½¿ç”¨æŒ‡å®šçš„ adapter_name
                                                adapter_to_use = adapter_name
                                        else:
                                            # æ²¡æœ‰ get_list_adapters æ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨æŒ‡å®šçš„ adapter_name
                                            adapter_to_use = adapter_name
                                        
                                        if adapter_to_use:
                                            try:
                                                self.pipeline.set_adapters([adapter_to_use], adapter_weights=[lora_weight])
                                                logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, adapter: {adapter_to_use})")
                                                print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, adapter: {adapter_to_use})")
                                                lora_loaded = True
                                            except Exception as set_e:
                                                logger.warning(f"  âš  è®¾ç½® adapter {adapter_to_use} å¤±è´¥: {set_e}")
                                                lora_loaded = False
                                        else:
                                            logger.warning(f"  âš  Adapter {adapter_name} æœªæˆåŠŸåŠ è½½ï¼Œå°è¯•ä¸ä½¿ç”¨ adapter_name")
                                            lora_loaded = False
                                    else:
                                        # æ²¡æœ‰ set_adapters æ–¹æ³•ï¼Œä½† load_lora_weights å¯èƒ½å·²æˆåŠŸ
                                        logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ—  set_adapters æ–¹æ³•)")
                                        print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline)")
                                        lora_loaded = True
                                except Exception as e:
                                    logger.warning(f"  âš  æ–°åŠ è½½çš„ Pipeline LoRA åŠ è½½å¤±è´¥ï¼ˆæ–¹æ³•1ï¼‰: {e}")
                                    lora_loaded = False
                                
                                # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ä¸ä½¿ç”¨ adapter_nameï¼ˆè®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ï¼‰
                                if not lora_loaded:
                                    try:
                                        logger.info(f"  å°è¯•æ–¹æ³•2ï¼šä¸ä½¿ç”¨ adapter_name åŠ è½½ LoRA...")
                                        self.pipeline.load_lora_weights(actual_lora_path)  # ä¸ä½¿ç”¨ adapter_name
                                        # è·å–å®é™…åŠ è½½çš„ adapter åç§°
                                        if hasattr(self.pipeline, 'get_list_adapters'):
                                            try:
                                                list_adapters = self.pipeline.get_list_adapters()
                                                all_adapters = {adapter for adapters in list_adapters.values() for adapter in adapters}
                                                if all_adapters:
                                                    actual_adapter = list(all_adapters)[0]
                                                    if hasattr(self.pipeline, 'set_adapters'):
                                                        self.pipeline.set_adapters([actual_adapter], adapter_weights=[lora_weight])
                                                    logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ–¹æ³•2, adapter: {actual_adapter})")
                                                    print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ–¹æ³•2, adapter: {actual_adapter})")
                                                    lora_loaded = True
                                                else:
                                                    logger.warning(f"  âš  æ–¹æ³•2ï¼šæœªæ£€æµ‹åˆ°ä»»ä½• adapter")
                                            except Exception as check_e2:
                                                logger.warning(f"  âš  æ–¹æ³•2ï¼šæ£€æŸ¥ adapter åˆ—è¡¨å¤±è´¥: {check_e2}")
                                        elif hasattr(self.pipeline, 'get_active_adapters'):
                                            # ä½¿ç”¨ get_active_adapters ä½œä¸ºå¤‡é€‰
                                            try:
                                                active_adapters = list(self.pipeline.get_active_adapters())
                                                if active_adapters:
                                                    if hasattr(self.pipeline, 'set_adapters'):
                                                        self.pipeline.set_adapters(active_adapters, adapter_weights=[lora_weight])
                                                    logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ–¹æ³•2, adapter: {active_adapters[0]})")
                                                    print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ–¹æ³•2, adapter: {active_adapters[0]})")
                                                    lora_loaded = True
                                            except Exception as active_e:
                                                logger.warning(f"  âš  æ–¹æ³•2ï¼šè·å– active adapters å¤±è´¥: {active_e}")
                                        else:
                                            # æ²¡æœ‰æ£€æŸ¥æ–¹æ³•ï¼Œå‡è®¾åŠ è½½æˆåŠŸ
                                            logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ–¹æ³•2, æ— æ³•éªŒè¯)")
                                            print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (æ–°åŠ è½½çš„ pipeline, æ–¹æ³•2)")
                                            lora_loaded = True
                                    except Exception as e2:
                                        logger.warning(f"  âš  æ–°åŠ è½½çš„ Pipeline LoRA åŠ è½½å¤±è´¥ï¼ˆæ–¹æ³•2ï¼‰: {e2}")
                        except Exception as e:
                            logger.warning(f"  âš  åŠ è½½ Pipeline å¤±è´¥: {e}")
                    
                    # 3. å°è¯•åœ¨åŸç”Ÿæ¨¡å‹ä¸ŠåŠ è½½ï¼ˆåŸç”Ÿæ¨¡å¼ï¼Œä¸æ”¯æŒç›´æ¥åŠ è½½ LoRAï¼‰
                    # æ³¨æ„ï¼šåŸç”Ÿ Flux æ¨¡å‹ï¼ˆflux.model.Fluxï¼‰ä¸æ”¯æŒç›´æ¥ load_lora_weights
                    # åŸç”Ÿæ¨¡å¼ä¸»è¦ç”¨äºæ€§èƒ½ä¼˜åŒ–ï¼Œå¦‚æœéœ€è¦ LoRAï¼Œå»ºè®®ä½¿ç”¨ pipeline æ¨¡å¼
                    if not lora_loaded and self.use_native and self.flux_model is not None:
                        try:
                            # å°è¯•ä½¿ç”¨ PEFT åŠ è½½ LoRA
                            try:
                                from peft import PeftModel
                                from safetensors.torch import load_file
                                
                                logger.info(f"  å°è¯•ä½¿ç”¨ PEFT åŠ è½½ LoRA åˆ°åŸç”Ÿæ¨¡å‹...")
                                
                                # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ PeftModel.from_pretrainedï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
                                # æ³¨æ„ï¼šåŸç”Ÿ Flux æ¨¡å‹å¯èƒ½ä¸æ”¯æŒ PeftModelï¼Œéœ€è¦æ‰‹åŠ¨åˆå¹¶æƒé‡
                                
                                # æ–¹æ³•2ï¼šæ‰‹åŠ¨åŠ è½½ LoRA æƒé‡å¹¶åˆå¹¶åˆ°æ¨¡å‹
                                logger.info(f"  æ‰‹åŠ¨åŠ è½½ LoRA æƒé‡: {lora_path}")
                                lora_state_dict = load_file(lora_path)
                                
                                # è·å–æ¨¡å‹çš„çŠ¶æ€å­—å…¸
                                model_state_dict = self.flux_model.state_dict()
                                
                                # åˆå¹¶ LoRA æƒé‡ï¼ˆç®€å•æ–¹æ³•ï¼šç›´æ¥æ·»åŠ åˆ°å¯¹åº”å±‚ï¼‰
                                # æ³¨æ„ï¼šè¿™éœ€è¦ LoRA æƒé‡æ ¼å¼ä¸æ¨¡å‹å±‚åç§°åŒ¹é…
                                merged_count = 0
                                for key, value in lora_state_dict.items():
                                    # LoRA æƒé‡é€šå¸¸ä»¥ "lora_A" æˆ– "lora_B" ç»“å°¾
                                    # éœ€è¦æ‰¾åˆ°å¯¹åº”çš„åŸºç¡€å±‚å¹¶åˆå¹¶
                                    base_key = key.replace(".lora_A", "").replace(".lora_B", "")
                                    if base_key in model_state_dict:
                                        # ç®€å•çš„æƒé‡åˆå¹¶ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨ LoRA çš„æ•°å­¦å…¬å¼ï¼‰
                                        # W_new = W_base + alpha * (lora_B @ lora_A)
                                        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥æŒ‰æƒé‡æ¯”ä¾‹åˆå¹¶
                                        if ".lora_A" in key or ".lora_B" in key:
                                            # è·³è¿‡ lora_A å’Œ lora_Bï¼Œéœ€è¦æˆå¯¹å¤„ç†
                                            continue
                                        else:
                                            # å¦‚æœæ˜¯åˆå¹¶åçš„æƒé‡ï¼Œç›´æ¥åº”ç”¨
                                            model_state_dict[base_key] = model_state_dict[base_key] + lora_weight * value
                                            merged_count += 1
                                
                                if merged_count > 0:
                                    # åŠ è½½åˆå¹¶åçš„æƒé‡
                                    self.flux_model.load_state_dict(model_state_dict, strict=False)
                                    logger.info(f"  âœ“ LoRA åŠ è½½æˆåŠŸ (åŸç”Ÿæ¨¡å‹ï¼Œåˆå¹¶äº† {merged_count} ä¸ªæƒé‡)")
                                    print(f"  [è°ƒè¯•] LoRA åŠ è½½æˆåŠŸ (åŸç”Ÿæ¨¡å‹ï¼Œåˆå¹¶äº† {merged_count} ä¸ªæƒé‡)")
                                    lora_loaded = True
                                else:
                                    logger.warning(f"  âš  æ— æ³•åŒ¹é… LoRA æƒé‡æ ¼å¼ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ diffusers pipeline æ¨¡å¼")
                                    
                            except ImportError:
                                logger.warning(f"  âš  PEFT åº“æœªå®‰è£…ï¼Œæ— æ³•åŠ è½½ LoRA åˆ°åŸç”Ÿæ¨¡å‹")
                            except Exception as e:
                                logger.warning(f"  âš  åŸç”Ÿæ¨¡å‹ LoRA åŠ è½½å¤±è´¥: {e}")
                                logger.info(f"  â„¹ å»ºè®®ï¼šä½¿ç”¨ diffusers pipeline æ¨¡å¼ä»¥æ”¯æŒ LoRA")
                                
                        except Exception as e:
                            logger.warning(f"  âš  åŸç”Ÿæ¨¡å‹ LoRA åŠ è½½å¼‚å¸¸: {e}")
                    
                    if not lora_loaded:
                        logger.warning(f"  âš  LoRA åŠ è½½å¤±è´¥ï¼ˆpipeline å’ŒåŸç”Ÿæ¨¡å‹éƒ½å¤±è´¥ï¼‰ï¼Œç»§ç»­ä½¿ç”¨ PuLIDï¼ˆæ—  LoRAï¼‰")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if converted_lora_path and converted_lora_path != lora_path and os.path.exists(converted_lora_path):
                        try:
                            os.unlink(converted_lora_path)
                        except:
                            pass
                            
                except Exception as e:
                    logger.warning(f"  âš  LoRA åŠ è½½å¼‚å¸¸: {e}ï¼Œç»§ç»­ä½¿ç”¨ PuLIDï¼ˆæ—  LoRAï¼‰")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if converted_lora_path and converted_lora_path != lora_path and os.path.exists(converted_lora_path):
                        try:
                            os.unlink(converted_lora_path)
                        except:
                            pass
            else:
                logger.warning(f"  âš  LoRA è·¯å¾„ä¸å­˜åœ¨: {lora_path}")
                print(f"  [è°ƒè¯•] LoRA è·¯å¾„ä¸å­˜åœ¨: {lora_path}")
        
        # è½¬æ¢å‚è€ƒå¼ºåº¦åˆ° PuLID æƒé‡
        # PuLID æƒé‡èŒƒå›´é€šå¸¸æ˜¯ 0.0-1.0
        # reference_strength 0-100 æ˜ å°„åˆ° 0.0-1.0
        pulid_weight = reference_strength / 100.0
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¢å¼ºæœé¥°ä¸€è‡´æ€§
        # å¦‚æœ prompt ä¸­åŒ…å«æœé¥°æè¿°ï¼Œæˆ–è€…å‚è€ƒå¼ºåº¦åœ¨ä¸­ç­‰èŒƒå›´ï¼ˆ50-75ï¼‰ï¼Œå¯ç”¨æœé¥°å¢å¼º
        enhance_clothing = kwargs.get('enhance_clothing_consistency', False)
        if not enhance_clothing:
            # è‡ªåŠ¨æ£€æµ‹ï¼šå¦‚æœ prompt ä¸­åŒ…å«æœé¥°å…³é”®è¯ï¼Œè‡ªåŠ¨å¯ç”¨
            clothing_keywords = ['robe', 'clothing', 'dress', 'outfit', 'garment', 'attire', 
                               'æœé¥°', 'è¡£æœ', 'æœè£…', 'é•¿è¢', 'é“è¢', 'è¡£è¢']
            prompt_lower = prompt.lower()
            if any(keyword in prompt_lower for keyword in clothing_keywords):
                enhance_clothing = True
                logger.info("  æ£€æµ‹åˆ°æœé¥°æè¿°ï¼Œè‡ªåŠ¨å¯ç”¨æœé¥°ä¸€è‡´æ€§å¢å¼º")
        
        # è°ƒæ•´æƒé‡æ›²çº¿ (éçº¿æ€§æ˜ å°„ï¼Œä½¿ä¸­é—´å€¼æ›´è‡ªç„¶)
        pulid_weight = self._adjust_weight_curve(pulid_weight, enhance_clothing=enhance_clothing)
        
        # åŸç”Ÿæ¨¡å¼ï¼šç”±äºå·²ç»å®ç°äº†æ˜¾å­˜ç®¡ç†ï¼Œä¸å†éœ€è¦é™ä½åˆ†è¾¨ç‡
        # ä¿æŒç”¨æˆ·é…ç½®çš„åŸå§‹åˆ†è¾¨ç‡å’Œæ­¥æ•°
        
        logger.info(f"ç”Ÿæˆå‚æ•°:")
        logger.info(f"  å‚è€ƒå¼ºåº¦: {reference_strength}% -> PuLID weight: {pulid_weight:.2f}")
        logger.info(f"  åˆ†è¾¨ç‡: {width}x{height}")
        logger.info(f"  æ­¥æ•°: {num_inference_steps}")
        print(f"  [è°ƒè¯•] PuLIDå¼•æ“æ¥æ”¶åˆ°çš„æ¨ç†æ­¥æ•°: {num_inference_steps}")
        
        # è®¾ç½®éšæœºç§å­
        generator = None
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        
        # åŠ è½½å‚è€ƒå›¾åƒ
        if isinstance(face_reference, str):
            face_reference_pil = Image.open(face_reference).convert('RGB')
        else:
            face_reference_pil = face_reference
        face_reference_np = np.array(face_reference_pil)
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ PuLID æ¨¡å‹å’Œé‡‡æ ·æ¨¡å—
            if hasattr(self, 'use_pulid') and self.use_pulid and self.pulid_model is not None:
                logger.info("ä½¿ç”¨ PuLID å®Œæ•´æ¨¡å¼è¿›è¡Œèº«ä»½æ³¨å…¥...")
                
                # ä½¿ç”¨ PuLID è·å–èº«ä»½åµŒå…¥
                try:
                    id_embedding, uncond_id_embedding = self.pulid_model.get_id_embedding(
                        face_reference_np, 
                        cal_uncond=True
                    )
                    logger.info(f"  èº«ä»½åµŒå…¥æå–æˆåŠŸ: {id_embedding.shape}")
                except Exception as e:
                    logger.warning(f"PuLID èº«ä»½åµŒå…¥æå–å¤±è´¥: {e}")
                    logger.info("å›é€€åˆ°æ— èº«ä»½æ³¨å…¥æ¨¡å¼")
                    id_embedding = None
                    uncond_id_embedding = None
                
                if id_embedding is not None:
                    # å°è¯•ä½¿ç”¨ PuLID çš„åŸç”Ÿé‡‡æ ·æµç¨‹
                    try:
                        result = self._generate_with_pulid_native(
                            prompt=prompt,
                            id_embedding=id_embedding,
                            uncond_id_embedding=uncond_id_embedding,
                            id_weight=pulid_weight,
                            width=width,
                            height=height,
                            num_inference_steps=num_inference_steps,
                            guidance_scale=guidance_scale,
                            seed=seed
                        )
                        if result is not None:
                            return result
                    except torch.cuda.OutOfMemoryError as e:
                        logger.error(f"PuLID åŸç”Ÿé‡‡æ ·æ˜¾å­˜ä¸è¶³: {e}")
                        logger.warning("å³ä½¿å¯ç”¨äº† aggressive_offload ä»ç„¶ OOMï¼Œå°è¯•å¸è½½åŸç”Ÿæ¨¡å‹å¹¶å›é€€åˆ° diffusers æ¨¡å¼...")
                        
                        # å…ˆå¸è½½åŸç”Ÿæ¨¡å‹ä»¥é‡Šæ”¾æ˜¾å­˜
                        if self.use_native:
                            logger.info("å¸è½½åŸç”Ÿ Flux æ¨¡å‹ä»¥é‡Šæ”¾æ˜¾å­˜...")
                            if self.flux_model is not None:
                                del self.flux_model
                                self.flux_model = None
                            if self.ae is not None:
                                del self.ae
                                self.ae = None
                            if self.t5 is not None:
                                del self.t5
                                self.t5 = None
                            if self.clip is not None:
                                del self.clip
                                self.clip = None
                            if self.pulid_model is not None:
                                del self.pulid_model
                                self.pulid_model = None
                            
                            # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
                            import gc
                            gc.collect()
                            torch.cuda.empty_cache()
                            torch.cuda.synchronize()
                            gc.collect()
                            torch.cuda.empty_cache()
                            
                            logger.info("åŸç”Ÿæ¨¡å‹å·²å¸è½½ï¼Œæ˜¾å­˜å·²é‡Šæ”¾")
                        
                        # å¦‚æœæ˜¯åŸç”Ÿæ¨¡å¼ä¸”æ²¡æœ‰ diffusers pipelineï¼Œå°è¯•åŠ è½½
                        if self.use_native and self.pipeline is None:
                            logger.info("å°è¯•åŠ è½½ diffusers pipeline ä½œä¸ºå¤‡ç”¨...")
                            try:
                                self._load_diffusers_pipeline()
                            except Exception as load_error:
                                logger.error(f"åŠ è½½ diffusers pipeline å¤±è´¥: {load_error}")
                                raise RuntimeError("åŸç”Ÿæ¨¡å¼å¤±è´¥ä¸”æ— æ³•åŠ è½½å¤‡ç”¨ pipeline")
                        
                        if self.pipeline is not None:
                            logger.info("å›é€€åˆ° diffusers æ¨¡å¼")
                        else:
                            raise RuntimeError("åŸç”Ÿæ¨¡å¼å¤±è´¥ä¸”æ— å¤‡ç”¨ pipeline")
                    except Exception as e:
                        logger.warning(f"PuLID åŸç”Ÿé‡‡æ ·å‡ºé”™: {e}")
                        # å¦‚æœæ˜¯åŸç”Ÿæ¨¡å¼ä¸”æ²¡æœ‰ diffusers pipelineï¼Œå°è¯•åŠ è½½
                        if self.use_native and self.pipeline is None:
                            logger.info("å°è¯•åŠ è½½ diffusers pipeline ä½œä¸ºå¤‡ç”¨...")
                            try:
                                self._load_diffusers_pipeline()
                            except Exception as load_error:
                                logger.error(f"åŠ è½½ diffusers pipeline å¤±è´¥: {load_error}")
                                raise
                        
                        if self.pipeline is not None:
                            logger.info("å›é€€åˆ° diffusers æ¨¡å¼")
                        else:
                            raise
                    
                    # å›é€€ï¼šä½¿ç”¨ diffusersï¼Œä½†è®¾ç½® ID åˆ° transformer
                    if self.pipeline is not None:
                        dit = self.pipeline.transformer
                        if hasattr(dit, 'pulid_ca'):
                            # è®¾ç½® ID åµŒå…¥åˆ° pulid_ca æ¨¡å—
                            for ca in dit.pulid_ca:
                                ca.id_embedding = id_embedding
                                ca.id_scale = pulid_weight
                        
                        # âš¡ å…³é”®ä¿®å¤ï¼šåœ¨ç”Ÿæˆå›¾åƒæ—¶æŠ‘åˆ¶ CLIP tokenizer çš„ 77 token è­¦å‘Š
                        with suppress_clip_tokenizer_warnings():
                            result = self.pipeline(
                                prompt=prompt,
                                width=width,
                                height=height,
                                num_inference_steps=num_inference_steps,
                                guidance_scale=guidance_scale,
                                generator=generator,
                            ).images[0]
                        
                        # æ¸…ç†
                        if hasattr(dit, 'pulid_ca'):
                            for ca in dit.pulid_ca:
                                ca.id_embedding = None
                        
                        return result
            
            # å›é€€ï¼šä½¿ç”¨çº¯ Flux ç”Ÿæˆï¼ˆæ— èº«ä»½æ³¨å…¥ï¼‰
            # åªæœ‰å½“ pipeline å­˜åœ¨æ—¶æ‰å›é€€
            if self.pipeline is not None:
                logger.warning("ä½¿ç”¨çº¯ Flux ç”Ÿæˆï¼ˆæ— èº«ä»½æ³¨å…¥ï¼‰")
                result = self.pipeline(
                    prompt=prompt,
                    width=width,
                    height=height,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    generator=generator,
                ).images[0]
                return result
            else:
                logger.error("åŸç”Ÿæ¨¡å¼å¤±è´¥ï¼Œä¸”æ— å¤‡ç”¨ pipelineï¼Œæ— æ³•ç”Ÿæˆ")
                raise RuntimeError("Native generation failed and no fallback pipeline available")
            
        except Exception as e:
            logger.error(f"å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _generate_with_pulid_native(
        self,
        prompt: str,
        id_embedding: torch.Tensor,
        uncond_id_embedding: torch.Tensor,
        id_weight: float,
        width: int,
        height: int,
        num_inference_steps: int,
        guidance_scale: float,
        seed: int
    ) -> Optional[Image.Image]:
        """
        ä½¿ç”¨ PuLID åŸç”Ÿé‡‡æ ·æµç¨‹ç”Ÿæˆ
        
        PuLID éœ€è¦ä½¿ç”¨è‡ªå®šä¹‰çš„ Flux æ¨¡å‹å’Œé‡‡æ ·å¾ªç¯
        """
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨åŸç”Ÿæ¨¡å¼
            if not self.use_native:
                logger.info("éåŸç”Ÿæ¨¡å¼ï¼Œè·³è¿‡åŸç”Ÿé‡‡æ ·")
                return None
            
            # å¯¼å…¥é‡‡æ ·æ¨¡å—
            from flux.sampling import denoise, get_noise, get_schedule, prepare, unpack
            import random
            
            logger.info("ä½¿ç”¨ PuLID åŸç”Ÿé‡‡æ ·æµç¨‹...")
            
            # å¤„ç† seed
            if seed is None:
                seed = random.randint(0, 2**32 - 1)
                logger.info(f"  ç”Ÿæˆéšæœºç§å­: {seed}")
            
            # æ¸…ç† GPU ç¼“å­˜ï¼ˆæ›´å½»åº•ï¼‰
            import gc
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()  # ç¡®ä¿æ‰€æœ‰ CUDA æ“ä½œå®Œæˆ
                # å†æ¬¡æ¸…ç†
                gc.collect()
                torch.cuda.empty_cache()
            
            # å‡†å¤‡å™ªå£°
            x = get_noise(
                num_samples=1,
                height=height,
                width=width,
                device=self.device,
                dtype=self.dtype,
                seed=seed
            )
            
            # è·å–é‡‡æ ·æ—¶é—´è¡¨
            timesteps = get_schedule(
                num_steps=num_inference_steps,
                image_seq_len=x.shape[1] * x.shape[2] // 4,
                shift=True
            )
            
            # å‡†å¤‡è¾“å…¥ (ä½¿ç”¨åŸç”Ÿ T5 å’Œ CLIP)
            # CPU offload: ä¸´æ—¶å°†ç¼–ç å™¨ç§»åˆ° GPU
            if hasattr(self, 'use_cpu_offload') and self.use_cpu_offload:
                logger.info("  ä¸´æ—¶ç§»åŠ¨ T5/CLIP åˆ° GPU...")
                self.t5.to(self.device)
                self.clip.to(self.device)
            
            inp = prepare(self.t5, self.clip, x, prompt)
            
            # è®°å½•è¾“å…¥å¼ é‡å¤§å°
            if torch.cuda.is_available():
                img_size_gb = inp["img"].element_size() * inp["img"].nelement() / 1024**3
                txt_size_gb = inp["txt"].element_size() * inp["txt"].nelement() / 1024**3
                logger.info(f"  è¾“å…¥å¼ é‡å¤§å°: img={img_size_gb:.2f}GB, txt={txt_size_gb:.2f}GB")
            
            # CPU offload: ç¼–ç å®Œæˆåç§»å› CPU
            if hasattr(self, 'use_cpu_offload') and self.use_cpu_offload:
                logger.info("  ç§»åŠ¨ T5/CLIP å› CPU...")
                self.t5.to("cpu")
                self.clip.to("cpu")
                # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
                import gc
                gc.collect()
                torch.cuda.empty_cache()
                log_memory("After Encoder Offload")
            
            # åŸç”Ÿæ¨¡å¼ï¼šç”±äºå·²ç»å®ç°äº†æ˜¾å­˜ç®¡ç†ï¼Œä¸å†éœ€è¦å¼ºåˆ¶ä½¿ç”¨ aggressive_offload
            # å¯ä»¥æ ¹æ®æ˜¾å­˜æƒ…å†µé€‰æ‹©æ˜¯å¦ä½¿ç”¨ï¼ˆæ˜¾å­˜å……è¶³æ—¶ä½¿ç”¨æ ‡å‡†æ¨¡å¼é€Ÿåº¦æ›´å¿«ï¼‰
            if torch.cuda.is_available():
                allocated = torch.cuda.memory_allocated() / 1024**3
                reserved = torch.cuda.memory_reserved() / 1024**3
                total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                free = total - reserved
                logger.info(f"  å»å™ªå‰æ˜¾å­˜: å·²åˆ†é…={allocated:.2f}GB, å·²ä¿ç•™={reserved:.2f}GB, å¯ç”¨={free:.2f}GB")
                
                # å¦‚æœå¯ç”¨æ˜¾å­˜å……è¶³ï¼ˆ>50GBï¼‰ï¼Œä¸ä½¿ç”¨ aggressive_offloadï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰
                # å¦‚æœå¯ç”¨æ˜¾å­˜è¾ƒå°‘ï¼ˆ<50GBï¼‰ï¼Œä½¿ç”¨ aggressive_offloadï¼ˆæ›´å®‰å…¨ï¼‰
                use_aggressive_offload = free < 50
                if use_aggressive_offload:
                    logger.info(f"  å¯ç”¨æ˜¾å­˜è¾ƒå°‘ ({free:.2f}GB)ï¼Œå¯ç”¨ aggressive_offload æ¨¡å¼")
                else:
                    logger.info(f"  å¯ç”¨æ˜¾å­˜å……è¶³ ({free:.2f}GB)ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰")
            else:
                use_aggressive_offload = False
            
            # å»å™ªå‰æ¸…ç†æ˜¾å­˜
            import gc
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            logger.info(f"  å¼€å§‹å»å™ª (æ­¥æ•°: {num_inference_steps}, IDæƒé‡: {id_weight:.2f}, aggressive_offload={use_aggressive_offload})...")
            
            # ä½¿ç”¨åŒ…è£…å‡½æ•°ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¹‹é—´æ¸…ç†æ˜¾å­˜
            x = self._denoise_with_memory_management(
                model=self.flux_model,
                img=inp["img"],
                img_ids=inp["img_ids"],
                txt=inp["txt"],
                txt_ids=inp["txt_ids"],
                vec=inp["vec"],
                timesteps=timesteps,
                guidance=guidance_scale,
                id=id_embedding,
                id_weight=id_weight,
                uncond_id=uncond_id_embedding,
                aggressive_offload=use_aggressive_offload
            )
            
            # è§£åŒ…
            x = unpack(x.float(), height, width)
            
            # ä½¿ç”¨ AutoEncoder è§£ç 
            logger.info("  è§£ç å›¾åƒ...")
            # å¦‚æœ AutoEncoder åœ¨ CPU ä¸Šï¼Œéœ€è¦ç§»åˆ° GPU
            if self.ae is not None:
                try:
                    ae_device = next(self.ae.parameters()).device
                    if ae_device.type == "cpu":
                        logger.info("  å°† AutoEncoder ç§»åˆ° GPU è¿›è¡Œè§£ç ...")
                        self.ae = self.ae.to(self.device)
                except Exception:
                    pass  # å¦‚æœæ— æ³•æ£€æŸ¥è®¾å¤‡ï¼Œç»§ç»­ä½¿ç”¨å½“å‰çŠ¶æ€
            
            # è·å– AutoEncoder çš„ dtypeï¼ˆé€šè¿‡å‚æ•°è·å–ï¼‰
            if self.ae is not None:
                ae_dtype = next(self.ae.parameters()).dtype
                x = x.to(ae_dtype)
                with torch.no_grad():
                    x = self.ae.decode(x)
            else:
                raise RuntimeError("AutoEncoder ä¸å¯ç”¨")
            
            # è½¬æ¢ä¸ºå›¾åƒ
            x = (x + 1.0) / 2.0
            x = x.clamp(0, 1)
            x = x.cpu().permute(0, 2, 3, 1).numpy()[0]
            x = (x * 255).astype(np.uint8)
            
            logger.info("  åŸç”Ÿé‡‡æ ·å®Œæˆ!")
            return Image.fromarray(x)
            
        except ImportError as e:
            logger.warning(f"PuLID flux æ¨¡å—æœªæ‰¾åˆ°: {e}")
            return None
        except Exception as e:
            logger.warning(f"PuLID åŸç”Ÿé‡‡æ ·å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _denoise_with_memory_management(
        self,
        model,
        img,
        img_ids,
        txt,
        txt_ids,
        vec,
        timesteps,
        guidance,
        id=None,
        id_weight=1.0,
        uncond_id=None,
        aggressive_offload=False,
        start_step=0,
        true_cfg=1.0,
        timestep_to_start_cfg=1,
        neg_txt=None,
        neg_txt_ids=None,
        neg_vec=None,
    ):
        """
        å¸¦æ˜¾å­˜ç®¡ç†çš„å»å™ªå‡½æ•°
        
        åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¹‹é—´æ¸…ç†æ˜¾å­˜ï¼Œé¿å…ä¸­é—´æ¿€æ´»å€¼ç´¯ç§¯å¯¼è‡´ OOM
        
        è¿™æ˜¯åŸå§‹ denoise å‡½æ•°çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œæ·»åŠ äº†æ˜¾å­˜ç®¡ç†
        """
        import gc
        
        # æ‰‹åŠ¨å®ç°å»å™ªå¾ªç¯ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¹‹é—´æ¸…ç†æ˜¾å­˜
        guidance_vec = torch.full((img.shape[0],), guidance, device=img.device, dtype=img.dtype)
        use_true_cfg = abs(true_cfg - 1.0) > 1e-2
        
        total_steps = len(timesteps) - 1
        logger.info(f"  ä½¿ç”¨æ˜¾å­˜ç®¡ç†å»å™ªï¼ˆ{total_steps} æ­¥ï¼‰...")
        
        for i, (t_curr, t_prev) in enumerate(zip(timesteps[:-1], timesteps[1:])):
            # æ¯ 5 æ­¥è®°å½•ä¸€æ¬¡è¿›åº¦å’Œæ˜¾å­˜
            if i % 5 == 0 or i == total_steps - 1:
                logger.info(f"    å»å™ªè¿›åº¦: {i+1}/{total_steps}")
                if torch.cuda.is_available():
                    allocated = torch.cuda.memory_allocated() / 1024**3
                    reserved = torch.cuda.memory_reserved() / 1024**3
                    logger.info(f"      æ˜¾å­˜: å·²åˆ†é…={allocated:.2f}GB, å·²ä¿ç•™={reserved:.2f}GB")
            
            t_vec = torch.full((img.shape[0],), t_curr, dtype=img.dtype, device=img.device)
            
            # å‰å‘ä¼ æ’­ï¼ˆæ¡ä»¶ï¼‰
            with torch.no_grad():  # ç¡®ä¿ä¸éœ€è¦æ¢¯åº¦ï¼Œå‡å°‘æ˜¾å­˜å ç”¨
                pred = model(
                    img=img,
                    img_ids=img_ids,
                    txt=txt,
                    txt_ids=txt_ids,
                    y=vec,
                    timesteps=t_vec,
                    guidance=guidance_vec,
                    id=id if i >= start_step else None,
                    id_weight=id_weight,
                    aggressive_offload=aggressive_offload,
                )
            
            # å¦‚æœä½¿ç”¨ true_cfgï¼Œéœ€è¦è®¡ç®— negative prediction
            if use_true_cfg and i >= timestep_to_start_cfg:
                with torch.no_grad():
                    neg_pred = model(
                        img=img,
                        img_ids=img_ids,
                        txt=neg_txt,
                        txt_ids=neg_txt_ids,
                        y=neg_vec,
                        timesteps=t_vec,
                        guidance=guidance_vec,
                        id=uncond_id if i >= start_step else None,
                        id_weight=id_weight,
                        aggressive_offload=aggressive_offload,
                    )
                pred = neg_pred + true_cfg * (pred - neg_pred)
                del neg_pred  # ç«‹å³é‡Šæ”¾
            
            # æ›´æ–°å›¾åƒ
            img = img + (t_prev - t_curr) * pred
            
            # æ¸…ç†ä¸­é—´å˜é‡ï¼ˆå…³é”®ï¼šç«‹å³é‡Šæ”¾ï¼Œé¿å…ç´¯ç§¯ï¼‰
            del pred
            del t_vec
            
            # æ¯ 2 æ­¥æ¸…ç†ä¸€æ¬¡æ˜¾å­˜ï¼ˆå¹³è¡¡æ€§èƒ½å’Œæ˜¾å­˜å ç”¨ï¼‰
            if (i + 1) % 2 == 0:
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # æœ€ç»ˆæ¸…ç†
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        logger.info("  å»å™ªå®Œæˆï¼Œæ˜¾å­˜å·²æ¸…ç†")
        return img
    
    def _adjust_weight_curve(self, weight: float, enhance_clothing: bool = False) -> float:
        """
        è°ƒæ•´æƒé‡æ›²çº¿
        
        ä½¿å‚è€ƒå¼ºåº¦çš„å˜åŒ–æ›´è‡ªç„¶:
        - ä½å€¼ (0-30%): å¿«é€Ÿé™ä½ï¼Œè®©ç¯å¢ƒå ä¸»å¯¼
        - ä¸­å€¼ (30-70%): å¹³æ»‘è¿‡æ¸¡
        - é«˜å€¼ (70-100%): è¶‹äºé¥±å’Œï¼Œå¼ºé”è„¸
        
        Args:
            weight: åŸå§‹æƒé‡ (0.0-1.0)
            enhance_clothing: æ˜¯å¦å¢å¼ºæœé¥°ä¸€è‡´æ€§ï¼ˆæé«˜ä¸­ç­‰å¼ºåº¦çš„æƒé‡ï¼‰
            
        Returns:
            è°ƒæ•´åçš„æƒé‡
        """
        # âš¡ 2024-12-22 ä¿®å¤ï¼šæé«˜æ•´ä½“æƒé‡ï¼Œè§£å†³äººè„¸ä¸åƒé—®é¢˜
        # æ ¹æ®æµ‹è¯•åé¦ˆï¼Œä¹‹å‰çš„æƒé‡å¤ªä½ï¼ŒPuLID èº«ä»½æ³¨å…¥æ•ˆæœä¸è¶³
        import math
        
        if enhance_clothing:
            # æœé¥°å¢å¼ºæ¨¡å¼ï¼šè®©ä¸­ç­‰å¼ºåº¦ä¹Ÿèƒ½è·å¾—æ›´é«˜æƒé‡
            k = 5
            center = 0.40  # æ›´æ—©è¾¾åˆ°é«˜æƒé‡
            min_weight = 0.50  # âš¡ æé«˜ï¼šä» 0.35 åˆ° 0.50
            max_weight = 1.0   # âš¡ æé«˜ï¼šä» 0.98 åˆ° 1.0
        else:
            # âš¡ æ ‡å‡†æ¨¡å¼ï¼šä¹Ÿéœ€è¦æé«˜æƒé‡
            k = 5          # ç¨å¾®å¹³ç¼“ï¼Œè®©ä¸­ç­‰å€¼æ›´ç¨³å®š
            center = 0.45  # å‘å·¦åç§»
            min_weight = 0.45  # âš¡ æé«˜ï¼šä» 0.30 åˆ° 0.45
            max_weight = 1.0   # âš¡ æé«˜ï¼šä» 0.95 åˆ° 1.0
        
        adjusted = 1 / (1 + math.exp(-k * (weight - center)))
        
        # ç¼©æ”¾åˆ°æŒ‡å®šèŒƒå›´ (PuLID æœ‰æ•ˆå·¥ä½œèŒƒå›´)
        adjusted = min_weight + adjusted * (max_weight - min_weight)
        
        return adjusted
    
    def calculate_reference_strength(
        self,
        shot_type: str,
        camera_angle: str = "eye_level",
        has_emotion: bool = False
    ) -> int:
        """
        æ ¹æ®é•œå¤´ç±»å‹è‡ªåŠ¨è®¡ç®—å‚è€ƒå¼ºåº¦
        
        å‚è€ƒå¯çµ/å³æ¢¦çš„ç­–ç•¥ï¼š
        - è¿œæ™¯: ç¯å¢ƒä¼˜å…ˆï¼Œå¼±å‚è€ƒ
        - ä¸­æ™¯: å¹³è¡¡
        - ç‰¹å†™: äººè„¸ä¼˜å…ˆï¼Œå¼ºå‚è€ƒ
        
        Args:
            shot_type: é•œå¤´ç±»å‹ (wide, full, medium, close, extreme_close)
            camera_angle: ç›¸æœºè§’åº¦
            has_emotion: æ˜¯å¦æœ‰è¡¨æƒ…éœ€æ±‚
            
        Returns:
            å‚è€ƒå¼ºåº¦ (0-100)
        """
        # åŸºç¡€å¼ºåº¦æ˜ å°„
        strength_map = {
            "extreme_wide": 20,
            "wide": 30,
            "full": 45,
            "american": 55,  # 7/8 èº«
            "medium": 60,
            "medium_close": 70,
            "close": 80,
            "extreme_close": 90,
        }
        
        base_strength = strength_map.get(shot_type, 60)
        
        # è§’åº¦è°ƒæ•´
        if camera_angle in ["top_down", "bird_eye"]:
            # ä¿¯æ‹ä¸éœ€è¦å¤ªå¼ºçš„äººè„¸å‚è€ƒ
            base_strength = min(base_strength, 40)
        elif camera_angle == "low":
            # ä»°æ‹éœ€è¦ç•¥å¼ºçš„å‚è€ƒ
            base_strength = min(base_strength + 10, 95)
        
        # è¡¨æƒ…è°ƒæ•´
        if has_emotion:
            # æœ‰è¡¨æƒ…éœ€æ±‚æ—¶ï¼Œå¢å¼ºå‚è€ƒä»¥ä¿æŒè¡¨æƒ…å‡†ç¡®
            base_strength = min(base_strength + 10, 95)
        
        return base_strength
    
    def unload(self):
        """å¸è½½æ¨¡å‹ä»¥é‡Šæ”¾æ˜¾å­˜"""
        log_memory("Before Unload")
        
        # âš¡ å…³é”®ä¿®å¤ï¼šå…ˆç§»åŠ¨åˆ° CPUï¼Œå†åˆ é™¤ï¼Œç¡®ä¿æ˜¾å­˜çœŸæ­£é‡Šæ”¾
        if self.pipeline is not None:
            try:
                # å¦‚æœæ˜¯ diffusers pipelineï¼Œå°è¯•ç§»åŠ¨åˆ° CPU
                if hasattr(self.pipeline, 'to'):
                    self.pipeline.to('cpu')
                del self.pipeline
            except:
                pass
            self.pipeline = None
            
        if self.flux_model is not None:
            try:
                # ç§»åŠ¨åˆ° CPU å†åˆ é™¤
                if hasattr(self.flux_model, 'to'):
                    self.flux_model.to('cpu')
                del self.flux_model
            except:
                pass
            self.flux_model = None
            
        if self.ae is not None:
            try:
                if hasattr(self.ae, 'to'):
                    self.ae.to('cpu')
                del self.ae
            except:
                pass
            self.ae = None
            
        if self.pulid_model is not None:
            try:
                if hasattr(self.pulid_model, 'to'):
                    self.pulid_model.to('cpu')
                del self.pulid_model
            except:
                pass
            self.pulid_model = None
            
        if self.t5 is not None:
            try:
                if hasattr(self.t5, 'to'):
                    self.t5.to('cpu')
                del self.t5
            except:
                pass
            self.t5 = None
            
        if self.clip is not None:
            try:
                if hasattr(self.clip, 'to'):
                    self.clip.to('cpu')
                del self.clip
            except:
                pass
            self.clip = None
        
        if self.face_analyzer is not None:
            try:
                del self.face_analyzer
            except:
                pass
            self.face_analyzer = None
        
        self.pulid_loaded = False
        
        # âš¡ å…³é”®ä¿®å¤ï¼šå¤šæ¬¡æ¸…ç† GPU ç¼“å­˜ï¼Œç¡®ä¿æ˜¾å­˜çœŸæ­£é‡Šæ”¾
        import gc
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
            # å¤šæ¬¡æ¸…ç†ï¼Œç¡®ä¿å½»åº•é‡Šæ”¾
            for i in range(5):
                gc.collect()
                torch.cuda.empty_cache()
                if i % 2 == 0:
                    torch.cuda.synchronize()
        
        logger.info("PuLID Engine å·²å½»åº•å¸è½½")
        log_memory("After Unload")


class CharacterProfile:
    """
    è§’è‰²æ¡£æ¡ˆç³»ç»Ÿ
    
    å‚è€ƒå¯çµ Element Library çš„å¤šå‚è€ƒå›¾æ–¹æ¡ˆ
    
    æ”¯æŒçš„ç›®å½•ç»“æ„:
    character_profiles/hanli/
    â”œâ”€â”€ front/           # æ­£é¢è§’åº¦
    â”‚   â”œâ”€â”€ neutral.jpg
    â”‚   â”œâ”€â”€ happy.jpg
    â”‚   â”œâ”€â”€ sad.jpg
    â”‚   â”œâ”€â”€ angry.jpg
    â”‚   â””â”€â”€ pain.jpg
    â”œâ”€â”€ side/            # ä¾§é¢è§’åº¦
    â”‚   â”œâ”€â”€ neutral.jpg
    â”‚   â””â”€â”€ angry.jpg
    â””â”€â”€ three_quarter/   # 3/4 ä¾§é¢
        â”œâ”€â”€ neutral.jpg
        â”œâ”€â”€ happy.jpg
        â””â”€â”€ angry.jpg
    """
    
    def __init__(self, character_id: str, profile_dir: str):
        """
        Args:
            character_id: è§’è‰²ID (å¦‚ "hanli")
            profile_dir: æ¡£æ¡ˆç›®å½•è·¯å¾„
        """
        self.character_id = character_id
        self.profile_dir = Path(profile_dir)
        
        # å‚è€ƒå›¾åƒ: {è§’åº¦: {è¡¨æƒ…: è·¯å¾„}}
        self.references = {}
        
        # å¯ç”¨çš„è§’åº¦åˆ—è¡¨
        self.available_angles = []
        
        # å¯ç”¨çš„è¡¨æƒ…åˆ—è¡¨
        self.available_expressions = set()
        
        # åŠ è½½å‚è€ƒå›¾åƒ
        self._load_references()
    
    def _load_references(self):
        """åŠ è½½å‚è€ƒå›¾åƒ - é€‚é…æ–°çš„ç›®å½•ç»“æ„"""
        if not self.profile_dir.exists():
            logger.warning(f"è§’è‰²æ¡£æ¡ˆç›®å½•ä¸å­˜åœ¨: {self.profile_dir}")
            return
        
        # æ”¯æŒçš„è§’åº¦ç›®å½•
        angle_dirs = {
            "front": ["front", "æ­£é¢"],
            "three_quarter": ["three_quarter", "3_4", "åŠä¾§é¢"],
            "side": ["side", "profile", "ä¾§é¢"],
            "back": ["back", "èƒŒé¢"],
        }
        
        # æ”¯æŒçš„è¡¨æƒ…æ–‡ä»¶å
        expression_names = {
            "neutral": ["neutral", "ä¸­æ€§", "default"],
            "happy": ["happy", "smile", "å¼€å¿ƒ", "å¾®ç¬‘"],
            "sad": ["sad", "æ‚²ä¼¤"],
            "angry": ["angry", "æ„¤æ€’"],
            "surprised": ["surprised", "æƒŠè®¶"],
            "pain": ["pain", "ç—›è‹¦"],
            "thinking": ["thinking", "æ€è€ƒ"],
        }
        
        # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        extensions = [".jpg", ".jpeg", ".png", ".webp"]
        
        # éå†è§’åº¦ç›®å½•
        for angle_key, angle_names in angle_dirs.items():
            for angle_name in angle_names:
                angle_path = self.profile_dir / angle_name
                if angle_path.exists() and angle_path.is_dir():
                    self.references[angle_key] = {}
                    self.available_angles.append(angle_key)
                    
                    # éå†è¡¨æƒ…æ–‡ä»¶
                    for expr_key, expr_names in expression_names.items():
                        for expr_name in expr_names:
                            for ext in extensions:
                                file_path = angle_path / f"{expr_name}{ext}"
                                if file_path.exists():
                                    self.references[angle_key][expr_key] = file_path
                                    self.available_expressions.add(expr_key)
                                    break
                            if expr_key in self.references.get(angle_key, {}):
                                break
                    
                    break  # æ‰¾åˆ°ä¸€ä¸ªè§’åº¦ç›®å½•å°±è·³å‡º
        
        # æ—¥å¿—
        logger.info(f"è§’è‰²æ¡£æ¡ˆåŠ è½½å®Œæˆ: {self.character_id}")
        logger.info(f"  å¯ç”¨è§’åº¦: {self.available_angles}")
        logger.info(f"  å¯ç”¨è¡¨æƒ…: {list(self.available_expressions)}")
        
        # è¯¦ç»†æ—¥å¿—
        for angle, expressions in self.references.items():
            logger.info(f"  {angle}: {list(expressions.keys())}")
    
    def get_reference_for_scene(
        self,
        camera_angle: str = "eye_level",
        emotion: str = "neutral"
    ) -> Tuple[Optional[Path], Optional[Path]]:
        """
        æ ¹æ®åœºæ™¯è·å–æœ€ä½³å‚è€ƒå›¾
        
        Args:
            camera_angle: ç›¸æœºè§’åº¦ (eye_level, side, profile, top_down, low, etc.)
            emotion: è¡¨æƒ…éœ€æ±‚ (neutral, happy, sad, angry, pain, etc.)
            
        Returns:
            (ä¸»å‚è€ƒå›¾è·¯å¾„, è¡¨æƒ…å‚è€ƒå›¾è·¯å¾„)
            ä¸»å‚è€ƒå›¾: æ ¹æ®è§’åº¦å’Œè¡¨æƒ…é€‰æ‹©çš„æœ€ä½³åŒ¹é…
            è¡¨æƒ…å‚è€ƒå›¾: å¦‚æœä¸»å‚è€ƒå›¾æ²¡æœ‰å¯¹åº”è¡¨æƒ…ï¼Œæä¾›æ­£é¢çš„è¡¨æƒ…å‚è€ƒ
        """
        primary = None
        expression_ref = None
        
        # 1. æ ¹æ®ç›¸æœºè§’åº¦é€‰æ‹©æœ€ä½³è§’åº¦ç›®å½•
        angle_key = self._map_camera_angle(camera_angle)
        
        # 2. å°è¯•è·å–å¯¹åº”è§’åº¦+è¡¨æƒ…çš„å›¾ç‰‡
        if angle_key in self.references:
            angle_refs = self.references[angle_key]
            
            # ä¼˜å…ˆï¼šå®Œå…¨åŒ¹é… (è§’åº¦+è¡¨æƒ…)
            if emotion in angle_refs:
                primary = angle_refs[emotion]
            # å¤‡é€‰ï¼šè¯¥è§’åº¦çš„ neutral è¡¨æƒ…
            elif "neutral" in angle_refs:
                primary = angle_refs["neutral"]
                # å¦‚æœéœ€è¦ç‰¹å®šè¡¨æƒ…ä½†è¯¥è§’åº¦æ²¡æœ‰ï¼Œä»æ­£é¢è·å–è¡¨æƒ…å‚è€ƒ
                if emotion != "neutral" and "front" in self.references:
                    if emotion in self.references["front"]:
                        expression_ref = self.references["front"][emotion]
            # å¤‡é€‰ï¼šè¯¥è§’åº¦çš„ä»»æ„è¡¨æƒ…
            elif angle_refs:
                primary = list(angle_refs.values())[0]
        
        # 3. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–è§’åº¦
        if primary is None:
            for fallback_angle in ["three_quarter", "front", "side"]:
                if fallback_angle in self.references:
                    angle_refs = self.references[fallback_angle]
                    if emotion in angle_refs:
                        primary = angle_refs[emotion]
                        break
                    elif "neutral" in angle_refs:
                        primary = angle_refs["neutral"]
                        break
                    elif angle_refs:
                        primary = list(angle_refs.values())[0]
                        break
        
        # 4. å¦‚æœä»ç„¶æ²¡æœ‰è¡¨æƒ…å‚è€ƒï¼Œå°è¯•ä»æ­£é¢è·å–
        if expression_ref is None and emotion != "neutral":
            if "front" in self.references and emotion in self.references["front"]:
                expression_ref = self.references["front"][emotion]
        
        return primary, expression_ref
    
    def _map_camera_angle(self, camera_angle: str) -> str:
        """
        å°†ç›¸æœºè§’åº¦æ˜ å°„åˆ°å‚è€ƒå›¾è§’åº¦
        
        Args:
            camera_angle: åœºæ™¯ä¸­çš„ç›¸æœºè§’åº¦æè¿°
            
        Returns:
            å¯¹åº”çš„å‚è€ƒå›¾è§’åº¦ key
        """
        angle_mapping = {
            # æ­£é¢
            "eye_level": "three_quarter",  # å¹³è§†é»˜è®¤ç”¨ 3/4 è§’åº¦
            "front": "front",
            "straight": "front",
            
            # ä¾§é¢
            "side": "side",
            "profile": "side",
            
            # 3/4 è§’åº¦
            "three_quarter": "three_quarter",
            "3/4": "three_quarter",
            
            # ä¿¯æ‹ç”¨æ­£é¢
            "top_down": "front",
            "bird_eye": "front",
            "high": "front",
            
            # ä»°æ‹ç”¨æ­£é¢æˆ– 3/4
            "low": "three_quarter",
            "worm_eye": "three_quarter",
            
            # èƒŒé¢
            "back": "back",
            "behind": "back",
        }
        
        return angle_mapping.get(camera_angle, "three_quarter")
    
    def get_best_reference(
        self,
        camera_angle: str = "eye_level",
        emotion: str = "neutral"
    ) -> Optional[Path]:
        """
        è·å–å•ä¸ªæœ€ä½³å‚è€ƒå›¾ (ç®€åŒ–æ¥å£)
        
        Args:
            camera_angle: ç›¸æœºè§’åº¦
            emotion: è¡¨æƒ…
            
        Returns:
            æœ€ä½³å‚è€ƒå›¾è·¯å¾„
        """
        primary, _ = self.get_reference_for_scene(camera_angle, emotion)
        return primary
    
    def list_all_references(self) -> Dict[str, Dict[str, Path]]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å‚è€ƒå›¾
        
        Returns:
            {è§’åº¦: {è¡¨æƒ…: è·¯å¾„}}
        """
        return self.references
    
    def __repr__(self):
        return f"CharacterProfile(id={self.character_id}, angles={self.available_angles}, expressions={list(self.available_expressions)})"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•é…ç½®
    config = {
        "device": "cuda",
        "quantization": "bfloat16",
        "model_dir": "/vepfs-dev/shawn/vid/fanren/gen_video/models"
    }
    
    # åˆ›å»ºå¼•æ“
    engine = PuLIDEngine(config)
    
    # æµ‹è¯•å‚è€ƒå¼ºåº¦è®¡ç®—
    print("\nå‚è€ƒå¼ºåº¦æµ‹è¯•:")
    for shot in ["wide", "medium", "close", "extreme_close"]:
        strength = engine.calculate_reference_strength(shot)
        print(f"  {shot}: {strength}%")
    
    print("\nPuLID Engine åˆå§‹åŒ–æˆåŠŸ!")

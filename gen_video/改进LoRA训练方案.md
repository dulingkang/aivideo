# æ”¹è¿› LoRA è®­ç»ƒæ–¹æ¡ˆ

## ğŸ” å½“å‰é—®é¢˜åˆ†æ

### âœ… å¥½æ¶ˆæ¯
- LoRA ç¡®å®ç”Ÿæ•ˆäº†ï¼ˆåŠ å’Œä¸åŠ æœ‰åŒºåˆ«ï¼‰
- å¾®ç¬‘ç‰¹å¾å¯¹ï¼ˆè¯´æ˜ LoRA æœ‰éƒ¨åˆ†æ•ˆæœï¼‰

### âŒ é—®é¢˜
- äººè„¸ä¸å¯¹ï¼ˆå¯èƒ½æ˜¯è®­ç»ƒæ•°æ®ä¸å¤Ÿæˆ–è®­ç»ƒä¸å……åˆ†ï¼‰
- å½¢è±¡ä¸å¯¹ï¼ˆå¯èƒ½æ˜¯æç¤ºè¯æˆ–è®­ç»ƒæ•°æ®é—®é¢˜ï¼‰

## ğŸ’¡ å¯èƒ½çš„åŸå› 

### 1. è®­ç»ƒæ•°æ®ä¸è¶³
- **å½“å‰ï¼š** 20 å¼ å›¾ç‰‡
- **å»ºè®®ï¼š** 30-50 å¼ å›¾ç‰‡
- **åˆ†å¸ƒï¼š**
  - æ­£é¢ï¼š10-15 å¼ 
  - å…¨èº«ï¼š5-8 å¼ 
  - ä¾§é¢ï¼š3-5 å¼ 
  - ä¸åŒè¡¨æƒ…ï¼š5-8 å¼ 
  - ä¸åŒæœè£…ï¼š5-8 å¼ 

### 2. è®­ç»ƒæ­¥æ•°ä¸å¤Ÿ
- **å½“å‰ï¼š** 1000 æ­¥ï¼ˆçº¦ 10 è½®ï¼Œbatch_size=1, gradient_accumulation=4ï¼‰
- **å»ºè®®ï¼š** 2000-3000 æ­¥ï¼ˆ20-30 è½®ï¼‰

### 3. LoRA å‚æ•°å¯èƒ½ä¸åˆé€‚
- **å½“å‰ï¼š** rank=32, alpha=16
- **å»ºè®®ï¼š** 
  - å¦‚æœæ•°æ®å°‘ï¼šrank=16, alpha=16ï¼ˆæ›´ä¿å®ˆï¼‰
  - å¦‚æœæ•°æ®å¤šï¼šrank=64, alpha=32ï¼ˆæ›´å¼ºï¼‰

### 4. å­¦ä¹ ç‡å¯èƒ½ä¸åˆé€‚
- **å½“å‰ï¼š** 1e-4
- **å»ºè®®ï¼š** 5e-5 æˆ– 2e-4ï¼ˆæ ¹æ®è®­ç»ƒæ›²çº¿è°ƒæ•´ï¼‰

## ğŸš€ æ”¹è¿›æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šå¢åŠ è®­ç»ƒæ•°æ®ï¼ˆæ¨èï¼‰

**æ­¥éª¤ï¼š**
1. æ”¶é›†æ›´å¤šè®­ç»ƒå›¾ç‰‡ï¼ˆç›®æ ‡ï¼š30-50 å¼ ï¼‰
2. ç¡®ä¿æ•°æ®å¤šæ ·æ€§ï¼š
   - ä¸åŒè§’åº¦ï¼ˆæ­£é¢ã€ä¾§é¢ã€45åº¦ï¼‰
   - ä¸åŒè¡¨æƒ…ï¼ˆå¾®ç¬‘ã€ä¸¥è‚ƒã€è‡ªç„¶ï¼‰
   - ä¸åŒæœè£…ï¼ˆæ­£è£…ã€ä¼‘é—²ã€ä¸åŒé¢œè‰²ï¼‰
   - ä¸åŒèƒŒæ™¯ï¼ˆæ¼”æ’­å®¤ã€çº¯è‰²ã€æˆ·å¤–ï¼‰

**æ•°æ®å‡†å¤‡ï¼š**
```bash
# ä½¿ç”¨é¢„å¤„ç†è„šæœ¬
python preprocess_training_images.py \
    --input-dir raw_images \
    --output-dir train_data/host_person \
    --target-size 1024 \
    --crop-bottom 50 \
    --crop-right 50
```

### æ–¹æ¡ˆ 2ï¼šè°ƒæ•´è®­ç»ƒå‚æ•°

**ä¿®æ”¹ `train_flux_lora_final.py`ï¼š**

```python
# å¢åŠ è®­ç»ƒæ­¥æ•°
num_train_epochs=20  # ä» 10 æ”¹ä¸º 20

# è°ƒæ•´ LoRA å‚æ•°ï¼ˆå¦‚æœæ•°æ®å°‘ï¼‰
lora_rank=16  # ä» 32 æ”¹ä¸º 16ï¼ˆæ›´ä¿å®ˆï¼‰
lora_alpha=16  # ä¿æŒä¸å˜

# è°ƒæ•´å­¦ä¹ ç‡
learning_rate=5e-5  # ä» 1e-4 æ”¹ä¸º 5e-5ï¼ˆæ›´ä¿å®ˆï¼‰
```

### æ–¹æ¡ˆ 3ï¼šä½¿ç”¨æ›´é•¿çš„è®­ç»ƒ

```bash
python train_flux_lora_final.py \
    --data-dir train_data/host_person \
    --output-dir models/lora/host_person_v2 \
    --base-model models/flux1-dev \
    --epochs 20 \
    --batch-size 1 \
    --gradient-accumulation 4 \
    --learning-rate 5e-5 \
    --lora-rank 16 \
    --lora-alpha 16 \
    --save-steps 500 \
    --resolution 512 \
    --use-bf16
```

### æ–¹æ¡ˆ 4ï¼šä½¿ç”¨å®˜æ–¹è®­ç»ƒè„šæœ¬ï¼ˆæ›´ç¨³å®šï¼‰

```bash
cd diffusers/examples/dreambooth

accelerate launch train_dreambooth_lora_flux.py \
    --pretrained_model_name_or_path=/vepfs-dev/shawn/vid/fanren/gen_video/models/flux1-dev \
    --instance_data_dir=/vepfs-dev/shawn/vid/fanren/gen_video/train_data/host_person \
    --output_dir=/vepfs-dev/shawn/vid/fanren/gen_video/models/lora/host_person_v2 \
    --mixed_precision="bf16" \
    --instance_prompt="ç§‘æ™®ä¸»æŒäººï¼Œç”·æ€§ï¼Œä¸“ä¸šå½¢è±¡" \
    --resolution=512 \
    --train_batch_size=1 \
    --gradient_accumulation_steps=4 \
    --optimizer="adamw" \
    --use_8bit_adam \
    --learning_rate=5e-5 \
    --lr_scheduler="cosine" \
    --lr_warmup_steps=100 \
    --max_train_steps=2000 \
    --rank=16 \
    --lora_alpha=16 \
    --save_steps=500 \
    --seed=0
```

## ğŸ“Š è®­ç»ƒç›‘æ§

### æ£€æŸ¥è®­ç»ƒæŸå¤±

è®­ç»ƒè¿‡ç¨‹ä¸­åº”è¯¥çœ‹åˆ°æŸå¤±é€æ¸ä¸‹é™ï¼š
- åˆå§‹æŸå¤±ï¼š~0.5-1.0
- æœ€ç»ˆæŸå¤±ï¼š~0.1-0.3

å¦‚æœæŸå¤±ä¸ä¸‹é™æˆ–æ³¢åŠ¨å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦ï¼š
- é™ä½å­¦ä¹ ç‡
- å¢åŠ è®­ç»ƒæ­¥æ•°
- æ£€æŸ¥æ•°æ®è´¨é‡

### éªŒè¯è®­ç»ƒæ•ˆæœ

è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥å®šæœŸç”Ÿæˆæµ‹è¯•å›¾åƒï¼š

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ éªŒè¯
if global_step % 500 == 0:
    # ç”Ÿæˆæµ‹è¯•å›¾åƒ
    test_image = pipe.generate(
        prompt="ç§‘æ™®ä¸»æŒäººï¼Œç”·æ€§ï¼Œä¸“ä¸šå½¢è±¡ï¼Œå¾®ç¬‘",
        lora_path=checkpoint_dir / "pytorch_lora_weights.safetensors",
        lora_alpha=1.0
    )
    test_image.save(f"test_step_{global_step}.png")
```

## ğŸ¯ æ¨èæ–¹æ¡ˆ

**å¦‚æœæ•°æ®å¯ä»¥å¢åŠ ï¼š**
1. æ”¶é›†æ›´å¤šè®­ç»ƒå›¾ç‰‡ï¼ˆ30-50 å¼ ï¼‰
2. ä½¿ç”¨æ–¹æ¡ˆ 3 é‡æ–°è®­ç»ƒï¼ˆ20 è½®ï¼Œrank=16ï¼‰
3. ç›‘æ§è®­ç»ƒæŸå¤±ï¼Œç¡®ä¿æ”¶æ•›

**å¦‚æœæ•°æ®æ— æ³•å¢åŠ ï¼š**
1. ä½¿ç”¨æ–¹æ¡ˆ 2 è°ƒæ•´å‚æ•°ï¼ˆæ›´ä¿å®ˆçš„ rank=16ï¼‰
2. å¢åŠ è®­ç»ƒæ­¥æ•°åˆ° 2000-3000
3. é™ä½å­¦ä¹ ç‡åˆ° 5e-5

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸è¦è¿‡åº¦è®­ç»ƒ**ï¼šå¦‚æœæŸå¤±å·²ç»å¾ˆä½ï¼ˆ<0.1ï¼‰ï¼Œç»§ç»­è®­ç»ƒå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
2. **ä¿å­˜æ£€æŸ¥ç‚¹**ï¼šæ¯ 500 æ­¥ä¿å­˜ä¸€æ¬¡ï¼Œé€‰æ‹©æŸå¤±æœ€ä½çš„æ£€æŸ¥ç‚¹
3. **éªŒè¯æ•ˆæœ**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸç”Ÿæˆæµ‹è¯•å›¾åƒï¼Œæ£€æŸ¥æ•ˆæœ
4. **æ•°æ®è´¨é‡**ï¼šç¡®ä¿è®­ç»ƒæ•°æ®éƒ½æ˜¯é«˜è´¨é‡ã€æ¸…æ™°çš„ä¸»æŒäººå›¾ç‰‡

## ğŸ“ è®­ç»ƒåéªŒè¯

è®­ç»ƒå®Œæˆåï¼Œæµ‹è¯•ä¸åŒåœºæ™¯ï¼š

```python
# æµ‹è¯• 1ï¼šåŸºæœ¬å½¢è±¡
image1 = manager.generate(
    task="host_face",
    prompt="ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡ï¼Œå¾®ç¬‘"
)

# æµ‹è¯• 2ï¼šä¸åŒè¡¨æƒ…
image2 = manager.generate(
    task="host_face",
    prompt="ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡ï¼Œä¸¥è‚ƒ"
)

# æµ‹è¯• 3ï¼šä¸åŒåœºæ™¯
image3 = manager.generate(
    task="host_face",
    prompt="ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡ï¼Œæ¼”æ’­å®¤èƒŒæ™¯"
)
```

å¦‚æœè¿™äº›æµ‹è¯•éƒ½èƒ½ç”Ÿæˆä¸€è‡´çš„ä¸»æŒäººå½¢è±¡ï¼Œè¯´æ˜ LoRA è®­ç»ƒæˆåŠŸã€‚


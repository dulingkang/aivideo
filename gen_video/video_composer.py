#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘åˆæˆè„šæœ¬
å°†è§†é¢‘ç‰‡æ®µã€éŸ³é¢‘ã€å­—å¹•åˆæˆæœ€ç»ˆè§†é¢‘
"""

import os
import math
import tempfile
import yaml
import argparse
from pathlib import Path
import ffmpeg
from typing import Dict, List, Optional, Any, Tuple
import subprocess


class VideoComposer:
    """è§†é¢‘åˆæˆå™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–è§†é¢‘åˆæˆå™¨"""
        self.config_path = Path(config_path)
        if not self.config_path.is_absolute():
            self.config_path = (Path.cwd() / self.config_path).resolve()

        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.composition_config = self.config['composition']
        self.subtitle_config = self.config['subtitle']
        self.config_dir = self.config_path.parent
        self._bgm_cache: Dict[str, Any] = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.config['paths']['output_dir'], exist_ok=True)
    
    def compose(
        self,
        video_paths: List[str],
        audio_path: Optional[str] = None,
        subtitle_path: Optional[str] = None,
        bgm_path: Optional[str] = None,
        output_path: str = "output.mp4",
        scene_metadata: Optional[List[Dict]] = None,
    ) -> str:
        """
        åˆæˆè§†é¢‘
        
        Args:
            video_paths: è§†é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨
            audio_path: é…éŸ³éŸ³é¢‘è·¯å¾„
            subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„
            bgm_path: èƒŒæ™¯éŸ³ä¹è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            
        Returns:
            è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        print(f"\nåˆæˆè§†é¢‘: {len(video_paths)} ä¸ªç‰‡æ®µ")
        
        # æ–¹æ³•1: ä½¿ç”¨ FFmpegï¼ˆæ›´å¿«é€Ÿï¼Œé€‚åˆæ‰¹é‡å¤„ç†ï¼‰
        if self.composition_config.get('use_ffmpeg', True):
            return self.compose_ffmpeg(
                video_paths,
                audio_path,
                subtitle_path,
                bgm_path,
                output_path,
                scene_metadata=scene_metadata,
            )
        else:
            # æ–¹æ³•2: ä½¿ç”¨ MoviePyï¼ˆæ›´çµæ´»ï¼Œé€‚åˆå¤æ‚ç¼–è¾‘ï¼‰
            return self.compose_moviepy(
                video_paths,
                audio_path,
                subtitle_path,
                bgm_path,
                output_path,
                scene_metadata=scene_metadata,
            )
    
    def compose_with_segment_audio(
        self,
        video_paths: List[str],
        audio_paths: List[str],
        subtitle_path: Optional[str] = None,
        bgm_path: Optional[str] = None,
        output_path: str = "output.mp4",
        *,
        scene_metadata: Optional[List[Dict]] = None,
        audio_durations: Optional[List[float]] = None,
    ) -> str:
        """ä½¿ç”¨åˆ†æ®µéŸ³é¢‘åˆæˆè§†é¢‘ï¼ˆæ¯ä¸ªè§†é¢‘ç‰‡æ®µå¯¹åº”ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼‰
        
        Args:
            video_paths: è§†é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨
            audio_paths: éŸ³é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨ï¼ˆä¸video_pathsä¸€ä¸€å¯¹åº”ï¼‰
            subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„
            bgm_path: èƒŒæ™¯éŸ³ä¹è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            scene_metadata: åœºæ™¯å…ƒæ•°æ®
        """
        if len(video_paths) != len(audio_paths):
            raise ValueError(f"è§†é¢‘ç‰‡æ®µæ•°é‡ ({len(video_paths)}) ä¸éŸ³é¢‘ç‰‡æ®µæ•°é‡ ({len(audio_paths)}) ä¸ä¸€è‡´")
        
        print(f"\nä½¿ç”¨åˆ†æ®µéŸ³é¢‘åˆæˆè§†é¢‘: {len(video_paths)} ä¸ªç‰‡æ®µ")
        temp_dir = Path(self.config['paths']['temp_dir'])
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ä¸ºæ¯ä¸ªè§†é¢‘ç‰‡æ®µæ·»åŠ å¯¹åº”çš„éŸ³é¢‘ç‰‡æ®µï¼ˆç¡®ä¿æ—¶é•¿å¯¹é½ï¼‰
        print("ä¸ºæ¯ä¸ªè§†é¢‘ç‰‡æ®µæ·»åŠ å¯¹åº”çš„éŸ³é¢‘ç‰‡æ®µ...")
        video_with_audio_paths = []
        for i, (video_path, audio_path) in enumerate(zip(video_paths, audio_paths)):
            if not os.path.exists(video_path):
                print(f"  âš  è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                continue
            if not os.path.exists(audio_path):
                print(f"  âš  éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                continue
            
            # è·å–è§†é¢‘å’ŒéŸ³é¢‘æ—¶é•¿ï¼Œç¡®ä¿å¯¹é½
            video_duration = self.get_media_duration(video_path)
            # ä½¿ç”¨ç²¾ç¡®çš„éŸ³é¢‘æ—¶é•¿ï¼ˆä¸å–æ•´ï¼‰ï¼Œç¡®ä¿å®Œå…¨åŒ¹é…
            audio_duration = self.get_media_duration(audio_path)
            
            # å¦‚æœæä¾›äº† audio_durationsï¼Œç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼ˆä½†å®é™…ä½¿ç”¨ç²¾ç¡®æ—¶é•¿ï¼‰
            if audio_durations and i < len(audio_durations):
                audio_duration_rounded = audio_durations[i]
                print(f"  ç‰‡æ®µ {i+1}: éŸ³é¢‘ç²¾ç¡®æ—¶é•¿ {audio_duration:.3f}s (å–æ•´å: {audio_duration_rounded:.0f}s)")
            else:
                print(f"  ç‰‡æ®µ {i+1}: éŸ³é¢‘ç²¾ç¡®æ—¶é•¿ {audio_duration:.3f}s")
            
            temp_video_with_audio = temp_dir / f"temp_video_audio_{i:03d}.mp4"
            try:
                # ä¸ºæ¯ä¸ªè§†é¢‘ç‰‡æ®µæ·»åŠ å¯¹åº”çš„éŸ³é¢‘ç‰‡æ®µï¼Œä½¿ç”¨ç²¾ç¡®çš„éŸ³é¢‘æ—¶é•¿ä½œä¸ºç›®æ ‡
                # è§†é¢‘æ—¶é•¿å¿…é¡»åŒ¹é…éŸ³é¢‘æ—¶é•¿ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
                target_duration = audio_duration  # ä½¿ç”¨ç²¾ç¡®çš„éŸ³é¢‘æ—¶é•¿ä½œä¸ºç›®æ ‡
                
                import ffmpeg
                # åˆ›å»ºè§†é¢‘å’ŒéŸ³é¢‘è¾“å…¥æµ
                video_stream = ffmpeg.input(video_path)
                audio_stream = ffmpeg.input(audio_path)
                # ç»„åˆè§†é¢‘å’ŒéŸ³é¢‘ï¼Œè¾“å‡ºåˆ°ç›®æ ‡æ–‡ä»¶
                (
                    ffmpeg
                    .output(
                        video_stream,
                        audio_stream,
                        str(temp_video_with_audio),
                        vcodec='copy',
                        acodec='aac',
                        ac=2,  # ç«‹ä½“å£°
                        ar=48000,  # é‡‡æ ·ç‡
                        t=target_duration,  # é™åˆ¶æ—¶é•¿ä¸ºè¾ƒé•¿çš„ä¸€ä¸ª
                        shortest=None,  # ä½¿ç”¨ shortest=Falseï¼Œè®©ä¸¤ä¸ªæµéƒ½è¾¾åˆ°ç›®æ ‡æ—¶é•¿
                    )
                    .overwrite_output()
                    .run(quiet=True, capture_stdout=True, capture_stderr=True)
                )
                
                if temp_video_with_audio.exists():
                    video_with_audio_paths.append(str(temp_video_with_audio))
                    # éªŒè¯å®é™…è¾“å‡ºæ—¶é•¿
                    actual_duration = self.get_media_duration(str(temp_video_with_audio))
                    duration_diff = abs(actual_duration - target_duration)
                    status = "âœ“" if duration_diff < 0.05 else "âš "
                    print(f"  {status} ç‰‡æ®µ {i+1}: {os.path.basename(video_path)} ({video_duration:.3f}s) + {os.path.basename(audio_path)} ({audio_duration:.3f}s) -> {actual_duration:.3f}s (ç›®æ ‡: {target_duration:.3f}s, å·®å¼‚: {duration_diff:.3f}s)")
                else:
                    print(f"  âœ— ç‰‡æ®µ {i+1} æ·»åŠ éŸ³é¢‘å¤±è´¥: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
            except Exception as e:
                print(f"  âœ— ç‰‡æ®µ {i+1} æ·»åŠ éŸ³é¢‘å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        if not video_with_audio_paths:
            raise RuntimeError("æ²¡æœ‰æˆåŠŸæ·»åŠ éŸ³é¢‘çš„è§†é¢‘ç‰‡æ®µ")
        
        # 2. æ‹¼æ¥æ‰€æœ‰å¸¦éŸ³é¢‘çš„è§†é¢‘ç‰‡æ®µ
        temp_concat = temp_dir / "temp_concat_with_audio.mp4"
        print(f"\næ‹¼æ¥ {len(video_with_audio_paths)} ä¸ªå¸¦éŸ³é¢‘çš„è§†é¢‘ç‰‡æ®µ...")
        self.concat_videos_ffmpeg(video_with_audio_paths, str(temp_concat))
        
        # 3. æ·»åŠ BGMå’Œå­—å¹•åˆ°æœ€ç»ˆè§†é¢‘ï¼ˆè§†é¢‘å·²ç»æœ‰éŸ³é¢‘äº†ï¼Œéœ€è¦ä¸BGMæ··åˆï¼‰
        print("æ·»åŠ BGMå’Œå­—å¹•åˆ°æœ€ç»ˆè§†é¢‘...")
        bgm_mix_path, bgm_cleanup, bgm_meter = self.prepare_bgm_tracks(
            video_paths,
            scene_metadata=scene_metadata,
            default_bgm_path=bgm_path,
        )
        
        # æ·»åŠ BGMå’Œå­—å¹•ï¼ˆè§†é¢‘å·²ç»æœ‰éŸ³é¢‘äº†ï¼Œéœ€è¦ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼Œä¸BGMæ··åˆï¼‰
        # ç›´æ¥ä½¿ç”¨ add_audio_subtitle_ffmpegï¼Œä¼ å…¥è§†é¢‘è·¯å¾„ï¼Œå®ƒä¼šä»è§†é¢‘ä¸­æå–éŸ³é¢‘
        # ä½†æˆ‘ä»¬éœ€è¦ä¼ å…¥ None ä½œä¸ºå•ç‹¬çš„éŸ³é¢‘è·¯å¾„ï¼Œç„¶åè®©æ–¹æ³•ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ä¸BGMæ··åˆ
        self.add_audio_subtitle_ffmpeg(
            str(temp_concat),
            None,  # ä¸ä½¿ç”¨å•ç‹¬çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆè§†é¢‘ä¸­å·²æœ‰éŸ³é¢‘ï¼‰
            subtitle_path,
            bgm_mix_path,
            output_path,
            bgm_pre_scaled=bool(bgm_meter.get("pre_scaled") if bgm_meter else False),
        )
        
        # 4. Real-ESRGAN è¶…åˆ†åå¤„ç†
        post_cfg = self.composition_config.get("postprocess", {})
        if post_cfg.get("enabled"):
            try:
                output_path = self.postprocess_with_realesrgan(output_path, post_cfg)
            except Exception as exc:
                print(f"âš  è§†é¢‘åå¤„ç†å¤±è´¥: {exc}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            for path in video_with_audio_paths:
                if os.path.exists(path):
                    os.unlink(path)
            if temp_concat.exists():
                temp_concat.unlink()
        except Exception:
            pass
        
        return output_path
    
    def compose_ffmpeg(
        self,
        video_paths: List[str],
        audio_path: Optional[str] = None,
        subtitle_path: Optional[str] = None,
        bgm_path: Optional[str] = None,
        output_path: str = "output.mp4",
        *,
        scene_metadata: Optional[List[Dict]] = None,
    ) -> str:
        """ä½¿ç”¨ FFmpeg åˆæˆè§†é¢‘"""
        temp_dir = Path(self.config['paths']['temp_dir'])
        temp_dir.mkdir(parents=True, exist_ok=True)
        temp_video = temp_dir / "temp_concat.mp4"
        
        # 1. æ‹¼æ¥è§†é¢‘ç‰‡æ®µ
        print("æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
        print(f"  è§†é¢‘ç‰‡æ®µæ•°é‡: {len(video_paths)}")
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„è§†é¢‘ç‰‡æ®µ
        seen = set()
        unique_paths = []
        for path in video_paths:
            if path not in seen:
                seen.add(path)
                unique_paths.append(path)
            else:
                print(f"  âš  è­¦å‘Š: å‘ç°é‡å¤çš„è§†é¢‘ç‰‡æ®µ: {os.path.basename(path)}")
        
        if len(unique_paths) != len(video_paths):
            print(f"  âš  å·²ç§»é™¤ {len(video_paths) - len(unique_paths)} ä¸ªé‡å¤ç‰‡æ®µ")
            video_paths = unique_paths
        
        self.concat_videos_ffmpeg(video_paths, str(temp_video))
        
        # 2. é¢„å¤„ç†èƒŒæ™¯éŸ³ä¹
        bgm_mix_path, bgm_cleanup, bgm_meter = self.prepare_bgm_tracks(
            video_paths,
            scene_metadata=scene_metadata,
            default_bgm_path=bgm_path,
        )

        # 3. æ·»åŠ éŸ³é¢‘å’Œå­—å¹•
        print("æ·»åŠ éŸ³é¢‘å’Œå­—å¹•...")
        self.add_audio_subtitle_ffmpeg(
            str(temp_video),
            audio_path,
            subtitle_path,
            bgm_mix_path,
            output_path,
            bgm_pre_scaled=bool(bgm_meter.get("pre_scaled") if bgm_meter else False),
        )

        # 4. Real-ESRGAN è¶…åˆ†åå¤„ç†
        post_cfg = self.composition_config.get("postprocess", {})
        if post_cfg.get("enabled"):
            try:
                output_path = self.postprocess_with_realesrgan(output_path, post_cfg)
            except Exception as exc:
                print(f"âš  è§†é¢‘åå¤„ç†å¤±è´¥: {exc}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_video.exists():
            temp_video.unlink()
        for temp_file in bgm_cleanup:
            try:
                Path(temp_file).unlink(missing_ok=True)
            except Exception:
                pass
        
        print(f"âœ“ è§†é¢‘å·²åˆæˆ: {output_path}")
        return output_path
    
    def concat_videos_ffmpeg(self, video_paths: List[str], output_path: str):
        """ä½¿ç”¨ FFmpeg æ‹¼æ¥è§†é¢‘ï¼ˆç¡®ä¿æ—¶é•¿ä¸ä¸¢å¤±ï¼‰"""
        if not video_paths:
            raise ValueError("è§†é¢‘ç‰‡æ®µåˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ‹¼æ¥")
        
        # æ£€æŸ¥æ‰€æœ‰è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        missing_files = []
        video_durations = []
        total_expected_duration = 0.0
        
        for video_path in video_paths:
            abs_path = os.path.abspath(video_path)
            if not os.path.exists(abs_path):
                missing_files.append(abs_path)
                continue
            # è·å–æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„æ—¶é•¿
            duration = self.get_media_duration(abs_path)
            video_durations.append((abs_path, duration))
            total_expected_duration += duration
        
        if missing_files:
            raise FileNotFoundError(f"ä»¥ä¸‹è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {missing_files}")
        
        print(f"  é¢„æœŸæ€»æ—¶é•¿: {total_expected_duration:.3f}s (å…± {len(video_paths)} ä¸ªç‰‡æ®µ)")
        
        print(f"  æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘ç‰‡æ®µ...")
        for i, (vp, dur) in enumerate(video_durations, 1):
            print(f"    {i}. {os.path.basename(vp)} ({dur:.3f}s)")
        
        # ç›´æ¥ä½¿ç”¨ filter_complex æ–¹å¼æ‹¼æ¥ï¼ˆæ›´å¯é ï¼Œç¡®ä¿æ—¶é•¿ä¸ä¸¢å¤±ï¼‰
        # concat demuxer æ–¹å¼åœ¨è§†é¢‘æ ¼å¼ä¸ä¸€è‡´æ—¶å¯èƒ½ä¸¢å¤±æ—¶é•¿ï¼Œfilter_complex æ›´å¯é 
        print(f"  ä½¿ç”¨ filter_complex æ–¹å¼æ‹¼æ¥ï¼ˆç¡®ä¿æ—¶é•¿ä¸ä¸¢å¤±ï¼‰...")
        try:
            self._concat_videos_with_filter_complex(video_paths, output_path, total_expected_duration)
        except Exception as e:
            print(f"âœ— filter_complex æ‹¼æ¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _concat_videos_with_filter_complex(self, video_paths: List[str], output_path: str, expected_duration: float):
        """ä½¿ç”¨ filter_complex æ–¹å¼æ‹¼æ¥è§†é¢‘ï¼ˆæ›´å¯é ï¼Œç¡®ä¿æ—¶é•¿ä¸ä¸¢å¤±ï¼‰"""
        print(f"  ä½¿ç”¨ filter_complex æ–¹å¼æ‹¼æ¥ï¼ˆç¡®ä¿æ—¶é•¿ä¸ä¸¢å¤±ï¼‰...")
        
        # æ£€æŸ¥å“ªäº›è§†é¢‘æœ‰éŸ³é¢‘æµ
        has_audio_list = []
        for video_path in video_paths:
            try:
                probe = ffmpeg.probe(video_path)
                has_audio = any(s.get('codec_type') == 'audio' for s in probe.get('streams', []))
                has_audio_list.append(has_audio)
            except:
                has_audio_list.append(False)
        
        # æ„å»ºè¾“å…¥æµ
        inputs = []
        for video_path in video_paths:
            inputs.append(ffmpeg.input(video_path))
        
        # ä½¿ç”¨ concat filter æ‹¼æ¥
        video_streams = [inp['v'] for inp in inputs]
        
        # æ‹¼æ¥è§†é¢‘æµ
        if len(video_streams) > 1:
            video_concat = ffmpeg.concat(*video_streams, v=1, a=0)
        else:
            video_concat = video_streams[0]
        
        # æ‹¼æ¥éŸ³é¢‘æµï¼ˆå¦‚æœæœ‰ï¼‰
        if any(has_audio_list):
            audio_streams = []
            for i, inp in enumerate(inputs):
                if has_audio_list[i]:
                    try:
                        audio_streams.append(inp['a'])
                    except:
                        pass  # å¦‚æœè·å–éŸ³é¢‘æµå¤±è´¥ï¼Œè·³è¿‡
            
            if len(audio_streams) > 1:
                audio_concat = ffmpeg.concat(*audio_streams, v=0, a=1)
            elif len(audio_streams) == 1:
                audio_concat = audio_streams[0]
            else:
                audio_concat = None
        else:
            audio_concat = None
        
        # è¾“å‡º
        # è·å–ç¼–ç å‚æ•°
        video_codec = self.composition_config.get('video_codec', 'libx264')
        video_bitrate = self.composition_config.get('video_bitrate', '8000k')
        video_preset = self.composition_config.get('video_preset', 'medium')
        video_crf = self.composition_config.get('video_crf')
        
        # æ„å»ºè¾“å‡ºå‚æ•°
        output_kwargs = {'vcodec': video_codec}
        if video_crf is not None and video_codec == 'libx264':
            # ä½¿ç”¨ CRF è´¨é‡æ¨¡å¼
            output_kwargs['crf'] = str(video_crf)
            if video_preset:
                output_kwargs['preset'] = video_preset
            print(f"  ä½¿ç”¨ CRF è´¨é‡æ¨¡å¼: {video_crf}, preset: {video_preset}")
        else:
            # ä½¿ç”¨æ¯”ç‰¹ç‡æ¨¡å¼
            output_kwargs['b:v'] = video_bitrate
            if video_preset and video_codec == 'libx264':
                output_kwargs['preset'] = video_preset
            print(f"  ä½¿ç”¨æ¯”ç‰¹ç‡æ¨¡å¼: {video_bitrate}, preset: {video_preset if video_preset else 'default'}")
        
        if audio_concat is not None:
            out = ffmpeg.output(video_concat, audio_concat, output_path, 
                              acodec='aac',
                              **output_kwargs)
        else:
            out = ffmpeg.output(video_concat, output_path,
                              **output_kwargs)
        
        out.overwrite_output().run(quiet=True, capture_stdout=True, capture_stderr=True)
        
        # éªŒè¯æ—¶é•¿
        actual_duration = self.get_media_duration(output_path)
        duration_diff = abs(actual_duration - expected_duration)
        if duration_diff < 0.1:
            print(f"  âœ“ filter_complex æ‹¼æ¥æˆåŠŸ: å®é™…æ—¶é•¿ {actual_duration:.3f}s (é¢„æœŸ: {expected_duration:.3f}s, å·®å¼‚: {duration_diff:.3f}s)")
        else:
            print(f"  âš  filter_complex æ‹¼æ¥å®Œæˆä½†æ—¶é•¿ä»æœ‰å·®å¼‚: å®é™…æ—¶é•¿ {actual_duration:.3f}s (é¢„æœŸ: {expected_duration:.3f}s, å·®å¼‚: {duration_diff:.3f}s)")
    
    def get_media_duration(self, media_path: str) -> float:
        """è·å–åª’ä½“æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰"""
        try:
            import subprocess
            result = subprocess.run(
                ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', media_path],
                capture_output=True,
                text=True,
                check=True
            )
            duration = float(result.stdout.strip())
            return duration
        except Exception as e:
            print(f"âš  æ— æ³•è·å– {media_path} çš„æ—¶é•¿: {e}")
            return 0.0
    
    def _get_video_fps(self, video_path: str) -> float:
        """è·å–è§†é¢‘å¸§ç‡"""
        try:
            import subprocess
            result = subprocess.run(
                ['ffprobe', '-v', 'error', '-select_streams', 'v:0', '-show_entries', 'stream=r_frame_rate', '-of', 'default=noprint_wrappers=1:nokey=1', video_path],
                capture_output=True,
                text=True,
                check=True
            )
            fps_str = result.stdout.strip()
            if '/' in fps_str:
                num, den = map(int, fps_str.split('/'))
                return num / den if den > 0 else 25.0
            return float(fps_str) if fps_str else 25.0
        except Exception as e:
            print(f"âš  æ— æ³•è·å– {video_path} çš„å¸§ç‡: {e}")
            return 25.0  # é»˜è®¤å¸§ç‡
    
    def add_audio_subtitle_ffmpeg(
        self,
        video_path: str,
        audio_path: Optional[str] = None,
        subtitle_path: Optional[str] = None,
        bgm_path: Optional[str] = None,
        output_path: str = "output.mp4",
        *,
        bgm_pre_scaled: bool = False,
    ):
        """ä½¿ç”¨ FFmpeg æ·»åŠ éŸ³é¢‘å’Œå­—å¹•"""
        import subprocess
        
        # è·å–è§†é¢‘å’ŒéŸ³é¢‘çš„å®é™…æ—¶é•¿
        video_duration = self.get_media_duration(video_path)
        # å¦‚æœ audio_path ä¸º Noneï¼Œè¯´æ˜è§†é¢‘ä¸­å·²æœ‰éŸ³é¢‘ï¼Œä»è§†é¢‘ä¸­æå–éŸ³é¢‘æ—¶é•¿
        if audio_path and os.path.exists(audio_path):
            audio_duration = self.get_media_duration(audio_path)
        else:
            # è§†é¢‘ä¸­å·²æœ‰éŸ³é¢‘ï¼Œè·å–è§†é¢‘çš„éŸ³é¢‘è½¨é“æ—¶é•¿
            audio_duration = video_duration  # é€šå¸¸è§†é¢‘ä¸­çš„éŸ³é¢‘æ—¶é•¿ç­‰äºè§†é¢‘æ—¶é•¿
        
        # å¦‚æœéŸ³é¢‘æ¯”è§†é¢‘é•¿ï¼Œéœ€è¦å»¶é•¿è§†é¢‘ï¼ˆé‡å¤æœ€åä¸€å¸§ï¼Œè€Œä¸æ˜¯å¾ªç¯æ•´ä¸ªè§†é¢‘ï¼‰
        if audio_path and audio_duration > video_duration and audio_duration > 0:
            duration_diff = audio_duration - video_duration
            print(f"  éŸ³é¢‘æ—¶é•¿ ({audio_duration:.2f}s) æ¯”è§†é¢‘æ—¶é•¿ ({video_duration:.2f}s) é•¿ {duration_diff:.2f}sï¼Œå°†å»¶é•¿è§†é¢‘ï¼ˆé‡å¤æœ€åä¸€å¸§ï¼‰")
            # ä½¿ç”¨ FFmpeg å»¶é•¿è§†é¢‘ï¼šé‡å¤æœ€åä¸€å¸§ï¼Œè€Œä¸æ˜¯å¾ªç¯æ•´ä¸ªè§†é¢‘
            # è¿™æ ·å¯ä»¥é¿å…é‡å¤å¼€å¤´ï¼Œåªå»¶é•¿ç»“å°¾
            temp_extended = Path(self.config['paths']['temp_dir']) / "temp_extended_video.mp4"
            temp_extended.parent.mkdir(parents=True, exist_ok=True)
            
            # æ–¹æ³•ï¼šä½¿ç”¨ filter_complex é‡å¤æœ€åä¸€å¸§æ¥å»¶é•¿è§†é¢‘
            # è¿™æ ·å¯ä»¥é¿å…å¾ªç¯æ•´ä¸ªè§†é¢‘ï¼ˆå¯¼è‡´é‡å¤å¼€å¤´ï¼‰ï¼Œåªå»¶é•¿ç»“å°¾
            # è·å–ç¼–ç å‚æ•°
            video_codec = self.composition_config.get('video_codec', 'libx264')
            video_bitrate = self.composition_config.get('video_bitrate', '8000k')
            video_preset = self.composition_config.get('video_preset', 'medium')
            video_crf = self.composition_config.get('video_crf')
            
            try:
                # æ„å»ºè¾“å‡ºå‚æ•°
                output_kwargs = {'vcodec': video_codec, 'acodec': 'copy'}
                if video_crf is not None and video_codec == 'libx264':
                    output_kwargs['crf'] = str(video_crf)
                    if video_preset:
                        output_kwargs['preset'] = video_preset
                else:
                    output_kwargs['b:v'] = video_bitrate
                    if video_preset and video_codec == 'libx264':
                        output_kwargs['preset'] = video_preset
                
                (
                    ffmpeg
                    .input(video_path)
                    .filter('tpad', stop_mode='clone', stop_duration=duration_diff)  # é‡å¤æœ€åä¸€å¸§
                    .output(
                        str(temp_extended),
                        **output_kwargs,
                    )
                    .overwrite_output()
                    .run(quiet=True)
                )
            except Exception as e:
                # å¦‚æœ tpad ä¸æ”¯æŒï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•ï¼šæå–æœ€åä¸€å¸§å¹¶é‡å¤
                print(f"  âš  tpad filter å¤±è´¥ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•: {e}")
                # æå–æœ€åä¸€å¸§
                last_frame = temp_extended.parent / "last_frame.png"
                (
                    ffmpeg
                    .input(video_path)
                    .filter('select', 'eq(n,-1)')  # é€‰æ‹©æœ€åä¸€å¸§
                    .output(str(last_frame), vframes=1)
                    .overwrite_output()
                    .run(quiet=True)
                )
                # åˆ›å»ºå»¶é•¿è§†é¢‘ï¼šåŸè§†é¢‘ + é‡å¤æœ€åä¸€å¸§
                fps = self._get_video_fps(video_path)
                num_frames_to_add = int(duration_diff * fps)
                # è·å–ç¼–ç å‚æ•°ï¼ˆåœ¨é“¾å¼è°ƒç”¨ä¹‹å‰ï¼‰
                video_codec = self.composition_config.get('video_codec', 'libx264')
                video_bitrate = self.composition_config.get('video_bitrate', '8000k')
                video_preset = self.composition_config.get('video_preset', 'medium')
                video_crf = self.composition_config.get('video_crf')
                
                # æ„å»ºè¾“å‡ºå‚æ•°
                output_kwargs = {'vcodec': video_codec}
                if video_crf is not None and video_codec == 'libx264':
                    output_kwargs['crf'] = str(video_crf)
                    if video_preset:
                        output_kwargs['preset'] = video_preset
                else:
                    output_kwargs['b:v'] = video_bitrate
                    if video_preset and video_codec == 'libx264':
                        output_kwargs['preset'] = video_preset
                
                # ä½¿ç”¨ loop filter é‡å¤æœ€åä¸€å¸§
                (
                    ffmpeg
                    .input(str(last_frame), loop=1, t=duration_diff, framerate=fps)
                    .output(
                        str(temp_extended.parent / "extended_part.mp4"),
                        **output_kwargs,
                    )
                    .overwrite_output()
                    .run(quiet=True)
                )
                # æ‹¼æ¥åŸè§†é¢‘å’Œå»¶é•¿éƒ¨åˆ†
                concat_list = temp_extended.parent / "extend_concat.txt"
                with open(concat_list, 'w') as f:
                    f.write(f"file '{video_path}'\n")
                    f.write(f"file '{temp_extended.parent / 'extended_part.mp4'}'\n")
                (
                    ffmpeg
                    .input(str(concat_list), format='concat', safe=0)
                    .output(
                        str(temp_extended),
                        vcodec=self.composition_config['video_codec'],
                        acodec='copy',
                        **{'b:v': self.composition_config['video_bitrate']},
                    )
                    .overwrite_output()
                    .run(quiet=True)
                )
            video_path = str(temp_extended)
            print(f"  âœ“ è§†é¢‘å·²å»¶é•¿è‡³ {audio_duration:.2f}sï¼ˆé‡å¤æœ€åä¸€å¸§ï¼‰")
        elif video_duration > audio_duration and audio_duration > 0:
            duration_diff = video_duration - audio_duration
            # è§†é¢‘æ—¶é•¿æ¯”éŸ³é¢‘æ—¶é•¿é•¿ï¼Œé€šå¸¸æ˜¯å› ä¸ºå‘ä¸Šå–æ•´å¯¼è‡´çš„ç´¯è®¡è¯¯å·®
            # ç”±äºéŸ³é¢‘æ˜¯å‡†ç¡®çš„è¯­éŸ³æ—¶é•¿ï¼Œåº”è¯¥è£å‰ªè§†é¢‘åˆ°éŸ³é¢‘æ—¶é•¿ï¼Œè€Œä¸æ˜¯å»¶é•¿éŸ³é¢‘
            # è¿™æ ·å¯ä»¥ç¡®ä¿è§†é¢‘æ—¶é•¿ä¸è¯­éŸ³å®Œå…¨å¯¹åº”ï¼Œé¿å…æœ«å°¾å‡ºç°é™éŸ³
            print(f"  è§†é¢‘æ—¶é•¿ ({video_duration:.2f}s) æ¯”éŸ³é¢‘æ—¶é•¿ ({audio_duration:.2f}s) é•¿ {duration_diff:.2f}s")
            print(f"  â„¹ å°†è§†é¢‘è£å‰ªåˆ°éŸ³é¢‘æ—¶é•¿ï¼ˆéŸ³é¢‘æ˜¯å‡†ç¡®çš„è¯­éŸ³æ—¶é•¿ï¼Œå‘ä¸Šå–æ•´å¯¼è‡´çš„ç´¯è®¡è¯¯å·®ï¼‰")
            # è£å‰ªè§†é¢‘åˆ°éŸ³é¢‘æ—¶é•¿ï¼šä½¿ç”¨ -t å‚æ•°é™åˆ¶è¾“å‡ºæ—¶é•¿
            temp_cropped_video = self.config['paths']['temp_dir'] + "/temp_cropped_video.mp4"
            (
                ffmpeg
                .input(video_path)
                .output(
                    temp_cropped_video,
                    vcodec='copy',  # ä½¿ç”¨ copy é¿å…é‡æ–°ç¼–ç 
                    acodec='copy',
                    t=audio_duration,  # é™åˆ¶è¾“å‡ºæ—¶é•¿ä¸ºéŸ³é¢‘æ—¶é•¿
                )
                .overwrite_output()
                .run(quiet=True)
            )
            video_path = temp_cropped_video
            video_duration = audio_duration  # æ›´æ–°è§†é¢‘æ—¶é•¿ä¸ºéŸ³é¢‘æ—¶é•¿
            print(f"  âœ“ è§†é¢‘å·²è£å‰ªè‡³ {audio_duration:.2f}sï¼ˆä¸éŸ³é¢‘æ—¶é•¿ä¸€è‡´ï¼‰")
        
        # æ„å»ºè¾“å…¥åˆ—è¡¨
        inputs = []
        input_index = 0
        
        # è§†é¢‘è¾“å…¥
        inputs.append(('-i', video_path))
        video_index = input_index
        input_index += 1
        
        # éŸ³é¢‘è¾“å…¥
        audio_index = None
        if audio_path and os.path.exists(audio_path):
            inputs.append(('-i', audio_path))
            audio_index = input_index
            input_index += 1
        
        # èƒŒæ™¯éŸ³ä¹è¾“å…¥
        bgm_index = None
        if bgm_path and os.path.exists(bgm_path):
            inputs.append(('-i', bgm_path))
            bgm_index = input_index
            input_index += 1
        
        # æ„å»ºåŸºç¡€å‘½ä»¤
        cmd = ['ffmpeg', '-y']
        for flag, path in inputs:
            cmd.extend([flag, path])
        
        # æ„å»ºæ»¤é•œ
        video_filters = []
        audio_filters = []
        filter_complex_parts = []
        
        # è§†é¢‘æ»¤é•œï¼šåˆ†è¾¨ç‡æå‡ / é”åŒ– / å­—å¹•
        upscale_cfg = self.composition_config.get("upscale", {})
        if upscale_cfg.get("enabled"):
            up_width = upscale_cfg.get("width")
            up_height = upscale_cfg.get("height")
            if up_width and up_height:
                scale_flags = upscale_cfg.get("flags", "lanczos")
                video_filters.append(f"scale={up_width}:{up_height}:flags={scale_flags}")

        sharpen_cfg = self.composition_config.get("sharpen", {})
        if sharpen_cfg.get("enabled"):
            lx = sharpen_cfg.get("luma_msize_x", 5)
            ly = sharpen_cfg.get("luma_msize_y", 5)
            la = sharpen_cfg.get("luma_amount", 1.0)
            cx = sharpen_cfg.get("chroma_msize_x", 5)
            cy = sharpen_cfg.get("chroma_msize_y", 5)
            ca = sharpen_cfg.get("chroma_amount", 0.0)
            video_filters.append(f"unsharp={lx}:{ly}:{la}:{cx}:{cy}:{ca}")

        if subtitle_path and os.path.exists(subtitle_path):
            subtitle_path_escaped = subtitle_path.replace('\\', '\\\\').replace(':', '\\:')
            video_filters.append(f"subtitles='{subtitle_path_escaped}'")
        
        audio_volume = float(self.composition_config.get("audio_volume", 1.0))
        bgm_config = self.composition_config.get('bgm', {})

        # éŸ³é¢‘æ»¤é•œï¼šæ··åˆéŸ³é¢‘
        # é¦–å…ˆå¤„ç†é…éŸ³éŸ³é¢‘ï¼šè½¬æ¢ä¸º 48000 Hz ç«‹ä½“å£°
        target_sample_rate = 48000
        if audio_index is not None:
            # ä½¿ç”¨å•ç‹¬çš„éŸ³é¢‘æ–‡ä»¶
            filter_complex_parts.append(
                f"[{audio_index}:a]aresample={target_sample_rate},"
                f"aformat=sample_rates={target_sample_rate}:channel_layouts=stereo,"
                f"volume={audio_volume}[a1_processed]"
            )
            processed_audio_index = "[a1_processed]"
            # ä½¿ç”¨å•ç‹¬éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿
            audio_duration_actual = audio_duration if audio_duration > 0 else (self.get_media_duration(audio_path) if audio_path else video_duration)
        elif video_duration > 0:
            # ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼ˆè§†é¢‘ä¸­å·²æœ‰éŸ³é¢‘è½¨é“ï¼‰
            # è§†é¢‘è¾“å…¥åœ¨ video_indexï¼Œæå–å…¶éŸ³é¢‘æµ
            filter_complex_parts.append(
                f"[{video_index}:a]aresample={target_sample_rate},"
                f"aformat=sample_rates={target_sample_rate}:channel_layouts=stereo,"
                f"volume={audio_volume}[a1_processed]"
            )
            processed_audio_index = "[a1_processed]"
            # ä½¿ç”¨è§†é¢‘æ—¶é•¿ï¼ˆè§†é¢‘ä¸­çš„éŸ³é¢‘æ—¶é•¿åº”è¯¥ç­‰äºè§†é¢‘æ—¶é•¿ï¼‰
            audio_duration_actual = video_duration
        else:
            processed_audio_index = None
            audio_duration_actual = 0.0

        if processed_audio_index is not None and bgm_index is not None:
            # BGM ä¸€ç›´æ’­æ”¾ï¼Œä¸é…éŸ³éŸ³é¢‘æ—¶é•¿åŒ¹é…
            
            if bgm_pre_scaled:
                # é¢„å¤„ç†è¿‡çš„ BGM ç›´æ¥ä½¿ç”¨ï¼Œä½†éœ€è¦ç¡®ä¿é‡‡æ ·ç‡åŒ¹é…
                filter_complex_parts.append(f"[{bgm_index}:a]aresample=48000[a2_raw]")
            else:
                bgm_volume = bgm_config.get('volume', 0.3)
                filter_complex_parts.append(f"[{bgm_index}:a]aresample=48000,volume={bgm_volume}[a2_raw]")
            
            # BGM å¾ªç¯æ’­æ”¾ç›´åˆ°è¾¾åˆ°éŸ³é¢‘æ—¶é•¿
            # å¦‚æœBGMæ—¶é•¿å°äºéŸ³é¢‘æ—¶é•¿ï¼Œå¾ªç¯BGM
            if audio_duration_actual > 0:
                # ä½¿ç”¨aloopå¾ªç¯BGMï¼Œç„¶åæˆªæ–­åˆ°éŸ³é¢‘æ—¶é•¿
                filter_complex_parts.append(
                    f"[a2_raw]aloop=loop=-1:size=2e+09,atrim=0:{audio_duration_actual},asetpts=PTS-STARTPTS[a2_final]"
                )
            else:
                # å¦‚æœæ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œä½¿ç”¨duration=firstè®©BGMè·ŸéšéŸ³é¢‘
                filter_complex_parts.append("[a2_raw]anull[a2_final]")
            
            # æ··åˆé…éŸ³å’ŒBGM
            filter_complex_parts.append(f"[a1_processed][a2_final]amix=inputs=2:duration=first:dropout_transition=2[aout]")
            audio_output = "[aout]"
            print(f"  BGM é…ç½®: å…¨ç¨‹æ’­æ”¾ï¼ŒéŸ³é‡ {bgm_config.get('volume', 0.3)}")
        elif processed_audio_index is not None:
            audio_output = processed_audio_index
        elif bgm_index is not None:
            if bgm_pre_scaled:
                filter_complex_parts.append(f"[{bgm_index}:a]anull[aout]")
            else:
                bgm_volume = bgm_config.get('volume', 0.3)
                filter_complex_parts.append(f"[{bgm_index}:a]volume={bgm_volume}[aout]")
            audio_output = "[aout]"
        else:
            audio_output = None
        
        # æ·»åŠ æ»¤é•œ
        # å¦‚æœåªæœ‰è§†é¢‘æ»¤é•œï¼Œä½¿ç”¨ -vfï¼›å¦‚æœæœ‰éŸ³é¢‘æ··åˆï¼Œä½¿ç”¨ -filter_complex
        if filter_complex_parts:
            # æœ‰éŸ³é¢‘æ··åˆï¼Œä½¿ç”¨ filter_complex
            if video_filters:
                # è§†é¢‘å’ŒéŸ³é¢‘éƒ½æœ‰æ»¤é•œ
                video_filter_str = f"[{video_index}:v]{','.join(video_filters)}[vout]"
                filter_complex_parts.insert(0, video_filter_str)
            cmd.extend(['-filter_complex', ';'.join(filter_complex_parts)])
            # æ˜ å°„å°†åœ¨åé¢å¤„ç†
        elif video_filters:
            # åªæœ‰è§†é¢‘æ»¤é•œ
            cmd.extend(['-vf', ','.join(video_filters)])
        
        # æ˜ å°„æµ
        # æ ¹æ®æ˜¯å¦æœ‰ filter_complex å†³å®šæ˜ å°„æ–¹å¼
        if filter_complex_parts:
            # ä½¿ç”¨äº† filter_complex
            if video_filters:
                # è§†é¢‘æœ‰æ»¤é•œï¼Œå·²åœ¨ filter_complex ä¸­å¤„ç†ä¸º [vout]
                cmd.extend(['-map', '[vout]'])
            else:
                # è§†é¢‘æ— æ»¤é•œï¼Œç›´æ¥æ˜ å°„
                cmd.extend(['-map', f'{video_index}:v'])
            
            # éŸ³é¢‘æ˜ å°„ï¼ˆä» filter_complex è¾“å‡ºï¼‰
            if audio_output:
                cmd.extend(['-map', audio_output])
        else:
            # æ²¡æœ‰ filter_complex
            cmd.extend(['-map', f'{video_index}:v'])  # è§†é¢‘æ˜ å°„
            
            if audio_index is not None:
                cmd.extend(['-map', f'{audio_index}:a'])
            elif bgm_index is not None:
                cmd.extend(['-map', f'{bgm_index}:a'])
            else:
                cmd.extend(['-an'])  # æ— éŸ³é¢‘
        
        # è¾“å‡ºå‚æ•°
        video_codec = self.composition_config.get('video_codec', 'libx264')
        video_bitrate = self.composition_config.get('video_bitrate', '8000k')
        video_preset = self.composition_config.get('video_preset', 'medium')
        video_crf = self.composition_config.get('video_crf')
        
        cmd.extend([
            '-c:v', video_codec,
            '-c:a', self.composition_config['audio_codec'] if audio_output else 'copy',
        ])
        
        # ä¼˜å…ˆä½¿ç”¨ CRFï¼ˆè´¨é‡æ¨¡å¼ï¼‰ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨æ¯”ç‰¹ç‡æ¨¡å¼
        if video_crf is not None and video_codec == 'libx264':
            cmd.extend(['-crf', str(video_crf)])
            # å¦‚æœé…ç½®äº† presetï¼Œä½¿ç”¨å®ƒ
            if video_preset:
                cmd.extend(['-preset', video_preset])
            print(f"  ä½¿ç”¨ CRF è´¨é‡æ¨¡å¼: {video_crf}, preset: {video_preset}")
        else:
            cmd.extend(['-b:v', video_bitrate])
            # å¦‚æœé…ç½®äº† presetï¼Œä½¿ç”¨å®ƒ
            if video_preset and video_codec == 'libx264':
                cmd.extend(['-preset', video_preset])
            print(f"  ä½¿ç”¨æ¯”ç‰¹ç‡æ¨¡å¼: {video_bitrate}, preset: {video_preset if video_preset else 'default'}")
        
        if audio_output:
            cmd.extend(['-b:a', self.composition_config['audio_bitrate']])
        
        cmd.extend([
            '-s', f"{self.composition_config['output_width']}x{self.composition_config['output_height']}",
            '-shortest',  # ä»¥æœ€çŸ­æµä¸ºå‡†
            output_path
        ])
        
        # æ‰§è¡Œå‘½ä»¤
        print(f"æ‰§è¡Œ FFmpeg å‘½ä»¤...")
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            print(f"âœ“ FFmpeg æ‰§è¡ŒæˆåŠŸ")
        except subprocess.CalledProcessError as e:
            print("âœ— FFmpeg æ‰§è¡Œå¤±è´¥")
            print(f"å‘½ä»¤: {' '.join(cmd)}")
            if e.stderr:
                snippet = e.stderr if len(e.stderr) <= 4000 else e.stderr[:4000] + "..."
                print("é”™è¯¯è¾“å‡º:\n" + snippet)
            raise

    def postprocess_with_realesrgan(self, video_path: str, cfg: dict) -> str:
        """åœ¨åˆæˆåè°ƒç”¨ Real-ESRGAN è¿›è¡Œè¶…åˆ†"""
        try:
            from realesrgan_upscale import build_model, upscale_video  # type: ignore
        except ImportError as exc:
            raise RuntimeError("æ— æ³•å¯¼å…¥ realesrgan_upscaleï¼Œè¯·ç¡®è®¤è„šæœ¬å­˜åœ¨å¹¶å·²å®‰è£…ä¾èµ–ã€‚") from exc

        input_path = Path(video_path)
        model_path = Path(cfg.get("model_path", "models/realesrgan/RealESRGAN_x4plus.pth"))
        scale = int(cfg.get("model_scale", 4))
        outscale = float(cfg.get("outscale", 2.0))
        target_resolution = cfg.get("target_resolution")  # æ ¼å¼: "1920x1080" æˆ– None
        tile = int(cfg.get("tile", 0))
        full_precision = bool(cfg.get("full_precision", False))
        codec = cfg.get("codec", "mp4v")
        suffix = cfg.get("suffix", "_upscaled")

        raw_upscaled_path = input_path.with_name(input_path.stem + suffix + "_video" + input_path.suffix)
        final_output_path = input_path.with_name(input_path.stem + suffix + input_path.suffix)
        preserve_audio = cfg.get("preserve_audio", True)
        print("\n=== Real-ESRGAN è§†é¢‘åå¤„ç† ===")
        print(f"è¾“å…¥: {input_path}")
        print(f"è¾“å‡º: {final_output_path}")
        print(f"æ¨¡å‹: {model_path.name}, outscale={outscale}x, tile={tile}")
        if target_resolution:
            print(f"ç›®æ ‡åˆ†è¾¨ç‡: {target_resolution} (è¶…åˆ†åå°†ç¼©æ”¾åˆ°æ­¤åˆ†è¾¨ç‡)")

        # ç›´æ¥ä½¿ç”¨é…ç½®çš„tileå€¼ï¼Œä¸è‡ªåŠ¨è°ƒæ•´ï¼ˆè®©ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶ï¼‰
        # tile=0 è¡¨ç¤ºä¸ä½¿ç”¨ç“¦ç‰‡ï¼Œé€‚åˆx2æ¨¡å‹ï¼ˆè®¡ç®—é‡å°ï¼Œæ•´å›¾å¤„ç†æ›´å¿«ï¼‰
        # tile>0 ç”¨äºæ˜¾å­˜ä¸è¶³çš„æƒ…å†µï¼Œä½†ä¼šå¢åŠ å¤„ç†æ—¶é—´
        upscaler = build_model(
            model_path=model_path,
            scale=scale,
            half=not full_precision,
            tile=tile,  # ä½¿ç”¨é…ç½®çš„tileå€¼ï¼Œä¸è‡ªåŠ¨è°ƒæ•´
            verbose=False,  # å…³é—­è¯¦ç»†æ—¥å¿—ï¼Œå‡å°‘è¾“å‡ºæé«˜é€Ÿåº¦
        )
        
        # è·å–å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°ï¼ˆä»é…ç½®ä¸­è¯»å–ï¼Œé»˜è®¤1ï¼‰
        num_workers = cfg.get("num_workers", 1)
        upscale_video(
            upscaler=upscaler,
            src_path=input_path,
            dst_path=raw_upscaled_path,
            outscale=outscale,
            fps=None,
            codec=codec,
            num_workers=num_workers,
        )

        if preserve_audio:
            try:
                self.copy_audio_track(
                    source_video=input_path,
                    processed_video=raw_upscaled_path,
                    output_video=final_output_path,
                    target_resolution=target_resolution,
                )
                raw_upscaled_path.unlink(missing_ok=True)
            except Exception as exc:
                print(f"âš  éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— å£°ç‰ˆæœ¬: {exc}")
                return str(raw_upscaled_path)

        return str(final_output_path)

    def copy_audio_track(self, source_video: Path, processed_video: Path, output_video: Path, target_resolution: Optional[str] = None) -> None:
        """å°†åŸå§‹è§†é¢‘çš„éŸ³é¢‘è½¨åˆå¹¶åˆ°å¤„ç†åçš„è§†é¢‘ï¼Œå¹¶é‡æ–°ç¼–ç è§†é¢‘ä»¥ä¼˜åŒ–æ–‡ä»¶å¤§å°
        
        Args:
            source_video: åŸå§‹è§†é¢‘ï¼ˆç”¨äºæå–éŸ³é¢‘ï¼‰
            processed_video: å¤„ç†åçš„è§†é¢‘ï¼ˆè¶…åˆ†åçš„è§†é¢‘ï¼‰
            output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
            target_resolution: ç›®æ ‡åˆ†è¾¨ç‡ï¼Œæ ¼å¼ "å®½åº¦xé«˜åº¦"ï¼Œä¾‹å¦‚ "1920x1080"ã€‚å¦‚æœè®¾ç½®ï¼Œä¼šå…ˆç¼©æ”¾åˆ°æ­¤åˆ†è¾¨ç‡
        """
        # è·å–é…ç½®å‚æ•°
        video_codec = self.composition_config.get("video_codec", "libx264")
        video_bitrate = self.composition_config.get("video_bitrate", "8000k")
        video_preset = self.composition_config.get("video_preset", "medium")
        video_crf = self.composition_config.get("video_crf", 23)  # é»˜è®¤ä½¿ç”¨ 23ï¼ˆå¹³è¡¡ç‚¹ï¼‰
        audio_codec = self.composition_config.get("audio_codec", "aac")
        audio_bitrate = self.composition_config.get("audio_bitrate", "192k")
        
        # æ„å»º ffmpeg å‘½ä»¤
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            str(processed_video),
            "-i",
            str(source_video),
            "-c:v",
            video_codec,
            "-crf",
            str(video_crf),  # ä½¿ç”¨é…ç½®ä¸­çš„ CRF å€¼ï¼ˆ18-28ï¼Œè¶Šå°è´¨é‡è¶Šå¥½æ–‡ä»¶è¶Šå¤§ï¼‰
            "-preset",
            video_preset,  # ä½¿ç”¨é…ç½®ä¸­çš„ preset å€¼ï¼ˆç¼–ç é€Ÿåº¦å’Œè´¨é‡å¹³è¡¡ï¼‰
        ]
        
        # å¦‚æœæŒ‡å®šäº†ç›®æ ‡åˆ†è¾¨ç‡ï¼Œæ·»åŠ ç¼©æ”¾æ»¤é•œ
        if target_resolution:
            try:
                width, height = map(int, target_resolution.split('x'))
                cmd.extend([
                    "-vf",
                    f"scale={width}:{height}:flags=lanczos",  # ä½¿ç”¨ lanczos ç®—æ³•è¿›è¡Œé«˜è´¨é‡ç¼©æ”¾
                ])
                print(f"  å°†è§†é¢‘ç¼©æ”¾åˆ°ç›®æ ‡åˆ†è¾¨ç‡: {width}x{height}")
            except ValueError:
                print(f"âš  è­¦å‘Š: æ— æ•ˆçš„ç›®æ ‡åˆ†è¾¨ç‡æ ¼å¼ '{target_resolution}'ï¼Œåº”æ ¼å¼ä¸º 'å®½åº¦xé«˜åº¦'ï¼Œè·³è¿‡ç¼©æ”¾")
        
        cmd.extend([
            "-map",
            "0:v",
            "-map",
            "1:a?",
            "-c:a",
            audio_codec,
            "-b:a",
            audio_bitrate,
            "-shortest",
            str(output_video),
        ])
        print("åˆå¹¶ Real-ESRGAN è§†é¢‘ä¸åŸå§‹éŸ³é¢‘ï¼ˆé‡æ–°ç¼–ç ä¼˜åŒ–æ–‡ä»¶å¤§å°ï¼‰...")
        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)
            print(f"âœ“ éŸ³é¢‘å·²ä¿ç•™ï¼Œè§†é¢‘å·²é‡æ–°ç¼–ç : {output_video}")
        except subprocess.CalledProcessError as exc:
            stderr = exc.stderr[:500] if exc.stderr else ""
            print(f"âœ— éŸ³é¢‘åˆå¹¶å¤±è´¥: {stderr}")
            raise
    
    def resolve_path(self, maybe_path: Optional[str]) -> Optional[str]:
        if not maybe_path:
            return None
        path = Path(maybe_path)
        if not path.is_absolute():
            path = (self.config_dir / path).resolve()
        if path.exists():
            return str(path)
        return None

    def get_media_duration(self, media_path: str) -> float:
        try:
            probe = ffmpeg.probe(media_path)
            if probe.get("format", {}).get("duration"):
                return float(probe["format"]["duration"])
            for stream in probe.get("streams", []):
                if stream.get("duration"):
                    return float(stream["duration"])
        except Exception as exc:
            print(f"âš  æ— æ³•è·å–åª’ä½“æ—¶é•¿ {media_path}: {exc}")
        return 0.0

    def prepare_bgm_tracks(
        self,
        video_paths: List[str],
        scene_metadata: Optional[List[Dict]] = None,
        default_bgm_path: Optional[str] = None,
    ) -> Tuple[Optional[str], List[str], Dict[str, Any]]:
        """æ ¹æ®åœºæ™¯ä¿¡æ¯ç”ŸæˆèƒŒæ™¯éŸ³ä¹æ—¶é—´çº¿ï¼Œè¿”å›å¯ç”¨äºæ··éŸ³çš„ä¸´æ—¶æ–‡ä»¶"""
        bgm_cfg = self.composition_config.get("bgm", {})
        if not bgm_cfg.get("enabled", False):
            return default_bgm_path, [], {"pre_scaled": False}

        tracks_cfg: Dict[str, Dict[str, Any]] = bgm_cfg.get("tracks", {})
        resolved_default = (
            self.resolve_path(tracks_cfg.get("default", {}).get("path"))
            or self.resolve_path(bgm_cfg.get("path"))
            or self.resolve_path(default_bgm_path)
        )

        if not resolved_default:
            print("âš  æœªæ‰¾åˆ°é»˜è®¤èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œä½¿ç”¨é™éŸ³èƒŒæ™¯ã€‚")
            return None, [], {"pre_scaled": False}

        try:
            from pydub import AudioSegment
        except ImportError:
            print("âš  æœªå®‰è£… pydubï¼Œæ— æ³•è‡ªåŠ¨æ··åˆ BGMï¼Œä½¿ç”¨é»˜è®¤èƒŒæ™¯éŸ³ä¹ã€‚")
            return resolved_default, [], {"pre_scaled": False}

        clip_durations = [self.get_media_duration(p) for p in video_paths]
        if not any(d > 0 for d in clip_durations):
            return resolved_default, [], {"pre_scaled": False}

        total_duration_ms = int(sum(clip_durations) * 1000)
        if total_duration_ms <= 0:
            return resolved_default, [], {"pre_scaled": False}

        # é¢„åŠ è½½å¹¶ç¼“å­˜éŸ³é¢‘ï¼Œå¹¶è¿›è¡Œå“åº¦æ ‡å‡†åŒ–
        def load_track(path: str, normalize: bool = True) -> AudioSegment:
            """åŠ è½½éŸ³è½¨å¹¶å¯é€‰åœ°è¿›è¡Œå“åº¦æ ‡å‡†åŒ–"""
            if path not in self._bgm_cache:
                audio = AudioSegment.from_file(path)
                # å¯¹æ¯ä¸ªBGMæ–‡ä»¶è¿›è¡Œå“åº¦æ ‡å‡†åŒ–ï¼Œç¡®ä¿æ‰€æœ‰BGMéŸ³é‡ä¸€è‡´
                if normalize:
                    # è®¡ç®—RMSï¼ˆå‡æ–¹æ ¹ï¼‰å“åº¦
                    raw_audio = audio.get_array_of_samples()
                    if len(raw_audio) > 0:
                        import numpy as np
                        audio_array = np.array(raw_audio, dtype=np.float32)
                        # å½’ä¸€åŒ–åˆ°[-1, 1]
                        if audio.sample_width == 1:
                            audio_array = (audio_array - 128) / 128.0
                        elif audio.sample_width == 2:
                            audio_array = audio_array / 32768.0
                        elif audio.sample_width == 4:
                            audio_array = audio_array / 2147483648.0
                        
                        # è®¡ç®—RMS
                        rms = np.sqrt(np.mean(audio_array ** 2))
                        # ç›®æ ‡RMSï¼ˆ-18dBFSï¼Œé€‚åˆèƒŒæ™¯éŸ³ä¹ï¼‰
                        target_rms = 0.125  # çº¦ç­‰äº -18dBFS
                        
                        if rms > 0:
                            # è®¡ç®—éœ€è¦çš„å¢ç›Š
                            gain_factor = target_rms / rms
                            # é™åˆ¶å¢ç›ŠèŒƒå›´ï¼Œé¿å…è¿‡åº¦æ”¾å¤§æˆ–ç¼©å°
                            gain_factor = max(0.1, min(10.0, gain_factor))
                            gain_db = 20 * math.log10(gain_factor)
                            audio = audio + gain_db
                
                self._bgm_cache[path] = audio
            return self._bgm_cache[path]

        result_audio = None
        timeline: List[Tuple[str, Dict[str, Any], int]] = []
        # è·Ÿè¸ªæ¯ä¸ªéŸ³è½¨çš„æ’­æ”¾ä½ç½®ï¼Œç¡®ä¿èƒŒæ™¯éŸ³ä¹è¿ç»­æ’­æ”¾
        track_positions: Dict[str, int] = {}  # {track_path: current_position_ms}
        
        for idx, duration in enumerate(clip_durations):
            if duration <= 0:
                continue
            scene = scene_metadata[idx] if scene_metadata and idx < len(scene_metadata) else {}
            track_cfg = self.select_bgm_track(
                index=idx,
                scene=scene,
                tracks_cfg=tracks_cfg,
            )
            track_path = self.resolve_path(track_cfg.get("path")) if track_cfg else None
            if not track_path or not Path(track_path).exists():
                track_path = resolved_default
                track_cfg = tracks_cfg.get("default", {}) or {}
            scene_id_dbg = scene.get("id") if isinstance(scene, dict) else None
            label_dbg = scene.get("label") if isinstance(scene, dict) else None
            # print(f"  ğŸµ åœºæ™¯ {idx+1} (id={scene_id_dbg}, label={label_dbg}) é€‰æ‹©BGM: {Path(track_path).name if track_path else 'None'}")
            timeline.append((track_path, track_cfg or {}, int(duration * 1000)))

        if not timeline:
            return resolved_default, [], {"pre_scaled": False}

        from pydub import AudioSegment  # type: ignore

        master_volume = float(bgm_cfg.get("volume", 0.3))
        global_fade_in = int(bgm_cfg.get("fade_in", 600))
        global_fade_out = int(bgm_cfg.get("fade_out", 600))
        global_crossfade = int(bgm_cfg.get("crossfade", 250))

        for idx, (track_path, track_cfg, duration_ms) in enumerate(timeline):
            try:
                base_audio = load_track(track_path)
            except Exception as exc:
                print(f"âš  åŠ è½½èƒŒæ™¯éŸ³ä¹å¤±è´¥ {track_path}: {exc}")
                base_audio = AudioSegment.silent(duration=duration_ms)

            if len(base_audio) <= 0:
                segment_audio = AudioSegment.silent(duration=duration_ms)
            else:
                # è·å–å½“å‰éŸ³è½¨çš„æ’­æ”¾ä½ç½®ï¼ˆå¦‚æœä¹‹å‰æ’­æ”¾è¿‡ï¼‰
                current_pos = track_positions.get(track_path, 0)
                
                # å¦‚æœå½“å‰ä½ç½®å·²ç»è¶…è¿‡éŸ³è½¨é•¿åº¦ï¼Œä»å¤´å¼€å§‹å¾ªç¯
                if current_pos >= len(base_audio):
                    current_pos = current_pos % len(base_audio)
                
                # ä»å½“å‰ä½ç½®å¼€å§‹æˆªå–éœ€è¦çš„æ—¶é•¿
                remaining = len(base_audio) - current_pos
                if remaining >= duration_ms:
                    # å‰©ä½™éƒ¨åˆ†è¶³å¤Ÿï¼Œç›´æ¥æˆªå–
                    segment_audio = base_audio[current_pos:current_pos + duration_ms]
                    track_positions[track_path] = current_pos + duration_ms
                else:
                    # å‰©ä½™éƒ¨åˆ†ä¸è¶³ï¼Œéœ€è¦å¾ªç¯
                    segment_parts = [base_audio[current_pos:]]
                    needed = duration_ms - remaining
                    next_pos = 0  # è®°å½•ä¸‹ä¸€ä¸ªåœºæ™¯åº”è¯¥ä»å“ªä¸ªä½ç½®å¼€å§‹
                    while needed > 0:
                        if needed >= len(base_audio):
                            segment_parts.append(base_audio)
                            needed -= len(base_audio)
                            next_pos = 0  # å®Œæ•´å¾ªç¯åï¼Œä¸‹ä¸€ä¸ªåœºæ™¯ä»å¤´å¼€å§‹
                        else:
                            segment_parts.append(base_audio[:needed])
                            next_pos = needed  # è®°å½•ä¸‹ä¸€ä¸ªåœºæ™¯åº”è¯¥ä» needed ä½ç½®å¼€å§‹
                            needed = 0
                    segment_audio = sum(segment_parts)[:duration_ms]
                    track_positions[track_path] = next_pos

            fade_in = int(track_cfg.get("fade_in", global_fade_in))
            fade_out = int(track_cfg.get("fade_out", global_fade_out))
            if fade_in > 0:
                segment_audio = segment_audio.fade_in(min(fade_in, duration_ms // 2))
            if fade_out > 0:
                segment_audio = segment_audio.fade_out(min(fade_out, duration_ms // 2))

            if result_audio is None:
                result_audio = segment_audio
            else:
                crossfade = int(track_cfg.get("crossfade", global_crossfade))
                crossfade = max(0, min(crossfade, min(len(segment_audio), len(result_audio)) // 2))
                result_audio = result_audio.append(segment_audio, crossfade=crossfade)

        if result_audio is None:
            return resolved_default, [], {"pre_scaled": False}

        if len(result_audio) < total_duration_ms:
            pad = total_duration_ms - len(result_audio)
            result_audio += AudioSegment.silent(duration=pad)

        if master_volume <= 0:
            result_audio = result_audio - 90
        else:
            gain_db = 20 * math.log10(master_volume)
            result_audio = result_audio + gain_db

        result_audio = result_audio.set_channels(2)

        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", prefix="bgm_mix_", delete=False)
        temp_file_path = temp_file.name
        temp_file.close()
        result_audio.export(temp_file_path, format="wav")

        return temp_file_path, [temp_file_path], {"pre_scaled": True}

    def select_bgm_track(
        self,
        index: int,
        scene: Dict[str, Any],
        tracks_cfg: Dict[str, Dict[str, Any]],
    ) -> Optional[Dict[str, Any]]:
        if not tracks_cfg:
            return None

        mood = (scene.get("mood") or "").lower()
        title = (scene.get("title") or "").lower()

        if index == 0 and "start" in tracks_cfg:
            return tracks_cfg["start"]

        # ç»“å°¾ä¼˜å…ˆï¼šåœºæ™¯ID=999 æˆ– label/type æ ‡è®° ending
        scene_id_raw = scene.get("id") if isinstance(scene, dict) else None
        if scene_id_raw is None and isinstance(scene, dict):
            scene_id_raw = scene.get("scene_number")
        scene_id_str = str(scene_id_raw).strip() if scene_id_raw is not None else ""
        try:
            scene_id_val = int(scene_id_str)
        except (ValueError, TypeError):
            scene_id_val = None
        scene_type = (scene.get("type") or "").lower()
        label = (scene.get("label") or "").lower()
        if (
            ("ending" in tracks_cfg)
            and (
                scene_id_val == 999
                or scene_id_str == "999"
                or scene_type == "ending"
                or label == "ending"
            )
        ):
            return tracks_cfg["ending"]

        # å…¶å®ƒè‡ªå®šä¹‰æ ‡ç­¾ä¼˜å…ˆ
        if label and label in tracks_cfg:
            return tracks_cfg[label]

        def match_keywords(candidate: Dict[str, Any], text: str) -> bool:
            keywords = candidate.get("match_moods") or candidate.get("match_keywords") or []
            for kw in keywords:
                if kw and kw.lower() in text:
                    return True
            return False

        for key in ["tense", "intense", "battle"]:
            candidate = tracks_cfg.get(key)
            if candidate and (match_keywords(candidate, mood) or match_keywords(candidate, title)):
                return candidate

        for name, candidate in tracks_cfg.items():
            if name in ("default", "start", "ending"):
                continue
            if match_keywords(candidate, mood) or match_keywords(candidate, title):
                return candidate

        return tracks_cfg.get("default")
    
    def compose_moviepy(
        self,
        video_paths: List[str],
        audio_path: Optional[str] = None,
        subtitle_path: Optional[str] = None,
        bgm_path: Optional[str] = None,
        output_path: str = "output.mp4",
        scene_metadata: Optional[List[Dict]] = None,
    ) -> str:
        """ä½¿ç”¨ MoviePy åˆæˆè§†é¢‘ï¼ˆå¾…å®ç°ï¼‰"""
        raise NotImplementedError("MoviePy åˆæˆæ–¹å¼å¾…å®ç°")


def main():
    parser = argparse.ArgumentParser(description="è§†é¢‘åˆæˆ")
    parser.add_argument("--config", type=str, default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--videos", type=str, nargs="+", required=True, help="è§†é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨")
    parser.add_argument("--audio", type=str, help="é…éŸ³éŸ³é¢‘è·¯å¾„")
    parser.add_argument("--subtitle", type=str, help="å­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--bgm", type=str, help="èƒŒæ™¯éŸ³ä¹è·¯å¾„")
    parser.add_argument("--output", type=str, default="output.mp4", help="è¾“å‡ºè§†é¢‘è·¯å¾„")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–åˆæˆå™¨
    composer = VideoComposer(args.config)
    
    # åˆæˆè§†é¢‘
    composer.compose(
        args.videos,
        args.audio,
        args.subtitle,
        args.bgm,
        args.output,
    )


if __name__ == "__main__":
    main()




#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è„šæœ¬ - éªŒè¯ PuLID + è§£è€¦èåˆ + Execution Planner V3

è¿è¡Œæ–¹å¼:
    python test_enhanced_generation.py

æµ‹è¯•å†…å®¹:
1. Execution Planner V3 ç­–ç•¥åˆ†æ
2. PuLID å¼•æ“åˆå§‹åŒ–
3. è§£è€¦èåˆå¼•æ“åˆå§‹åŒ–
4. ç«¯åˆ°ç«¯ç”Ÿæˆæµ‹è¯• (å¯é€‰)
"""

import os
import sys
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_execution_planner():
    """æµ‹è¯• Execution Planner V3"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: Execution Planner V3")
    print("=" * 60)
    
    try:
        from execution_planner_v3 import ExecutionPlannerV3
        
        planner = ExecutionPlannerV3()
        
        # æµ‹è¯•ä¸åŒé•œå¤´ç±»å‹
        test_cases = [
            # wide + top_down: ä¿¯æ‹è¿œæ™¯ï¼Œå‡ ä¹çœ‹ä¸åˆ°è„¸ï¼Œå‚è€ƒå¼ºåº¦å¯ä»¥å¾ˆä½
            {"shot": "wide", "angle": "top_down", "emotion": "neutral", "expected_range": (5, 35)},
            {"shot": "medium", "angle": "eye_level", "emotion": "neutral", "expected_range": (55, 65)},
            {"shot": "close", "angle": "eye_level", "emotion": "angry", "expected_range": (80, 100)},
            {"shot": "extreme_close", "angle": "low", "emotion": "pain", "expected_range": (90, 100)},
        ]
        
        all_passed = True
        for case in test_cases:
            scene = {
                "camera": {"shot": case["shot"], "angle": case["angle"]},
                "character": {"present": True, "emotion": case["emotion"]},
                "environment": {"description": "test scene"}
            }
            
            strategy = planner.analyze_scene(scene)
            strength = strategy.reference_strength
            
            min_expected, max_expected = case["expected_range"]
            passed = min_expected <= strength <= max_expected
            
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {case['shot']} + {case['angle']} + {case['emotion']}: {strength}% (æœŸæœ›: {min_expected}-{max_expected}%)")
            
            if not passed:
                all_passed = False
        
        if all_passed:
            print("\nâœ… Execution Planner V3 æµ‹è¯•é€šè¿‡!")
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥å‚æ•°è°ƒæ•´é€»è¾‘")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_pulid_engine():
    """æµ‹è¯• PuLID å¼•æ“åˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: PuLID å¼•æ“")
    print("=" * 60)
    
    try:
        from pulid_engine import PuLIDEngine
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        models_dir = Path("/vepfs-dev/shawn/vid/fanren/gen_video/models")
        pulid_path = models_dir / "pulid" / "pulid_flux_v0.9.1.safetensors"
        
        if pulid_path.exists():
            print(f"  âœ… PuLID æ¨¡å‹å­˜åœ¨: {pulid_path}")
            print(f"     å¤§å°: {pulid_path.stat().st_size / 1024 / 1024:.1f} MB")
        else:
            print(f"  âŒ PuLID æ¨¡å‹ä¸å­˜åœ¨: {pulid_path}")
            return False
        
        # æµ‹è¯•å¼•æ“åˆå§‹åŒ–
        config = {
            "device": "cuda",
            "quantization": "bfloat16",
            "model_dir": str(models_dir)
        }
        
        engine = PuLIDEngine(config)
        
        # æµ‹è¯•å‚è€ƒå¼ºåº¦è®¡ç®—
        print("\n  å‚è€ƒå¼ºåº¦è®¡ç®—æµ‹è¯•:")
        for shot in ["wide", "medium", "close"]:
            strength = engine.calculate_reference_strength(shot)
            print(f"    {shot}: {strength}%")
        
        print("\nâœ… PuLID å¼•æ“åˆå§‹åŒ–æˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_decoupled_fusion():
    """æµ‹è¯•è§£è€¦èåˆå¼•æ“"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: è§£è€¦èåˆå¼•æ“")
    print("=" * 60)
    
    try:
        from decoupled_fusion_engine import DecoupledFusionEngine
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        models_dir = Path("/vepfs-dev/shawn/vid/fanren/gen_video/models")
        sam2_path = models_dir / "sam2"
        
        if sam2_path.exists():
            print(f"  âœ… SAM2 ç›®å½•å­˜åœ¨: {sam2_path}")
            # åˆ—å‡º SAM2 ç›®å½•å†…å®¹
            files = list(sam2_path.glob("*"))
            print(f"     æ–‡ä»¶: {[f.name for f in files[:5]]}")
        else:
            print(f"  âŒ SAM2 ç›®å½•ä¸å­˜åœ¨: {sam2_path}")
        
        # æµ‹è¯•å¼•æ“åˆå§‹åŒ–
        config = {
            "device": "cuda",
            "model_dir": str(models_dir)
        }
        
        engine = DecoupledFusionEngine(config)
        
        # æµ‹è¯• YOLO åŠ è½½
        print("\n  åŠ è½½ YOLO...")
        engine.load_yolo()
        print("  âœ… YOLO åŠ è½½æˆåŠŸ")
        
        # å¸è½½
        engine.unload()
        
        print("\nâœ… è§£è€¦èåˆå¼•æ“åˆå§‹åŒ–æˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_enhanced_generator():
    """æµ‹è¯•å¢å¼ºå‹å›¾åƒç”Ÿæˆå™¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: å¢å¼ºå‹å›¾åƒç”Ÿæˆå™¨")
    print("=" * 60)
    
    try:
        from enhanced_image_generator import EnhancedImageGenerator
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_path = "config.yaml"
        if not os.path.exists(config_path):
            print(f"  âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = EnhancedImageGenerator(config_path)
        print("  âœ… EnhancedImageGenerator åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åœºæ™¯
        test_scene = {
            "camera": {"shot": "medium", "angle": "eye_level"},
            "character": {
                "present": True,
                "id": "hanli",
                "emotion": "neutral"
            },
            "environment": {
                "description": "ancient mountain temple, misty clouds",
                "lighting": "soft morning light"
            }
        }
        
        # åˆ†æç­–ç•¥ (ä¸å®é™…ç”Ÿæˆ)
        strategy = generator.planner.analyze_scene(test_scene)
        prompt = generator.planner.build_weighted_prompt(test_scene, strategy)
        
        print(f"\n  ç­–ç•¥åˆ†æ:")
        print(f"    å‚è€ƒå¼ºåº¦: {strategy.reference_strength}%")
        print(f"    èº«ä»½å¼•æ“: {strategy.identity_engine.value}")
        print(f"    è§£è€¦ç”Ÿæˆ: {strategy.use_decoupled_pipeline}")
        print(f"    ç¯å¢ƒæƒé‡: {strategy.environment_weight}x")
        print(f"\n  æ„å»ºçš„ Prompt:")
        print(f"    {prompt[:100]}...")
        
        generator.unload_all()
        
        print("\nâœ… å¢å¼ºå‹å›¾åƒç”Ÿæˆå™¨æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_end_to_end(run_generation: bool = False):
    """ç«¯åˆ°ç«¯æµ‹è¯• (å¯é€‰)"""
    if not run_generation:
        print("\n" + "=" * 60)
        print("æµ‹è¯• 5: ç«¯åˆ°ç«¯ç”Ÿæˆ (è·³è¿‡)")
        print("=" * 60)
        print("  æç¤º: ä½¿ç”¨ --full å‚æ•°è¿è¡Œå®Œæ•´æµ‹è¯•")
        return True
    
    print("\n" + "=" * 60)
    print("æµ‹è¯• 5: ç«¯åˆ°ç«¯ç”Ÿæˆ")
    print("=" * 60)
    
    try:
        import os
        import torch
        
        # è®¾ç½® PyTorch CUDA å†…å­˜åˆ†é…é…ç½®ï¼Œå‡å°‘å†…å­˜ç¢ç‰‡
        os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')
        print("  å·²è®¾ç½® PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True")
        
        from enhanced_image_generator import EnhancedImageGenerator
        from PIL import Image
        
        # æ£€æŸ¥æ˜¾å­˜
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            free = total - reserved
            print(f"\næ˜¾å­˜çŠ¶æ€:")
            print(f"  æ€»è®¡: {total:.2f} GB")
            print(f"  å·²åˆ†é…: {allocated:.2f} GB")
            print(f"  å·²ä¿ç•™: {reserved:.2f} GB")
            print(f"  å¯ç”¨: {free:.2f} GB")
            
            if free < 25:
                print(f"\nâš ï¸  è­¦å‘Š: å¯ç”¨æ˜¾å­˜è¾ƒå°‘ ({free:.2f}GB)ï¼Œå¯èƒ½ä¼šè¶…å‡ºæ˜¾å­˜é™åˆ¶")
                print("  å»ºè®®:")
                print("  1. å…³é—­å…¶ä»–å ç”¨æ˜¾å­˜çš„ç¨‹åº")
                print("  2. ç¡®ä¿æ²¡æœ‰å…¶ä»– Python è¿›ç¨‹å ç”¨æ˜¾å­˜")
                print("  3. å¦‚æœä»ç„¶å¤±è´¥ï¼Œè€ƒè™‘é™ä½åˆ†è¾¨ç‡æˆ–ä½¿ç”¨ CPU offload")
        
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = EnhancedImageGenerator("config.yaml")
        
        # æµ‹è¯•åœºæ™¯ - æ³¨æ„è¦åŒ…å«äººç‰©æè¿°å’Œæœå‘
        test_scene = {
            "camera": {"shot": "medium", "angle": "eye_level"},
            "character": {
                "present": True,
                "emotion": "neutral",
                "description": "a young Chinese male cultivator with long black hair tied up, wearing flowing white and blue traditional robes, facing the camera, looking at viewer, front view portrait"
            },
            "environment": {
                "description": "misty mountain valley with ancient Chinese pavilion, bamboo forest in background",
                "lighting": "soft dawn light through mist",
                "atmosphere": "serene and mystical"
            }
        }
        
        # è·å–å‚è€ƒå›¾åƒ
        ref_path = "/vepfs-dev/shawn/vid/fanren/gen_video/reference_image/hanli_mid.jpg"
        if not os.path.exists(ref_path):
            print(f"  âš ï¸ å‚è€ƒå›¾åƒä¸å­˜åœ¨: {ref_path}")
            ref_path = None
        
        print("  å¼€å§‹ç”Ÿæˆ...")
        
        # ç”Ÿæˆå›¾åƒ
        image = generator.generate_scene(
            scene=test_scene,
            face_reference=ref_path
        )
        
        # ä¿å­˜ç»“æœ
        output_path = "outputs/test_enhanced_generation.png"
        os.makedirs("outputs", exist_ok=True)
        image.save(output_path)
        print(f"  âœ… å›¾åƒå·²ä¿å­˜: {output_path}")
        
        # å¸è½½æ¨¡å‹
        print("\n  å¸è½½æ¨¡å‹...")
        generator.unload_all()
        
        # æ£€æŸ¥å¸è½½åçš„æ˜¾å­˜
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            print(f"  å¸è½½åæ˜¾å­˜: å·²åˆ†é…={allocated:.2f}GB, å·²ä¿ç•™={reserved:.2f}GB")
        
        print("\nâœ… ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("PuLID + è§£è€¦èåˆ + Execution Planner V3 æµ‹è¯•")
    print("=" * 60)
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # æ£€æŸ¥æ˜¯å¦è¿è¡Œå®Œæ•´æµ‹è¯•
    run_full = "--full" in sys.argv
    
    # è¿è¡Œæµ‹è¯•
    results = {}
    
    results["Execution Planner V3"] = test_execution_planner()
    results["PuLID Engine"] = test_pulid_engine()
    results["Decoupled Fusion"] = test_decoupled_fusion()
    results["Enhanced Generator"] = test_enhanced_generator()
    results["End-to-End"] = test_end_to_end(run_generation=run_full)
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    all_passed = True
    for name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")
        if not passed:
            all_passed = False
    
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    print("=" * 60)
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())

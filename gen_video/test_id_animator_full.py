#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ID-Animator å®Œæ•´æµ‹è¯•è„šæœ¬
æµ‹è¯•è§†é¢‘èº«ä»½ä¿æŒåŠŸèƒ½ï¼ˆM6 é‡Œç¨‹ç¢‘ï¼‰

æµ‹è¯•å†…å®¹:
1. äººè„¸åµŒå…¥æå–
2. AnimateDiff Pipeline åŠ è½½
3. è§†é¢‘ç”Ÿæˆï¼ˆåŸºç¡€ç‰ˆï¼‰
4. èº«ä»½ä¸€è‡´æ€§éªŒè¯

Author: AI Video Team
Date: 2025-12-18
Project: M6 - è§†é¢‘èº«ä»½ä¿æŒ
"""

import sys
import os
import time
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_face_embedding():
    """æµ‹è¯• 1: äººè„¸åµŒå…¥æå–"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 1: äººè„¸åµŒå…¥æå–")
    print("=" * 60)
    
    from id_animator_engine import IDAnimatorEngine
    
    # åˆ›å»ºå¼•æ“
    engine = IDAnimatorEngine({
        "model_dir": "models",
        "id_strength": 0.7,
    })
    
    # æŸ¥æ‰¾å‚è€ƒå›¾
    ref_candidates = [
        "reference_image/hanli_mid.jpg",
        "reference_image/hanli/front_neutral.jpg",
        "character_profiles/hanli/references/front_neutral.png",
    ]
    
    ref_path = None
    for r in ref_candidates:
        if Path(r).exists():
            ref_path = r
            break
    
    if not ref_path:
        print("âŒ æœªæ‰¾åˆ°å‚è€ƒå›¾")
        print("   æ£€æŸ¥çš„è·¯å¾„:")
        for r in ref_candidates:
            print(f"     - {r}: {'å­˜åœ¨' if Path(r).exists() else 'ä¸å­˜åœ¨'}")
        return False, None
    
    print(f"ğŸ“ å‚è€ƒå›¾: {ref_path}")
    
    # åŠ è½½äººè„¸åˆ†æå™¨
    print("\nåŠ è½½äººè„¸åˆ†æå™¨...")
    engine._load_face_analyzer()
    
    if engine.face_analyzer is None:
        print("âŒ äººè„¸åˆ†æå™¨åŠ è½½å¤±è´¥")
        return False, None
    
    print("âœ… äººè„¸åˆ†æå™¨åŠ è½½æˆåŠŸ")
    
    # æå–åµŒå…¥
    print("\næå–äººè„¸åµŒå…¥...")
    embedding = engine.extract_face_embedding(ref_path)
    
    if embedding is None:
        print("âŒ äººè„¸åµŒå…¥æå–å¤±è´¥")
        return False, None
    
    print(f"âœ… äººè„¸åµŒå…¥æå–æˆåŠŸ")
    print(f"   åµŒå…¥ç»´åº¦: {embedding.shape}")
    print(f"   åµŒå…¥èŒƒå›´: [{embedding.min():.3f}, {embedding.max():.3f}]")
    
    # æ¸…ç†
    engine.unload()
    
    return True, ref_path


def test_animatediff_pipeline():
    """æµ‹è¯• 2: AnimateDiff Pipeline åŠ è½½"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 2: AnimateDiff Pipeline åŠ è½½")
    print("=" * 60)
    
    import torch
    
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    from id_animator_engine import IDAnimatorEngine
    
    # åˆ›å»ºå¼•æ“
    engine = IDAnimatorEngine({
        "model_dir": "models",
        "id_strength": 0.7,
        "num_frames": 16,
        "fps": 8,
    })
    
    print("\nåŠ è½½ AnimateDiff Pipeline...")
    start_time = time.time()
    
    try:
        engine._load_animatediff_pipeline()
        load_time = time.time() - start_time
        print(f"âœ… Pipeline åŠ è½½æˆåŠŸ ({load_time:.1f}s)")
        
        # æ˜¾ç¤º Pipeline ä¿¡æ¯
        if engine.pipeline is not None:
            print(f"\nPipeline ä¿¡æ¯:")
            print(f"   ç±»å‹: {type(engine.pipeline).__name__}")
            print(f"   è®¾å¤‡: {engine.pipeline.device if hasattr(engine.pipeline, 'device') else 'N/A'}")
            print(f"   æ­¥æ•°: {engine.num_inference_steps}")
        
        # æ¸…ç†
        engine.unload()
        return True
        
    except Exception as e:
        print(f"âŒ Pipeline åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_video_generation(ref_path: str = None):
    """æµ‹è¯• 3: è§†é¢‘ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 3: è§†é¢‘ç”Ÿæˆ")
    print("=" * 60)
    
    if ref_path is None:
        # æŸ¥æ‰¾å‚è€ƒå›¾
        ref_candidates = [
            "reference_image/hanli_mid.jpg",
            "reference_image/hanli/front_neutral.jpg",
        ]
        for r in ref_candidates:
            if Path(r).exists():
                ref_path = r
                break
        
        if ref_path is None:
            print("âŒ æœªæ‰¾åˆ°å‚è€ƒå›¾")
            return False, None
    
    print(f"ğŸ“ å‚è€ƒå›¾: {ref_path}")
    
    from id_animator_engine import IDAnimatorEngine
    
    # åˆ›å»ºå¼•æ“
    engine = IDAnimatorEngine({
        "model_dir": "models",
        "id_strength": 0.7,
        "num_frames": 16,  # çŸ­è§†é¢‘æµ‹è¯•
        "fps": 8,
        "num_inference_steps": 20,  # è¾ƒå°‘æ­¥æ•°åŠ é€Ÿæµ‹è¯•
        "guidance_scale": 7.0,
    })
    
    # è¾“å‡ºç›®å½•
    output_dir = Path("outputs/id_animator_test")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = output_dir / f"test_video_{timestamp}.mp4"
    
    # æµ‹è¯• prompt
    prompt = "A Chinese man in traditional Chinese clothes walking slowly, ancient Chinese style, high quality, detailed face"
    
    print(f"\nç”Ÿæˆæµ‹è¯•è§†é¢‘...")
    print(f"   Prompt: {prompt[:60]}...")
    print(f"   å¸§æ•°: {engine.num_frames}")
    print(f"   æ­¥æ•°: {engine.num_inference_steps}")
    print(f"   è¾“å‡º: {output_path}")
    
    start_time = time.time()
    
    try:
        frames = engine.generate_video(
            prompt=prompt,
            reference_image=ref_path,
            output_path=str(output_path),
            seed=42,  # å›ºå®šç§å­ä¾¿äºå¤ç°
        )
        
        gen_time = time.time() - start_time
        print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ ({gen_time:.1f}s)")
        print(f"   ç”Ÿæˆå¸§æ•°: {len(frames)}")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if output_path.exists():
            size_mb = output_path.stat().st_size / 1024 / 1024
            print(f"   æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")
        
        engine.unload()
        return True, str(output_path)
        
    except Exception as e:
        print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        engine.unload()
        return False, None


def test_identity_verification(video_path: str, ref_path: str):
    """æµ‹è¯• 4: èº«ä»½ä¸€è‡´æ€§éªŒè¯"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 4: èº«ä»½ä¸€è‡´æ€§éªŒè¯")
    print("=" * 60)
    
    if not video_path or not Path(video_path).exists():
        print("âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    if not ref_path or not Path(ref_path).exists():
        print("âŒ å‚è€ƒå›¾ä¸å­˜åœ¨")
        return False
    
    print(f"ğŸ“ è§†é¢‘: {video_path}")
    print(f"ğŸ“ å‚è€ƒå›¾: {ref_path}")
    
    try:
        from utils.video_identity_analyzer import VideoIdentityAnalyzer
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = VideoIdentityAnalyzer()
        
        print("\nåˆ†æè§†é¢‘èº«ä»½ä¸€è‡´æ€§...")
        report = analyzer.analyze_video(
            video_path=video_path,
            reference_image=ref_path,
            sample_interval=2,  # æ¯ 2 å¸§é‡‡æ ·
        )
        
        # æ‰“å°ç»“æœ
        print("\n" + analyzer.format_report(report))
        
        # ä¿å­˜æŠ¥å‘Š
        output_dir = Path("outputs/id_animator_test")
        report_path = output_dir / f"identity_report_{Path(video_path).stem}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report.to_json())
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        analyzer.unload()
        
        return report.overall_passed
        
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥è§†é¢‘åˆ†æå™¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("ğŸš€ ID-Animator å®Œæ•´æµ‹è¯•")
    print("=" * 60)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    results = {}
    
    # æµ‹è¯• 1: äººè„¸åµŒå…¥æå–
    success, ref_path = test_face_embedding()
    results["face_embedding"] = success
    
    if not success:
        print("\nâš ï¸ äººè„¸åµŒå…¥æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        return results
    
    # æµ‹è¯• 2: AnimateDiff Pipeline åŠ è½½
    success = test_animatediff_pipeline()
    results["animatediff_pipeline"] = success
    
    if not success:
        print("\nâš ï¸ Pipeline åŠ è½½å¤±è´¥ï¼Œåœæ­¢è§†é¢‘ç”Ÿæˆæµ‹è¯•")
        return results
    
    # æµ‹è¯• 3: è§†é¢‘ç”Ÿæˆ
    success, video_path = test_video_generation(ref_path)
    results["video_generation"] = success
    
    if success and video_path:
        # æµ‹è¯• 4: èº«ä»½ä¸€è‡´æ€§éªŒè¯
        success = test_identity_verification(video_path, ref_path)
        results["identity_verification"] = success
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else ("âš ï¸ è·³è¿‡" if passed is None else "âŒ å¤±è´¥")
        print(f"   {test_name}: {status}")
    
    total_passed = sum(1 for v in results.values() if v is True)
    total_tests = len(results)
    print(f"\nâœ… é€šè¿‡: {total_passed}/{total_tests}")
    
    return results


def quick_test():
    """å¿«é€Ÿæµ‹è¯•ï¼ˆä»…æµ‹è¯•äººè„¸åµŒå…¥ï¼‰"""
    print("\n" + "=" * 60)
    print("âš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    print("=" * 60)
    
    success, ref_path = test_face_embedding()
    
    if success:
        print("\nâœ… å¿«é€Ÿæµ‹è¯•é€šè¿‡ï¼")
        print("   ID-Animator åŸºç¡€åŠŸèƒ½æ­£å¸¸")
    else:
        print("\nâŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥")
    
    return success


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ID-Animator æµ‹è¯•è„šæœ¬")
    parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    parser.add_argument("--skip-video", action="store_true", help="è·³è¿‡è§†é¢‘ç”Ÿæˆæµ‹è¯•")
    args = parser.parse_args()
    
    if args.quick:
        quick_test()
    else:
        results = run_all_tests()
        
        # è¿”å›é€€å‡ºç 
        all_passed = all(v is True or v is None for v in results.values())
        sys.exit(0 if all_passed else 1)

# HunyuanVideo 显存优化总结

## 已实施的优化

### 1. 模型加载优化 ✅
- **CPU加载**: 使用 `CUDA_VISIBLE_DEVICES=''` 临时隐藏GPU，强制在CPU上加载模型
- **低显存模式**: 使用 `low_cpu_mem_usage=True` 降低内存使用
- **结果**: 模型加载时显存占用 **0.00GB**（完全在CPU上）

### 2. 运行时显存优化 ✅
- **CPU Offload**: 使用 `enable_model_cpu_offload()` 让组件按需加载到GPU
- **Attention Slicing**: 使用 `enable_attention_slicing(slice_size="max")` 减少attention计算显存占用
- **Gradient Checkpointing**: 启用梯度检查点进一步减少显存占用
- **VAE Tiling**: 启用VAE tiling降低VAE解码时的显存占用
- **VAE Slicing**: 启用VAE slicing进一步降低VAE解码时的显存占用

### 3. 参数优化 ✅
- **分辨率**: 降低到 960x544（从1280x720）
- **帧数**: 降低到 40帧（从120帧）
- **动态调整**: 根据可用显存自动调整分辨率和帧数

### 4. 显存清理 ✅
- **生成前清理**: 在生成视频前调用 `torch.cuda.empty_cache()` 和 `gc.collect()`
- **Tensor转换后清理**: 将GPU tensor转换为numpy后立即删除并清理显存
- **生成后清理**: 生成完成后删除中间变量并清理显存
- **错误时清理**: 发生错误时也会清理显存

## 当前问题

**其他进程占用了几乎所有显存**：
- Process 1373363: 92.51 GiB
- Process 1391831: 2.69 GiB
- 可用显存: 仅 19.88 MiB

## 解决方案

### 方案1：释放其他进程的显存（推荐）

```bash
# 检查占用显存的进程
python gen_video/check_gpu_memory.py

# 查看进程详情
ps aux | grep <PID>

# 如果进程可以停止，先停止它们
kill <PID>
```

### 方案2：使用480p模型

480p模型的显存需求更低（约10-15GB），可以在当前环境下运行：

```yaml
hunyuanvideo:
  model_path: hunyuanvideo-community/HunyuanVideo-1.5-480p_i2v
  width: 640
  height: 480
  num_frames: 60
```

### 方案3：等待其他进程完成

如果其他进程是重要的任务，可以等待它们完成后再运行视频生成。

## 代码优化效果

- ✅ 模型加载时显存占用：**0.00GB**（完全在CPU上）
- ✅ 所有显存优化已启用
- ✅ 代码不会造成显存泄漏

**结论**: 代码已完全优化，不会一次性分配显存。需要足够的可用显存才能运行视频生成。


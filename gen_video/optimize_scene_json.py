#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–åœºæ™¯ JSON æ–‡ä»¶ï¼š
1. ç¼©çŸ­è¿‡é•¿çš„ narrationï¼ˆä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼‰
2. ä¼˜åŒ– visual å­—æ®µï¼Œä» description ä¸­æ™ºèƒ½æå–å¹¶å¡«å……æ­£ç¡®çš„ä¸­æ–‡å†…å®¹
"""

import json
import re
import argparse
from pathlib import Path
from typing import Dict, Any, List, Optional
import shutil

def has_chinese(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    if not text:
        return False
    return bool(re.search(r'[\u4e00-\u9fff]', str(text)))

def shorten_narration(narration: str, max_length: int = 30) -> str:
    """
    ç¼©çŸ­è¿‡é•¿çš„ narrationï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯
    
    Args:
        narration: åŸå§‹æ—ç™½
        max_length: æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤30ï¼Œçº¦3-4ç§’ï¼‰
    
    Returns:
        ç¼©çŸ­åçš„æ—ç™½
    """
    if not narration:
        return narration
    
    narration = narration.strip()
    
    # å¦‚æœå·²ç»è¶³å¤ŸçŸ­ï¼Œç›´æ¥è¿”å›
    if len(narration) <= max_length:
        return narration
    
    # å°è¯•æŒ‰å¥å·ã€é€—å·ã€æ„Ÿå¹å·ç­‰åˆ†å‰²
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼Œ,ï¼›;]', narration)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if not sentences:
        return narration[:max_length] + "..."
    
    # ä¼˜å…ˆä¿ç•™ç¬¬ä¸€å¥ï¼ˆé€šå¸¸æ˜¯æ ¸å¿ƒä¿¡æ¯ï¼‰
    result = sentences[0]
    
    # å¦‚æœç¬¬ä¸€å¥å·²ç»è¶…è¿‡é™åˆ¶ï¼Œç›´æ¥æˆªæ–­
    if len(result) > max_length:
        # å°è¯•ä¿ç•™å‰åŠéƒ¨åˆ†
        if "ï¼Œ" in result:
            parts = result.split("ï¼Œ")
            result = parts[0]
            if len(result) > max_length:
                return result[:max_length-2] + "..."
        else:
            return result[:max_length-2] + "..."
    
    # å¦‚æœç¬¬ä¸€å¥ä¸å¤Ÿé•¿ï¼Œå°è¯•æ·»åŠ ç¬¬äºŒå¥
    if len(sentences) > 1:
        next_sentence = sentences[1]
        if len(result + "ï¼Œ" + next_sentence) <= max_length:
            result = result + "ï¼Œ" + next_sentence
        elif len(result + "ã€‚" + next_sentence) <= max_length:
            result = result + "ã€‚" + next_sentence
    
    # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œæˆªæ–­
    if len(result) > max_length:
        result = result[:max_length-2] + "..."
    
    return result

def extract_environment(text: str) -> str:
    """ä»æè¿°ä¸­æå–ç¯å¢ƒä¿¡æ¯"""
    if not text:
        return ""
    
    # ç¯å¢ƒå…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    env_keywords = [
        "æ²™æ¼ ", "æ²™åœ°", "æ²™ç ¾", "é’ç°è‰²æ²™åœ°", "é’ç°è‰²æ²™ç ¾", "ä¸€æœ›æ— é™…",
        "å¤©ç©º", "å¤ªé˜³", "æœˆäº®", "æ˜Ÿè¾°", "å¼¯æœˆ", "è™šå½±", "é«˜ç©º", "ä½ç©º", "ä¸Šç©º",
        "åœ°é¢", "è¿œå¤„", "é™„è¿‘", "æ–¹å‘",
        "é»¯æ·¡", "æ˜äº®", "æ˜æš—", "çšæ´", "å¤ºç›®", "æœ¦èƒ§"
    ]
    
    extracted_parts = []
    found_keywords = set()
    
    # ä¼˜å…ˆæå–é•¿å…³é”®è¯
    for kw in sorted(env_keywords, key=len, reverse=True):
        if kw in text and kw not in found_keywords:
            # æå–åŒ…å«å…³é”®è¯çš„çŸ­è¯­ï¼ˆå‘å‰å‘åå„æ‰©å±•ä¸€äº›å­—ç¬¦ï¼‰
            idx = text.find(kw)
            if idx >= 0:
                # å‘å‰æ‰¾èµ·å§‹ä½ç½®ï¼ˆå¥é¦–ã€é€—å·ã€æˆ–å‰5ä¸ªå­—ç¬¦ï¼‰
                start = max(0, idx - 5)
                while start > 0 and text[start] not in "ï¼Œã€‚ï¼ï¼Ÿã€":
                    start -= 1
                if start > 0:
                    start += 1
                
                # å‘åæ‰¾ç»“æŸä½ç½®ï¼ˆå¥æœ«ã€é€—å·ã€æˆ–å10ä¸ªå­—ç¬¦ï¼‰
                end = min(len(text), idx + len(kw) + 10)
                while end < len(text) and text[end] not in "ï¼Œã€‚ï¼ï¼Ÿã€":
                    end += 1
                
                phrase = text[start:end].strip()
                if phrase and phrase not in extracted_parts and len(phrase) <= 25:
                    extracted_parts.append(phrase)
                    found_keywords.add(kw)
                    if len(extracted_parts) >= 2:  # æœ€å¤š2ä¸ªçŸ­è¯­
                        break
    
    if extracted_parts:
        return "ï¼Œ".join(extracted_parts[:2])
    return ""

def extract_character_pose(text: str) -> str:
    """ä»æè¿°ä¸­æå–è§’è‰²å§¿åŠ¿/åŠ¨ä½œä¿¡æ¯"""
    if not text:
        return ""
    
    # è§’è‰²åŠ¨ä½œå…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    pose_keywords = [
        "éŸ©ç«‹", "èººåœ¨", "èºº", "ä¸€åŠ¨ä¸åŠ¨", "æ„Ÿå—", "å›å¿†", "è„¸è‰²éš¾çœ‹", "è„¸è‰²", "éš¾çœ‹",
        "çå¤§åŒç›®", "çå¤§", "åŒç›®", "æ³¨è§†", "å‡è§†", "æ³¨è§†é«˜ç©º",
        "ååŠ¨å¤´é¢…", "ååŠ¨", "å¤´é¢…", "ä¸€å", "ä¸€ç˜ª", "ä¸€é¼“",
        "èƒ¸è†›ä¸€é¼“", "èƒ¸è†›ä¸€ç˜ª", "èƒ¸è„¯ä¸€ç˜ª",
        "ç¥è‰²ä¸€å˜", "ç¥è‰²", "ä¸€å˜", "å¬åˆ°", "çœ‹æ¸…", "çœ‹åˆ°"
    ]
    
    extracted_parts = []
    found_keywords = set()
    
    # ä¼˜å…ˆæå–é•¿å…³é”®è¯
    for kw in sorted(pose_keywords, key=len, reverse=True):
        if kw in text and kw not in found_keywords:
            idx = text.find(kw)
            if idx >= 0:
                # å‘å‰æ‰¾èµ·å§‹ä½ç½®
                start = max(0, idx - 5)
                while start > 0 and text[start] not in "ï¼Œã€‚ï¼ï¼Ÿã€":
                    start -= 1
                if start > 0:
                    start += 1
                
                # å‘åæ‰¾ç»“æŸä½ç½®
                end = min(len(text), idx + len(kw) + 10)
                while end < len(text) and text[end] not in "ï¼Œã€‚ï¼ï¼Ÿã€":
                    end += 1
                
                phrase = text[start:end].strip()
                if phrase and phrase not in extracted_parts and len(phrase) <= 25:
                    extracted_parts.append(phrase)
                    found_keywords.add(kw)
                    if len(extracted_parts) >= 2:  # æœ€å¤š2ä¸ªçŸ­è¯­
                        break
    
    if extracted_parts:
        return "ï¼Œ".join(extracted_parts[:2])
    return ""

def extract_fx(text: str) -> str:
    """ä»æè¿°ä¸­æå–ç‰¹æ•ˆä¿¡æ¯"""
    if not text:
        return ""
    
    # ç‰¹æ•ˆå…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    fx_keywords = [
        "è“èŠ’é—ªåŠ¨", "è“èŠ’", "é—ªåŠ¨", "é’èŠ’æ¿€å°„", "é’èŠ’", "æ¿€å°„", 
        "ç™½æ¿›æ¿›å¼ºé£", "ç™½æ¿›æ¿›", "å¼ºé£", "è½°éš†éš†", "å°–é¸£", "å‡„å‰å°–é¸£",
        "é‡‘å±æ‘©æ“¦èˆ¬", "é‡‘å±æ‘©æ“¦", "æƒ¨å«", "éœ‡åŠ¨", "è½»å¾®éœ‡åŠ¨",
        "ç›˜æ—‹ä¸å®š", "ç›˜æ—‹", "æ¸…é¸£", "æ‚¦è€³æ¸…é¸£",
        "æ’•è£‚åˆ†å°¸", "æ’•è£‚", "åˆ†å°¸",
        "å˜å¹»å½¢æ€", "å˜å¹»", "é»¯æ·¡", "å¤ºç›®", "æœ¦èƒ§", "è™šå½±", "çšæ´", "å¼¯æœˆ",
        "æ»´æºœæºœè½¬åŠ¨", "å¯†å¯†éº»éº»", "æ¼«å¤©èŠ±é›¨"
    ]
    
    extracted_parts = []
    found_keywords = set()
    
    # ä¼˜å…ˆæå–é•¿å…³é”®è¯
    for kw in sorted(fx_keywords, key=len, reverse=True):
        if kw in text and kw not in found_keywords:
            idx = text.find(kw)
            if idx >= 0:
                # å‘å‰æ‰¾èµ·å§‹ä½ç½®
                start = max(0, idx - 5)
                while start > 0 and text[start] not in "ï¼Œã€‚ï¼ï¼Ÿã€":
                    start -= 1
                if start > 0:
                    start += 1
                
                # å‘åæ‰¾ç»“æŸä½ç½®
                end = min(len(text), idx + len(kw) + 10)
                while end < len(text) and text[end] not in "ï¼Œã€‚ï¼ï¼Ÿã€":
                    end += 1
                
                phrase = text[start:end].strip()
                if phrase and phrase not in extracted_parts and len(phrase) <= 25:
                    extracted_parts.append(phrase)
                    found_keywords.add(kw)
                    if len(extracted_parts) >= 2:  # æœ€å¤š2ä¸ªçŸ­è¯­
                        break
    
    if extracted_parts:
        return "ï¼Œ".join(extracted_parts[:2])
    return ""

def extract_composition(text: str) -> str:
    """ä»æè¿°ä¸­æå–æ„å›¾ä¿¡æ¯ï¼ˆæ•´ä½“ç”»é¢æè¿°ï¼‰"""
    if not text:
        return ""
    
    # æ„å›¾é€šå¸¸åŒ…å«ä¸»ä½“å’ŒèƒŒæ™¯çš„å…³ç³»
    # å¦‚æœæè¿°è¾ƒçŸ­ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœè¾ƒé•¿ï¼Œæå–æ ¸å¿ƒéƒ¨åˆ†
    if len(text) <= 28:
        return text
    
    # å°è¯•æå–å‰åŠéƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯ä¸»è¦æ„å›¾ä¿¡æ¯ï¼‰
    if "ï¼Œ" in text:
        parts = text.split("ï¼Œ")
        if len(parts) >= 2:
            # å–å‰ä¸¤ä¸ªéƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯ä¸»ä½“+èƒŒæ™¯ï¼‰
            composition = "ï¼Œ".join(parts[:2])
            if len(composition) <= 30:
                return composition
        elif len(parts) == 1:
            # åªæœ‰ä¸€ä¸ªéƒ¨åˆ†ï¼Œæˆªæ–­åˆ°åˆé€‚é•¿åº¦
            return parts[0][:28] + "..."
    
    # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œç›´æ¥æˆªæ–­
    return text[:28] + "..."

def optimize_visual_field(scene: Dict[str, Any]) -> List[str]:
    """
    ä¼˜åŒ– visual å­—æ®µï¼Œä» description ä¸­æ™ºèƒ½æå–å¹¶å¡«å……
    
    Returns:
        ä¿®æ”¹åˆ—è¡¨
    """
    changes = []
    description = scene.get("description", "")
    
    if not description or not has_chinese(description):
        return changes
    
    visual = scene.get("visual", {}) or {}
    if not isinstance(visual, dict):
        visual = {}
    
    # æå–å„ä¸ªå­—æ®µ
    new_composition = extract_composition(description)
    new_environment = extract_environment(description)
    new_character_pose = extract_character_pose(description)
    new_fx = extract_fx(description)
    
    # æ›´æ–° composition
    if new_composition and visual.get("composition") != new_composition:
        old_comp = visual.get("composition", "")
        visual["composition"] = new_composition
        if old_comp != new_composition:
            changes.append(f"visual.composition: {old_comp[:40] if old_comp else '(ç©º)'}... -> {new_composition[:40]}...")
    
    # æ›´æ–° environment
    if new_environment and visual.get("environment") != new_environment:
        old_env = visual.get("environment", "")
        visual["environment"] = new_environment
        if old_env != new_environment:
            changes.append(f"visual.environment: {old_env[:40] if old_env else '(ç©º)'}... -> {new_environment[:40]}...")
    
    # æ›´æ–° character_pose
    if new_character_pose and visual.get("character_pose") != new_character_pose:
        old_pose = visual.get("character_pose", "")
        visual["character_pose"] = new_character_pose
        if old_pose != new_character_pose:
            changes.append(f"visual.character_pose: {old_pose[:40] if old_pose else '(ç©º)'}... -> {new_character_pose[:40]}...")
    
    # æ›´æ–° fxï¼ˆå¯ä»¥ä¸ºç©ºï¼‰
    if visual.get("fx") != new_fx:
        old_fx = visual.get("fx", "")
        visual["fx"] = new_fx
        if old_fx != new_fx:
            if new_fx:
                changes.append(f"visual.fx: {old_fx[:40] if old_fx else '(ç©º)'}... -> {new_fx[:40]}...")
            else:
                changes.append(f"visual.fx: {old_fx[:40] if old_fx else '(ç©º)'}... -> (å·²æ¸…ç©º)")
    
    # ä¿æŒ motion å­—æ®µä¸å˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if "motion" not in visual and scene.get("camera"):
        # å¯ä»¥æ ¹æ® camera æ¨æ–­ motionï¼Œä½†è¿™é‡Œå…ˆä¸å¤„ç†
        pass
    
    scene["visual"] = visual
    return changes

def optimize_scene(scene: Dict[str, Any], max_narration_length: int = 30) -> Dict[str, List[str]]:
    """
    ä¼˜åŒ–å•ä¸ªåœºæ™¯
    
    Returns:
        {"narration_changes": [...], "visual_changes": [...]}
    """
    changes = {"narration_changes": [], "visual_changes": []}
    scene_id = scene.get("id", "æœªçŸ¥")
    
    # ä¼˜åŒ– narration
    narration = scene.get("narration", "")
    if narration:
        old_narration = narration
        new_narration = shorten_narration(narration, max_narration_length)
        if new_narration != old_narration:
            scene["narration"] = new_narration
            changes["narration_changes"].append(
                f"åœºæ™¯ {scene_id}: {len(old_narration)}å­— -> {len(new_narration)}å­—"
            )
            changes["narration_changes"].append(f"  åŸæ–‡: {old_narration[:50]}...")
            changes["narration_changes"].append(f"  ä¼˜åŒ–: {new_narration}")
    
    # ä¼˜åŒ– visual å­—æ®µ
    visual_changes = optimize_visual_field(scene)
    if visual_changes:
        changes["visual_changes"].extend([f"åœºæ™¯ {scene_id}:"] + visual_changes)
    
    return changes

def main():
    parser = argparse.ArgumentParser(description="ä¼˜åŒ–åœºæ™¯ JSON æ–‡ä»¶ï¼šç¼©çŸ­ narration å¹¶ä¼˜åŒ– visual å­—æ®µ")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥çš„ JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max-narration-length", "-m", type=int, default=30, 
                       help="narration æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤30ï¼Œçº¦3-4ç§’ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶")
    
    args = parser.parse_args()
    
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return
    
    # è¯»å–æ–‡ä»¶
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # å¤‡ä»½åŸæ–‡ä»¶
    if not args.dry_run:
        backup_path = input_path.with_suffix('.json.bak')
        if not backup_path.exists():
            shutil.copy2(input_path, backup_path)
            print(f"âœ“ å·²å¤‡ä»½åŸæ–‡ä»¶: {backup_path}")
    
    all_narration_changes = []
    all_visual_changes = []
    
    # ä¼˜åŒ– opening
    if "opening" in data and data["opening"].get("narration"):
        old_narr = data["opening"]["narration"]
        new_narr = shorten_narration(old_narr, args.max_narration_length)
        if new_narr != old_narr:
            if not args.dry_run:
                data["opening"]["narration"] = new_narr
            all_narration_changes.append(f"å¼€å¤´: {len(old_narr)}å­— -> {len(new_narr)}å­—")
            all_narration_changes.append(f"  åŸæ–‡: {old_narr}")
            all_narration_changes.append(f"  ä¼˜åŒ–: {new_narr}")
    
    # ä¼˜åŒ– scenes
    if "scenes" in data and isinstance(data["scenes"], list):
        for scene in data["scenes"]:
            changes = optimize_scene(scene, args.max_narration_length)
            if changes["narration_changes"]:
                all_narration_changes.extend(changes["narration_changes"])
            if changes["visual_changes"]:
                all_visual_changes.extend(changes["visual_changes"])
    
    # ä¼˜åŒ– ending
    if "ending" in data and data["ending"].get("narration"):
        old_narr = data["ending"]["narration"]
        new_narr = shorten_narration(old_narr, args.max_narration_length)
        if new_narr != old_narr:
            if not args.dry_run:
                data["ending"]["narration"] = new_narr
            all_narration_changes.append(f"ç»“å°¾: {len(old_narr)}å­— -> {len(new_narr)}å­—")
            all_narration_changes.append(f"  åŸæ–‡: {old_narr}")
            all_narration_changes.append(f"  ä¼˜åŒ–: {new_narr}")
    
    # æ˜¾ç¤ºä¿®æ”¹æ‘˜è¦
    if all_narration_changes or all_visual_changes:
        print("\n" + "=" * 60)
        print("ä¼˜åŒ–æ‘˜è¦")
        print("=" * 60)
        
        if all_narration_changes:
            print("\nğŸ“ Narration ä¼˜åŒ–:")
            for change in all_narration_changes:
                print(f"  {change}")
        
        if all_visual_changes:
            print("\nğŸ¨ Visual å­—æ®µä¼˜åŒ–:")
            for change in all_visual_changes:
                print(f"  {change}")
        
        # ä¿å­˜æ–‡ä»¶
        if not args.dry_run:
            with open(input_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"\nâœ“ å·²ä¿å­˜ä¼˜åŒ–åçš„æ–‡ä»¶: {input_path}")
        else:
            print(f"\nâš  é¢„è§ˆæ¨¡å¼ï¼Œæœªå®é™…ä¿®æ”¹æ–‡ä»¶")
    else:
        print("\nâœ“ æœªå‘ç°éœ€è¦ä¼˜åŒ–çš„å†…å®¹")

if __name__ == "__main__":
    main()


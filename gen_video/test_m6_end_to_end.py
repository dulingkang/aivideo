#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
M6 ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬
MVP ç­–ç•¥éªŒè¯ï¼šHunyuanVideo + VideoIdentityAnalyzer + å¤±è´¥é‡è¯•

æµç¨‹:
1. åŠ è½½ Anchor å›¾ (Hanli)
2. è°ƒç”¨ EnhancedVideoGeneratorM6 ç”Ÿæˆè§†é¢‘
3. è‡ªåŠ¨æ‰§è¡Œèº«ä»½éªŒè¯
4. è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š

Author: AI Video Team
Date: 2025-12-18
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
import json
import argparse

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('m6_test.log', mode='w')
    ]
)
logger = logging.getLogger(__name__)

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.abspath("."))

from enhanced_video_generator_m6 import EnhancedVideoGeneratorM6
from video_identity_verifier import ShotLanguage

def run_test(args: argparse.Namespace):
    print("=" * 60)
    print("M6 MVP ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 60)
    
    # 1. è®¾ç½®è·¯å¾„
    input_image = args.input_image
    reference_image = args.reference_image or args.input_image  # é»˜è®¤ä½¿ç”¨åŒä¸€å¼ ä½œä¸ºå‚è€ƒ
    output_dir = args.output_dir
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_video = os.path.join(output_dir, f"{args.output_prefix}_{timestamp}.mp4")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # æ£€æŸ¥è¾“å…¥
    if not os.path.exists(input_image):
        logger.error(f"âŒ è¾“å…¥å›¾åƒä¸å­˜åœ¨: {input_image}")
        return
    
    logger.info(f"è¾“å…¥å›¾åƒ: {input_image}")
    logger.info(f"è¾“å‡ºè·¯å¾„: {output_video}")
    
    # 2. åˆå§‹åŒ–ç”Ÿæˆå™¨
    logger.info("åˆå§‹åŒ–å¢å¼ºç‰ˆç”Ÿæˆå™¨...")
    try:
        generator = EnhancedVideoGeneratorM6("config.yaml")
        
        # è¦†ç›– HunyuanVideo å‚æ•°ï¼ˆä¼šåœ¨é¦–æ¬¡ç”Ÿæˆæ—¶è¢« load_model è¯»å–ï¼‰
        if args.model_path:
            generator.video_config.setdefault("hunyuanvideo", {})
            generator.video_config["hunyuanvideo"]["model_path"] = args.model_path
        if args.num_frames is not None:
            generator.video_config.setdefault("hunyuanvideo", {})
            generator.video_config["hunyuanvideo"]["num_frames"] = int(args.num_frames)
        if args.num_inference_steps is not None:
            generator.video_config.setdefault("hunyuanvideo", {})
            generator.video_config["hunyuanvideo"]["num_inference_steps"] = int(args.num_inference_steps)
        if args.width is not None:
            generator.video_config.setdefault("hunyuanvideo", {})
            generator.video_config["hunyuanvideo"]["width"] = int(args.width)
        if args.height is not None:
            generator.video_config.setdefault("hunyuanvideo", {})
            generator.video_config["hunyuanvideo"]["height"] = int(args.height)

        logger.info(
            "  é…ç½®è¦†ç›–: model_path=%s, num_frames=%s, steps=%s, size=%sx%s",
            args.model_path or "(config.yaml)",
            str(args.num_frames) if args.num_frames is not None else "(config.yaml)",
            str(args.num_inference_steps) if args.num_inference_steps is not None else "(config.yaml)",
            str(args.width) if args.width is not None else "(config.yaml)",
            str(args.height) if args.height is not None else "(config.yaml)",
        )
        
    except Exception as e:
        logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # 3. ç”Ÿæˆè§†é¢‘
    logger.info("å¼€å§‹ç”Ÿæˆè§†é¢‘...")
    
    scene_config = {
        "prompt": args.prompt,
        "description": "Han Li portrait shot",
        "motion_intensity": args.motion_intensity,
        "negative_prompt": args.negative_prompt or ""
    }
    
    try:
        video_path, result = generator.generate_video_with_identity_check(
            image_path=input_image,
            output_path=output_video,
            reference_image=reference_image,
            scene=scene_config,
            shot_type=args.shot_type,
            enable_verification=(not args.no_verify),
            max_retries=args.max_retries
        )
        
        # 4. è¾“å‡ºç»“æœ
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç»“æœ")
        print("=" * 60)
        
        if video_path:
            print(f"ğŸ“ è§†é¢‘è·¯å¾„: {video_path}")
            
            if result:
                status = "âœ… éªŒè¯é€šè¿‡" if result.passed else "âŒ éªŒè¯å¤±è´¥"
                print(f"ğŸ¯ æœ€ç»ˆçŠ¶æ€: {status}")
                print(f"   å¹³å‡ç›¸ä¼¼åº¦: {result.avg_similarity:.3f}")
                print(f"   æ¼‚ç§»æ¯”ä¾‹: {result.drift_ratio*100:.1f}%")
                print(f"   äººè„¸æ£€æµ‹ç‡: {result.face_detect_ratio*100:.1f}%")
                
                if result.issues:
                    print("âš ï¸ å‘ç°é—®é¢˜:")
                    for issue in result.issues:
                        print(f"   â€¢ {issue}")
                
                # ä¿å­˜ç»“æœ JSON
                result_json = os.path.join(output_dir, f"result_{timestamp}.json")
                with open(result_json, "w", encoding="utf-8") as f:
                    json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
                print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {result_json}")
            else:
                print("âš  æ— éªŒè¯ç»“æœ (å¯èƒ½å·²ç¦ç”¨éªŒè¯)")
        else:
            print("âŒ è§†é¢‘ç”Ÿæˆå®Œå…¨å¤±è´¥ (æ‰€æœ‰é‡è¯•å‡æœªæˆåŠŸ)")
            if result and result.issues:
                print("æœ€åä¸€è½®å¤±è´¥åŸå› :")
                for issue in result.issues:
                    print(f"   â€¢ {issue}")
    
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        generator.unload_all()
        logger.info("æµ‹è¯•ç»“æŸï¼Œèµ„æºå·²é‡Šæ”¾")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="M6 ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆHunyuanVideo + èº«ä»½éªŒè¯ + é‡è¯•ï¼‰")
    parser.add_argument("--input-image", default="reference_image/hanli_mid.jpg", help="è¾“å…¥ Anchor å›¾è·¯å¾„")
    parser.add_argument("--reference-image", default=None, help="å‚è€ƒå›¾è·¯å¾„ï¼ˆç”¨äºèº«ä»½éªŒè¯ï¼Œé»˜è®¤åŒ input-imageï¼‰")
    parser.add_argument("--output-dir", default="outputs/m6_test", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--output-prefix", default="hanli_test", help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€")

    parser.add_argument("--shot-type", default="medium", choices=["wide", "medium", "medium_close", "close", "extreme_close"], help="é•œå¤´ç±»å‹")
    parser.add_argument("--max-retries", type=int, default=2, help="æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆè¦†ç›– configï¼‰")
    parser.add_argument("--no-verify", action="store_true", help="ç¦ç”¨èº«ä»½éªŒè¯ï¼ˆä»…ç”Ÿæˆè§†é¢‘ï¼‰")

    parser.add_argument("--prompt", default="Han Li standing in a mystical garden, gentle breeze moving his hair, subtle movement, high quality, cinematic lighting", help="è§†é¢‘ promptï¼ˆä¼šè¢«ç¨³å®šæ€§å¢å¼ºå™¨è‡ªåŠ¨å¢å¼ºï¼‰")
    parser.add_argument("--negative-prompt", default="", help="é¢å¤– negative promptï¼ˆä¼šå åŠ ç¨³å®šæ€§ negative promptï¼‰")
    parser.add_argument("--motion-intensity", default="gentle", choices=["gentle", "moderate", "dynamic"], help="è¿åŠ¨å¼ºåº¦")

    # HunyuanVideo è¦†ç›–å‚æ•°ï¼ˆå¯é€‰ï¼‰
    parser.add_argument("--model-path", default=None, help="HunyuanVideo æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œè¦†ç›– configï¼‰")
    parser.add_argument("--num-frames", type=int, default=None, help="å¸§æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›– configï¼‰")
    parser.add_argument("--num-inference-steps", type=int, default=None, help="æ¨ç†æ­¥æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›– configï¼‰")
    parser.add_argument("--width", type=int, default=None, help="å®½åº¦ï¼ˆå¯é€‰ï¼Œè¦†ç›– configï¼‰")
    parser.add_argument("--height", type=int, default=None, help="é«˜åº¦ï¼ˆå¯é€‰ï¼Œè¦†ç›– configï¼‰")

    run_test(parser.parse_args())

# LoRA è®­ç»ƒç§‘æ™®ä¸»æŒäººæŒ‡å—

## ğŸ“‹ æ˜¯å¦éœ€è¦è®­ç»ƒä¸»æŒäºº LoRAï¼Ÿ

### âœ… **å»ºè®®è®­ç»ƒ LoRA çš„æƒ…å†µï¼š**

1. **éœ€è¦å›ºå®šä¸»æŒäººå½¢è±¡**
   - æ¯æ¬¡ç”Ÿæˆéƒ½æ˜¯åŒä¸€ä¸ªäºº
   - ä¿æŒäººè„¸ç‰¹å¾ä¸€è‡´æ€§
   - é€‚åˆæ‰¹é‡ç”Ÿæˆç§‘æ™®è§†é¢‘

2. **éœ€è¦æ§åˆ¶æ›´å¤šç»†èŠ‚**
   - æœè£…ã€å‘å‹ã€è¡¨æƒ…ç­‰
   - æ¯” InstantID æ›´çµæ´»
   - å¯ä»¥è®­ç»ƒå¤šä¸ªä¸»æŒäººï¼ˆä¸åŒ LoRAï¼‰

3. **éœ€è¦æ‰¹é‡ç”Ÿæˆ**
   - ç”Ÿæˆé€Ÿåº¦å¿«ï¼ˆLoRA æƒé‡å°ï¼‰
   - æ˜¾å­˜å ç”¨ä½
   - é€‚åˆæµæ°´çº¿ç”Ÿäº§

### âŒ **å¯ä»¥ä¸è®­ç»ƒ LoRA çš„æƒ…å†µï¼š**

1. **ä½¿ç”¨ InstantID**
   - åªéœ€è¦ä¸€å¼ å‚è€ƒå›¾
   - é€‚åˆå¿«é€Ÿæµ‹è¯•
   - ä½†çµæ´»æ€§è¾ƒä½

2. **ä¸´æ—¶ç”Ÿæˆ**
   - ä¸éœ€è¦å›ºå®šå½¢è±¡
   - æ¯æ¬¡å¯ä»¥ä¸åŒ

---

## ğŸš€ è®­ç»ƒæ–¹æ¡ˆ

### **æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ Kohya_ssï¼ˆæ¨èï¼‰**

Kohya_ss æ˜¯æœ€æµè¡Œçš„ LoRA è®­ç»ƒå·¥å…·ï¼Œæ”¯æŒ Fluxã€SDXLã€SD1.5 ç­‰ã€‚

#### å®‰è£…æ­¥éª¤ï¼š

```bash
# 1. å…‹éš†ä»“åº“
cd /vepfs-dev/shawn/vid/fanren/gen_video
git clone https://github.com/bmaltais/kohya_ss.git
cd kohya_ss

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt

# 4. å®‰è£… xformersï¼ˆå¯é€‰ï¼ŒåŠ é€Ÿè®­ç»ƒï¼‰
pip install xformers
```

#### å‡†å¤‡è®­ç»ƒæ•°æ®ï¼š

```
train_data/
  host_person/
    _repeat_10_ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡ï¼Œå¾®ç¬‘.jpg
    _repeat_10_ç§‘æ™®ä¸»æŒäººï¼Œæ­£å¼ç€è£…ï¼Œæ­£é¢.jpg
    _repeat_10_ç§‘æ™®ä¸»æŒäººï¼Œæ¸©å’Œè¡¨æƒ…ï¼ŒåŠèº«.jpg
    _repeat_10_ç§‘æ™®ä¸»æŒäººï¼Œå•†åŠ¡æ­£è£…ï¼Œå…¨èº«.jpg
    ...
```

**å‘½åè§„åˆ™ï¼š**
- `_repeat_N_` è¡¨ç¤ºé‡å¤ N æ¬¡ï¼ˆå»ºè®® 10-20ï¼‰
- æ–‡ä»¶ååŒ…å«æç¤ºè¯ï¼Œç”¨äºè‡ªåŠ¨æ ‡æ³¨

#### è®­ç»ƒé…ç½®ï¼ˆFlux.1ï¼‰ï¼š

```yaml
# train_config.yaml
pretrained_model_name_or_path: /vepfs-dev/shawn/vid/fanren/gen_video/models/flux1-dev
output_dir: /vepfs-dev/shawn/vid/fanren/gen_video/models/lora/host_person
train_data_dir: /vepfs-dev/shawn/vid/fanren/gen_video/train_data/host_person

# è®­ç»ƒå‚æ•°
resolution: 1024,1024
train_batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 1e-4
lr_scheduler: cosine
lr_warmup_steps: 100
max_train_steps: 1000
save_every_n_steps: 200

# LoRA å‚æ•°
network_module: lycoris.kohya
network_dim: 32  # LoRA ç»´åº¦ï¼ˆ16/32/64ï¼Œè¶Šå¤§è¶Šå¼ºä½†è¶Šå®¹æ˜“è¿‡æ‹Ÿåˆï¼‰
network_alpha: 16  # é€šå¸¸è®¾ä¸º network_dim çš„ä¸€åŠ
network_dropout: 0.1

# ä¼˜åŒ–å™¨
optimizer_type: adamw8bit
mixed_precision: fp16
```

#### å¯åŠ¨è®­ç»ƒï¼š

```bash
cd kohya_ss
python train_network.py --config train_config.yaml
```

---

### **æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ diffusers + PEFTï¼ˆä»£ç é›†æˆï¼‰**

é€‚åˆç›´æ¥åœ¨é¡¹ç›®ä¸­é›†æˆè®­ç»ƒåŠŸèƒ½ã€‚

#### è®­ç»ƒè„šæœ¬ç¤ºä¾‹ï¼š

```python
# train_host_lora.py
from diffusers import DiffusionPipeline, UNet2DConditionModel
from peft import LoraConfig, get_peft_model
import torch
from torch.utils.data import Dataset
from PIL import Image
import os

# 1. åŠ è½½åŸºç¡€æ¨¡å‹
pipe = DiffusionPipeline.from_pretrained(
    "/vepfs-dev/shawn/vid/fanren/gen_video/models/flux1-dev",
    torch_dtype=torch.float16
)

# 2. é…ç½® LoRA
lora_config = LoraConfig(
    r=32,  # LoRA ç»´åº¦
    lora_alpha=16,
    target_modules=["to_k", "to_q", "to_v", "to_out.0"],  # Flux çš„æ³¨æ„åŠ›å±‚
    lora_dropout=0.1,
)

# 3. åº”ç”¨ LoRA
pipe.unet = get_peft_model(pipe.unet, lora_config)

# 4. å‡†å¤‡æ•°æ®é›†
class HostDataset(Dataset):
    def __init__(self, data_dir):
        self.images = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(('.jpg', '.png'))]
        self.prompts = ["ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡"] * len(self.images)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = Image.open(self.images[idx]).convert("RGB")
        prompt = self.prompts[idx]
        return {"image": image, "prompt": prompt}

# 5. è®­ç»ƒå¾ªç¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
dataset = HostDataset("/vepfs-dev/shawn/vid/fanren/gen_video/train_data/host_person")
# ... è®­ç»ƒä»£ç  ...

# 6. ä¿å­˜ LoRA
pipe.unet.save_pretrained("/vepfs-dev/shawn/vid/fanren/gen_video/models/lora/host_person")
```

---

## ğŸ“¦ é›†æˆåˆ° ModelManager

è®­ç»ƒå®Œæˆåï¼Œéœ€è¦æ›´æ–° `FluxPipeline` ä»¥æ”¯æŒ LoRAï¼š

### æ›´æ–° `pipelines/flux_pipeline.py`ï¼š

```python
def generate(
    self,
    prompt: str,
    negative_prompt: Optional[str] = None,
    lora_path: Optional[str] = None,  # æ–°å¢ï¼šLoRA è·¯å¾„
    lora_alpha: float = 1.0,  # æ–°å¢ï¼šLoRA æƒé‡
    **kwargs
) -> Image.Image:
    """ç”Ÿæˆå›¾åƒ"""
    if not self.loaded:
        self.load()
    
    # åŠ è½½ LoRAï¼ˆå¦‚æœæä¾›ï¼‰
    if lora_path and Path(lora_path).exists():
        self.pipe.load_lora_weights(lora_path, adapter_name="host_person")
        self.pipe.set_adapters(["host_person"], adapter_weights=[lora_alpha])
        print(f"  â„¹ å·²åŠ è½½ LoRA: {lora_path} (alpha={lora_alpha})")
    
    # ... ç”Ÿæˆä»£ç  ...
```

### æ›´æ–° `model_manager.py`ï¼š

```python
# åœ¨ ModelManager ä¸­æ·»åŠ  LoRA é…ç½®
self.lora_configs = {
    "host_face": {
        "lora_path": "/vepfs-dev/shawn/vid/fanren/gen_video/models/lora/host_person/pytorch_lora_weights.safetensors",
        "lora_alpha": 0.7
    }
}

# åœ¨ generate æ–¹æ³•ä¸­ä½¿ç”¨
if task == "host_face" and "host_face" in self.lora_configs:
    lora_cfg = self.lora_configs["host_face"]
    image = pipeline.generate(
        prompt=optimized_prompt,
        lora_path=lora_cfg["lora_path"],
        lora_alpha=lora_cfg["lora_alpha"],
        **kwargs
    )
```

---

## ğŸ¯ è®­ç»ƒæ•°æ®å‡†å¤‡å»ºè®®

### 1. **å›¾ç‰‡è¦æ±‚ï¼š**
- åˆ†è¾¨ç‡ï¼š1024x1024 æˆ–æ›´é«˜
- æ•°é‡ï¼š20-50 å¼ ï¼ˆè¶Šå¤šè¶Šå¥½ï¼‰
- è´¨é‡ï¼šæ¸…æ™°ã€æ­£é¢ã€å…‰çº¿å‡åŒ€
- å¤šæ ·æ€§ï¼šä¸åŒè§’åº¦ã€è¡¨æƒ…ã€æœè£…

### 2. **æ ‡æ³¨è¦æ±‚ï¼š**
- æ¯å¼ å›¾ç‰‡å¯¹åº”ä¸€ä¸ªæç¤ºè¯
- åŒ…å«å…³é”®ç‰¹å¾ï¼šæ€§åˆ«ã€èŒä¸šã€é£æ ¼
- ç¤ºä¾‹ï¼š`ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡ï¼Œå¾®ç¬‘ï¼Œæ­£å¼ç€è£…`

### 3. **æ•°æ®å¢å¼ºï¼ˆå¯é€‰ï¼‰ï¼š**
- æ°´å¹³ç¿»è½¬
- è½»å¾®æ—‹è½¬
- äº®åº¦è°ƒæ•´

---

## âš¡ å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èæµç¨‹ï¼‰

1. **å‡†å¤‡ 20-50 å¼ ä¸»æŒäººå›¾ç‰‡**
   - æ”¾åœ¨ `train_data/host_person/` ç›®å½•

2. **ä½¿ç”¨ Kohya_ss è®­ç»ƒ**
   - å‚è€ƒä¸Šé¢çš„é…ç½®
   - è®­ç»ƒ 500-1000 æ­¥

3. **æµ‹è¯• LoRA**
   - åŠ è½½è®­ç»ƒå¥½çš„ LoRA
   - ç”Ÿæˆæµ‹è¯•å›¾åƒ

4. **é›†æˆåˆ° ModelManager**
   - æ›´æ–° `FluxPipeline` æ”¯æŒ LoRA
   - é…ç½® `model_manager.py`

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **è¿‡æ‹Ÿåˆé—®é¢˜**
   - LoRA ç»´åº¦ä¸è¦å¤ªå¤§ï¼ˆå»ºè®® 16-32ï¼‰
   - è®­ç»ƒæ­¥æ•°ä¸è¦å¤ªå¤šï¼ˆ500-1000 æ­¥ï¼‰

2. **æ˜¾å­˜å ç”¨**
   - Flux.1 è®­ç»ƒéœ€è¦ 24GB+ æ˜¾å­˜
   - å¯ä»¥ä½¿ç”¨ `gradient_checkpointing` é™ä½æ˜¾å­˜

3. **è®­ç»ƒæ—¶é—´**
   - 20 å¼ å›¾ç‰‡ï¼Œ1000 æ­¥ï¼Œçº¦ 1-2 å°æ—¶ï¼ˆA100ï¼‰

4. **æ•ˆæœå¯¹æ¯”**
   - LoRAï¼šå›ºå®šå½¢è±¡ï¼Œçµæ´»æ§åˆ¶
   - InstantIDï¼šå¿«é€Ÿæµ‹è¯•ï¼Œä¸€å¼ å›¾å³å¯

---

## ğŸ”— å‚è€ƒèµ„æº

- [Kohya_ss å®˜æ–¹æ–‡æ¡£](https://github.com/bmaltais/kohya_ss)
- [Flux LoRA è®­ç»ƒæŒ‡å—](https://huggingface.co/docs/diffusers/training/lora)
- [PEFT æ–‡æ¡£](https://huggingface.co/docs/peft)


# ä½¿ç”¨ diffusers å®˜æ–¹ Flux LoRA è®­ç»ƒè„šæœ¬

## âœ… æ¨èæ–¹æ¡ˆï¼šä½¿ç”¨å®˜æ–¹è®­ç»ƒè„šæœ¬

diffusers å®˜æ–¹æä¾›äº†ä¸“é—¨çš„ Flux LoRA è®­ç»ƒè„šæœ¬ï¼Œå®Œå…¨å…¼å®¹ Flux DiT æ¶æ„ã€‚

---

## ğŸ“¦ å‡†å¤‡

### 1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
source /vepfs-dev/shawn/venv/py312/bin/activate
```

### 2. æ£€æŸ¥ diffusers ç‰ˆæœ¬

```bash
python -c "import diffusers; print(diffusers.__version__)"
```

**éœ€è¦ >= 0.36.0.dev0**ï¼ˆå¦‚æœç‰ˆæœ¬ä¸å¤Ÿï¼Œéœ€è¦å‡çº§ï¼‰

### 3. å®‰è£…ä¾èµ–ï¼ˆå¦‚æœéœ€è¦ï¼‰

```bash
cd diffusers/examples/dreambooth
pip install -r requirements_flux.txt
```

---

## ğŸš€ ä½¿ç”¨å®˜æ–¹è„šæœ¬è®­ç»ƒ

### æ–¹æ³• 1ï¼šç›´æ¥ä½¿ç”¨å®˜æ–¹è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /vepfs-dev/shawn/vid/fanren/gen_video
source /vepfs-dev/shawn/venv/py312/bin/activate

cd diffusers/examples/dreambooth

accelerate launch train_dreambooth_lora_flux.py \
    --pretrained_model_name_or_path=/vepfs-dev/shawn/vid/fanren/gen_video/models/flux1-dev \
    --instance_data_dir=/vepfs-dev/shawn/vid/fanren/gen_video/train_data/host_person \
    --output_dir=/vepfs-dev/shawn/vid/fanren/gen_video/models/lora/host_person \
    --instance_prompt="ç§‘æ™®ä¸»æŒäººï¼Œä¸“ä¸šå½¢è±¡" \
    --resolution=1024 \
    --train_batch_size=2 \
    --gradient_accumulation_steps=2 \
    --learning_rate=1e-4 \
    --max_train_steps=1000 \
    --lr_scheduler="cosine" \
    --lr_warmup_steps=100 \
    --use_bf16 \
    --save_steps=200
```

### æ–¹æ³• 2ï¼šä½¿ç”¨æˆ‘åˆ›å»ºçš„é€‚é…è„šæœ¬

```bash
cd /vepfs-dev/shawn/vid/fanren/gen_video
source /vepfs-dev/shawn/venv/py312/bin/activate

python train_flux_lora_final.py \
    --data-dir train_data/host_person \
    --output-dir models/lora/host_person \
    --base-model models/flux1-dev \
    --epochs 10 \
    --batch-size 2 \
    --gradient-accumulation 2 \
    --learning-rate 1e-4 \
    --lora-rank 32 \
    --lora-alpha 16 \
    --use-bf16
```

---

## âš™ï¸ H20 GPU ä¼˜åŒ–é…ç½®

### æ¨èé…ç½®ï¼ˆH20ï¼Œ97GB æ˜¾å­˜ï¼‰

```bash
train_batch_size=2          # å¯ä»¥æ›´å¤§
gradient_accumulation_steps=2
learning_rate=1e-4
use_bf16=true               # H20 æ”¯æŒ bf16ï¼Œæ€§èƒ½æ›´å¥½
use_8bit_adam=true          # èŠ‚çœæ˜¾å­˜ï¼ˆå¦‚æœå®‰è£…äº† bitsandbytesï¼‰
resolution=1024
lora_rank=32
lora_alpha=16
max_train_steps=1000
```

### å¦‚æœæ˜¾å­˜ä¸è¶³

```bash
train_batch_size=1
gradient_accumulation_steps=4
use_8bit_adam=true
```

---

## ğŸ“ è®­ç»ƒæ•°æ®æ ¼å¼

å®˜æ–¹è„šæœ¬æ”¯æŒä¸¤ç§æ•°æ®æ ¼å¼ï¼š

### æ ¼å¼ 1ï¼šImageFolderï¼ˆæ¨èï¼‰

```
train_data/host_person/
  image1.png
  image2.png
  ...
```

é…åˆ `--instance_prompt` ä½¿ç”¨ç»Ÿä¸€æç¤ºè¯ã€‚

### æ ¼å¼ 2ï¼šå¸¦æç¤ºè¯çš„æ–‡ä»¶åï¼ˆä½ çš„æ ¼å¼ï¼‰

```
train_data/host_person/
  _repeat_10_ç§‘æ™®ä¸»æŒäººï¼Œç”·æ€§ï¼Œä¸“ä¸šå½¢è±¡ï¼Œå¾®ç¬‘ï¼Œæ­£å¼ç€è£…ï¼Œæ­£é¢ï¼Œæ¼”æ’­å®¤èƒŒæ™¯.png
  ...
```

éœ€è¦ä¿®æ”¹è„šæœ¬ä»¥ä»æ–‡ä»¶åæå–æç¤ºè¯ï¼ˆæˆ–ä½¿ç”¨æˆ‘åˆ›å»ºçš„é€‚é…è„šæœ¬ï¼‰ã€‚

---

## ğŸ¯ å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | H20 æ¨èå€¼ |
|------|------|-----------|
| `train_batch_size` | æ‰¹æ¬¡å¤§å° | 2 |
| `gradient_accumulation_steps` | æ¢¯åº¦ç´¯ç§¯ | 2 |
| `learning_rate` | å­¦ä¹ ç‡ | 1e-4 |
| `lora_rank` | LoRA ç»´åº¦ | 32 |
| `lora_alpha` | LoRA alpha | 16 |
| `max_train_steps` | æœ€å¤§æ­¥æ•° | 1000 |
| `use_bf16` | ä½¿ç”¨ bf16 | true |
| `resolution` | åˆ†è¾¨ç‡ | 1024 |

---

## âœ… è®­ç»ƒå®Œæˆå

LoRA æ¨¡å‹ä¿å­˜åœ¨ï¼š
```
models/lora/host_person/pytorch_lora_weights.safetensors
```

åœ¨ `model_manager.py` ä¸­é…ç½®ï¼š
```python
self.lora_configs = {
    "host_face": {
        "lora_path": "models/lora/host_person/pytorch_lora_weights.safetensors",
        "lora_alpha": 0.7
    }
}
```

---

## ğŸ”— å‚è€ƒèµ„æº

- [å®˜æ–¹ Flux LoRA è®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#flux)
- [Flux README](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_flux.md)


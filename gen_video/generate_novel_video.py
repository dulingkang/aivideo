#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´æ¨æ–‡è§†é¢‘ç”Ÿæˆè„šæœ¬
ä½¿ç”¨ Flux ç”Ÿæˆå›¾ç‰‡ï¼Œç„¶åç”¨ HunyuanVideo ç”Ÿæˆè§†é¢‘
"""

import sys
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import yaml
import json
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from image_generator import ImageGenerator
from video_generator import VideoGenerator
from PIL import Image


class NovelVideoGenerator:
    """å°è¯´æ¨æ–‡è§†é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.config_path = Path(config_path)
        if not self.config_path.is_absolute():
            self.config_path = (project_root / self.config_path).resolve()
        
        # åŠ è½½é…ç½®
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # åˆå§‹åŒ–å›¾åƒç”Ÿæˆå™¨ï¼ˆä½¿ç”¨ Fluxï¼‰
        print("=" * 60)
        print("åˆå§‹åŒ–å›¾åƒç”Ÿæˆå™¨ï¼ˆFluxï¼‰...")
        self.image_generator = ImageGenerator(str(self.config_path))
        
        # åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆå™¨ï¼ˆä½¿ç”¨ HunyuanVideoï¼‰
        print("åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆå™¨ï¼ˆHunyuanVideoï¼‰...")
        self.video_generator = VideoGenerator(str(self.config_path))

        # M6 å¢å¼ºè§†é¢‘ç”Ÿæˆå™¨ï¼ˆæ‡’åŠ è½½ï¼šä»…åœ¨å¯ç”¨èº«ä»½éªŒè¯æ—¶åˆå§‹åŒ–ï¼‰
        self._m6_video_generator = None
        
        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹
        self._ensure_model_config()
        
        print("=" * 60)
        print("âœ… åˆå§‹åŒ–å®Œæˆ")
        print("=" * 60)

    @staticmethod
    def _infer_character_id_from_text(text: str) -> Optional[str]:
        """
        ä»æ–‡æœ¬ä¸­æ¨æ–­è§’è‰²IDï¼ˆå½“å‰åªåšâ€œéŸ©ç«‹â€è¯†åˆ«ï¼Œé¿å…è¯¯ä¼¤çº¯åœºæ™¯æ¨æ–‡ï¼‰ã€‚
        - å‘½ä¸­ â€œéŸ©ç«‹â€/â€œHan Liâ€/â€œhanliâ€ ç­‰ â†’ hanli
        """
        if not text:
            return None
        t = str(text)
        if "éŸ©ç«‹" in t:
            return "hanli"
        tl = t.lower()
        if "hanli" in tl:
            return "hanli"
        if re.search(r"\bhan\s*li\b", tl):
            return "hanli"
        return None

    def _resolve_character_and_m6(
        self,
        prompt: str,
        scene: Optional[Dict[str, Any]],
        include_character: Optional[bool],
        character_id: Optional[str],
        enable_m6_identity: Optional[bool],
        auto_character: bool,
        auto_m6_identity: bool,
        force_scene: bool,
    ) -> Tuple[bool, Optional[str], bool]:
        """
        ç»Ÿä¸€å†³ç­–ï¼š
        - æ˜¯å¦åŒ…å«éŸ©ç«‹ï¼ˆä»¥åŠè§’è‰²IDï¼‰
        - æ˜¯å¦å¯ç”¨ M6 èº«ä»½éªŒè¯
        """
        if force_scene:
            return False, None, False

        inferred_id = self._infer_character_id_from_text(prompt) if auto_character else None

        # scene ä¸­æ˜¾å¼ character.id ä¼˜å…ˆ
        if scene and isinstance(scene, dict):
            c = scene.get("character")
            if isinstance(c, dict):
                cid = c.get("id")
                if cid:
                    inferred_id = str(cid)

        effective_character_id = str(character_id) if character_id else inferred_id

        if include_character is None:
            effective_include_character = bool(effective_character_id)
        else:
            effective_include_character = bool(include_character)

        # M6 å¼€å…³ï¼šæ˜¾å¼ä¼˜å…ˆï¼›å¦åˆ™è‡ªåŠ¨ï¼ˆä»…å¯¹éŸ©ç«‹åœºæ™¯æ‰“å¼€ï¼‰
        if enable_m6_identity is None:
            effective_enable_m6 = bool(auto_m6_identity and effective_include_character and effective_character_id == "hanli")
        else:
            effective_enable_m6 = bool(enable_m6_identity and effective_include_character)

        return effective_include_character, effective_character_id, effective_enable_m6
    
    def _ensure_model_config(self):
        """ç¡®ä¿é…ç½®ä½¿ç”¨ Flux + HunyuanVideo"""
        # ä¿®æ”¹é…ç½®ï¼Œç¡®ä¿ä½¿ç”¨ Flux ç”Ÿæˆå›¾åƒ
        image_config = self.config.get('image', {})
        if image_config.get('engine') != 'flux-instantid':
            print("  âš  è­¦å‘Š: image.engine ä¸æ˜¯ flux-instantidï¼Œå»ºè®®ä¿®æ”¹é…ç½®")
        
        # ä¿®æ”¹é…ç½®ï¼Œç¡®ä¿ä½¿ç”¨ HunyuanVideo ç”Ÿæˆè§†é¢‘
        video_config = self.config.get('video', {})
        if video_config.get('model_type') != 'hunyuanvideo':
            print("  âš  è­¦å‘Š: video.model_type ä¸æ˜¯ hunyuanvideoï¼Œå»ºè®®ä¿®æ”¹é…ç½®")
            print("  â„¹ ä¸´æ—¶ä¿®æ”¹é…ç½®ä¸º hunyuanvideo")
            video_config['model_type'] = 'hunyuanvideo'
            self.video_generator.video_config['model_type'] = 'hunyuanvideo'
    
    def generate(
        self,
        prompt: str = None,
        output_dir: Optional[Path] = None,
        image_output_path: Optional[Path] = None,
        video_output_path: Optional[Path] = None,
        width: int = 1280,
        height: int = 768,
        num_frames: int = 120,
        fps: int = 24,
        scene: Optional[Dict[str, Any]] = None,
        use_v21_exec: bool = False,  # v2.1-execæ¨¡å¼å¼€å…³
        # === è§’è‰²ä¸€è‡´ï¼ˆå›¾ç‰‡ç«¯ï¼‰===
        include_character: Optional[bool] = None,
        character_id: Optional[str] = None,
        auto_character: bool = True,
        force_scene: bool = False,
        image_model_engine: Optional[str] = None,
        # === è§†é¢‘ä¸€è‡´ï¼ˆM6 èº«ä»½éªŒè¯+é‡è¯•ï¼‰===
        enable_m6_identity: Optional[bool] = None,
        auto_m6_identity: bool = True,
        reference_image_path: Optional[str] = None,
        shot_type: str = "medium",
        motion_intensity: str = "moderate",
        m6_max_retries: Optional[int] = None,
        m6_quick: bool = False,
    ) -> Dict[str, Path]:
        """
        ç”Ÿæˆå°è¯´æ¨æ–‡è§†é¢‘
        
        Args:
            prompt: æ–‡æœ¬æç¤ºè¯ï¼ˆå°è¯´åœºæ™¯æè¿°ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            image_output_path: å›¾åƒè¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            video_output_path: è§†é¢‘è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            num_frames: è§†é¢‘å¸§æ•°
            fps: è§†é¢‘å¸§ç‡
            scene: åœºæ™¯é…ç½®ï¼ˆå¯é€‰ï¼‰
            include_character: æ˜¯å¦ç”Ÿæˆå¸¦è§’è‰²çš„ç”»é¢ï¼ˆå¯ç”¨åä¼šä½¿ç”¨ç°æœ‰â€œè§’è‰²ä¸€è‡´â€ç³»ç»Ÿï¼‰
            character_id: è§’è‰²IDï¼ˆé»˜è®¤ hanliï¼‰
            auto_character: æ˜¯å¦è‡ªåŠ¨ä» prompt/scene æ¨æ–­æ˜¯å¦åŒ…å«éŸ©ç«‹ï¼ˆé»˜è®¤ Trueï¼Œä»…è¯†åˆ«éŸ©ç«‹ï¼Œé¿å…è¯¯ä¼¤çº¯åœºæ™¯ï¼‰
            force_scene: å¼ºåˆ¶æŒ‰çº¯åœºæ™¯ç”Ÿæˆï¼ˆå¿½ç•¥è‡ªåŠ¨æ¨æ–­/æ‰‹åŠ¨è§’è‰²ï¼‰
            image_model_engine: è¦†ç›–å›¾ç‰‡å¼•æ“ï¼ˆä¾‹å¦‚ auto / flux-instantid / pulid / flux1 ç­‰ï¼›ä¸ä¼ åˆ™æŒ‰æ¨¡å¼é€‰æ‹©é»˜è®¤ï¼‰
            enable_m6_identity: æ˜¯å¦å¯ç”¨ M6 èº«ä»½éªŒè¯ + é‡è¯•ï¼ˆä»…åœ¨ include_character=True æ—¶å¼ºçƒˆå»ºè®®å¼€å¯ï¼‰
            auto_m6_identity: æ˜¯å¦è‡ªåŠ¨å¯¹â€œéŸ©ç«‹åœºæ™¯â€å¯ç”¨ M6ï¼ˆé»˜è®¤ Trueï¼‰
            reference_image_path: èº«ä»½éªŒè¯å‚è€ƒå›¾ï¼ˆä¸ä¼ åˆ™è‡ªåŠ¨æŒ‰ character_id é€‰æ‹©ï¼Œæ‰¾ä¸åˆ°åˆ™ç”¨ç”Ÿæˆå›¾ï¼‰
            shot_type: é•œå¤´ç±»å‹ï¼ˆå½±å“é˜ˆå€¼å®¹å¿åº¦ï¼‰
            motion_intensity: è¿åŠ¨å¼ºåº¦ï¼ˆä¼šä¼ å…¥ sceneï¼Œä¾›ç”Ÿæˆ/é‡è¯•ç­–ç•¥å‚è€ƒï¼‰
            m6_max_retries: è¦†ç›–æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆNone=ç”¨ config.yamlï¼‰
            m6_quick: å¿«é€Ÿæ¨¡å¼ï¼ˆæ›´å°‘æ­¥æ•°/æ›´å°‘é‡è¯•ï¼Œé€‚åˆå†’çƒŸï¼‰
        
        Returns:
            dict: åŒ…å« 'image' å’Œ 'video' è·¯å¾„çš„å­—å…¸
        """
        print("=" * 60)
        print("å¼€å§‹ç”Ÿæˆå°è¯´æ¨æ–‡è§†é¢‘")
        print("=" * 60)
        
        # âš¡ v2.1-execæ¨¡å¼ï¼šå¦‚æœsceneæ˜¯v2.1-execæ ¼å¼ï¼Œä½¿ç”¨Execution Executor
        if use_v21_exec and scene and scene.get("version", "").startswith("v2.1"):
            return self._generate_v21_exec(scene, output_dir, width, height, num_frames, fps)
        
        # å…¼å®¹æ¨¡å¼ï¼šå¦‚æœsceneæ˜¯v2æ ¼å¼ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºv2.1-execï¼ˆå¯é€‰ï¼‰
        if scene and scene.get("version") == "v2" and use_v21_exec:
            print("  â„¹ æ£€æµ‹åˆ°v2æ ¼å¼ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºv2.1-exec")
            from utils.json_v2_to_v21_converter import JSONV2ToV21Converter
            converter = JSONV2ToV21Converter()
            scene = converter.convert_scene(scene)
            return self._generate_v21_exec(scene, output_dir, width, height, num_frames, fps)
        
        # åŸæœ‰æµç¨‹ï¼ˆå…¼å®¹ï¼‰
        if prompt is None:
            prompt = scene.get("prompt", {}).get("positive_core", "") if scene else ""
        
        print(f"æç¤ºè¯: {prompt}")
        print()

        # âš¡ å…³é”®ä¿®å¤ï¼šæ ¹æ®é…éŸ³æ—¶é•¿ï¼ˆduration_secï¼‰è®¡ç®—å¸§æ•°
        # å¦‚æœ scene ä¸­æœ‰ duration_secï¼Œä¼˜å…ˆä½¿ç”¨å®ƒæ¥è®¡ç®—å¸§æ•°
        if scene and isinstance(scene, dict):
            duration_sec = scene.get('duration_sec')
            if duration_sec:
                # æ ¹æ®é…éŸ³æ—¶é•¿è®¡ç®—å¸§æ•°ï¼šå¸§æ•° = æ—¶é•¿(ç§’) Ã— å¸§ç‡
                calculated_frames = int(duration_sec * fps)
                if calculated_frames != num_frames:
                    print(f"  â„¹ æ ¹æ®é…éŸ³æ—¶é•¿è°ƒæ•´å¸§æ•°: {duration_sec}ç§’ Ã— {fps}fps = {calculated_frames}å¸§ (åŸå€¼: {num_frames}å¸§)")
                    num_frames = calculated_frames
                else:
                    print(f"  â„¹ å¸§æ•°å·²åŒ¹é…é…éŸ³æ—¶é•¿: {num_frames}å¸§ = {duration_sec}ç§’ Ã— {fps}fps")

        # è‡ªåŠ¨æ¨æ–­æ˜¯å¦æœ‰éŸ©ç«‹ï¼Œå¹¶æ®æ­¤å†³å®šæ˜¯å¦å¯ç”¨ M6
        effective_include_character, effective_character_id, effective_enable_m6 = self._resolve_character_and_m6(
            prompt=prompt,
            scene=scene,
            include_character=include_character,
            character_id=character_id,
            enable_m6_identity=enable_m6_identity,
            auto_character=auto_character,
            auto_m6_identity=auto_m6_identity,
            force_scene=force_scene,
        )
        if effective_character_id:
            print(f"  â„¹ è§’è‰²æ¨æ–­: character_id={effective_character_id}, include_character={effective_include_character}")
        else:
            print(f"  â„¹ è§’è‰²æ¨æ–­: æ— éŸ©ç«‹ï¼ˆæŒ‰çº¯åœºæ™¯ç”Ÿæˆï¼‰")
        print(f"  â„¹ M6 èº«ä»½éªŒè¯: {'å¯ç”¨' if effective_enable_m6 else 'å…³é—­'}")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = project_root / "outputs" / "novel_videos"
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ­¥éª¤1: ä½¿ç”¨ Flux ç”Ÿæˆå›¾åƒ
        print("=" * 60)
        print("æ­¥éª¤1: ä½¿ç”¨ Flux ç”Ÿæˆå›¾åƒ")
        print("=" * 60)
        
        if image_output_path is None:
            image_output_path = output_dir / "novel_image.png"
        
        try:
            # æ„å»ºsceneå­—å…¸ï¼ˆåŒ…å«widthå’Œheightï¼‰
            image_scene = scene.copy() if scene else {}
            image_scene['width'] = width
            image_scene['height'] = height
            
            # è§’è‰²æ¨¡å¼ï¼šè®© ImageGenerator/EnhancedImageGenerator æ¥ç®¡â€œè§’è‰²ä¸€è‡´â€
            if effective_include_character:
                # ç»™ä¸‹æ¸¸ä¸€ä¸ªæ˜ç¡®çš„è§’è‰²ä¿¡å·ï¼ˆImageGenerator å†…éƒ¨ä¼šè¯†åˆ« character.idï¼‰
                image_scene.setdefault("character", {})
                if isinstance(image_scene.get("character"), dict):
                    if effective_character_id:
                        image_scene["character"].setdefault("id", effective_character_id)
                # è¿åŠ¨å¼ºåº¦ä¹Ÿå†™å…¥ï¼ˆPrompt Engine / ç”Ÿæˆå™¨å¯æŒ‰éœ€ä½¿ç”¨ï¼‰
                image_scene.setdefault("motion_intensity", motion_intensity)
            
            # ç”Ÿæˆå›¾åƒï¼š
            # - é»˜è®¤ï¼ˆinclude_character=Falseï¼‰ï¼šèµ°â€œåœºæ™¯å›¾â€é€»è¾‘ï¼ˆæ— äººç‰©ï¼‰
            # - è§’è‰²æ¨¡å¼ï¼ˆinclude_character=Trueï¼‰ï¼šèµ°â€œè§’è‰²ä¸€è‡´â€é€»è¾‘ï¼ˆäººç‰©+åœºæ™¯ï¼‰
            print(f"  [DEBUG] åŸå§‹prompt: {prompt}")
            print(f"  [DEBUG] scene: {image_scene}")
            if effective_include_character:
                print(f"  [DEBUG] character_id: {effective_character_id}")
            
            # ä½¿ç”¨ Prompt Engine V2 ä¼˜åŒ–æç¤ºè¯ï¼ˆå®Œå…¨æœ¬åœ°æ¨¡å¼ï¼Œæ— éœ€LLM APIï¼‰
            print(f"  ğŸ”§ å¼€å§‹ä¼˜åŒ–æç¤ºè¯ï¼ˆä½¿ç”¨ Prompt Engine V2 æœ¬åœ°æ¨¡å¼ï¼‰...")
            original_prompt = prompt
            negative_prompt = None
            optimized_prompt = None
            
            try:
                from utils.prompt_engine_v2 import PromptEngine, UserRequest
                
                # åˆ›å»º Prompt Engine V2ï¼ˆé»˜è®¤æœ¬åœ°æ¨¡å¼ï¼Œæ— éœ€LLM APIï¼‰
                prompt_engine_v2 = PromptEngine()
                
                # åˆ›å»ºç”¨æˆ·è¯·æ±‚ï¼ˆå›¾åƒç”Ÿæˆé˜¶æ®µï¼‰
                req = UserRequest(
                    text=original_prompt,
                    scene_type="novel",  # å°è¯´æ¨æ–‡åœºæ™¯
                    style="novel",  # ä½¿ç”¨novelé£æ ¼æ¨¡æ¿
                    target_model="flux",  # å›¾åƒç”Ÿæˆä½¿ç”¨Flux
                    params={"width": width, "height": height}
                )
                
                # æ‰§è¡Œå¤„ç†
                pkg = prompt_engine_v2.run(req)
                
                # è·å–ä¼˜åŒ–åçš„promptå’Œnegative prompt
                optimized_prompt = pkg.final_prompt
                negative_prompt = pkg.negative
                
                # âš¡ å·¥ç¨‹çº§ä¼˜åŒ–ï¼šç§»é™¤ HF token ç»Ÿè®¡ï¼ˆLLM å·²è¿”å›æ­£ç¡®æ•°é‡ï¼Œä¸”å¯èƒ½é˜»å¡ï¼‰
                # å¦‚æœç¡®å®éœ€è¦ token ç»Ÿè®¡ï¼Œå¯ä»¥ä½¿ç”¨ LLM è¿”å›çš„ä¿¡æ¯æˆ–ç®€å•ä¼°ç®—
                # ä¸å†ä½¿ç”¨ T5Tokenizerï¼ˆå¯èƒ½é˜»å¡æˆ–åŠ è½½æ…¢ï¼‰
                
                # æ·»åŠ åœºæ™¯å¼ºåŒ–å…³é”®è¯ï¼ˆç¡®ä¿æ˜¯åœºæ™¯è€Œéäººç‰©ï¼‰
                # è§’è‰²æ¨¡å¼ä¸‹ä¸è¦åŠ  no people
                scene_enhancers = "landscape, nature" if effective_include_character else "landscape, nature, no people"
                optimized_prompt = f"{optimized_prompt}, {scene_enhancers}"
                
                # å¢å¼ºè´Ÿé¢æç¤ºè¯ï¼ˆç¡®ä¿æ’é™¤äººç‰©ï¼‰
                if not effective_include_character:
                    additional_negatives = [
                        "faces, portraits, black faces, dark faces, human faces, person faces, character faces",
                        "people in image, humans in scene, any people, any persons, any characters, any human figures",
                    ]
                    negative_prompt = f"{negative_prompt}, {', '.join(additional_negatives)}"
                
                # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœåŒ…å«è§’è‰²ï¼Œå¼ºåˆ¶æ·»åŠ è§’è‰²æè¿°ï¼ˆç‰¹åˆ«æ˜¯æœé¥°æè¿°å’Œæ€§åˆ«ï¼‰ï¼Œç¡®ä¿ä¸è¢«ä¼˜åŒ–æ‰
                if effective_include_character and effective_character_id:
                    try:
                        # âš¡ ä¿®å¤ï¼šä¸è¦åœ¨è¿™é‡Œé‡æ–°å¯¼å…¥ Pathï¼Œä½¿ç”¨æ–‡ä»¶é¡¶éƒ¨å·²å¯¼å…¥çš„ Path
                        # from pathlib import Path  # åˆ é™¤è¿™è¡Œï¼Œå› ä¸ºæ–‡ä»¶é¡¶éƒ¨å·²ç»å¯¼å…¥äº†
                        # è¯»å–è§’è‰²æ¡£æ¡ˆ
                        profile_path = Path(__file__).parent / "character_profiles.yaml"
                        if profile_path.exists():
                            with open(profile_path, 'r', encoding='utf-8') as f:
                                profiles = yaml.safe_load(f) or {}
                            character_profile = profiles.get("characters", {}).get(effective_character_id, {})
                            
                            if character_profile:
                                # æ„å»ºè§’è‰²æè¿°ï¼ˆç‰¹åˆ«æ˜¯æœé¥°æè¿°å’Œæ€§åˆ«ï¼‰
                                character_parts = []
                                
                                # âš¡ å…³é”®ä¿®å¤ï¼šæ·»åŠ æ€§åˆ«æè¿°ï¼ˆä» identity å­—æ®µæå–ï¼‰
                                # âš¡ æ³¨æ„ï¼šFlux ä½¿ç”¨ T5 ç¼–ç å™¨ï¼Œä¸æ”¯æŒæƒé‡è¯­æ³• (xxx:1.5)
                                # ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€šè¿‡é‡å¤å’Œä½ç½®æ¥å¼ºè°ƒé‡è¦æ€§
                                identity = character_profile.get("identity", "")
                                if identity:
                                    # æå–æ€§åˆ«ï¼ˆMale/Femaleï¼‰
                                    identity_lower = identity.lower()
                                    if "male" in identity_lower:
                                        character_parts.append("Male, male character, male person")  # é€šè¿‡é‡å¤å¼ºè°ƒ
                                    elif "female" in identity_lower:
                                        character_parts.append("Female, female character, female person")
                
                                # æœé¥°æè¿°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç¡®ä¿ä¸è¢«ä¼˜åŒ–æ‰ï¼‰
                                # âš¡ æ³¨æ„ï¼šcharacter_profiles.yaml ä¸­çš„ prompt_keywords å¯èƒ½åŒ…å«æƒé‡è¯­æ³•
                                # éœ€è¦ç§»é™¤æƒé‡è¯­æ³•ï¼Œåªä¿ç•™æè¿°å†…å®¹
                                clothes = character_profile.get("clothes", {})
                                clothes_keywords = clothes.get("prompt_keywords", "")
                                if clothes_keywords:
                                    # ç§»é™¤æƒé‡è¯­æ³• (xxx:1.5)ï¼Œåªä¿ç•™æè¿°å†…å®¹
                                    import re
                                    clothes_clean = re.sub(r'\(([^:]+):[\d.]+\)', r'\1', clothes_keywords)
                                    clothes_clean = re.sub(r'\(([^)]+)\)', r'\1', clothes_clean)  # ç§»é™¤æ™®é€šæ‹¬å·
                                    character_parts.append(clothes_clean)
                                
                                # å‘å‹æè¿°
                                hair = character_profile.get("hair", {})
                                hair_keywords = hair.get("prompt_keywords", "")
                                if hair_keywords:
                                    # ç§»é™¤æƒé‡è¯­æ³•
                                    import re
                                    hair_clean = re.sub(r'\(([^:]+):[\d.]+\)', r'\1', hair_keywords)
                                    hair_clean = re.sub(r'\(([^)]+)\)', r'\1', hair_clean)
                                    character_parts.append(hair_clean)
                                
                                # å¦‚æœæ„å»ºäº†è§’è‰²æè¿°ï¼Œæ·»åŠ åˆ° prompt æœ€å‰é¢ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                                if character_parts:
                                    # âš¡ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å»é‡å·¥å…·ï¼Œé¿å…è§’è‰²æè¿°ä¸ prompt é‡å¤
                                    try:
                                        from utils.prompt_deduplicator import filter_duplicates, merge_prompt_parts
                                        
                                        # æ£€æŸ¥è§’è‰²æè¿°æ˜¯å¦ä¸ prompt é‡å¤
                                        filtered_character_parts = filter_duplicates(
                                            new_descriptions=character_parts,
                                            existing_texts=[optimized_prompt],
                                            threshold=0.5  # 50% é‡å è®¤ä¸ºæ˜¯é‡å¤ï¼ˆè§’è‰²æè¿°æ›´ä¸¥æ ¼ï¼‰
                                        )
                                        
                                        if filtered_character_parts:
                                            # åˆå¹¶è§’è‰²æè¿°å’Œ prompt
                                            all_parts = filtered_character_parts + [optimized_prompt]
                                            optimized_prompt = merge_prompt_parts(all_parts)
                                            print(f"  âœ“ å·²æ·»åŠ è§’è‰²æè¿°ï¼ˆæ€§åˆ«+æœé¥°+å‘å‹ï¼‰åˆ° prompt æœ€å‰é¢ï¼Œå·²å»é‡")
                                        else:
                                            print(f"  â„¹ è§’è‰²æè¿°ä¸ prompt é‡å¤ï¼Œå·²è·³è¿‡")
                                    except ImportError:
                                        # å¦‚æœå»é‡å·¥å…·ä¸å¯ç”¨ï¼Œç›´æ¥åˆå¹¶
                                        character_desc = ", ".join(character_parts)
                                        optimized_prompt = f"{character_desc}, {optimized_prompt}"
                                        print(f"  âœ“ å·²å¼ºåˆ¶æ·»åŠ è§’è‰²æè¿°ï¼ˆæ€§åˆ«+æœé¥°+å‘å‹ï¼‰åˆ° prompt æœ€å‰é¢ï¼Œç¡®ä¿ä¸è¢«ä¼˜åŒ–æ‰")
                    except Exception as e:
                        print(f"  âš  æ·»åŠ è§’è‰²æè¿°æ—¶å‡ºé”™: {e}")
                
                # âš¡ å…³é”®ä¿®å¤ï¼šåœºæ™¯å¢å¼ºæè¿°ç”± ExecutionPlannerV3 çš„åœºæ™¯åˆ†æå™¨ç»Ÿä¸€å¤„ç†
                # è¿™é‡Œä¸å†é‡å¤æ·»åŠ ï¼Œé¿å… prompt é‡å¤
                # ExecutionPlannerV3 ä¼šä½¿ç”¨åœºæ™¯åˆ†æå™¨è¿›è¡Œæ›´æ™ºèƒ½çš„åˆ†æï¼Œå¹¶è‡ªåŠ¨æ·»åŠ å¢å¼ºæè¿°
                
                print(f"  âœ“ Prompt Engine V2 å¤„ç†å®Œæˆ")
                print(f"  â„¹ åŸå§‹æç¤ºè¯: {original_prompt[:80]}...")
                print(f"  â„¹ ä¼˜åŒ–åæç¤ºè¯: {optimized_prompt[:100]}...")
                print(f"  â„¹ QAè¯„åˆ†: {pkg.metadata.get('qa_score', 0)}/{pkg.metadata.get('qa_max_score', 0)}")
                
            except Exception as e:
                print(f"  âš  Prompt Engine V2 å¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                import traceback
                traceback.print_exc()
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹æç¤ºè¯+åœºæ™¯å¼ºåŒ–
                # âš¡ ä¿®å¤ï¼šFlux ä½¿ç”¨ T5ï¼Œæ”¯æŒ 512 tokensï¼Œä¸éœ€è¦ 77 token é™åˆ¶
                scene_enhancers = "landscape, nature" if effective_include_character else "landscape, nature, no people"
                optimized_prompt = f"{original_prompt}, {scene_enhancers}"
                
                # âš¡ å·¥ç¨‹çº§ä¼˜åŒ–ï¼šç§»é™¤ HF token ç»Ÿè®¡ï¼ˆLLM å·²è¿”å›æ­£ç¡®æ•°é‡ï¼Œä¸”å¯èƒ½é˜»å¡ï¼‰
                # ä¸å†ä½¿ç”¨ T5Tokenizerï¼ˆå¯èƒ½é˜»å¡æˆ–åŠ è½½æ…¢ï¼‰
                # å¦‚æœéœ€è¦ token ç»Ÿè®¡ï¼Œå¯ä»¥ä½¿ç”¨ç®€å•ä¼°ç®—æˆ– LLM è¿”å›çš„ä¿¡æ¯
                if effective_include_character:
                    # âš¡ å…³é”®ä¿®å¤ï¼šå¢å¼ºè´Ÿé¢æç¤ºè¯ï¼Œç‰¹åˆ«æ˜¯æ’é™¤"ç«™ç«‹"ã€"ç›´ç«‹"ç­‰å§¿æ€
                    # æ£€æŸ¥åœºæ™¯åˆ†æç»“æœï¼Œå¦‚æœæ˜¯"lying"åŠ¨ä½œï¼Œæ·»åŠ æ›´å¼ºçš„è´Ÿé¢æç¤º
                    # âš¡ å…³é”®ä¿®å¤ï¼šæ’é™¤è€³å ã€é¥°å“ç­‰ä¸éœ€è¦çš„è£…é¥°
                    negative_prompt = "low quality, blurry, distorted, deformed, bad anatomy, bad hands, text, watermark, flickering, jittery, unstable, abrupt changes, worst quality, unrealistic details, earrings, earring, jewelry, accessories, decorative ornaments, decorative items, unnecessary decorations"
                    
                    # âš¡ å…³é”®ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨ LLM è¿”å›çš„å§¿æ€è´Ÿé¢æç¤ºè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    # å¦‚æœ LLM å·²ç»è¿”å›äº†ç²¾ç¡®çš„å§¿æ€è´Ÿé¢æç¤ºè¯ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦å†æ¬¡è°ƒç”¨ PostureController
                    try:
                        # å°è¯•ä»åœºæ™¯åˆ†æç»“æœä¸­è·å–å§¿æ€è´Ÿé¢æç¤ºè¯
                        from utils.scene_analyzer import analyze_scene
                        prompt_engine_config = self.config.get("prompt_engine", {})
                        use_llm = prompt_engine_config.get("scene_analyzer_mode", "local") in ["llm", "hybrid"]
                        
                        if use_llm:
                            llm_client = None
                            try:
                                llm_api_config = prompt_engine_config.get("llm_api", {})
                                if llm_api_config.get("api_key"):
                                    from utils.scene_analyzer import OpenAILLMClient
                                    llm_client = OpenAILLMClient(
                                        api_key=llm_api_config.get("api_key"),
                                        model=llm_api_config.get("model", "gpt-4o-mini"),
                                        base_url=llm_api_config.get("base_url")
                                    )
                            except Exception as e:
                                print(f"  âš  LLM å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å¼")
                                use_llm = False
                            
                            analysis_result = analyze_scene(
                                prompt=original_prompt,
                                current_shot_type=scene.get('shot_type', 'medium') if scene else 'medium',
                                use_llm=use_llm,
                                llm_client=llm_client
                            )
                            
                            if analysis_result and analysis_result.posture_negative:
                                # LLM å·²ç»è¿”å›äº†ç²¾ç¡®çš„å§¿æ€è´Ÿé¢æç¤ºè¯ï¼Œç›´æ¥ä½¿ç”¨
                                negative_prompt = f"{analysis_result.posture_negative}, {negative_prompt}"
                                print(f"  âœ“ LLM å·²è¿”å›å§¿æ€è´Ÿé¢æç¤ºè¯: {analysis_result.posture_type}")
                        else:
                            # ä½¿ç”¨ PostureController ä½œä¸ºå›é€€
                            from utils.posture_controller import PostureController
                            posture_controller = PostureController()
                            
                            # æ£€æµ‹å§¿æ€
                            posture = posture_controller.detect_posture(original_prompt)
                            if posture:
                                posture_prompt = posture_controller.get_posture_prompt(posture, use_chinese=False)
                                if posture_prompt["negative"]:
                                    # æ·»åŠ å§¿æ€ç›¸å…³çš„è´Ÿé¢æç¤ºè¯
                                    negative_prompt = f"{posture_prompt['negative']}, {negative_prompt}"
                                    print(f"  âœ“ PostureController æ£€æµ‹åˆ°å§¿æ€: {posture}ï¼Œå·²æ·»åŠ å§¿æ€è´Ÿé¢æç¤ºè¯")
                    except ImportError:
                        # å›é€€åˆ°åŸæœ‰é€»è¾‘
                        try:
                            from utils.scene_analyzer import analyze_scene
                            # âš¡ å…³é”®ä¿®å¤ï¼šè¯»å–é…ç½®ï¼Œå†³å®šæ˜¯å¦ä½¿ç”¨ LLM
                            prompt_engine_config = self.config.get("prompt_engine", {})
                            use_llm = prompt_engine_config.get("scene_analyzer_mode", "local") in ["llm", "hybrid"]
                            
                            # å¦‚æœä½¿ç”¨ LLMï¼Œéœ€è¦åˆ›å»º LLM å®¢æˆ·ç«¯
                            llm_client = None
                            if use_llm:
                                try:
                                    llm_api_config = prompt_engine_config.get("llm_api", {})
                                    if llm_api_config.get("api_key"):
                                        from utils.scene_analyzer import OpenAILLMClient
                                        llm_client = OpenAILLMClient(
                                            api_key=llm_api_config.get("api_key"),
                                            model=llm_api_config.get("model", "gpt-4o-mini"),
                                            base_url=llm_api_config.get("base_url")
                                        )
                                except Exception as e:
                                    print(f"  âš  LLM å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å¼")
                                    use_llm = False
                            
                            analysis_result = analyze_scene(
                                prompt=original_prompt,
                                current_shot_type=scene.get('shot_type', 'medium') if scene else 'medium',
                                use_llm=use_llm,
                                llm_client=llm_client
                            )
                            if analysis_result and analysis_result.action_type == "lying":
                                # âš¡ å…³é”®ä¿®å¤ï¼šå¢å¼ºè´Ÿé¢æç¤ºè¯ï¼Œå¼ºçƒˆæ’é™¤ç«™ç«‹å’Œç›´ç«‹å§¿æ€
                                # æ³¨æ„ï¼šFlux å¯¹è´Ÿé¢æè¿°ä¸å¤Ÿæ•æ„Ÿï¼Œä¸»è¦ä¾èµ–æ­£é¢æè¿°ï¼ˆåœ¨ prompt ä¸­å¼ºè°ƒ"èººä¸‹"ï¼‰
                                # è´Ÿé¢æç¤ºè¯åªä½œä¸ºè¾…åŠ©ï¼Œä¸è¦æ·»åŠ å¤ªå¤š"ä¸è¦xx"ï¼Œé¿å… prompt è¿‡é•¿
                                negative_prompt = "standing, upright, vertical position, person standing, person upright, standing pose, upright pose, vertical pose, " + negative_prompt
                                print(f"  âœ“ æ£€æµ‹åˆ°'lying'åŠ¨ä½œï¼Œå·²å¢å¼ºè´Ÿé¢æç¤ºè¯ï¼ˆæ’é™¤ç«™ç«‹ï¼‰")
                        except Exception as e:
                            # å¦‚æœåœºæ™¯åˆ†æå¤±è´¥ï¼Œå¿½ç•¥
                            print(f"  âš  åœºæ™¯åˆ†æå¤±è´¥: {e}")
                            pass
                else:
                    # éè§’è‰²æ¨¡å¼ï¼šä½¿ç”¨çº¯åœºæ™¯çš„è´Ÿé¢æç¤ºè¯
                    # âš¡ å…³é”®ä¿®å¤ï¼šä¸è¦æ’é™¤ anime/cartoon é£æ ¼ï¼ˆå› ä¸º quality_target.style å¯èƒ½æ˜¯ xianxia_animeï¼‰
                    # åªæ’é™¤äººç‰©ï¼Œä¿ç•™é£æ ¼çµæ´»æ€§
                    negative_prompt = "characters, people, persons, human figures, faces, portraits, black faces, dark faces, human faces, person faces, character faces, people in image, humans in scene, any people, any persons, any characters, any human figures, low quality, blurry, distorted, deformed, bad anatomy, bad hands, text, watermark, worst quality, distorted proportions, unrealistic details"
            
            print(f"  âœ… æç¤ºè¯ä¼˜åŒ–å®Œæˆ:")
            print(f"     åŸå§‹: {original_prompt}")
            print(f"     ä¼˜åŒ–å: {optimized_prompt[:150]}...")
            print(f"     è´Ÿé¢æç¤ºè¯: {negative_prompt[:150]}...")
            
            prompt = optimized_prompt
            negative_prompt = negative_prompt
            
            # éè§’è‰²æ¨¡å¼ï¼šç¡®ä¿ scene ä¸­ä¸åŒ…å«è§’è‰²ä¿¡æ¯ï¼Œé¿å…è¯¯è¯†åˆ«ä¸ºäººç‰©ç”Ÿæˆ
            if (not effective_include_character) and image_scene:
                image_scene.pop('character', None)
                image_scene.pop('characters', None)
                image_scene.pop('primary_character', None)
                image_scene.pop('face_reference_image_path', None)
                image_scene.pop('reference_image_path', None)
                print(f"  [DEBUG] å·²æ¸…ç†sceneä¸­çš„è§’è‰²ç›¸å…³å­—æ®µï¼Œç¡®ä¿ç”Ÿæˆåœºæ™¯å›¾åƒ")

            # é€‰æ‹©å›¾ç‰‡å¼•æ“/ä»»åŠ¡ç±»å‹
            if image_model_engine is None:
                # é»˜è®¤ç­–ç•¥ï¼šåœºæ™¯=flux1ï¼›è§’è‰²=autoï¼ˆèµ°ä½ ç°æœ‰"è§’è‰²ä¸€è‡´"è·¯ç”±ï¼‰
                image_model_engine = "auto" if effective_include_character else "flux1"
            image_task_type = "character" if effective_include_character else "scene"
            
            # âš¡ å…³é”®ä¿®å¤ï¼šä¸ºè§’è‰²æ¨¡å¼æŸ¥æ‰¾å¹¶ä¼ é€’å‚è€ƒå›¾è·¯å¾„
            face_ref_path = None
            if effective_include_character and effective_character_id:
                # ä¼˜å…ˆçº§ 1ï¼šç”¨æˆ·æ˜¾å¼æŒ‡å®šçš„å‚è€ƒå›¾
                if reference_image_path:
                    ref_p = Path(reference_image_path)
                    if not ref_p.is_absolute():
                        ref_p = (project_root / ref_p).resolve()
                    if ref_p.exists():
                        face_ref_path = ref_p
                        print(f"  âœ“ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å‚è€ƒå›¾: {face_ref_path.name}")
                
                # ä¼˜å…ˆçº§ 2ï¼šè‡ªåŠ¨æŸ¥æ‰¾ reference_image/{character_id}_mid.jpg
                if face_ref_path is None:
                    candidate = (project_root / "reference_image" / f"{effective_character_id}_mid.jpg").resolve()
                    if candidate.exists():
                        face_ref_path = candidate
                        print(f"  âœ“ è‡ªåŠ¨æ‰¾åˆ°å‚è€ƒå›¾: {face_ref_path.name}")
                    else:
                        # å°è¯• .png
                        candidate = (project_root / "reference_image" / f"{effective_character_id}_mid.png").resolve()
                        if candidate.exists():
                            face_ref_path = candidate
                            print(f"  âœ“ è‡ªåŠ¨æ‰¾åˆ°å‚è€ƒå›¾: {face_ref_path.name}")
                
                # ä¼˜å…ˆçº§ 3ï¼šä½¿ç”¨ ImageGenerator çš„è‡ªåŠ¨æŸ¥æ‰¾é€»è¾‘ï¼ˆé€šè¿‡ scene ä¸­çš„ character_idï¼‰
                # è¿™ä¼šåœ¨ image_generator.generate_image å†…éƒ¨è°ƒç”¨ _select_face_reference_image
                if face_ref_path is None:
                    print(f"  âš  æœªæ‰¾åˆ°æ˜¾å¼å‚è€ƒå›¾ï¼Œå°†ä½¿ç”¨ ImageGenerator çš„è‡ªåŠ¨æŸ¥æ‰¾é€»è¾‘")
            
            image_path = self.image_generator.generate_image(
                prompt=prompt,
                output_path=image_output_path,
                scene=image_scene,
                model_engine=image_model_engine,
                task_type=image_task_type,
                negative_prompt=negative_prompt,  # ä½¿ç”¨ä¼˜åŒ–åçš„è´Ÿé¢æç¤ºè¯
                face_reference_image_path=face_ref_path,  # âš¡ å…³é”®ä¿®å¤ï¼šä¼ é€’å‚è€ƒå›¾è·¯å¾„
            )
            print(f"âœ… å›¾åƒç”ŸæˆæˆåŠŸ: {image_path}")
            
            # è¯»å–ç”Ÿæˆå›¾åƒçš„å®é™…åˆ†è¾¨ç‡ï¼Œç¡®ä¿è§†é¢‘ä½¿ç”¨ç›¸åŒçš„åˆ†è¾¨ç‡
            from PIL import Image as PILImage
            generated_image = PILImage.open(image_path)
            actual_image_width, actual_image_height = generated_image.size
            image_aspect_ratio = actual_image_width / actual_image_height
            print(f"  â„¹ ç”Ÿæˆå›¾åƒå®é™…åˆ†è¾¨ç‡: {actual_image_width}x{actual_image_height} (å®½é«˜æ¯”: {image_aspect_ratio:.2f})")
            
            # æ›´æ–°widthå’Œheightä¸ºå›¾åƒçš„å®é™…åˆ†è¾¨ç‡
            width = actual_image_width
            height = actual_image_height
        except Exception as e:
            print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        # æ¸…ç†å›¾åƒç”Ÿæˆå™¨çš„æ¨¡å‹å’Œæ˜¾å­˜ï¼Œä¸ºè§†é¢‘ç”Ÿæˆé‡Šæ”¾æ˜¾å­˜
        print()
        print("=" * 60)
        print("æ¸…ç†å›¾åƒç”Ÿæˆå™¨æ¨¡å‹ï¼Œé‡Šæ”¾æ˜¾å­˜")
        print("=" * 60)
        try:
            import torch
            import gc
            
            # è®°å½•æ¸…ç†å‰çš„æ˜¾å­˜çŠ¶æ€
            if torch.cuda.is_available():
                allocated_before = torch.cuda.memory_allocated() / 1024**3
                reserved_before = torch.cuda.memory_reserved() / 1024**3
                print(f"  â„¹ æ¸…ç†å‰æ˜¾å­˜: å·²åˆ†é…={allocated_before:.2f}GB, å·²ä¿ç•™={reserved_before:.2f}GB")
            
            # æ¸…ç†æ‰€æœ‰å¯èƒ½çš„pipelineå¼•ç”¨ï¼ˆå…ˆè°ƒç”¨unloadï¼Œå†åˆ é™¤å¼•ç”¨ï¼‰
            pipelines_to_clean = [
                'pipeline',
                'flux_pipeline',
                'flux1_pipeline',  # Flux.1 pipeline
                'flux2_pipeline',  # Flux.2 pipeline
                'sdxl_pipeline',
                'instantid_pipeline',
                'kolors_pipeline',
                'hunyuan_dit_pipeline',
            ]
            
            for pipeline_name in pipelines_to_clean:
                if hasattr(self.image_generator, pipeline_name):
                    pipeline = getattr(self.image_generator, pipeline_name)
                    if pipeline is not None:
                        try:
                            # å…ˆå°è¯•è°ƒç”¨unloadæ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            if hasattr(pipeline, 'unload'):
                                pipeline.unload()
                                print(f"  âœ“ å·²å¸è½½ {pipeline_name} (é€šè¿‡unloadæ–¹æ³•)")
                            elif hasattr(pipeline, 'pipe'):
                                # å¦‚æœæ˜¯diffusers pipelineï¼Œæ‰‹åŠ¨ç§»åŠ¨åˆ°CPUå¹¶åˆ é™¤
                                pipe = pipeline.pipe
                                try:
                                    # ç§»åŠ¨åˆ°CPU
                                    if hasattr(pipe, 'to'):
                                        pipe.to('cpu')
                                    # åˆ é™¤æ‰€æœ‰ç»„ä»¶
                                    components = ['transformer', 'vae', 'text_encoder', 'text_encoder_2', 'tokenizer', 'tokenizer_2']
                                    for comp_name in components:
                                        if hasattr(pipe, comp_name):
                                            comp = getattr(pipe, comp_name)
                                            if comp is not None:
                                                try:
                                                    if hasattr(comp, 'to'):
                                                        comp.to('cpu')
                                                    del comp
                                                except:
                                                    pass
                                    # åˆ é™¤pipe
                                    del pipe
                                    print(f"  âœ“ å·²å¸è½½ {pipeline_name} (æ‰‹åŠ¨æ¸…ç†diffusers pipeline)")
                                except Exception as e:
                                    print(f"  âš  æ‰‹åŠ¨æ¸…ç† {pipeline_name} æ—¶å‡ºé”™: {e}")
                        except Exception as e:
                            print(f"  âš  å¸è½½ {pipeline_name} æ—¶å‡ºé”™: {e}")
                        finally:
                            # åˆ é™¤å¼•ç”¨
                            try:
                                delattr(self.image_generator, pipeline_name)
                                setattr(self.image_generator, pipeline_name, None)
                            except:
                                pass
            
            # âš¡ å…³é”®ä¿®å¤ï¼šæ¸…ç† EnhancedImageGenerator çš„ PuLID å¼•æ“å’Œèåˆå¼•æ“
            # å…ˆæ£€æŸ¥ enhanced_generatorï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(self.image_generator, 'enhanced_generator') and self.image_generator.enhanced_generator is not None:
                try:
                    # æ¸…ç† enhanced_generator çš„ PuLID å¼•æ“
                    if hasattr(self.image_generator.enhanced_generator, 'pulid_engine') and self.image_generator.enhanced_generator.pulid_engine is not None:
                        try:
                            self.image_generator.enhanced_generator.pulid_engine.unload()
                            self.image_generator.enhanced_generator.pulid_engine = None
                            print("  âœ“ å·²å¸è½½ enhanced_generator çš„ PuLID å¼•æ“")
                        except Exception as e:
                            print(f"  âš  å¸è½½ enhanced_generator PuLID å¼•æ“æ—¶å‡ºé”™: {e}")
                    
                    # æ¸…ç† enhanced_generator çš„èåˆå¼•æ“
                    if hasattr(self.image_generator.enhanced_generator, 'fusion_engine') and self.image_generator.enhanced_generator.fusion_engine is not None:
                        try:
                            if hasattr(self.image_generator.enhanced_generator.fusion_engine, 'unload'):
                                self.image_generator.enhanced_generator.fusion_engine.unload()
                            self.image_generator.enhanced_generator.fusion_engine = None
                            print("  âœ“ å·²å¸è½½ enhanced_generator çš„èåˆå¼•æ“")
                        except Exception as e:
                            print(f"  âš  å¸è½½ enhanced_generator èåˆå¼•æ“æ—¶å‡ºé”™: {e}")
                    
                    # æ¸…ç† enhanced_generator çš„ flux_pipeline
                    if hasattr(self.image_generator.enhanced_generator, 'flux_pipeline') and self.image_generator.enhanced_generator.flux_pipeline is not None:
                        try:
                            if hasattr(self.image_generator.enhanced_generator.flux_pipeline, 'unload'):
                                self.image_generator.enhanced_generator.flux_pipeline.unload()
                            del self.image_generator.enhanced_generator.flux_pipeline
                            self.image_generator.enhanced_generator.flux_pipeline = None
                            print("  âœ“ å·²å¸è½½ enhanced_generator çš„ flux_pipeline")
                        except Exception as e:
                            print(f"  âš  å¸è½½ enhanced_generator flux_pipeline æ—¶å‡ºé”™: {e}")
                    
                    # è°ƒç”¨ enhanced_generator çš„ unload_all
                    if hasattr(self.image_generator.enhanced_generator, 'unload_all'):
                        try:
                            self.image_generator.enhanced_generator.unload_all()
                            print("  âœ“ å·²è°ƒç”¨ enhanced_generator.unload_all()")
                        except Exception as e:
                            print(f"  âš  è°ƒç”¨ enhanced_generator.unload_all æ—¶å‡ºé”™: {e}")
                    
                    # âš¡ å…³é”®ä¿®å¤ï¼šåˆ é™¤ enhanced_generator å¯¹è±¡æœ¬èº«ï¼Œç¡®ä¿æ‰€æœ‰å¼•ç”¨éƒ½è¢«æ¸…ç†
                    try:
                        del self.image_generator.enhanced_generator
                        self.image_generator.enhanced_generator = None
                        print("  âœ“ å·²åˆ é™¤ enhanced_generator å¯¹è±¡")
                    except Exception as e:
                        print(f"  âš  åˆ é™¤ enhanced_generator å¯¹è±¡æ—¶å‡ºé”™: {e}")
                except Exception as e:
                    print(f"  âš  æ¸…ç† enhanced_generator æ—¶å‡ºé”™: {e}")
            
            # æ¸…ç† ImageGenerator è‡ªå·±çš„ PuLID å¼•æ“å’Œèåˆå¼•æ“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(self.image_generator, 'pulid_engine') and self.image_generator.pulid_engine is not None:
                try:
                    self.image_generator.pulid_engine.unload()
                    self.image_generator.pulid_engine = None
                    print("  âœ“ å·²å¸è½½ ImageGenerator çš„ PuLID å¼•æ“")
                except Exception as e:
                    print(f"  âš  å¸è½½ ImageGenerator PuLID å¼•æ“æ—¶å‡ºé”™: {e}")
            
            if hasattr(self.image_generator, 'fusion_engine') and self.image_generator.fusion_engine is not None:
                try:
                    if hasattr(self.image_generator.fusion_engine, 'unload'):
                        self.image_generator.fusion_engine.unload()
                    self.image_generator.fusion_engine = None
                    print("  âœ“ å·²å¸è½½ ImageGenerator çš„èåˆå¼•æ“")
                except Exception as e:
                    print(f"  âš  å¸è½½ ImageGenerator èåˆå¼•æ“æ—¶å‡ºé”™: {e}")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šæ¸…ç† planner çš„ LLM å®¢æˆ·ç«¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(self.image_generator, 'planner') and self.image_generator.planner is not None:
                try:
                    if hasattr(self.image_generator.planner, 'llm_client') and self.image_generator.planner.llm_client is not None:
                        # LLM å®¢æˆ·ç«¯é€šå¸¸ä¸å ç”¨æ˜¾å­˜ï¼Œä½†æ¸…ç†å¼•ç”¨æœ‰åŠ©äºåƒåœ¾å›æ”¶
                        self.image_generator.planner.llm_client = None
                        print("  âœ“ å·²æ¸…ç† planner çš„ LLM å®¢æˆ·ç«¯")
                except Exception as e:
                    print(f"  âš  æ¸…ç† planner LLM å®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
            
            # å¦‚æœ EnhancedImageGenerator æœ‰ unload_all æ–¹æ³•ï¼Œè°ƒç”¨å®ƒ
            if hasattr(self.image_generator, 'unload_all'):
                try:
                    self.image_generator.unload_all()
                    print("  âœ“ å·²è°ƒç”¨ EnhancedImageGenerator.unload_all()")
                except Exception as e:
                    print(f"  âš  è°ƒç”¨ unload_all æ—¶å‡ºé”™: {e}")
            
            # æ¸…ç†ModelManagerï¼ˆå¦‚æœä½¿ç”¨ï¼‰
            if hasattr(self.image_generator, 'model_manager') and self.image_generator.model_manager is not None:
                try:
                    if hasattr(self.image_generator.model_manager, 'unload_all'):
                        self.image_generator.model_manager.unload_all(include_critical=False)
                        print("  âœ“ å·²å¸è½½ModelManageræ‰€æœ‰æ¨¡å‹")
                    elif hasattr(self.image_generator.model_manager, 'unload'):
                        self.image_generator.model_manager.unload()
                        print("  âœ“ å·²å¸è½½ModelManager")
                except Exception as e:
                    print(f"  âš  å¸è½½ModelManageræ—¶å‡ºé”™: {e}")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šæ¸…ç† quality_analyzerï¼ˆå¦‚æœå­˜åœ¨ï¼Œå¯èƒ½æŒæœ‰ InsightFace æ¨¡å‹ï¼‰
            if hasattr(self.image_generator, 'quality_analyzer') and self.image_generator.quality_analyzer is not None:
                try:
                    # InsightFace æ¨¡å‹å¯èƒ½å ç”¨æ˜¾å­˜
                    if hasattr(self.image_generator.quality_analyzer, 'face_analyzer'):
                        self.image_generator.quality_analyzer.face_analyzer = None
                    self.image_generator.quality_analyzer = None
                    print("  âœ“ å·²æ¸…ç† quality_analyzer")
                except Exception as e:
                    print(f"  âš  æ¸…ç† quality_analyzer æ—¶å‡ºé”™: {e}")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æ¸…ç†æ‰€æœ‰CUDAç¼“å­˜ï¼Œæ¯å‡ æ­¥æ¸…ç†ä¸€æ¬¡
            if torch.cuda.is_available():
                # åŒæ­¥æ‰€æœ‰ CUDA æ“ä½œ
                torch.cuda.synchronize()
                
                # å¤šæ¬¡æ¸…ç†ï¼Œæ¯å‡ æ­¥æ¸…ç†ä¸€æ¬¡ï¼ˆæ¨¡æ‹Ÿä¹‹å‰ä¼˜åŒ–çš„æ–¹å¼ï¼‰
                for i in range(20):  # å¢åŠ åˆ°20æ¬¡ï¼Œæ›´å½»åº•
                    if i % 3 == 0:  # æ¯3æ¬¡åŒæ­¥ä¸€æ¬¡
                        torch.cuda.synchronize()
                    torch.cuda.empty_cache()
                    gc.collect()
                
                # æœ€ç»ˆåŒæ­¥å’Œæ¸…ç†
                torch.cuda.synchronize()
                torch.cuda.empty_cache()
                gc.collect()
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©æ˜¾å­˜çœŸæ­£é‡Šæ”¾
                import time
                time.sleep(1.0)  # å¢åŠ åˆ°1ç§’ï¼Œè®©æ˜¾å­˜æœ‰æ›´å¤šæ—¶é—´é‡Šæ”¾
                
                # å†æ¬¡æ¸…ç†
                for i in range(10):
                    torch.cuda.empty_cache()
                    gc.collect()
                    if i % 2 == 0:
                        torch.cuda.synchronize()
                
                allocated_after = torch.cuda.memory_allocated() / 1024**3
                reserved_after = torch.cuda.memory_reserved() / 1024**3
                freed = allocated_before - allocated_after if torch.cuda.is_available() else 0
                print(f"  â„¹ æ¸…ç†åæ˜¾å­˜: å·²åˆ†é…={allocated_after:.2f}GB, å·²ä¿ç•™={reserved_after:.2f}GB")
                if freed > 0:
                    print(f"  âœ“ å·²é‡Šæ”¾æ˜¾å­˜: {freed:.2f}GB")
                else:
                    print(f"  âš  è­¦å‘Šï¼šæ˜¾å­˜æœªé‡Šæ”¾ï¼Œå¯èƒ½ä»æœ‰æ¨¡å‹å ç”¨æ˜¾å­˜")
                
                # æ£€æŸ¥å¯ç”¨æ˜¾å­˜æ˜¯å¦è¶³å¤Ÿ
                total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                free = total - reserved_after
                print(f"  â„¹ å¯ç”¨æ˜¾å­˜: {free:.2f}GB / {total:.2f}GB")
                if free < 20:
                    print(f"  âš  è­¦å‘Š: å¯ç”¨æ˜¾å­˜è¾ƒå°‘ ({free:.2f}GB)ï¼Œè§†é¢‘ç”Ÿæˆå¯èƒ½ä¼šå¤±è´¥")
            
        except Exception as e:
            print(f"  âš  æ¸…ç†æ˜¾å­˜æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        # æ­¥éª¤2: ä½¿ç”¨ HunyuanVideo ç”Ÿæˆè§†é¢‘
        print()
        print("=" * 60)
        print("æ­¥éª¤2: ä½¿ç”¨ HunyuanVideo ç”Ÿæˆè§†é¢‘")
        print("=" * 60)
        
        # âš¡ å…³é”®ä¿®å¤ï¼šè§†é¢‘ç”Ÿæˆå‰å†æ¬¡å½»åº•æ¸…ç†æ˜¾å­˜
        print("  ğŸ”§ è§†é¢‘ç”Ÿæˆå‰æœ€åä¸€æ¬¡æ¸…ç†æ˜¾å­˜...")
        try:
            import torch
            import gc
            
            if torch.cuda.is_available():
                allocated_before_video = torch.cuda.memory_allocated() / 1024**3
                reserved_before_video = torch.cuda.memory_reserved() / 1024**3
                print(f"  â„¹ è§†é¢‘ç”Ÿæˆå‰æ˜¾å­˜: å·²åˆ†é…={allocated_before_video:.2f}GB, å·²ä¿ç•™={reserved_before_video:.2f}GB")
                
                # å¤šæ¬¡å½»åº•æ¸…ç†
                for i in range(10):
                    if i % 2 == 0:
                        torch.cuda.synchronize()
                    torch.cuda.empty_cache()
                    gc.collect()
                
                # æœ€ç»ˆåŒæ­¥å’Œæ¸…ç†
                torch.cuda.synchronize()
                torch.cuda.empty_cache()
                gc.collect()
                
                # ç­‰å¾…æ˜¾å­˜çœŸæ­£é‡Šæ”¾
                import time
                time.sleep(0.3)
                
                # å†æ¬¡æ¸…ç†
                torch.cuda.empty_cache()
                gc.collect()
                torch.cuda.synchronize()
                
                allocated_after_cleanup = torch.cuda.memory_allocated() / 1024**3
                reserved_after_cleanup = torch.cuda.memory_reserved() / 1024**3
                freed = allocated_before_video - allocated_after_cleanup
                print(f"  â„¹ æ¸…ç†åæ˜¾å­˜: å·²åˆ†é…={allocated_after_cleanup:.2f}GB, å·²ä¿ç•™={reserved_after_cleanup:.2f}GB")
                if freed > 0:
                    print(f"  âœ“ å·²é‡Šæ”¾æ˜¾å­˜: {freed:.2f}GB")
                
                # æ£€æŸ¥å¯ç”¨æ˜¾å­˜
                total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                free = total - reserved_after_cleanup
                print(f"  â„¹ å¯ç”¨æ˜¾å­˜: {free:.2f}GB / {total:.2f}GB")
                if free < 15:
                    print(f"  âš  è­¦å‘Š: å¯ç”¨æ˜¾å­˜è¾ƒå°‘ ({free:.2f}GB)ï¼Œè§†é¢‘ç”Ÿæˆå¯èƒ½ä¼šå¤±è´¥")
        except Exception as e:
            print(f"  âš  è§†é¢‘ç”Ÿæˆå‰æ¸…ç†æ˜¾å­˜æ—¶å‡ºé”™: {e}")
        
        if video_output_path is None:
            video_output_path = output_dir / "novel_video.mp4"
        
        try:
            # æ„å»ºè§†é¢‘ç”Ÿæˆæç¤ºè¯ï¼ˆå¯ä»¥æ›´è¯¦ç»†ï¼Œæè¿°è¿åŠ¨æ–¹å¼ï¼‰
            video_prompt = self._build_video_prompt(prompt, scene)
            
            # æ„å»ºsceneå­—å…¸ï¼ˆåŒ…å«promptä¿¡æ¯å’Œåˆ†è¾¨ç‡ï¼‰
            video_scene = scene.copy() if scene else {}
            video_scene['description'] = video_prompt
            video_scene['prompt'] = video_prompt  # ä¹Ÿæ·»åŠ åˆ°promptå­—æ®µ
            video_scene['motion_intensity'] = motion_intensity
            # é‡è¦ï¼šç¡®ä¿è§†é¢‘ä½¿ç”¨ä¸å›¾åƒç›¸åŒçš„åˆ†è¾¨ç‡ï¼Œä¿æŒé•¿å®½æ¯”ä¸€è‡´
            # widthå’Œheightå·²ç»åœ¨å›¾åƒç”Ÿæˆåæ›´æ–°ä¸ºå®é™…åˆ†è¾¨ç‡
            video_scene['width'] = width  # ä½¿ç”¨å›¾åƒçš„å®é™…å®½åº¦
            video_scene['height'] = height  # ä½¿ç”¨å›¾åƒçš„å®é™…é«˜åº¦
            print(f"  â„¹ è§†é¢‘å°†ä½¿ç”¨åˆ†è¾¨ç‡: {width}x{height} (ä¸å›¾åƒä¸€è‡´ï¼Œä¿æŒé•¿å®½æ¯” {width/height:.2f})")
            
            # ç”Ÿæˆè§†é¢‘ï¼š
            # - é»˜è®¤ï¼šVideoGeneratorï¼ˆçº¯ç”Ÿæˆï¼‰
            # - å¯ç”¨ enable_m6_identityï¼šEnhancedVideoGeneratorM6ï¼ˆéªŒè¯ + é‡è¯• + äº§å‡º reportï¼‰
            if effective_enable_m6:
                if not effective_include_character:
                    print("  âš  è­¦å‘Šï¼šenable_m6_identity=True ä½† include_character=Falseï¼ˆæ— äººç‰©åœºæ™¯é€šå¸¸æ— æ³•åšäººè„¸éªŒè¯ï¼‰ï¼Œå°†é€€å›æ™®é€šè§†é¢‘ç”Ÿæˆ")
                    effective_enable_m6 = False

            identity_report_path: Optional[Path] = None
            if effective_enable_m6:
                from enhanced_video_generator_m6 import EnhancedVideoGeneratorM6
                if self._m6_video_generator is None:
                    print("åˆå§‹åŒ– M6 å¢å¼ºè§†é¢‘ç”Ÿæˆå™¨ï¼ˆèº«ä»½éªŒè¯+é‡è¯•ï¼‰...")
                    self._m6_video_generator = EnhancedVideoGeneratorM6(str(self.config_path))

                # é€‰æ‹©å‚è€ƒå›¾ï¼šä¼˜å…ˆç”¨æˆ·æ˜¾å¼ä¼ å…¥ï¼›å¦åˆ™å°è¯•æŒ‰ character_id æ‰¾ reference_image/<id>_mid.jpgï¼›å¦åˆ™ç”¨ç”Ÿæˆå›¾
                ref = None
                if reference_image_path:
                    rp = Path(reference_image_path)
                    if not rp.is_absolute():
                        rp = (project_root / rp).resolve()
                    if rp.exists():
                        ref = str(rp)
                if ref is None and effective_character_id:
                    candidate = (project_root / "reference_image" / f"{effective_character_id}_mid.jpg").resolve()
                    if candidate.exists():
                        ref = str(candidate)
                if ref is None:
                    ref = str(image_path)

                # quick æ¨¡å¼ï¼šå‡å°‘æ­¥æ•°ï¼ˆä¿å®ˆé»˜è®¤ 8ï¼‰å¹¶å°†é‡è¯•è®¾ä¸º 0ï¼ˆé™¤éç”¨æˆ·æ˜¾å¼ä¼ ï¼‰
                if m6_quick:
                    self._m6_video_generator.video_config.setdefault("hunyuanvideo", {})
                    hv = self._m6_video_generator.video_config["hunyuanvideo"]
                    hv["num_inference_steps"] = min(int(hv.get("num_inference_steps", 25)), 8)
                    if m6_max_retries is None:
                        m6_max_retries = 0

                vp, result = self._m6_video_generator.generate_video_with_identity_check(
                    image_path=str(image_path),
                    output_path=str(video_output_path),
                    reference_image=ref,
                    scene=video_scene,
                    shot_type=shot_type,
                    enable_verification=True,
                    max_retries=m6_max_retries,
                    num_frames=num_frames,
                    fps=fps,
                )
                video_path = vp

                # å†™ä¸€ä¸ªè½»é‡ reportï¼ˆä¾¿äºåç»­æ‰¹é‡ç»Ÿè®¡/å½’æ¡£ï¼‰
                identity_report_path = output_dir / "novel_video_identity.json"
                payload = {
                    "passed": bool(result.passed) if result else False,
                    "avg_similarity": float(result.avg_similarity) if result else 0.0,
                    "min_similarity": float(result.min_similarity) if result else 0.0,
                    "drift_ratio": float(result.drift_ratio) if result else 1.0,
                    "face_detect_ratio": float(result.face_detect_ratio) if result else 0.0,
                    "issues": list(result.issues or []) if result else ["result=None"],
                    "reference_image": ref,
                    "video_path": str(video_path),
                    "character_id": effective_character_id,
                }
                identity_report_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
                print(f"âœ… M6 èº«ä»½éªŒè¯æŠ¥å‘Š: {identity_report_path}")
            else:
                # é M6 æ¨¡å¼ï¼šä½¿ç”¨æ™®é€šè§†é¢‘ç”Ÿæˆå™¨
                video_path = self.video_generator.generate_video(
                    image_path=str(image_path),
                    output_path=str(video_output_path),
                    num_frames=num_frames,
                    fps=fps,
                    scene=video_scene,
                )

            print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_path}")
            
            # âš¡ å…³é”®ä¿®å¤ï¼šè§†é¢‘ç”Ÿæˆåå½»åº•æ¸…ç†æ˜¾å­˜
            print()
            print("  ğŸ”§ è§†é¢‘ç”Ÿæˆåæ¸…ç†æ˜¾å­˜...")
            try:
                import torch
                import gc
                
                if torch.cuda.is_available():
                    # å¤šæ¬¡æ¸…ç†ï¼Œç¡®ä¿å½»åº•é‡Šæ”¾
                    for i in range(10):
                        if i % 2 == 0:
                            torch.cuda.synchronize()
                        torch.cuda.empty_cache()
                        gc.collect()
                    
                    # æœ€ç»ˆåŒæ­¥å’Œæ¸…ç†
                    torch.cuda.synchronize()
                    torch.cuda.empty_cache()
                    gc.collect()
                    
                    # ç­‰å¾…æ˜¾å­˜çœŸæ­£é‡Šæ”¾
                    import time
                    time.sleep(0.2)
                    
                    # å†æ¬¡æ¸…ç†
                    torch.cuda.empty_cache()
                    gc.collect()
                    torch.cuda.synchronize()
                    
                    allocated_after = torch.cuda.memory_allocated() / 1024**3
                    reserved_after = torch.cuda.memory_reserved() / 1024**3
                    print(f"  â„¹ è§†é¢‘ç”Ÿæˆåæ˜¾å­˜: å·²åˆ†é…={allocated_after:.2f}GB, å·²ä¿ç•™={reserved_after:.2f}GB")
            except Exception as e:
                print(f"  âš  è§†é¢‘ç”Ÿæˆåæ¸…ç†æ˜¾å­˜æ—¶å‡ºé”™: {e}")
                
        except Exception as e:
            print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        print()
        print("=" * 60)
        print("âœ… å°è¯´æ¨æ–‡è§†é¢‘ç”Ÿæˆå®Œæˆ")
        print("=" * 60)
        print(f"å›¾åƒ: {image_path}")
        print(f"è§†é¢‘: {video_path}")
        
        return {
            'image': image_path,
            'video': video_path,
            **({"identity_report": identity_report_path} if effective_enable_m6 and identity_report_path else {}),
        }
    
    def _generate_v21_exec(
        self,
        scene: Dict[str, Any],
        output_dir: Path,
        width: int,
        height: int,
        num_frames: int,
        fps: int
    ) -> Dict[str, Path]:
        """
        ä½¿ç”¨v2.1-execæ ¼å¼ç”Ÿæˆï¼ˆExecution Executoræ¨¡å¼ï¼‰
        
        Args:
            scene: v2.1-execæ ¼å¼çš„åœºæ™¯JSON
            output_dir: è¾“å‡ºç›®å½•
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            num_frames: è§†é¢‘å¸§æ•°
            fps: è§†é¢‘å¸§ç‡
            
        Returns:
            dict: åŒ…å« 'image' å’Œ 'video' è·¯å¾„çš„å­—å…¸
        """
        print("=" * 60)
        print("ä½¿ç”¨v2.1-execæ¨¡å¼ç”Ÿæˆ")
        print("=" * 60)
        
        try:
            from utils.execution_executor_v21 import (
                ExecutionExecutorV21,
                ExecutionConfig,
                ExecutionMode
            )
            from utils.execution_validator import ExecutionValidator
            
            # 1. æ ¡éªŒJSON
            validator = ExecutionValidator()
            validation_result = validator.validate_scene(scene)
            if not validation_result.is_valid:
                print(f"  âœ— JSONæ ¡éªŒå¤±è´¥: {validation_result.errors_count} ä¸ªé”™è¯¯")
                raise ValueError("åœºæ™¯JSONæ ¡éªŒå¤±è´¥")
            
            print(f"  âœ“ JSONæ ¡éªŒé€šè¿‡")
            
            # 2. åˆ›å»ºExecution Executor
            config = ExecutionConfig(mode=ExecutionMode.STRICT)
            executor = ExecutionExecutorV21(
                config=config,
                image_generator=self.image_generator,
                video_generator=self.video_generator,
                tts_generator=None  # TTSå¯ä»¥åç»­æ·»åŠ 
            )
            
            # 3. æ‰§è¡Œåœºæ™¯ç”Ÿæˆ
            result = executor.execute_scene(scene, str(output_dir))
            
            if result.success:
                print(f"  âœ“ åœºæ™¯ {scene.get('scene_id')} ç”ŸæˆæˆåŠŸ")
                return {
                    "image": Path(result.image_path) if result.image_path else None,
                    "video": Path(result.video_path) if result.video_path else None
                }
            else:
                print(f"  âœ— åœºæ™¯ {scene.get('scene_id')} ç”Ÿæˆå¤±è´¥: {result.error_message}")
                raise RuntimeError(f"ç”Ÿæˆå¤±è´¥: {result.error_message}")
                
        except ImportError as e:
            print(f"  âš  v2.1-execæ¨¡å—æœªæ‰¾åˆ°: {e}")
            print("  å›é€€åˆ°åŸæœ‰æµç¨‹")
            # å›é€€åˆ°åŸæœ‰æµç¨‹
            prompt = scene.get("prompt", {}).get("positive_core", "")
            return self.generate(
                prompt=prompt,
                output_dir=output_dir,
                width=width,
                height=height,
                num_frames=num_frames,
                fps=fps,
                scene=scene,
                use_v21_exec=False
            )
        except Exception as e:
            print(f"  âœ— v2.1-execç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _build_video_prompt(self, image_prompt: str, scene: Optional[Dict[str, Any]] = None) -> str:
        """
        æ„å»ºè§†é¢‘ç”Ÿæˆæç¤ºè¯ï¼ˆä½¿ç”¨ Prompt Engine V2ï¼‰
        
        Args:
            image_prompt: å›¾åƒç”Ÿæˆæ—¶çš„æç¤ºè¯
            scene: åœºæ™¯é…ç½®
            
        Returns:
            ä¼˜åŒ–åçš„è§†é¢‘ç”Ÿæˆæç¤ºè¯
        """
        def _extract_scene_motion(prompt_text: str) -> list:
            """
            ä»promptä¸­æå–åœºæ™¯å…ƒç´ ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è¿åŠ¨æè¿°
            
            Args:
                prompt_text: æç¤ºè¯æ–‡æœ¬
                
            Returns:
                åœºæ™¯å…ƒç´ çš„è¿åŠ¨æè¿°åˆ—è¡¨
            """
            motion_keywords = {
                # æ°´ç›¸å…³ - ä½¿ç”¨æ›´å¼ºçƒˆçš„è¿åŠ¨æè¿°
                'ç€‘å¸ƒ': ['waterfall continuously flowing down', 'water cascading and rushing', 'waterfall in motion'],
                'ç€‘å¸ƒæµ': ['waterfall continuously flowing', 'water cascading'],
                'waterfall': ['waterfall continuously flowing down', 'water cascading'],
                'æ²³æµ': ['river flowing and streaming', 'water continuously moving'],
                'river': ['river flowing and streaming'],
                'æºªæµ': ['stream flowing and trickling', 'water moving'],
                'stream': ['stream flowing and trickling'],
                'æ°´': ['water rippling and flowing', 'water in motion'],
                'water': ['water rippling and flowing'],
                'æ¹–': ['lake rippling with waves', 'water gently moving'],
                'lake': ['lake rippling with waves'],
                'æµ·': ['waves rolling and crashing', 'ocean waves in motion'],
                'sea': ['waves rolling and crashing'],
                'ocean': ['waves rolling and crashing'],
                
                # å¤©ç©ºç›¸å…³ - ä½¿ç”¨æ›´æ˜ç¡®çš„è¿åŠ¨æè¿°
                'äº‘': ['clouds slowly drifting across the sky', 'clouds moving in the wind'],
                'äº‘å½©': ['clouds slowly drifting across the sky', 'clouds moving'],
                'cloud': ['clouds slowly drifting', 'clouds moving'],
                'clouds': ['clouds slowly drifting across the sky', 'clouds moving'],
                'å½©è™¹': ['rainbow shimmering and glowing', 'rainbow light effects in motion'],
                'rainbow': ['rainbow shimmering and glowing'],
                'é˜³å…‰': ['sunlight shifting and moving', 'light rays in motion'],
                'sunlight': ['sunlight shifting and moving'],
                'å…‰çº¿': ['light rays moving and shifting', 'light in motion'],
                'light': ['light rays moving and shifting'],
                
                # æ¤ç‰©ç›¸å…³ - å¼ºè°ƒè¿åŠ¨
                'æ ‘': ['leaves swaying in the wind', 'trees gently moving'],
                'æ ‘å¶': ['leaves swaying and rustling', 'leaves in motion'],
                'tree': ['leaves swaying in the wind'],
                'leaves': ['leaves swaying and rustling'],
                'è‰': ['grass swaying in the breeze', 'grass moving'],
                'grass': ['grass swaying in the breeze'],
                'èŠ±': ['flowers swaying gently', 'flowers moving'],
                'flower': ['flowers swaying gently'],
                'flowers': ['flowers swaying gently'],
                
                # é£ç›¸å…³
                'é£': ['wind blowing and moving', 'breeze in motion'],
                'wind': ['wind blowing and moving'],
                'breeze': ['wind blowing and moving'],
                
                # é›¾æ°”ç›¸å…³
                'é›¾': ['mist rising and drifting', 'fog moving'],
                'é›¾æ°”': ['mist rising and drifting'],
                'mist': ['mist rising and drifting'],
                'fog': ['mist rising and drifting'],
                
                # ç«ç›¸å…³
                'ç«': ['flames flickering and dancing', 'fire in motion'],
                'ç«ç„°': ['flames flickering and dancing'],
                'fire': ['flames flickering and dancing'],
                'flame': ['flames flickering and dancing'],
                
                # é›ªç›¸å…³
                'é›ª': ['snow falling and drifting', 'snowflakes in motion'],
                'snow': ['snow falling and drifting'],
                'snowflake': ['snow falling and drifting'],
                
                # é¸Ÿç›¸å…³
                'é¸Ÿ': ['birds flying and soaring', 'birds in motion'],
                'bird': ['birds flying and soaring'],
                'birds': ['birds flying and soaring'],
            }
            
            scene_motions = []
            prompt_lower = prompt_text.lower()
            
            # æ£€æŸ¥æ¯ä¸ªå…³é”®è¯
            for keyword, motions in motion_keywords.items():
                if keyword.lower() in prompt_lower:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¿åŠ¨æè¿°ï¼ˆæœ€å¸¸ç”¨ï¼‰
                    scene_motions.append(motions[0])
            
            return scene_motions
        
        try:
            from utils.prompt_engine_v2 import PromptEngine, UserRequest
            
            # åˆ›å»º Prompt Engine V2ï¼ˆæœ¬åœ°æ¨¡å¼ï¼‰
            prompt_engine_v2 = PromptEngine()
            
            # åˆ›å»ºç”¨æˆ·è¯·æ±‚ï¼ˆè§†é¢‘ç”Ÿæˆé˜¶æ®µï¼‰
            req = UserRequest(
                text=image_prompt,
                scene_type="novel",  # å°è¯´æ¨æ–‡åœºæ™¯
                style="novel",  # ä½¿ç”¨novelé£æ ¼æ¨¡æ¿
                target_model="hunyuanvideo",  # è§†é¢‘ç”Ÿæˆä½¿ç”¨HunyuanVideo
                params=scene.get('params', {}) if scene else {}
            )
            
            # æ‰§è¡Œå¤„ç†
            pkg = prompt_engine_v2.run(req)
            
            # è·å–ä¼˜åŒ–åçš„prompt
            video_prompt = pkg.final_prompt
            
            # æå–åœºæ™¯å…ƒç´ çš„è¿åŠ¨æè¿°ï¼ˆå…³é”®ï¼šæ·»åŠ ç‰©ä½“è¿åŠ¨ï¼Œè€Œä¸ä»…ä»…æ˜¯ç›¸æœºè¿åŠ¨ï¼‰
            scene_motions = _extract_scene_motion(image_prompt)
            
            # å…³é”®ä¿®å¤ï¼šå°†è¿åŠ¨æè¿°ç›´æ¥èå…¥åˆ°promptä¸­ï¼Œè€Œä¸æ˜¯ä½œä¸ºåç¼€
            # HunyuanVideoéœ€è¦è¿åŠ¨æè¿°ç›´æ¥èå…¥åˆ°åœºæ™¯æè¿°ä¸­
            if scene_motions:
                print(f"  â„¹ æ£€æµ‹åˆ°åœºæ™¯å…ƒç´ è¿åŠ¨: {', '.join(scene_motions)}")
                
                # å°†è¿åŠ¨æè¿°ç›´æ¥æ’å…¥åˆ°promptçš„å‰é¢éƒ¨åˆ†ï¼ˆåœ¨ä¸»ä½“æè¿°ä¹‹åï¼‰
                # æ ¼å¼ï¼šä¸»ä½“æè¿° + è¿åŠ¨æè¿° + å…¶ä»–æè¿°
                prompt_parts = video_prompt.split('.')
                if len(prompt_parts) > 1:
                    # åœ¨ç¬¬ä¸€ä¸ªå¥å·åæ’å…¥è¿åŠ¨æè¿°
                    enhanced_prompt = prompt_parts[0] + ". " + ", ".join(scene_motions) + ". " + ". ".join(prompt_parts[1:])
                    video_prompt = enhanced_prompt
                else:
                    # å¦‚æœæ²¡æœ‰å¥å·ï¼Œç›´æ¥æ·»åŠ åˆ°å‰é¢
                    video_prompt = ", ".join(scene_motions) + ". " + video_prompt
            
            # æ·»åŠ è¿åŠ¨æè¿°ï¼ˆå¢å¼ºç‰ˆï¼Œç¡®ä¿ç‰©ä½“è¿åŠ¨ï¼‰
            motion_descriptions = []
            
            # 1. å†æ¬¡å¼ºè°ƒåœºæ™¯å…ƒç´ çš„è¿åŠ¨ï¼ˆä½¿ç”¨æ›´å¼ºçƒˆçš„æè¿°ï¼‰
            if scene_motions:
                # ä½¿ç”¨æ›´å¼ºçƒˆçš„è¿åŠ¨æè¿°
                strong_motions = []
                for motion in scene_motions:
                    if 'flowing' in motion:
                        strong_motions.append("water continuously flowing, dynamic water movement")
                    elif 'drifting' in motion:
                        strong_motions.append("clouds slowly drifting, sky in motion")
                    elif 'shimmering' in motion:
                        strong_motions.append("rainbow shimmering and glowing, light effects in motion")
                    elif 'swaying' in motion:
                        strong_motions.append("leaves gently swaying, natural wind movement")
                    else:
                        strong_motions.append(motion + ", motion visible")
                motion_descriptions.extend(strong_motions)
            
            # 2. æ·»åŠ åœºæ™¯é…ç½®ä¸­çš„è¿åŠ¨å¼ºåº¦
            if scene and isinstance(scene, dict):
                motion_intensity = scene.get('motion_intensity', 'moderate')
                camera_motion = scene.get('camera_motion', {})
                
                if motion_intensity == 'dynamic':
                    motion_descriptions.append("dynamic movement, active motion, objects in motion")
                elif motion_intensity == 'moderate':
                    motion_descriptions.append("moderate movement, natural motion, elements moving")
                else:
                    motion_descriptions.append("gentle movement, subtle motion, natural flow")
                
                # 3. æ·»åŠ ç›¸æœºè¿åŠ¨ï¼ˆæ¬¡è¦ï¼Œé¿å…åªæœ‰ç›¸æœºè¿åŠ¨ï¼‰
                if isinstance(camera_motion, dict):
                    camera_type = camera_motion.get('type', 'static')
                    if camera_type == 'pan':
                        motion_descriptions.append("smooth camera pan")
                    elif camera_type == 'zoom':
                        motion_descriptions.append("smooth camera zoom")
                    elif camera_type == 'dolly':
                        motion_descriptions.append("smooth camera dolly")
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åœºæ™¯è¿åŠ¨ï¼Œæ·»åŠ é»˜è®¤çš„è‡ªç„¶è¿åŠ¨æè¿°
            if not scene_motions:
                motion_descriptions.append("natural movement, subtle motion, elements in motion")
                print(f"  â„¹ æœªæ£€æµ‹åˆ°ç‰¹å®šåœºæ™¯å…ƒç´ ï¼Œæ·»åŠ é»˜è®¤è‡ªç„¶è¿åŠ¨æè¿°")
            
            # ç»„åˆè¿åŠ¨æè¿°ï¼ˆæ·»åŠ åˆ°promptæœ«å°¾ï¼Œä½œä¸ºè¡¥å……ï¼‰
            if motion_descriptions:
                video_prompt += ". " + ", ".join(motion_descriptions)
            
            # æ·»åŠ è§†é¢‘è´¨é‡æè¿°
            video_prompt += ". High quality, cinematic, smooth motion, natural movement, objects in motion"
            
            print(f"  âœ“ è§†é¢‘æç¤ºè¯å·²ä½¿ç”¨ Prompt Engine V2 ä¼˜åŒ–")
            print(f"  â„¹ QAè¯„åˆ†: {pkg.metadata.get('qa_score', 0)}/{pkg.metadata.get('qa_max_score', 0)}")
            
            return video_prompt
            
        except Exception as e:
            print(f"  âš  Prompt Engine V2 å¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸºç¡€æ–¹æ¡ˆ")
            import traceback
            traceback.print_exc()
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºç¡€æç¤ºè¯æ„å»º
            video_prompt = image_prompt
            
            # æå–åœºæ™¯å…ƒç´ çš„è¿åŠ¨æè¿°
            scene_motions = _extract_scene_motion(image_prompt)
            
            # å…³é”®ä¿®å¤ï¼šå°†è¿åŠ¨æè¿°ç›´æ¥èå…¥åˆ°promptä¸­
            if scene_motions:
                print(f"  â„¹ æ£€æµ‹åˆ°åœºæ™¯å…ƒç´ è¿åŠ¨: {', '.join(scene_motions)}")
                
                # å°†è¿åŠ¨æè¿°ç›´æ¥æ’å…¥åˆ°promptçš„å‰é¢éƒ¨åˆ†
                prompt_parts = video_prompt.split('.')
                if len(prompt_parts) > 1:
                    enhanced_prompt = prompt_parts[0] + ". " + ", ".join(scene_motions) + ". " + ". ".join(prompt_parts[1:])
                    video_prompt = enhanced_prompt
                else:
                    video_prompt = ", ".join(scene_motions) + ". " + video_prompt
            
            # æ·»åŠ è¿åŠ¨æè¿°ï¼ˆå¢å¼ºç‰ˆï¼‰
            motion_descriptions = []
            
            # 1. å†æ¬¡å¼ºè°ƒåœºæ™¯å…ƒç´ çš„è¿åŠ¨ï¼ˆä½¿ç”¨æ›´å¼ºçƒˆçš„æè¿°ï¼‰
            if scene_motions:
                strong_motions = []
                for motion in scene_motions:
                    if 'flowing' in motion:
                        strong_motions.append("water continuously flowing, dynamic water movement")
                    elif 'drifting' in motion:
                        strong_motions.append("clouds slowly drifting, sky in motion")
                    elif 'shimmering' in motion:
                        strong_motions.append("rainbow shimmering and glowing, light effects in motion")
                    elif 'swaying' in motion:
                        strong_motions.append("leaves gently swaying, natural wind movement")
                    else:
                        strong_motions.append(motion + ", motion visible")
                motion_descriptions.extend(strong_motions)
            
            # 2. æ·»åŠ åœºæ™¯é…ç½®ä¸­çš„è¿åŠ¨å¼ºåº¦
            if scene and isinstance(scene, dict):
                motion_intensity = scene.get('motion_intensity', 'moderate')
                camera_motion = scene.get('camera_motion', {})
                
                if motion_intensity == 'dynamic':
                    motion_descriptions.append("dynamic movement, active motion, objects in motion")
                elif motion_intensity == 'moderate':
                    motion_descriptions.append("moderate movement, natural motion, elements moving")
                else:
                    motion_descriptions.append("gentle movement, subtle motion, natural flow")
                
                # 3. æ·»åŠ ç›¸æœºè¿åŠ¨
                if isinstance(camera_motion, dict):
                    camera_type = camera_motion.get('type', 'static')
                    if camera_type == 'pan':
                        motion_descriptions.append("smooth camera pan")
                    elif camera_type == 'zoom':
                        motion_descriptions.append("smooth camera zoom")
                    elif camera_type == 'dolly':
                        motion_descriptions.append("smooth camera dolly")
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åœºæ™¯è¿åŠ¨ï¼Œæ·»åŠ é»˜è®¤çš„è‡ªç„¶è¿åŠ¨æè¿°
            if not scene_motions:
                motion_descriptions.append("natural movement, subtle motion, elements in motion")
                print(f"  â„¹ æœªæ£€æµ‹åˆ°ç‰¹å®šåœºæ™¯å…ƒç´ ï¼Œæ·»åŠ é»˜è®¤è‡ªç„¶è¿åŠ¨æè¿°")
            
            # ç»„åˆè¿åŠ¨æè¿°
            if motion_descriptions:
                video_prompt += ". " + ", ".join(motion_descriptions)
            
            # æ·»åŠ è´¨é‡æè¿°
            video_prompt += ". High quality, cinematic, smooth motion, natural movement, objects in motion"
            
            return video_prompt


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”Ÿæˆå°è¯´æ¨æ–‡è§†é¢‘")
    parser.add_argument("--prompt", type=str, required=True, help="æ–‡æœ¬æç¤ºè¯ï¼ˆå°è¯´åœºæ™¯æè¿°ï¼‰")
    parser.add_argument("--output-dir", type=str, default=None, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--width", type=int, default=1280, help="å›¾åƒå®½åº¦")
    parser.add_argument("--height", type=int, default=768, help="å›¾åƒé«˜åº¦")
    parser.add_argument("--num-frames", type=int, default=120, help="è§†é¢‘å¸§æ•°")
    parser.add_argument("--fps", type=int, default=24, help="è§†é¢‘å¸§ç‡")
    parser.add_argument("--config", type=str, default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")

    # è§’è‰²ä¸€è‡´ï¼ˆå›¾ç‰‡ç«¯ï¼‰
    parser.add_argument("--include-character", action="store_true", help="å¼ºåˆ¶å¯ç”¨è§’è‰²æ¨¡å¼ï¼ˆäººç‰©å‡ºé•œï¼Œèµ°è§’è‰²ä¸€è‡´ç³»ç»Ÿï¼‰")
    parser.add_argument("--force-scene", action="store_true", help="å¼ºåˆ¶çº¯åœºæ™¯æ¨¡å¼ï¼ˆå¿½ç•¥è‡ªåŠ¨æ¨æ–­/æ‰‹åŠ¨è§’è‰²ï¼‰")
    parser.add_argument("--auto-character", action=argparse.BooleanOptionalAction, default=True, help="æ˜¯å¦è‡ªåŠ¨è¯†åˆ«æ˜¯å¦åŒ…å«éŸ©ç«‹ï¼ˆé»˜è®¤å¼€å¯ï¼‰")
    parser.add_argument("--character-id", type=str, default=None, help="è§’è‰²IDï¼ˆå¯é€‰ï¼Œè¦†ç›–è‡ªåŠ¨æ¨æ–­ï¼‰")
    parser.add_argument("--image-model-engine", type=str, default=None, help="è¦†ç›–å›¾ç‰‡å¼•æ“ï¼ˆauto/flux-instantid/pulid/flux1...ï¼‰")

    # è§†é¢‘ä¸€è‡´ï¼ˆM6ï¼‰
    parser.add_argument("--enable-m6-identity", action="store_true", help="å¼ºåˆ¶å¯ç”¨ M6 èº«ä»½éªŒè¯+é‡è¯•ï¼ˆä»…åœ¨æ£€æµ‹åˆ°éŸ©ç«‹/è§’è‰²æ¨¡å¼æ—¶ç”Ÿæ•ˆï¼‰")
    parser.add_argument("--disable-m6-identity", action="store_true", help="å¼ºåˆ¶å…³é—­ M6ï¼ˆå³ä½¿æ£€æµ‹åˆ°éŸ©ç«‹ï¼‰")
    parser.add_argument("--auto-m6-identity", action=argparse.BooleanOptionalAction, default=True, help="æ˜¯å¦å¯¹éŸ©ç«‹åœºæ™¯è‡ªåŠ¨å¯ç”¨ M6ï¼ˆé»˜è®¤å¼€å¯ï¼‰")
    parser.add_argument("--reference-image-path", type=str, default=None, help="èº«ä»½éªŒè¯å‚è€ƒå›¾ï¼ˆä¸ä¼ åˆ™æŒ‰ character-id è‡ªåŠ¨æ‰¾ *_mid.jpgï¼Œå¦åˆ™ç”¨ç”Ÿæˆå›¾ï¼‰")
    parser.add_argument("--shot-type", type=str, default="medium", choices=["wide", "medium", "medium_close", "close", "extreme_close"], help="é•œå¤´ç±»å‹")
    parser.add_argument("--motion-intensity", type=str, default="moderate", choices=["gentle", "moderate", "dynamic"], help="è¿åŠ¨å¼ºåº¦")
    parser.add_argument("--m6-max-retries", type=int, default=None, help="è¦†ç›– M6 æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆ0=ä¸é‡è¯•ï¼‰")
    parser.add_argument("--m6-quick", action="store_true", help="M6 å¿«é€Ÿæ¨¡å¼ï¼ˆæ›´å°‘æ­¥æ•°/é»˜è®¤ä¸é‡è¯•ï¼Œé€‚åˆå†’çƒŸï¼‰")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = NovelVideoGenerator(config_path=args.config)
    
    # M6 æ˜¾å¼å¼€å…³ä¼˜å…ˆçº§ï¼šdisable > enable > auto(None)
    enable_m6_identity = None
    if args.disable_m6_identity:
        enable_m6_identity = False
    elif args.enable_m6_identity:
        enable_m6_identity = True
    
    # ç”Ÿæˆè§†é¢‘
    result = generator.generate(
        prompt=args.prompt,
        output_dir=Path(args.output_dir) if args.output_dir else None,
        width=args.width,
        height=args.height,
        num_frames=args.num_frames,
        fps=args.fps,
        include_character=True if args.include_character else None,
        character_id=args.character_id,
        auto_character=bool(args.auto_character),
        force_scene=bool(args.force_scene),
        image_model_engine=args.image_model_engine,
        enable_m6_identity=enable_m6_identity,
        auto_m6_identity=bool(args.auto_m6_identity),
        reference_image_path=args.reference_image_path,
        shot_type=args.shot_type,
        motion_intensity=args.motion_intensity,
        m6_max_retries=args.m6_max_retries,
        m6_quick=bool(args.m6_quick),
    )
    
    print("\nç”Ÿæˆå®Œæˆï¼")
    print(f"å›¾åƒ: {result['image']}")
    print(f"è§†é¢‘: {result['video']}")


if __name__ == "__main__":
    main()


# æ•´ä½“é£æ ¼å­¦ä¹ ä¸äºŒæ¬¡åˆ›ä½œæ–¹æ¡ˆ

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

ä»åŸåŠ¨æ¼«ç´ æä¸­**å­¦ä¹ æ•´ä½“é£æ ¼**ï¼ˆè€Œéå•å¼ å›¾ç‰‡å‚è€ƒï¼‰ï¼Œç„¶ååŸºäºå­¦ä¹ çš„é£æ ¼ç”Ÿæˆç¬¦åˆè§£è¯´åœºæ™¯çš„æ–°å›¾ç‰‡å’Œè§†é¢‘ã€‚

## ğŸš€ æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆAï¼šå•å¼ å›¾ç‰‡å‚è€ƒï¼ˆå½“å‰ï¼‰
- âŒ åªèƒ½å‚è€ƒå•å¼ å›¾ç‰‡çš„é£æ ¼
- âŒ é£æ ¼å­¦ä¹ ä¸å…¨é¢
- âŒ ä¸åŒåœºæ™¯é£æ ¼å¯èƒ½ä¸ä¸€è‡´

### æ–¹æ¡ˆBï¼šæ•´ä½“é£æ ¼å­¦ä¹ ï¼ˆæ¨èï¼‰â­

**æ ¸å¿ƒæ€è·¯ï¼š**
```
åŸåŠ¨æ¼«ç´ æï¼ˆå¤šå¼ å›¾ç‰‡/è§†é¢‘ï¼‰
  â†“ æå–å…³é”®å¸§ï¼ˆ20-50å¼ ï¼‰
  â†“ è®­ç»ƒé£æ ¼LoRAï¼ˆå­¦ä¹ æ•´ä½“é£æ ¼ï¼‰
é£æ ¼LoRAæ¨¡å‹
  â†“ ç»“åˆInstantID + è§’è‰²LoRA
ç”Ÿæˆæ–°å›¾ç‰‡ï¼ˆä¿æŒæ•´ä½“é£æ ¼ï¼‰
  â†“ SVD
ç”Ÿæˆæ–°è§†é¢‘
```

**ä¼˜ç‚¹ï¼š**
- âœ… å­¦ä¹ æ•´ä½“é£æ ¼ï¼Œè€Œéå•å¼ å›¾ç‰‡
- âœ… é£æ ¼ç»Ÿä¸€ï¼Œæ‰€æœ‰åœºæ™¯ä¿æŒä¸€è‡´
- âœ… å¯ä»¥ç”Ÿæˆä»»æ„åœºæ™¯ï¼Œéƒ½ä¿æŒåŸåŠ¨æ¼«é£æ ¼
- âœ… è®­ç»ƒä¸€æ¬¡ï¼Œé•¿æœŸä½¿ç”¨

## ğŸ› ï¸ æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šé£æ ¼LoRAè®­ç»ƒï¼ˆæœ€æ¨èï¼‰â­â­â­

**æµç¨‹ï¼š**

1. **æå–é£æ ¼å‚è€ƒå›¾åƒ**
   ```bash
   # ä»åŸåŠ¨æ¼«è§†é¢‘ä¸­æå–20-50å¼ å…³é”®å¸§
   python tools/extract_style_reference_frames.py \
       --input reference_materials/videos/ \
       --output reference_materials/style_frames/ \
       --num_frames 30 \
       --method diverse  # ç¡®ä¿å¤šæ ·æ€§
   ```

2. **è®­ç»ƒé£æ ¼LoRA**
   ```bash
   # ä½¿ç”¨DreamBooth LoRAè®­ç»ƒé£æ ¼æ¨¡å‹
   python scripts/train_style_lora_sdxl.py \
       --instance_data_dir reference_materials/style_frames/ \
       --output_dir models/lora/anime_style/ \
       --instance_prompt "anime style, xianxia animation style" \
       --resolution 1024 \
       --train_batch_size 1 \
       --gradient_accumulation_steps 4 \
       --learning_rate 1e-4 \
       --max_train_steps 1000
   ```

3. **ä½¿ç”¨é£æ ¼LoRAç”Ÿæˆ**
   ```yaml
   # config.yaml
   image:
     lora:
       enabled: true
       # è§’è‰²LoRA
       weights_path: models/lora/hanli/pytorch_lora_weights.safetensors
       adapter_name: hanli
       alpha: 0.60
       # é£æ ¼LoRAï¼ˆæ–°å¢ï¼‰
       style_lora:
         enabled: true
         weights_path: models/lora/anime_style/pytorch_lora_weights.safetensors
         adapter_name: anime_style
         alpha: 0.7  # é£æ ¼æƒé‡ï¼Œæ§åˆ¶é£æ ¼å¼ºåº¦
   ```

**ç‰¹ç‚¹ï¼š**
- è®­ç»ƒæ—¶é—´ï¼šçº¦1-2å°æ—¶ï¼ˆ30å¼ å›¾ç‰‡ï¼Œ1000æ­¥ï¼‰
- æ¨¡å‹å¤§å°ï¼šçº¦50-100MB
- æ•ˆæœï¼šé£æ ¼ç»Ÿä¸€ï¼Œè´¨é‡é«˜
- å¯å¤ç”¨ï¼šè®­ç»ƒä¸€æ¬¡ï¼Œæ‰€æœ‰åœºæ™¯éƒ½ä½¿ç”¨

### æ–¹æ¡ˆ2ï¼šIP-Adapter Plus å¤šå‚è€ƒå›¾åƒ â­â­

**æµç¨‹ï¼š**

1. **å‡†å¤‡å¤šå‚è€ƒå›¾åƒ**
   - ä»åŸåŠ¨æ¼«ä¸­æå–10-20å¼ ä»£è¡¨æ€§å›¾åƒ
   - è¦†ç›–ä¸åŒåœºæ™¯ç±»å‹ï¼ˆå®¤å†…ã€å®¤å¤–ã€æˆ˜æ–—ã€å¯¹è¯ç­‰ï¼‰

2. **ä½¿ç”¨IP-Adapter Plus**
   ```python
   # æ”¯æŒå¤šå‚è€ƒå›¾åƒ
   from diffusers import StableDiffusionXLControlNetPipeline
   from diffusers.pipelines.controlnet import MultiControlNetModel
   
   # åŠ è½½å¤šå¼ å‚è€ƒå›¾åƒ
   reference_images = [
       load_image("style_ref_001.jpg"),
       load_image("style_ref_002.jpg"),
       load_image("style_ref_003.jpg"),
       # ... æ›´å¤šå‚è€ƒå›¾åƒ
   ]
   
   # ä½¿ç”¨IP-Adapter Plus
   pipe.set_ip_adapter_scale(0.6)
   image = pipe(
       prompt=prompt,
       ip_adapter_image=reference_images,  # å¤šå‚è€ƒå›¾åƒ
       num_inference_steps=40,
   ).images[0]
   ```

**ç‰¹ç‚¹ï¼š**
- æ— éœ€è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨
- æ”¯æŒåŠ¨æ€åˆ‡æ¢å‚è€ƒå›¾åƒ
- æ•ˆæœï¼šé£æ ¼è¿ç§»ï¼Œä½†å¯èƒ½ä¸å¦‚LoRAç»Ÿä¸€

### æ–¹æ¡ˆ3ï¼šStyle Embeddingæå– â­

**æµç¨‹ï¼š**

1. **æå–é£æ ¼ç‰¹å¾å‘é‡**
   ```python
   # ä½¿ç”¨CLIPæå–å¤šå¼ å‚è€ƒå›¾åƒçš„é£æ ¼ç‰¹å¾
   from transformers import CLIPProcessor, CLIPModel
   
   clip_model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
   clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
   
   # æå–å¤šå¼ å›¾åƒçš„ç‰¹å¾
   style_embeddings = []
   for img_path in reference_images:
       image = Image.open(img_path)
       inputs = clip_processor(images=image, return_tensors="pt")
       embedding = clip_model.get_image_features(**inputs)
       style_embeddings.append(embedding)
   
   # å¹³å‡é£æ ¼ç‰¹å¾
   avg_style_embedding = torch.mean(torch.stack(style_embeddings), dim=0)
   ```

2. **åº”ç”¨åˆ°ç”Ÿæˆè¿‡ç¨‹**
   - å°†é£æ ¼ç‰¹å¾æ³¨å…¥åˆ°ç”Ÿæˆè¿‡ç¨‹
   - ç»“åˆControlNetæˆ–IP-Adapterä½¿ç”¨

**ç‰¹ç‚¹ï¼š**
- è½»é‡çº§ï¼Œæ— éœ€è®­ç»ƒ
- å¯ä»¥åŠ¨æ€è°ƒæ•´é£æ ¼å¼ºåº¦
- æ•ˆæœï¼šä¸­ç­‰ï¼Œä¸å¦‚LoRAç¨³å®š

### æ–¹æ¡ˆ4ï¼šæ··åˆæ–¹æ¡ˆï¼ˆæœ€ä½³ï¼‰â­â­â­â­â­

**ç»„åˆä½¿ç”¨ï¼š**
```
é£æ ¼LoRAï¼ˆæ•´ä½“é£æ ¼ï¼‰
  + 
è§’è‰²LoRAï¼ˆè§’è‰²ä¸€è‡´æ€§ï¼‰
  +
InstantIDï¼ˆé¢éƒ¨ç‰¹å¾ï¼‰
  +
IP-Adapterå¤šå‚è€ƒï¼ˆåœºæ™¯ç»†èŠ‚ï¼‰
  =
å®Œç¾çš„äºŒæ¬¡åˆ›ä½œ
```

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
image:
  engine: instantid
  lora:
    enabled: true
    # è§’è‰²LoRA
    weights_path: models/lora/hanli/pytorch_lora_weights.safetensors
    adapter_name: hanli
    alpha: 0.60
    # é£æ ¼LoRAï¼ˆæ–°å¢ï¼‰
    style_lora:
      enabled: true
      weights_path: models/lora/anime_style/pytorch_lora_weights.safetensors
      adapter_name: anime_style
      alpha: 0.7
  
  # é£æ ¼å‚è€ƒé…ç½®
  style_reference:
    enabled: true
    # ä½¿ç”¨IP-Adapter Plusæ”¯æŒå¤šå‚è€ƒå›¾åƒ
    use_ip_adapter_plus: true
    # å‚è€ƒå›¾åƒç›®å½•
    reference_dir: reference_materials/style_frames/
    # æ¯æ¬¡ç”Ÿæˆä½¿ç”¨çš„å‚è€ƒå›¾åƒæ•°é‡
    num_references: 3
    # å‚è€ƒå›¾åƒæƒé‡
    reference_scale: 0.5
```

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”è¡¨

| æ–¹æ¡ˆ | è®­ç»ƒæ—¶é—´ | æ¨¡å‹å¤§å° | é£æ ¼ç»Ÿä¸€æ€§ | çµæ´»æ€§ | æ¨èåº¦ |
|------|---------|---------|----------|--------|--------|
| å•å¼ å‚è€ƒ | 0 | 0 | â­â­ | â­â­â­ | â­â­ |
| é£æ ¼LoRA | 1-2å°æ—¶ | 50-100MB | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| IP-Adapter Plus | 0 | 0 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| Style Embedding | 0 | å° | â­â­â­ | â­â­â­â­ | â­â­â­ |
| æ··åˆæ–¹æ¡ˆ | 1-2å°æ—¶ | 50-100MB | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |

## ğŸ¯ æ¨èå®æ–½æ–¹æ¡ˆ

### é˜¶æ®µ1ï¼šå¿«é€ŸéªŒè¯ï¼ˆ1-2å¤©ï¼‰

ä½¿ç”¨ **IP-Adapter Plus å¤šå‚è€ƒå›¾åƒ**ï¼š
- æ— éœ€è®­ç»ƒï¼Œå¿«é€ŸéªŒè¯æ•ˆæœ
- æå–10-20å¼ ä»£è¡¨æ€§å‚è€ƒå›¾åƒ
- å®ç°å¤šå‚è€ƒå›¾åƒæ”¯æŒ

### é˜¶æ®µ2ï¼šä¼˜åŒ–æ–¹æ¡ˆï¼ˆ3-5å¤©ï¼‰

è®­ç»ƒ **é£æ ¼LoRA**ï¼š
- æå–30-50å¼ é£æ ¼å‚è€ƒå›¾åƒ
- è®­ç»ƒé£æ ¼LoRAæ¨¡å‹
- é›†æˆåˆ°ç°æœ‰ç”Ÿæˆæµç¨‹

### é˜¶æ®µ3ï¼šå®Œå–„æ–¹æ¡ˆï¼ˆæŒç»­ä¼˜åŒ–ï¼‰

å®ç° **æ··åˆæ–¹æ¡ˆ**ï¼š
- é£æ ¼LoRA + IP-Adapter Plus
- åŠ¨æ€è°ƒæ•´é£æ ¼å¼ºåº¦
- åœºæ™¯è‡ªé€‚åº”é£æ ¼é€‰æ‹©

## ğŸ”§ å®ç°ç»†èŠ‚

### 1. é£æ ¼å‚è€ƒå›¾åƒæå–

**è¦æ±‚ï¼š**
- å¤šæ ·æ€§ï¼šè¦†ç›–ä¸åŒåœºæ™¯ã€è§’åº¦ã€å…‰ç…§
- ä»£è¡¨æ€§ï¼šé€‰æ‹©æœ€èƒ½ä½“ç°æ•´ä½“é£æ ¼çš„å›¾åƒ
- æ•°é‡ï¼š20-50å¼ ï¼ˆLoRAè®­ç»ƒï¼‰ï¼Œ10-20å¼ ï¼ˆIP-Adapterï¼‰

**æå–ç­–ç•¥ï¼š**
```python
# 1. åœºæ™¯å˜åŒ–æ£€æµ‹ï¼šæå–åœºæ™¯åˆ‡æ¢çš„å…³é”®å¸§
# 2. å¤šæ ·æ€§é‡‡æ ·ï¼šç¡®ä¿è¦†ç›–ä¸åŒåœºæ™¯ç±»å‹
# 3. è´¨é‡ç­›é€‰ï¼šé€‰æ‹©æ¸…æ™°ã€æœ‰ä»£è¡¨æ€§çš„å›¾åƒ
# 4. é£æ ¼ä¸€è‡´æ€§æ£€æŸ¥ï¼šç¡®ä¿é£æ ¼ç»Ÿä¸€
```

### 2. é£æ ¼LoRAè®­ç»ƒ

**è®­ç»ƒå‚æ•°ï¼š**
- å­¦ä¹ ç‡ï¼š1e-4
- è®­ç»ƒæ­¥æ•°ï¼š800-1200æ­¥
- Batch sizeï¼š1-2
- åˆ†è¾¨ç‡ï¼š1024x1024
- æç¤ºè¯ï¼š`"anime style, xianxia animation style, [åŸåŠ¨æ¼«åç§°] style"`

**è®­ç»ƒæŠ€å·§ï¼š**
- ä½¿ç”¨é«˜è´¨é‡å‚è€ƒå›¾åƒ
- ç¡®ä¿é£æ ¼ä¸€è‡´æ€§
- é€‚å½“çš„æ•°æ®å¢å¼º
- å®šæœŸæ£€æŸ¥è®­ç»ƒæ•ˆæœ

### 3. å¤šLoRAç»„åˆä½¿ç”¨

**æƒé‡åˆ†é…ï¼š**
- è§’è‰²LoRAï¼š0.6ï¼ˆä¿æŒè§’è‰²ç‰¹å¾ï¼‰
- é£æ ¼LoRAï¼š0.7ï¼ˆæ§åˆ¶æ•´ä½“é£æ ¼ï¼‰
- InstantIDï¼š0.85ï¼ˆé¢éƒ¨ç‰¹å¾ï¼‰
- IP-Adapterï¼š0.5ï¼ˆåœºæ™¯ç»†èŠ‚ï¼‰

**åŠ¨æ€è°ƒæ•´ï¼š**
- æ ¹æ®åœºæ™¯ç±»å‹è°ƒæ•´æƒé‡
- è¿œæ™¯åœºæ™¯ï¼šé™ä½è§’è‰²LoRAï¼Œæé«˜é£æ ¼LoRA
- ç‰¹å†™åœºæ™¯ï¼šæé«˜è§’è‰²LoRAï¼Œé™ä½é£æ ¼LoRA

## ğŸ“ ç›®å½•ç»“æ„

```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ processed/                  # åŸåŠ¨æ¼«ç´ æï¼ˆå·²æœ‰ï¼‰
â”‚   â”œâ”€â”€ keyframes/              # å…¨å±€å…³é”®å¸§ç›®å½•ï¼ˆ5500+å¼ ï¼‰
â”‚   â”‚   â”œâ”€â”€ episode_170_clean-Scene-001_start.jpg
â”‚   â”‚   â”œâ”€â”€ episode_170_clean-Scene-001_middle.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ episode_142/
â”‚   â”‚   â”œâ”€â”€ keyframes/          # å„episodeçš„å…³é”®å¸§
â”‚   â”‚   â”œâ”€â”€ scenes/             # åˆ‡åˆ†çš„åœºæ™¯è§†é¢‘
â”‚   â”‚   â””â”€â”€ clean/              # æ¸…ç†åçš„å®Œæ•´è§†é¢‘
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ gen_video/
â”‚   â”œâ”€â”€ reference_materials/
â”‚   â”‚   â””â”€â”€ style_frames/       # æ”¶é›†çš„é£æ ¼å‚è€ƒå›¾åƒï¼ˆ30-50å¼ ï¼‰
â”‚   â”‚       â”œâ”€â”€ style_ref_001.jpg
â”‚   â”‚       â”œâ”€â”€ style_ref_002.jpg
â”‚   â”‚       â”œâ”€â”€ ...
â”‚   â”‚       â””â”€â”€ metadata.json    # å…ƒæ•°æ®
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ lora/
â”‚   â”‚       â”œâ”€â”€ hanli/          # è§’è‰²LoRAï¼ˆå·²æœ‰ï¼‰
â”‚   â”‚       â””â”€â”€ anime_style/   # é£æ ¼LoRAï¼ˆæ–°å¢ï¼‰
â”‚   â”‚           â””â”€â”€ pytorch_lora_weights.safetensors
â”‚   â”‚
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ collect_style_reference_frames.py  # æ”¶é›†é£æ ¼å‚è€ƒå›¾åƒï¼ˆä»processedï¼‰
â”‚       â””â”€â”€ train_style_lora_sdxl.py          # è®­ç»ƒé£æ ¼LoRA
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1ï¼šæ”¶é›†é£æ ¼å‚è€ƒå›¾åƒ

**ä»processedç›®å½•æ”¶é›†å·²æœ‰çš„å…³é”®å¸§ï¼š**

```bash
# ä»processedç›®å½•æ”¶é›†30å¼ ä»£è¡¨æ€§å…³é”®å¸§
python gen_video/tools/collect_style_reference_frames.py \
    --base-dir . \
    --output gen_video/reference_materials/style_frames \
    --num-frames 30 \
    --method diverse \
    --rename
```

**è¯´æ˜ï¼š**
- `--base-dir`: é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å«processedç›®å½•ï¼‰
- `--output`: è¾“å‡ºç›®å½•
- `--num-frames`: éœ€è¦é€‰æ‹©çš„å¸§æ•°ï¼ˆæ¨è30-50å¼ ï¼‰
- `--method`: é€‰æ‹©æ–¹æ³•
  - `diverse`: ç¡®ä¿å¤šæ ·æ€§ï¼ˆæ¨èï¼‰ï¼Œä»ä¸åŒåœºæ™¯é€‰æ‹©
  - `balanced`: å¹³è¡¡é€‰æ‹©ï¼Œæ¯ä¸ªepisodeå¹³å‡åˆ†é…
  - `random`: éšæœºé€‰æ‹©
- `--rename`: é‡å‘½åä¸º style_ref_001.jpg, style_ref_002.jpg ...

**å¦‚æœprocessedç›®å½•ä¸­æ²¡æœ‰å…³é”®å¸§ï¼Œå¯ä»¥ä»è§†é¢‘æå–ï¼š**

```bash
# ä»è§†é¢‘ä¸­æå–å…³é”®å¸§ï¼ˆå¦‚æœéœ€è¦ï¼‰
python tools/extract_keyframes.py \
    --input processed/episode_*/clean/*.mp4 \
    --output reference_materials/style_frames/ \
    --num-frames 30 \
    --method scene_change
```

### æ­¥éª¤2ï¼šè®­ç»ƒé£æ ¼LoRA

```bash
python scripts/train_style_lora_sdxl.py \
    --instance_data_dir reference_materials/style_frames/ \
    --output_dir models/lora/anime_style/ \
    --instance_prompt "anime style, xianxia animation style, å‡¡äººä¿®ä»™ä¼  style"
```

### æ­¥éª¤3ï¼šé…ç½®ä½¿ç”¨

åœ¨ `config.yaml` ä¸­é…ç½®é£æ ¼LoRAï¼š

```yaml
image:
  lora:
    style_lora:
      enabled: true
      weights_path: models/lora/anime_style/pytorch_lora_weights.safetensors
      adapter_name: anime_style
      alpha: 0.7
```

### æ­¥éª¤4ï¼šç”Ÿæˆæµ‹è¯•

```bash
python main.py --script test_scene.json --output test_style
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å‚è€ƒå›¾åƒé€‰æ‹©**ï¼š
   - é€‰æ‹©é«˜è´¨é‡ã€é£æ ¼ç»Ÿä¸€çš„å›¾åƒ
   - è¦†ç›–ä¸åŒåœºæ™¯ç±»å‹
   - ç¡®ä¿é£æ ¼ä¸€è‡´æ€§

2. **LoRAè®­ç»ƒ**ï¼š
   - ä½¿ç”¨è¶³å¤Ÿçš„è®­ç»ƒæ­¥æ•°ï¼ˆ800-1200ï¼‰
   - å®šæœŸæ£€æŸ¥è®­ç»ƒæ•ˆæœ
   - é¿å…è¿‡æ‹Ÿåˆ

3. **æƒé‡è°ƒèŠ‚**ï¼š
   - æ ¹æ®åœºæ™¯ç±»å‹åŠ¨æ€è°ƒæ•´
   - å¹³è¡¡è§’è‰²å’Œé£æ ¼
   - æµ‹è¯•ä¸åŒæƒé‡ç»„åˆ

4. **è´¨é‡æ§åˆ¶**ï¼š
   - ç”Ÿæˆåæ£€æŸ¥é£æ ¼ä¸€è‡´æ€§
   - å¯¹æ¯”åŸåŠ¨æ¼«å’Œæ–°ç”Ÿæˆå†…å®¹
   - æ ¹æ®æ•ˆæœè°ƒæ•´å‚æ•°

## ğŸ¯ æ€»ç»“

**æ¨èä½¿ç”¨æ··åˆæ–¹æ¡ˆ**ï¼š
- é£æ ¼LoRAï¼šå­¦ä¹ æ•´ä½“é£æ ¼ï¼Œä¿è¯ç»Ÿä¸€æ€§
- IP-Adapter Plusï¼šè¡¥å……åœºæ™¯ç»†èŠ‚ï¼Œæé«˜çµæ´»æ€§
- è§’è‰²LoRA + InstantIDï¼šä¿æŒè§’è‰²ä¸€è‡´æ€§

è¿™æ ·æ—¢èƒ½å­¦ä¹ æ•´ä½“é£æ ¼ï¼Œåˆèƒ½çµæ´»ç”Ÿæˆç¬¦åˆè§£è¯´åœºæ™¯çš„æ–°å†…å®¹ï¼


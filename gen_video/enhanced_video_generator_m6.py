#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘ç”Ÿæˆå™¨å¢å¼ºæ¨¡å—
åœ¨ VideoGenerator åŸºç¡€ä¸Šæ·»åŠ èº«ä»½éªŒè¯åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
    from enhanced_video_generator_m6 import EnhancedVideoGeneratorM6
    
    generator = EnhancedVideoGeneratorM6("config.yaml")
    video_path, result = generator.generate_video_with_identity_check(
        image_path="input.png",
        output_path="output.mp4",
        reference_image="reference.jpg",
        scene=scene_config
    )

Author: AI Video Team
Date: 2025-12-18
Project: M6 - è§†é¢‘èº«ä»½ä¿æŒ
"""

import os
import shutil
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

from video_generator import VideoGenerator
from video_identity_verifier import (
    VideoIdentityVerifier,
    IdentityVerificationConfig,
    VerificationResult,
    ShotLanguageAdvisor,
    ShotLanguage
)

logger = logging.getLogger(__name__)


class EnhancedVideoGeneratorM6(VideoGenerator):
    """
    å¢å¼ºç‰ˆè§†é¢‘ç”Ÿæˆå™¨ - M6 èº«ä»½ä¿æŒ
    
    åœ¨ VideoGenerator åŸºç¡€ä¸Šæ·»åŠ :
    1. èº«ä»½ä¸€è‡´æ€§éªŒè¯
    2. å¤±è´¥é‡è¯•
    3. é•œå¤´è¯­è¨€å¢å¼º
    """
    
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆç”Ÿæˆå™¨"""
        super().__init__(config_path)
        
        # èº«ä»½éªŒè¯é…ç½®
        identity_config = self.video_config.get("identity_verification", {})
        
        self.identity_config = IdentityVerificationConfig(
            similarity_threshold=identity_config.get("similarity_threshold", 0.70),
            similarity_discard=identity_config.get("similarity_discard", 0.65),
            drift_threshold=identity_config.get("drift_threshold", 0.50),
            max_drift_ratio=identity_config.get("max_drift_ratio", 0.10),
            min_face_detect_ratio=identity_config.get("min_face_detect_ratio", 0.80),
            min_similarity_floor=float(identity_config.get("min_similarity_floor", 0.30)),
            max_retries=identity_config.get("max_retries", 3),
            retry_reduce_motion=identity_config.get("retry_reduce_motion", True),
            retry_adjust_prompt=identity_config.get("retry_adjust_prompt", True),
            include_last_n_frames=int(identity_config.get("include_last_n_frames", 3)),
            shot_type_tolerance=identity_config.get("shot_type_tolerance"),
        )

        # éªŒè¯é‡‡æ ·é…ç½®ï¼ˆé¿å…æ¯æ¬¡ç¡¬ç¼–ç ï¼‰
        self.verification_sample_interval = int(identity_config.get("sample_interval", 5))
        self.verification_max_frames = int(identity_config.get("max_frames", 30))
        
        # æ‡’åŠ è½½éªŒè¯å™¨
        self._verifier = None
        
        logger.info("EnhancedVideoGeneratorM6 åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  èº«ä»½éªŒè¯é˜ˆå€¼: {self.identity_config.similarity_threshold}")
    
    def _get_verifier(self) -> VideoIdentityVerifier:
        """è·å–éªŒè¯å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._verifier is None:
            self._verifier = VideoIdentityVerifier(self.identity_config)
        return self._verifier

    def _promote_video_to_output(self, src_video_path: str, dst_output_path: str) -> str:
        """
        å°†é€šè¿‡éªŒè¯çš„å°è¯•è§†é¢‘æå‡ä¸ºæœ€ç»ˆè¾“å‡ºï¼ˆè¦†ç›– dst_output_pathï¼‰ã€‚
        è¿™æ ·è°ƒç”¨æ–¹æ— è®ºæ˜¯å¦å¿½ç•¥è¿”å›å€¼ï¼Œéƒ½èƒ½æ‹¿åˆ°â€œé€šè¿‡éªŒè¯â€çš„æœ€ç»ˆè§†é¢‘ã€‚
        """
        if not src_video_path or not dst_output_path:
            return dst_output_path

        src = Path(src_video_path)
        dst = Path(dst_output_path)
        if not src.exists():
            logger.warning(f"æ— æ³•æå‡è§†é¢‘ï¼šæºæ–‡ä»¶ä¸å­˜åœ¨: {src}")
            return dst_output_path

        dst.parent.mkdir(parents=True, exist_ok=True)

        # è‹¥è·¯å¾„ä¸åŒåˆ™å¤åˆ¶è¦†ç›–ï¼›ä¿ç•™ attempt æ–‡ä»¶ï¼Œé¿å…ä¸¢å¤±è¯Šæ–­ç´ æ
        if src.resolve() != dst.resolve():
            try:
                shutil.copy2(str(src), str(dst))
                logger.info(f"å·²å°†é€šè¿‡éªŒè¯çš„è§†é¢‘å¤åˆ¶ä¸ºæœ€ç»ˆè¾“å‡º: {dst}")
            except Exception as e:
                logger.warning(f"å¤åˆ¶æœ€ç»ˆè¾“å‡ºå¤±è´¥ï¼ˆå°†è¿”å›æºè·¯å¾„ï¼‰: {e}")
                return src_video_path

        return str(dst)

    def _apply_layered_retry_tuning(
        self,
        scene: Dict[str, Any],
        shot_type: str,
        result: VerificationResult,
    ) -> str:
        """
        åˆ†å±‚è°ƒå‚ï¼šæ ¹æ®å¤±è´¥ç±»å‹/ä¸¥é‡åº¦è°ƒæ•´ scene ä¸ hunyuanvideo é…ç½®ã€‚
        è¿”å›ï¼ˆå¯èƒ½æ›´æ–°åçš„ï¼‰shot_typeã€‚
        """
        identity_cfg = self.video_config.get("identity_verification", {}) or {}
        policy = identity_cfg.get("layered_tuning", {}) or {}

        # é˜ˆå€¼/ç­–ç•¥å‚æ•°ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
        catastrophic_min_sim = float(policy.get("catastrophic_min_similarity", 0.15))
        high_drift_ratio = float(policy.get("high_drift_ratio", 0.12))
        low_face_ratio = float(policy.get("low_face_detect_ratio", 0.80))
        inc_small = int(policy.get("steps_increase_small", 4))
        inc_large = int(policy.get("steps_increase_large", 8))
        inc_cat = int(policy.get("steps_increase_catastrophic", 12))
        steps_max = int(policy.get("steps_max", 45))
        downgrade_motion = bool(policy.get("downgrade_motion_on_retry", True))

        # å¤±è´¥ç±»å‹åˆ†å±‚
        catastrophic = (result.min_similarity is not None and result.min_similarity < catastrophic_min_sim)
        drift_heavy = (result.drift_ratio is not None and result.drift_ratio > high_drift_ratio)
        face_low = (result.face_detect_ratio is not None and result.face_detect_ratio < low_face_ratio)

        # 1) prompt å±‚ï¼šæ›´å¼ºçš„â€œé”è„¸/ç¨³å®šâ€çº¦æŸ
        if catastrophic:
            scene["prompt"] = (
                "same face, no morphing, no face change, stable identity, "
                "avoid large head turn, avoid fast rotation, "
                "keep facial features consistent, "
                + scene.get("prompt", "")
            )
            logger.info("  åˆ†å±‚è°ƒå‚: catastrophic(min_similarityä½) â†’ å¼ºåŒ–é”è„¸ prompt")
        elif drift_heavy:
            scene["prompt"] = "stable face details, consistent facial features, " + scene.get("prompt", "")
            logger.info("  åˆ†å±‚è°ƒå‚: drift_ratioé«˜ â†’ å¼ºåŒ–é¢éƒ¨ä¸€è‡´æ€§ prompt")
        elif face_low:
            scene["prompt"] = "face clearly visible, front-facing, avoid occlusion, " + scene.get("prompt", "")
            logger.info("  åˆ†å±‚è°ƒå‚: äººè„¸æ£€æµ‹ç‡ä½ â†’ å¼ºåŒ–â€œå¯è§è„¸â€ prompt")

        # 2) è¿åŠ¨å±‚ï¼šæ¼‚ç§»/å´©è„¸é€šå¸¸å…ˆå‡è¿åŠ¨
        scene["prompt"] = "minimal slow movement, static camera, " + scene.get("prompt", "")
        if downgrade_motion:
            mi = scene.get("motion_intensity")
            if mi == "dynamic":
                scene["motion_intensity"] = "moderate"
                logger.info("  åˆ†å±‚è°ƒå‚: motion_intensity dynamic -> moderate")
            elif mi == "moderate" and (catastrophic or drift_heavy):
                scene["motion_intensity"] = "gentle"
                logger.info("  åˆ†å±‚è°ƒå‚: motion_intensity moderate -> gentle")

        # 3) é•œå¤´å±‚ï¼šé«˜æ¼‚ç§»/å´©è„¸/æ£€å‡ºå·®æ—¶ï¼Œä¼˜å…ˆå›åˆ°æ›´å®‰å…¨çš„ mediumï¼ˆé¿å… close / medium_closeï¼‰
        if (catastrophic or drift_heavy or face_low) and shot_type in ("close", "extreme_close", "medium_close"):
            shot_type = "medium"
            logger.info("  åˆ†å±‚è°ƒå‚: é«˜é£é™©å¤±è´¥ â†’ shot_type å›é€€åˆ° medium")

        # åŒæ­¥ prompt ä¸­çš„é•œå¤´è¯ï¼ˆé¿å… prompt ä»ç„¶å« close-up è¯±å¯¼ï¼‰
        p = scene.get("prompt", "")
        for bad in ["extreme close-up", "extreme close up", "close-up", "close up", "medium close-up", "medium close up"]:
            p = p.replace(bad, "medium shot")
        scene["prompt"] = p

        # ç§»é™¤é«˜é£é™©è¿åŠ¨è¯ï¼ˆé¿å…æ®‹ç•™çš„ dynamic/fast å¼ºè¿åŠ¨æè¿°å½±å“åç»­é‡è¯•ï¼‰
        for bad in ["dynamic action", "fast movement", "energetic", "rapid movement", "strong motion"]:
            scene["prompt"] = scene["prompt"].replace(bad, "")

        # 4) æ­¥æ•°å±‚ï¼šä¸¥é‡é—®é¢˜åŠ å¤§æ­¥æ•°ï¼ˆæ›´ç¨³å®šï¼‰
        try:
            hv = self.video_config.get("hunyuanvideo", {}) or {}
            cur_steps = int(hv.get("num_inference_steps", 25))
            if catastrophic:
                inc = inc_cat
            elif drift_heavy:
                inc = inc_large
            else:
                inc = inc_small
            new_steps = min(cur_steps + inc, steps_max)
            self.video_config.setdefault("hunyuanvideo", {})
            self.video_config["hunyuanvideo"]["num_inference_steps"] = new_steps
            logger.info(f"  åˆ†å±‚è°ƒå‚: num_inference_steps {cur_steps} -> {new_steps}")
        except Exception:
            pass

        # 5) ç”Ÿæˆå‚æ•°å±‚ï¼šè¿›ä¸€æ­¥é™ä½è¿åŠ¨å™ªå£°ï¼ˆé€šè¿‡ scene['_gen_kwargs'] ä¼ ç»™ VideoGeneratorï¼‰
        try:
            gen_kwargs = scene.setdefault("_gen_kwargs", {})
            base_mb = float(gen_kwargs.get("motion_bucket_id", self.video_config.get("motion_bucket_id", 1.5)))
            base_noise = float(gen_kwargs.get("noise_aug_strength", self.video_config.get("noise_aug_strength", 0.00025)))
            if catastrophic or drift_heavy:
                gen_kwargs["motion_bucket_id"] = min(base_mb, 1.6)
                gen_kwargs["noise_aug_strength"] = min(base_noise, 0.00025)
                logger.info(
                    f"  åˆ†å±‚è°ƒå‚: gen_kwargs motion_bucket_id->{gen_kwargs['motion_bucket_id']}, noise_aug_strength->{gen_kwargs['noise_aug_strength']}"
                )
        except Exception:
            pass

        # 6) guidance_scale å±‚ï¼šæç«¯å´©è„¸æ—¶ç•¥é™ guidanceï¼ˆå‡å°‘è¿‡åº¦ç‰µå¼•å¯¼è‡´çš„äººè„¸ç•¸å˜é£é™©ï¼‰
        try:
            hv = self.video_config.get("hunyuanvideo", {}) or {}
            cur_g = float(hv.get("guidance_scale", 7.5))
            if catastrophic:
                new_g = max(6.5, cur_g - 0.5)
            elif drift_heavy:
                new_g = max(7.0, cur_g - 0.3)
            else:
                new_g = cur_g
            if new_g != cur_g:
                self.video_config.setdefault("hunyuanvideo", {})
                self.video_config["hunyuanvideo"]["guidance_scale"] = new_g
                logger.info(f"  åˆ†å±‚è°ƒå‚: guidance_scale {cur_g:.2f} -> {new_g:.2f}")
        except Exception:
            pass

        return shot_type
    
    def generate_video_with_identity_check(
        self,
        image_path: str,
        output_path: str,
        reference_image: Optional[str] = None,
        scene: Optional[Dict[str, Any]] = None,
        shot_type: str = "medium",
        enable_verification: bool = True,
        max_retries: Optional[int] = None,
        **kwargs
    ) -> Tuple[str, Optional[VerificationResult]]:
        """
        ç”Ÿæˆè§†é¢‘å¹¶éªŒè¯èº«ä»½ä¸€è‡´æ€§
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆAnchor å›¾ï¼‰
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            reference_image: å‚è€ƒå›¾åƒè·¯å¾„ï¼ˆç”¨äºèº«ä»½éªŒè¯ï¼Œå¦‚æœä¸ä¼ åˆ™ä½¿ç”¨ image_pathï¼‰
            scene: åœºæ™¯é…ç½®
            shot_type: é•œå¤´ç±»å‹ (wide/medium/close)
            enable_verification: æ˜¯å¦å¯ç”¨éªŒè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆè¦†ç›–é…ç½®ï¼‰
            **kwargs: å…¶ä»–ä¼ é€’ç»™ generate_video çš„å‚æ•°
            
        Returns:
            (è§†é¢‘è·¯å¾„, éªŒè¯ç»“æœ)
        """
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå‚è€ƒå›¾ï¼Œä½¿ç”¨è¾“å…¥å›¾
        if reference_image is None:
            reference_image = image_path
        
        # é‡è¯•æ¬¡æ•°ï¼ˆæ³¨æ„ï¼šmax_retries=0 æ˜¯åˆæ³•å€¼ï¼Œè¡¨ç¤ºä¸é‡è¯•ï¼›ä¸èƒ½ç”¨ `or`ï¼‰
        if max_retries is None:
            max_retries = self.identity_config.max_retries
        
        # ä» scene ä¸­è·å–æˆ–æ„å»º prompt
        prompt = ""
        if scene:
            prompt = scene.get("prompt") or scene.get("description") or ""
        
        # å¢å¼º promptï¼ˆæ·»åŠ èº«ä»½ç¨³å®šæ€§å…³é”®è¯ï¼‰
        shot_enum = getattr(ShotLanguage, shot_type.upper(), ShotLanguage.MEDIUM)
        enhanced_prompt = ShotLanguageAdvisor.enhance_prompt_for_stability(prompt, shot_enum)
        
        # æ›´æ–° scene ä¸­çš„ prompt
        if scene is None:
            scene = {}
        scene["prompt"] = enhanced_prompt
        
        # æ·»åŠ ç¨³å®šæ€§ negative prompt
        stability_negative = ShotLanguageAdvisor.get_negative_prompt_for_stability()
        existing_negative = scene.get("negative_prompt", "")
        if existing_negative:
            scene["negative_prompt"] = f"{existing_negative}, {stability_negative}"
        else:
            scene["negative_prompt"] = stability_negative
        
        retry_count = 0
        best_result = None
        best_video_path = None

        # è®©é‡è¯•çœŸæ­£äº§ç”Ÿâ€œä¸åŒæ ·æœ¬â€ï¼šæ¯æ¬¡å°è¯•è®¾ç½®ä¸åŒ seed
        identity_cfg = self.video_config.get("identity_verification", {})
        base_seed = identity_cfg.get("seed_base", 42)
        seed_step = identity_cfg.get("seed_step", 1)
        try:
            base_seed = int(base_seed)
            seed_step = int(seed_step)
        except Exception:
            base_seed, seed_step = 42, 1

        # è®°å½•åŸå§‹ hunyuan å‚æ•°ï¼ˆç”¨äºé‡è¯•æ—¶ä¸´æ—¶è°ƒå‚ï¼‰
        hunyuan_cfg = self.video_config.get("hunyuanvideo", {})
        original_steps = hunyuan_cfg.get("num_inference_steps")
        original_guidance = hunyuan_cfg.get("guidance_scale")

        # ä»…å…è®¸é€ä¼ ç»™ VideoGenerator.generate_video çš„å‚æ•°ï¼ˆé¿å… **kwargs è¯¯ä¼ å¯¼è‡´å´©æºƒï¼‰
        allowed_kwargs = {"num_frames", "fps", "motion_bucket_id", "noise_aug_strength"}
        passthrough = {k: v for k, v in kwargs.items() if k in allowed_kwargs and v is not None}
        dropped = sorted([k for k in kwargs.keys() if k not in allowed_kwargs])
        if dropped:
            logger.warning(f"å¿½ç•¥ä¸æ”¯æŒçš„å‚æ•°: {dropped}")

        # ä¸¢å¼ƒçº§åˆ«çš„å…œåº•é‡è¯•ï¼ˆhard case å¯èƒ½é  seed æ‰èƒ½æ•‘å›ï¼‰
        discard_retry_used = 0
        retry_on_discard = bool(identity_cfg.get("retry_on_discard", False))
        try:
            discard_retry_max = int(identity_cfg.get("discard_retry_max", 0) or 0)
        except Exception:
            discard_retry_max = 0
        
        while retry_count <= max_retries:
            # æ„å»ºè¾“å‡ºè·¯å¾„
            if retry_count > 0:
                base, ext = os.path.splitext(output_path)
                current_output = f"{base}_attempt{retry_count}{ext}"
            else:
                current_output = output_path
            
            logger.info(f"ç”Ÿæˆè§†é¢‘ (å°è¯• {retry_count + 1}/{max_retries + 1})")
            logger.info(f"  é•œå¤´ç±»å‹: {shot_type}")
            # è®¾ç½®æœ¬æ¬¡å°è¯•çš„ seedï¼ˆVideoGenerator ä¼šè¯»å– scene['seed']ï¼‰
            scene["seed"] = base_seed + retry_count * seed_step
            
            try:
                # åˆå¹¶åˆ†å±‚è°ƒå‚å†™å…¥çš„ç”Ÿæˆå‚æ•°è¦†ç›–ï¼ˆä¾‹å¦‚ motion_bucket_id/noise_aug_strengthï¼‰
                attempt_kwargs = dict(passthrough)
                extra = scene.get("_gen_kwargs") if isinstance(scene, dict) else None
                if isinstance(extra, dict) and extra:
                    for k, v in extra.items():
                        if k in allowed_kwargs and v is not None:
                            attempt_kwargs[k] = v

                # è°ƒç”¨çˆ¶ç±»æ–¹æ³•ç”Ÿæˆè§†é¢‘
                video_path = self.generate_video(
                    image_path=image_path,
                    output_path=current_output,
                    scene=scene,
                    **attempt_kwargs
                )
                
                if video_path is None:
                    logger.error("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¿”å› None")
                    retry_count += 1
                    continue
                
                # å¦‚æœä¸å¯ç”¨éªŒè¯ï¼Œç›´æ¥è¿”å›
                if not enable_verification:
                    logger.info("èº«ä»½éªŒè¯å·²ç¦ç”¨ï¼Œç›´æ¥è¿”å›è§†é¢‘")
                    return video_path, None
                
                # éªŒè¯èº«ä»½ä¸€è‡´æ€§
                verifier = self._get_verifier()
                result = verifier.verify_video(
                    video_path=video_path,
                    reference_image=reference_image,
                    shot_type=shot_type,
                    sample_interval=self.verification_sample_interval,
                    max_frames=self.verification_max_frames
                )
                
                # è®°å½•æœ€ä½³ç»“æœ
                if best_result is None or result.avg_similarity > best_result.avg_similarity:
                    best_result = result
                    best_video_path = video_path
                
                # å¦‚æœé€šè¿‡éªŒè¯
                if result.passed:
                    logger.info(f"âœ… è§†é¢‘èº«ä»½éªŒè¯é€šè¿‡ï¼ç›¸ä¼¼åº¦: {result.avg_similarity:.3f}")
                    final_path = self._promote_video_to_output(video_path, output_path)
                    return final_path, result
                
                # å¦‚æœåº”è¯¥ä¸¢å¼ƒ
                if result.should_discard:
                    if retry_on_discard and discard_retry_used < discard_retry_max and retry_count < max_retries:
                        discard_retry_used += 1
                        logger.warning(
                            f"âŒ è§†é¢‘è´¨é‡è¿‡ä½(ä¸¢å¼ƒçº§)ï¼Œä½†å¯ç”¨ retry_on_discardï¼šç»§ç»­é‡è¯•ï¼ˆ{discard_retry_used}/{discard_retry_max}ï¼‰"
                        )
                        shot_type = self._apply_layered_retry_tuning(scene, shot_type, result)
                        retry_count += 1
                        continue

                    logger.warning("âŒ è§†é¢‘è´¨é‡è¿‡ä½ï¼Œåœæ­¢é‡è¯•")
                    break
                
                # å‡†å¤‡é‡è¯•
                if result.should_retry and retry_count < max_retries:
                    logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯•...")

                    # åˆ†å±‚è°ƒå‚ï¼šæŒ‰å¤±è´¥ç±»å‹å‡çº§å‚æ•°
                    shot_type = self._apply_layered_retry_tuning(scene, shot_type, result)

                    # å…¼å®¹æ—§ hintï¼šå¦‚æœæç¤ºè¦åˆ‡æ¢ä¸ºä¸­æ™¯ï¼Œè¿›ä¸€æ­¥åš prompt æ›¿æ¢
                    if result.retry_hints.get("use_medium_shot"):
                        scene["prompt"] = scene["prompt"].replace("close-up", "medium shot")
                        scene["prompt"] = scene["prompt"].replace("close up", "medium shot")
                        logger.info("  è°ƒæ•´: prompt æ›¿æ¢ close-up -> medium shot")
                
                retry_count += 1
                
            except Exception as e:
                logger.error(f"è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                retry_count += 1

        # æ¢å¤åŸå§‹æ­¥æ•°ï¼ˆé¿å…æ±¡æŸ“åç»­ç”Ÿæˆï¼‰
        try:
            if original_steps is not None:
                self.video_config.setdefault("hunyuanvideo", {})
                self.video_config["hunyuanvideo"]["num_inference_steps"] = original_steps
            if original_guidance is not None:
                self.video_config.setdefault("hunyuanvideo", {})
                self.video_config["hunyuanvideo"]["guidance_scale"] = original_guidance
        except Exception:
            pass
        
        # è¿”å›æœ€ä½³ç»“æœ
        if best_video_path:
            logger.info(f"è¿”å›æœ€ä½³å°è¯•ç»“æœ: ç›¸ä¼¼åº¦ {best_result.avg_similarity:.3f}")
            final_path = self._promote_video_to_output(best_video_path, output_path)
            return final_path, best_result
        else:
            logger.error("æ‰€æœ‰å°è¯•éƒ½å¤±è´¥")
            return None, VerificationResult(
                passed=False,
                avg_similarity=0.0,
                min_similarity=0.0,
                drift_ratio=1.0,
                face_detect_ratio=0.0,
                issues=["æ‰€æœ‰ç”Ÿæˆå°è¯•éƒ½å¤±è´¥"],
                should_retry=False,
                should_discard=True,
                retry_hints={}
            )
    
    def unload_verifier(self):
        """å¸è½½éªŒè¯å™¨"""
        if self._verifier is not None:
            self._verifier.unload()
            self._verifier = None
    
    def unload_all(self):
        """å¸è½½æ‰€æœ‰æ¨¡å‹"""
        self.unload_verifier()
        self.unload_model()


def quick_test():
    """å¿«é€Ÿæµ‹è¯•"""
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 60)
    print("å¢å¼ºç‰ˆè§†é¢‘ç”Ÿæˆå™¨ M6 æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ–‡ä»¶
    test_image = Path("reference_image/hanli_mid.jpg")
    
    if not test_image.exists():
        print(f"âš  æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
        print("è·³è¿‡å®é™…ç”Ÿæˆæµ‹è¯•")
    else:
        print(f"âœ“ æ‰¾åˆ°æµ‹è¯•å›¾åƒ: {test_image}")
    
    # æµ‹è¯•åˆå§‹åŒ–
    print("\nåˆå§‹åŒ–ç”Ÿæˆå™¨...")
    try:
        generator = EnhancedVideoGeneratorM6("config.yaml")
        print(f"âœ“ ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"  èº«ä»½éªŒè¯é˜ˆå€¼: {generator.identity_config.similarity_threshold}")
        print(f"  æœ€å¤§é‡è¯•æ¬¡æ•°: {generator.identity_config.max_retries}")
        
        # æµ‹è¯•é•œå¤´å»ºè®®
        print("\né•œå¤´æ¼‚ç§»é£é™©:")
        for shot in ShotLanguage:
            risk = ShotLanguageAdvisor.get_drift_risk(shot)
            print(f"  {shot.value}: {risk}")
        
        generator.unload_all()
        print("\nâœ… æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    quick_test()

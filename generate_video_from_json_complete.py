#!/usr/bin/env python3
"""
æ ¹æ® renjie/episode_*.json æ–‡ä»¶ç”Ÿæˆå®Œæ•´è§†é¢‘ï¼ˆå®Œæ•´å·¥ä½œæµï¼‰
å·¥ä½œæµç¨‹ï¼š
1. è¯»å–JSONæ–‡ä»¶ï¼Œæå–narrationæ–‡æœ¬
2. ä½¿ç”¨TTSç”Ÿæˆé…éŸ³ï¼ˆå…ˆè¯»é…éŸ³ï¼Œæ‰èƒ½ç¡®å®šæ¯ä¸ªåœºæ™¯å¯¹åº”çš„æ—¶é•¿ï¼‰
3. è·å–å®é™…éŸ³é¢‘æ—¶é•¿
4. æ ¹æ®éŸ³é¢‘æ—¶é•¿å’Œåœºæ™¯æè¿°æ£€ç´¢åŸè§†é¢‘ï¼Œæˆ–AIç”Ÿæˆè§†é¢‘
5. æ·»åŠ å¼€å¤´å’Œç»“å°¾è§†é¢‘
6. æ‹¼æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
7. åç»­æ·»åŠ BGM
"""

import json
import argparse
import subprocess
import os
import sys
import shutil
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# æ·»åŠ gen_videoè·¯å¾„ä»¥ä½¿ç”¨TTSå’ŒAIç”ŸæˆåŠŸèƒ½
sys.path.insert(0, str(Path(__file__).parent / "gen_video"))
# æ·»åŠ tools/video_processingè·¯å¾„ä»¥ä½¿ç”¨è§†é¢‘æ£€ç´¢åŠŸèƒ½
sys.path.insert(0, str(Path(__file__).parent / "tools" / "video_processing"))

from search_scenes import load_index, load_scene_metadata, hybrid_search, build_keyword_index
from sentence_transformers import SentenceTransformer
from smart_scene_matcher import decision_make
import faiss

# å¯¼å…¥gen_videoçš„æ¨¡å—
try:
    from tts_generator import TTSGenerator
    from image_generator import ImageGenerator
    from video_generator import VideoGenerator
    from video_composer import VideoComposer
    from subtitle_generator import SubtitleGenerator
    GEN_VIDEO_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥gen_videoæ¨¡å—: {e}")
    print("  å°†åªæ”¯æŒåŸè§†é¢‘æ£€ç´¢ï¼Œä¸æ”¯æŒAIç”Ÿæˆå’ŒBGM")
    GEN_VIDEO_AVAILABLE = False

def get_media_duration(media_path: Path) -> float:
    """è·å–è§†é¢‘æˆ–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
    if not media_path.exists():
        return 0.0
    cmd = [
        'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        str(media_path)
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    try:
        return float(result.stdout.strip())
    except:
        return 0.0

def trim_video(input_path: Path, output_path: Path, duration: float):
    """è£å‰ªè§†é¢‘åˆ°æŒ‡å®šæ—¶é•¿ï¼ˆé‡æ–°ç¼–ç ä¿è¯æ—¶é—´æˆ³ç²¾å‡†ï¼‰"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    cmd = [
        'ffmpeg', '-hide_banner', '-loglevel', 'error',
        '-y',
        '-i', str(input_path),
        '-t', f"{duration:.3f}",
        '-c:v', 'libx264',
        '-preset', 'veryfast',
        '-crf', '20',
        '-c:a', 'aac',
        '-ar', '48000',
        '-ac', '2',
        str(output_path)
    ]
    subprocess.run(cmd, capture_output=True, text=True, check=True)

def concatenate_videos(video_paths: List[Path], output_path: Path):
    """æ‹¼æ¥å¤šä¸ªè§†é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨-c copyå¿«é€Ÿæ‹¼æ¥ï¼‰"""
    if len(video_paths) == 1:
        import shutil
        shutil.copy2(video_paths[0], output_path)
        return
    
    concat_file = output_path.parent / f"concat_{output_path.stem}.txt"
    try:
        with open(concat_file, 'w') as f:
            for video_path in video_paths:
                if video_path.exists():
                    f.write(f"file '{video_path.absolute()}'\n")
        
        cmd = [
            'ffmpeg', '-f', 'concat', '-safe', '0',
            '-i', str(concat_file),
            '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµï¼ˆå¿«é€Ÿï¼‰
            '-y',
            str(output_path)
        ]
        subprocess.run(cmd, capture_output=True, text=True, check=True)
    finally:
        if concat_file.exists():
            concat_file.unlink()

def assemble_scene_videos(
    matched_videos: List[Path],
    target_duration: float,
    temp_root: Path,
    label: str,
    video_base_dir: Path,
    primary_scene_key: Optional[str] = None,
    max_adjacent: int = 3
) -> Tuple[Optional[Path], float]:
    """
    å°†å¤šä¸ªåŸè§†é¢‘ç‰‡æ®µè£å‰ª/æ‹¼æ¥ï¼Œä½¿å…¶æ€»æ—¶é•¿ç²¾ç¡®åŒ¹é… target_durationã€‚
    è¿”å› (assembled_path, remaining_shortfall)
    """
    tolerance = 0.05  # 50ms å®¹å·®
    attempt_videos = [Path(v) for v in matched_videos]
    attempt = 0
    
    while True:
        assembled_path, remaining = _assemble_once(
            attempt_videos,
            target_duration,
            temp_root,
            f"{label}_try{attempt}",
            tolerance
        )
        if assembled_path or remaining <= tolerance:
            return assembled_path, max(remaining, 0.0)
        
        if not primary_scene_key or not video_base_dir:
            return None, remaining
        
        extras = find_adjacent_scene_videos(
            primary_scene_key,
            video_base_dir,
            max_extra=max_adjacent,
            exclude_paths=attempt_videos
        )
        if not extras:
            print("    âš ï¸ æ— æ³•æ‰¾åˆ°ç›¸é‚»ç‰‡æ®µï¼Œæ”¾å¼ƒåŸè§†é¢‘æ‹¼æ¥")
            return None, remaining
        
        print(f"    â„¹ æ—¶é•¿ä¸è¶³ï¼Œè¿½åŠ ç›¸é‚»ç‰‡æ®µ {len(extras)} ä¸ªï¼Œé‡æ–°å°è¯•æ‹¼æ¥")
        attempt_videos.extend(extras)
        attempt += 1

def _assemble_once(
    video_list: List[Path],
    target_duration: float,
    temp_root: Path,
    label: str,
    tolerance: float
) -> Tuple[Optional[Path], float]:
    temp_root.mkdir(parents=True, exist_ok=True)
    remaining = max(target_duration, 0.0)
    assembled_segments: List[Path] = []
    
    for idx, video in enumerate(video_list):
        src_path = Path(video)
        if not src_path.exists():
            print(f"    âš ï¸ åŒ¹é…è§†é¢‘ä¸å­˜åœ¨ï¼Œè·³è¿‡: {src_path}")
            continue
        
        duration = get_media_duration(src_path)
        if duration <= 0:
            print(f"    âš ï¸ æ— æ³•è·å–è§†é¢‘æ—¶é•¿ï¼Œè·³è¿‡: {src_path}")
            continue
        
        # ä¿ç•™ä¸‰ä½å°æ•°ï¼Œé¿å…ç´¯è®¡è¯¯å·®
        clip_duration = round(min(duration, remaining), 3)
        if clip_duration <= 0:
            break
        
        segment_path = temp_root / f"{label}_seg_{idx:02d}.mp4"
        segment_path.parent.mkdir(parents=True, exist_ok=True)
        trim_video(src_path, segment_path, clip_duration)
        assembled_segments.append(segment_path)
        remaining -= clip_duration
        
        if remaining <= tolerance:
            remaining = 0.0
            break
    
    if not assembled_segments:
        return None, target_duration
    
    if remaining > tolerance:
        for seg in assembled_segments:
            if seg.exists():
                seg.unlink(missing_ok=True)
        return None, remaining
    
    if len(assembled_segments) == 1:
        return assembled_segments[0], remaining
    
    final_path = temp_root / f"{label}_assembled.mp4"
    concatenate_videos(assembled_segments, final_path)
    return (final_path if final_path.exists() else None), remaining
def find_scene_video(episode_id: str, scene_id: str, base_dir: Path) -> Optional[Path]:
    """æŸ¥æ‰¾åœºæ™¯è§†é¢‘æ–‡ä»¶"""
    possible_names = [
        f"episode_{episode_id}_clean-Scene-{scene_id:03d}.mp4",
        f"episode_{episode_id}_clean-Scene-{scene_id}.mp4",
        f"{episode_id}_scene_{scene_id:03d}.mp4",
        f"{episode_id}_scene_{scene_id}.mp4",
    ]
    
    episode_dir = base_dir / f"episode_{episode_id}" / "scenes"
    
    for name in possible_names:
        video_path = episode_dir / name
        if video_path.exists():
            return video_path
    
    # å°è¯•åœ¨scenesç›®å½•ä¸­æŸ¥æ‰¾
    scene_files = list(episode_dir.glob(f"*Scene-{scene_id:03d}*.mp4"))
    if not scene_files:
        scene_files = list(episode_dir.glob(f"*Scene-{scene_id}*.mp4"))
    if scene_files:
        return scene_files[0]
    
    return None

def run_upscale_only(
    video_path: Path,
    output_path: Optional[Path],
    config_path: Optional[Path]
) -> bool:
    """
    ä»…æ‰§è¡Œ Real-ESRGAN è¶…åˆ†å¤„ç†ï¼ˆè·³è¿‡å®Œæ•´ç”Ÿæˆæµç¨‹ï¼‰
    """
    if not video_path.exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥è§†é¢‘ä¸å­˜åœ¨: {video_path}")
        return False
    
    if not config_path or not config_path.exists():
        config_path = Path(__file__).parent.parent.parent / "gen_video" / "config.yaml"
        if not config_path.exists():
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° gen_video/config.yamlï¼Œæ— æ³•æ‰§è¡Œè¶…åˆ†")
            return False
    
    try:
        from video_composer import VideoComposer
    except ImportError as exc:
        print(f"âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ VideoComposer: {exc}")
        return False
    
    composer = VideoComposer(str(config_path))
    post_cfg = composer.composition_config.get("postprocess", {})
    if not post_cfg.get("enabled", False):
        print("âš  æç¤º: é…ç½®ä¸­ postprocess.enabled = falseï¼Œå·²ä¸´æ—¶å¯ç”¨ä»¥æ‰§è¡Œè¶…åˆ†")
        post_cfg = dict(post_cfg)
        post_cfg["enabled"] = True
    
    try:
        upscaled_path = composer.postprocess_with_realesrgan(str(video_path), post_cfg)
    except Exception as exc:
        print(f"âŒ Real-ESRGAN è¶…åˆ†å¤±è´¥: {exc}")
        return False
    
    final_path = Path(upscaled_path)
    if output_path:
        try:
            shutil.move(str(final_path), str(output_path))
            final_path = output_path
        except Exception as exc:
            print(f"âš  è¶…åˆ†ç»“æœç§»åŠ¨åˆ° {output_path} å¤±è´¥: {exc}")
    
    print(f"âœ… è¶…åˆ†å®Œæˆ: {final_path}")
    return True

def parse_scene_key(scene_key: Optional[str]) -> Optional[Tuple[str, int]]:
    if not scene_key or '_scene_' not in scene_key.lower():
        return None
    parts = scene_key.lower().split('_scene_', 1)
    if len(parts) != 2:
        return None
    episode_part, scene_part = parts
    try:
        return episode_part.strip(), int(scene_part)
    except ValueError:
        return None

def find_adjacent_scene_videos(
    scene_key: Optional[str],
    base_dir: Path,
    max_extra: int = 3,
    exclude_paths: Optional[List[Path]] = None
) -> List[Path]:
    parsed = parse_scene_key(scene_key)
    if not parsed:
        return []
    episode_id, start_scene = parsed
    exclude_set = {Path(p).resolve() for p in (exclude_paths or [])}
    extras: List[Path] = []
    
    for offset in range(1, max_extra + 1):
        next_scene_num = start_scene + offset
        video_path = find_scene_video(episode_id, next_scene_num, base_dir)
        if video_path and video_path.exists():
            resolved = video_path.resolve()
            if resolved not in exclude_set:
                extras.append(video_path)
                exclude_set.add(resolved)
            else:
                continue
        else:
            break
    return extras

def try_alternative_candidates(
    search_results: List[Tuple[str, float, Dict]],
    audio_duration: float,
    temp_root: Path,
    label: str,
    video_base_dir: Path,
    start_index: int = 1,
    max_adjacent: int = 3
) -> Tuple[Optional[Path], Optional[str]]:
    """
    å½“é¦–ä¸ªæ£€ç´¢ç»“æœæ— æ³•æ»¡è¶³æ—¶ï¼Œå°è¯•ä½¿ç”¨åç»­å€™é€‰åŠå…¶ç›¸é‚»ç‰‡æ®µ
    """
    for candidate in search_results[start_index:]:
        scene_key = candidate[0]
        parsed = parse_scene_key(scene_key)
        if not parsed:
            continue
        episode_id, scene_num = parsed
        base_video = find_scene_video(episode_id, scene_num, video_base_dir)
        if not base_video or not base_video.exists():
            continue
        
        base_list = [base_video]
        base_list.extend(
            find_adjacent_scene_videos(
                scene_key,
                video_base_dir,
                max_extra=max_adjacent,
                exclude_paths=base_list
            )
        )
        
        assembled_path, remaining = assemble_scene_videos(
            base_list,
            audio_duration,
            temp_root,
            f"{label}_alt",
            video_base_dir,
            primary_scene_key=scene_key,
            max_adjacent=max_adjacent
        )
        if assembled_path:
            print(f"    âœ… ä½¿ç”¨å€™é€‰ {scene_key} åŠç›¸é‚»ç‰‡æ®µå®Œæˆæ‹¼æ¥: {assembled_path.name}")
            return assembled_path, scene_key
        elif remaining <= 0.05:
            print(f"    âš ï¸ å€™é€‰ {scene_key} æ‹¼æ¥å¤±è´¥ï¼ˆé•¿åº¦å·²è¶³å¤Ÿä½†åˆæˆå¤±è´¥ï¼‰ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª")
        else:
            print(f"    âš ï¸ å€™é€‰ {scene_key} æ—¶é•¿ä»ä¸è¶³ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª")
    
    return None

def generate_audio_for_scenes(
    scenes: List[Dict],
    output_dir: Path,
    tts_generator: TTSGenerator,
    skip_existing: bool = True
) -> Tuple[List[Path], List[float]]:
    """
    ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆé…éŸ³éŸ³é¢‘
    
    Returns:
        (audio_paths, audio_durations) - éŸ³é¢‘è·¯å¾„åˆ—è¡¨å’Œæ—¶é•¿åˆ—è¡¨
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    audio_paths = []
    audio_durations = []
    
    print("=" * 60)
    print("ç”Ÿæˆé…éŸ³éŸ³é¢‘ï¼ˆä½¿ç”¨å£°éŸ³å…‹éš†ï¼‰")
    print("=" * 60)
    print()
    
    for i, scene in enumerate(scenes):
        narration = scene.get("narration", "")
        scene_id = scene.get("id", i)
        
        if not narration:
            print(f"[{i+1}/{len(scenes)}] åœºæ™¯ {scene_id}: æ— æ—ç™½ï¼Œè·³è¿‡")
            continue
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if scene_id == 0:
            audio_file = output_dir / "audio_opening.wav"
        elif scene_id == 999:
            audio_file = output_dir / "audio_ending.wav"
        else:
            audio_file = output_dir / f"audio_scene_{scene_id:03d}.wav"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if skip_existing and audio_file.exists():
            duration = get_media_duration(audio_file)
            audio_paths.append(audio_file)
            audio_durations.append(duration)
            scene_label = f"åœºæ™¯ {scene_id}" if scene_id not in [0, 999] else ("å¼€å¤´" if scene_id == 0 else "ç»“å°¾")
            print(f"[{i+1}/{len(scenes)}] {scene_label}: éŸ³é¢‘å·²å­˜åœ¨ ({duration:.2f}ç§’) - {narration[:30]}...")
            continue
        
        # ç”ŸæˆéŸ³é¢‘
        try:
            scene_label = f"åœºæ™¯ {scene_id}" if scene_id not in [0, 999] else ("å¼€å¤´" if scene_id == 0 else "ç»“å°¾")
            print(f"[{i+1}/{len(scenes)}] {scene_label}: ç”Ÿæˆé…éŸ³ - {narration[:30]}...")
            tts_generator.generate(narration, str(audio_file))
            
            duration = get_media_duration(audio_file)
            audio_paths.append(audio_file)
            audio_durations.append(duration)
            print(f"  âœ“ ç”Ÿæˆå®Œæˆ: {duration:.2f}ç§’")
        except Exception as e:
            print(f"  âœ— ç”Ÿæˆå¤±è´¥: {e}")
            continue
    
    print()
    print(f"âœ“ å…±ç”Ÿæˆ {len(audio_paths)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    print(f"  æ€»æ—¶é•¿: {sum(audio_durations):.2f}ç§’ ({sum(audio_durations)/60:.2f}åˆ†é’Ÿ)")
    print()
    
    return audio_paths, audio_durations

def search_or_generate_video(
    scene: Dict,
    audio_duration: float,
    index,
    index_metadata,
    all_scenes,
    keyword_index,
    clip_model,
    video_base_dir: Path,
    scene_index: int,
    tts_generator: Optional[TTSGenerator] = None,
    image_generator: Optional[ImageGenerator] = None,
    video_generator: Optional[VideoGenerator] = None,
    ai_output_dir: Optional[Path] = None,
    used_scenes: Optional[dict] = None,
    max_reuse_count: int = 1
) -> Tuple[Optional[Path], Optional[str]]:
    """
    æ£€ç´¢åŸè§†é¢‘æˆ–AIç”Ÿæˆè§†é¢‘
    
    ç­–ç•¥ï¼š
    1. å…ˆå°è¯•æ£€ç´¢åŸè§†é¢‘ï¼ˆä¼šè¿‡æ»¤æ‰å·²è¾¾åˆ°æœ€å¤§ä½¿ç”¨æ¬¡æ•°çš„åœºæ™¯ï¼‰
    2. å¦‚æœæ£€ç´¢ä¸åˆ°æˆ–åˆ†æ•°å¤ªä½ï¼Œä½¿ç”¨AIç”Ÿæˆ
    
    å»é‡æœºåˆ¶ï¼š
    - used_scenes: å­—å…¸ï¼Œè®°å½•æ¯ä¸ªåœºæ™¯çš„ä½¿ç”¨æ¬¡æ•° {scene_key: count}
    - max_reuse_count: æœ€å¤šå…è®¸é‡å¤ä½¿ç”¨æ¬¡æ•°ï¼ˆé»˜è®¤2æ¬¡ï¼‰
    - è¿”å›: (è§†é¢‘è·¯å¾„, åœºæ™¯key) å…ƒç»„ï¼Œåœºæ™¯keyç”¨äºè®°å½•ä½¿ç”¨æ¬¡æ•°
    
    Returns:
        Tuple[Optional[Path], Optional[str]]: (è§†é¢‘è·¯å¾„, åœºæ™¯key)ï¼Œåœºæ™¯keyä¸ºNoneè¡¨ç¤ºAIç”Ÿæˆ
    """
    description = scene.get('description', '') or scene.get('narration', '')
    scene_id = scene.get('id', scene_index)
    
    print(f"  åœºæ™¯ {scene_id} (ç›®æ ‡æ—¶é•¿: {audio_duration:.2f}ç§’):")
    print(f"    æè¿°: {description[:50]}...")
    
    # 1. å°è¯•æ£€ç´¢åŸè§†é¢‘
    if description:
        search_results = hybrid_search(
            description,
            index,
            index_metadata,
            all_scenes,
            keyword_index,
            clip_model,
            vector_weight=0.7,
            keyword_weight=0.3,
            top_k=30  # å¢åŠ æ£€ç´¢æ•°é‡ï¼Œæé«˜åŒ¹é…æ¦‚ç‡
        )
        
        # è¿‡æ»¤æ‰å·²è¾¾åˆ°æœ€å¤§ä½¿ç”¨æ¬¡æ•°çš„åœºæ™¯
        if used_scenes and search_results:
            original_count = len(search_results)
            search_results = [
                (scene_key, score, scene_meta)
                for scene_key, score, scene_meta in search_results
                if used_scenes.get(scene_key, 0) < max_reuse_count
            ]
            filtered_count = len(search_results)
            if filtered_count < original_count:
                excluded_count = original_count - filtered_count
                print(f"    ğŸ” è¿‡æ»¤æ‰ {excluded_count} ä¸ªå·²è¾¾åˆ°æœ€å¤§ä½¿ç”¨æ¬¡æ•°ï¼ˆ{max_reuse_count}æ¬¡ï¼‰çš„åœºæ™¯")
        
        primary_scene_key = search_results[0][0] if search_results else None
        
        if search_results:
            print("    ğŸ” æ£€ç´¢ç»“æœï¼ˆå‰5ä¸ªï¼Œå·²æ’é™¤è¾¾åˆ°æœ€å¤§ä½¿ç”¨æ¬¡æ•°çš„åœºæ™¯ï¼‰:")
            for rank, (scene_key, score, scene_meta) in enumerate(search_results[:5], 1):
                episode = scene_meta.get('episode_id')
                caption = (scene_meta.get('caption') or scene_meta.get('visual_caption') or scene_meta.get('text') or "")[:40]
                use_count = used_scenes.get(scene_key, 0) if used_scenes else 0
                used_mark = f" [å·²ä½¿ç”¨{use_count}æ¬¡]" if use_count > 0 else ""
                print(f"      #{rank}: {scene_key} | score={score:.3f} | episode={episode} | desc={caption}{used_mark}")
        
            # ä½¿ç”¨æ™ºèƒ½å†³ç­–ï¼ˆå¤§å¹…é™ä½æ ‡å‡†ï¼Œä¼˜å…ˆä½¿ç”¨ä»»ä½•å¯ç”¨çš„åŸè§†é¢‘ï¼‰
            decision = decision_make(
                search_results=[{
                    'scene_id': r[0],
                    'score': r[1],
                    'scene_data': r[2]
                } for r in search_results],
                target_duration=audio_duration,
                base_dir=video_base_dir,
                narration_text=description,
                score_threshold_high=0.2,   # å¤§å¹…é™ä½é˜ˆå€¼ï¼ˆ0.2ï¼‰
                score_threshold_low=0.05,   # æä½é˜ˆå€¼ï¼ˆ0.05ï¼‰
                duration_tolerance=1.0,     # æ”¾å®½æ—¶é•¿å·®å¼‚ï¼ˆÂ±100%ï¼Œå‡ ä¹ä¸é™åˆ¶ï¼‰
                avoid_ai_for_characters=False,
                prefer_retrieved=True
            )
            
            print(f"    ğŸ›ˆ å†³ç­–: {decision.get('decision')} | åŸå› : {decision.get('reason')}")
            if decision.get('decision') in ('use_retrieved', 'retrieved'):
                matched_videos = decision.get('matched_videos', [])
                if matched_videos:
                    temp_root = (ai_output_dir if ai_output_dir else (video_base_dir.parent / 'temp')) / "retrieved_segments"
                    assembled_path, remaining_shortfall = assemble_scene_videos(
                        matched_videos,
                        audio_duration,
                        temp_root,
                        f"scene_{scene_id}",
                        video_base_dir,
                        primary_scene_key=primary_scene_key,
                        max_adjacent=5
                    )
                    if assembled_path:
                        print(f"    âœ… åŸè§†é¢‘æ‹¼æ¥å®Œæˆï¼Œæ»¡è¶³éŸ³é¢‘æ—¶é•¿: {assembled_path.name}")
                        return assembled_path, primary_scene_key
                    else:
                        if remaining_shortfall > 0.05:
                            print(f"    âš ï¸ åŒ¹é…åˆ°çš„åŸè§†é¢‘æ€»æ—¶é•¿ä»çŸ­ {remaining_shortfall:.2f}sï¼Œå°è¯•ä½¿ç”¨å…¶ä»–å€™é€‰")
                        else:
                            print("    âš ï¸ åŸè§†é¢‘æ‹¼æ¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–å€™é€‰")
                        alt_path, alt_scene_key = try_alternative_candidates(
                            search_results,
                            audio_duration,
                            temp_root,
                            f"scene_{scene_id}",
                            video_base_dir,
                            start_index=1,
                            max_adjacent=5
                        )
                        if alt_path:
                            return alt_path, alt_scene_key or primary_scene_key
                        else:
                            print("    âš ï¸ æ‰€æœ‰å€™é€‰éƒ½æ— æ³•æ»¡è¶³æ—¶é•¿ï¼Œå°†å›é€€åˆ°AIç”Ÿæˆ")
                print("    âš ï¸ å†³ç­–æŒ‡å‘æ£€ç´¢ï¼Œä½† matched_videos ä¸ºç©ºæˆ–æ–‡ä»¶ä¸å­˜åœ¨")
    
    # 2. æ£€ç´¢ä¸åˆ°æˆ–åˆ†æ•°å¤ªä½ï¼Œä½¿ç”¨AIç”Ÿæˆ
    if not GEN_VIDEO_AVAILABLE:
        print(f"    âš ï¸  æ— æ³•åŒ¹é…åŸè§†é¢‘ï¼Œä¸”AIç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
        return None, None
    
    if not image_generator or not video_generator:
        print(f"    âš ï¸  æ— æ³•åŒ¹é…åŸè§†é¢‘ï¼Œä½†AIç”Ÿæˆå™¨æœªåŠ è½½")
        return None, None
    
    print(f"    ğŸ¨ æœªæ‰¾åˆ°åŒ¹é…çš„åŸè§†é¢‘ï¼Œä½¿ç”¨AIç”Ÿæˆ...")
    
    # æ‡’åŠ è½½å›¾åƒ/è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œé¿å…ä¸å¿…è¦çš„åŠ è½½
    try:
        if image_generator and getattr(image_generator, "pipeline", None) is None:
            print("      â†» åŠ è½½å›¾åƒç”Ÿæˆæ¨¡å‹...")
            image_generator.load_pipeline()
    except Exception as e:
        print(f"      âœ— å›¾åƒç”Ÿæˆæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None
    
    try:
        if video_generator and not getattr(video_generator, "model_loaded", False):
            print("      â†» åŠ è½½è§†é¢‘ç”Ÿæˆæ¨¡å‹...")
            video_generator.load_model()
    except Exception as e:
        print(f"      âœ— è§†é¢‘ç”Ÿæˆæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None
    
    try:
        # ç”Ÿæˆå›¾ç‰‡
        prompt = scene.get('prompt', '') or scene.get('description', '')
        if not prompt:
            print(f"    âœ— ç¼ºå°‘promptæˆ–descriptionï¼Œæ— æ³•ç”Ÿæˆ")
            return None, None
        
        image_output_dir = ai_output_dir / "images"
        image_output_dir.mkdir(parents=True, exist_ok=True)
        image_path = image_output_dir / f"scene_{scene_id:03d}.png"
        
        print(f"      1/2 ç”Ÿæˆå›¾ç‰‡...")
        image_generator.generate_image(
            prompt=prompt,
            output_path=image_path,
            scene=scene
        )
        
        if not image_path.exists():
            print(f"      âœ— å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
            return None, None
        
        # ç”Ÿæˆè§†é¢‘
        video_output_dir = ai_output_dir / "videos"
        video_output_dir.mkdir(parents=True, exist_ok=True)
        video_path = video_output_dir / f"scene_{scene_id:03d}.mp4"
        
        print(f"      2/2 ç”Ÿæˆè§†é¢‘ (æ—¶é•¿: {audio_duration:.2f}ç§’)...")
        # è®¾ç½®durationä»¥ä¾¿ç”ŸæˆåŒ¹é…æ—¶é•¿çš„è§†é¢‘
        scene_with_duration = scene.copy()
        scene_with_duration['duration'] = audio_duration
        
        video_generator.generate_video(
            image_path=str(image_path),
            output_path=str(video_path),
            scene=scene_with_duration
        )
        
        if video_path.exists():
            print(f"      âœ… AIç”Ÿæˆå®Œæˆ: {video_path.name}")
            return video_path, None  # AIç”Ÿæˆçš„è§†é¢‘æ²¡æœ‰å¯¹åº”çš„åœºæ™¯key
        else:
            print(f"      âœ— è§†é¢‘ç”Ÿæˆå¤±è´¥")
            return None, None
            
    except Exception as e:
        print(f"    âœ— AIç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def generate_video_from_json_complete(
    json_file: Path,
    index_path: Path,
    metadata_path: Path,
    scene_metadata_files: List[Path],
    video_base_dir: Path,
    opening_video: Optional[Path],
    ending_video: Optional[Path],
    output_path: Path,
    gen_video_config: Optional[Path] = None,
    skip_opening: bool = False,
    skip_ending: bool = False,
    skip_tts: bool = False
):
    """æ ¹æ®JSONæ–‡ä»¶ç”Ÿæˆå®Œæ•´è§†é¢‘ï¼ˆå®Œæ•´å·¥ä½œæµï¼‰"""
    
    # åŠ è½½JSON
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    episode_id = data.get('episode')
    scenes = data.get('scenes', [])
    
    print("=" * 60)
    print(f"ç”Ÿæˆè§†é¢‘: ç¬¬{episode_id}é›† - {data.get('title', '')}")
    print("=" * 60)
    print(f"æ€»åœºæ™¯æ•°: {len(scenes)}")
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = output_path.parent / f"episode_{episode_id}_work"
    output_dir.mkdir(parents=True, exist_ok=True)
    audio_dir = output_dir / "audios"
    temp_dir = output_dir / "temp"
    temp_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½TTSç”Ÿæˆå™¨å’Œè§†é¢‘åˆæˆå™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
    tts_generator = None
    image_generator = None
    video_generator = None
    video_composer = None
    subtitle_generator = None
    
    if GEN_VIDEO_AVAILABLE:
        if gen_video_config and gen_video_config.exists():
            config_path = gen_video_config
        else:
            # å°è¯•æŸ¥æ‰¾é»˜è®¤é…ç½®
            config_path = Path(__file__).parent.parent.parent / "gen_video" / "config.yaml"
            if not config_path.exists():
                print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°gen_videoé…ç½®ï¼Œå°†åªæ”¯æŒåŸè§†é¢‘æ£€ç´¢")
        
        if config_path.exists():
            print("åŠ è½½AIç”Ÿæˆå’Œè§†é¢‘åˆæˆæ¨¡å—...")
            try:
                if not skip_tts:
                    tts_generator = TTSGenerator(str(config_path))
                image_generator = ImageGenerator(str(config_path))
                video_generator = VideoGenerator(str(config_path))
                video_composer = VideoComposer(str(config_path))
                subtitle_generator = SubtitleGenerator(str(config_path))
                print("âœ“ AIç”Ÿæˆå’Œè§†é¢‘åˆæˆæ¨¡å—åŠ è½½æˆåŠŸ\n")
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Š: AIç”Ÿæˆæ¨¡å—åŠ è½½å¤±è´¥: {e}")
                print("  å°†åªæ”¯æŒåŸè§†é¢‘æ£€ç´¢\n")
                import traceback
                traceback.print_exc()
    
    # æ­¥éª¤1: ç”Ÿæˆé…éŸ³éŸ³é¢‘
    audio_paths = []
    audio_durations = []
    
    if tts_generator and not skip_tts:
        audio_paths, audio_durations = generate_audio_for_scenes(
            scenes, audio_dir, tts_generator, skip_existing=True
        )
    else:
        print("âš ï¸  è·³è¿‡é…éŸ³ç”Ÿæˆï¼ˆTTSæœªåŠ è½½æˆ–å·²è·³è¿‡ï¼‰")
        print("  å°†ä½¿ç”¨JSONä¸­çš„durationå­—æ®µ\n")
        # ä½¿ç”¨JSONä¸­çš„duration
        for scene in scenes:
            duration = scene.get('duration', 0)
            if duration > 0:
                audio_durations.append(duration)
    
    # åŠ è½½ç´¢å¼•ï¼ˆç”¨äºè§†é¢‘æ£€ç´¢ï¼‰
    print("åŠ è½½åœºæ™¯ç´¢å¼•...")
    index, index_metadata = load_index(index_path, metadata_path)
    # ä½¿ç”¨ä¸ search_scenes ç›¸åŒçš„è¾…åŠ©å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¯ä¸ªåœºæ™¯éƒ½å¸¦æœ‰ episode_id/scene_id ä¿¡æ¯
    all_scenes = load_scene_metadata(scene_metadata_files)
    
    # ä¸ºäº†å°½å¯èƒ½æé«˜å‘½ä¸­ç‡ï¼Œè¿™é‡Œå…è®¸ä½¿ç”¨å­—å¹•æ–‡æœ¬å‚ä¸å…³é”®è¯ç´¢å¼•ï¼ˆä¸ CLI è¡Œä¸ºä¿æŒä¸€è‡´ï¼‰
    keyword_index = build_keyword_index(all_scenes, use_subtitle=True)
    clip_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    print("âœ“ ç´¢å¼•åŠ è½½å®Œæˆ\n")
    
    # æ­¥éª¤2: ä¸ºæ¯ä¸ªåœºæ™¯åŒ¹é…æˆ–ç”Ÿæˆè§†é¢‘
    video_segments = []
    audio_idx = 0
    used_scenes = {}  # è®°å½•å·²ä½¿ç”¨åœºæ™¯çš„æ¬¡æ•° {scene_key: count}ï¼Œæœ€å¤šå…è®¸ä½¿ç”¨2æ¬¡
    max_reuse_count = 1  # æœ€å¤šå…è®¸é‡å¤ä½¿ç”¨2æ¬¡
    
    for i, scene in enumerate(scenes):
        scene_id = scene.get('id', i)
        narration = scene.get('narration', '')
        
        # è·å–å¯¹åº”çš„éŸ³é¢‘æ—¶é•¿
        if audio_idx < len(audio_durations):
            target_duration = audio_durations[audio_idx]
            audio_idx += 1
        else:
            target_duration = scene.get('duration', 0)
            if target_duration <= 0:
                print(f"[{i+1}/{len(scenes)}] åœºæ™¯ {scene_id}: âš ï¸  æ— æ³•ç¡®å®šæ—¶é•¿ï¼Œè·³è¿‡")
                continue
        
        # å¼€å¤´åœºæ™¯ï¼ˆid=0ï¼‰
        if scene_id == 0:
            if skip_opening:
                print(f"[{i+1}/{len(scenes)}] è·³è¿‡å¼€å¤´åœºæ™¯")
                continue
            if opening_video and opening_video.exists():
                temp_path = temp_dir / 'opening_trimmed.mp4'
                trim_video(opening_video, temp_path, target_duration)
                video_segments.append(temp_path)
                print(f"[{i+1}/{len(scenes)}] âœ… å¼€å¤´è§†é¢‘: {target_duration:.2f}ç§’")
            else:
                print(f"[{i+1}/{len(scenes)}] âš ï¸  å¼€å¤´è§†é¢‘ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        # ç»“å°¾åœºæ™¯ï¼ˆid=999ï¼‰
        if scene_id == 999:
            if skip_ending:
                print(f"[{i+1}/{len(scenes)}] è·³è¿‡ç»“å°¾åœºæ™¯")
                continue
            if ending_video and ending_video.exists():
                temp_path = temp_dir / 'ending_trimmed.mp4'
                trim_video(ending_video, temp_path, target_duration)
                video_segments.append(temp_path)
                print(f"[{i+1}/{len(scenes)}] âœ… ç»“å°¾è§†é¢‘: {target_duration:.2f}ç§’")
            else:
                print(f"[{i+1}/{len(scenes)}] âš ï¸  ç»“å°¾è§†é¢‘ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        # æ™®é€šåœºæ™¯ï¼šæ£€ç´¢æˆ–ç”Ÿæˆè§†é¢‘
        print(f"[{i+1}/{len(scenes)}] åœºæ™¯ {scene_id}")
        matched_video, used_scene_key = search_or_generate_video(
            scene,
            target_duration,
            index,
            index_metadata,
            all_scenes,
            keyword_index,
            clip_model,
            video_base_dir,
            scene_id,
            tts_generator=tts_generator,
            image_generator=image_generator,
            video_generator=video_generator,
            ai_output_dir=output_dir,
            used_scenes=used_scenes,
            max_reuse_count=max_reuse_count
        )
        
        if matched_video:
            video_segments.append(matched_video)
            # è®°å½•å·²ä½¿ç”¨çš„åœºæ™¯ï¼ˆè®¡æ•°ï¼‰
            if used_scene_key:
                used_scenes[used_scene_key] = used_scenes.get(used_scene_key, 0) + 1
                count = used_scenes[used_scene_key]
                status = f"ç¬¬{count}æ¬¡ä½¿ç”¨" if count > 1 else "é¦–æ¬¡ä½¿ç”¨"
                print(f"    ğŸ“ å·²è®°å½•ä½¿ç”¨åœºæ™¯: {used_scene_key}ï¼ˆ{status}ï¼Œæœ€å¤šå…è®¸{max_reuse_count}æ¬¡ï¼‰")
        else:
            print(f"    âš ï¸  æœªæ‰¾åˆ°/ç”Ÿæˆè§†é¢‘ï¼Œè·³è¿‡æ­¤åœºæ™¯")
        
        print()
    
    # æ­¥éª¤3: æ‹¼æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µï¼ˆé™éŸ³ç‰ˆæœ¬ï¼‰
    if not video_segments:
        print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘ç‰‡æ®µ")
        return False
    
    print("=" * 60)
    print(f"æ‹¼æ¥ {len(video_segments)} ä¸ªè§†é¢‘ç‰‡æ®µï¼ˆé™éŸ³ï¼‰...")
    print("=" * 60)
    
    # å…ˆæ‹¼æ¥é™éŸ³è§†é¢‘
    temp_video_silent = temp_dir / "video_silent.mp4"
    concatenate_videos(video_segments, temp_video_silent)
    
    # æ­¥éª¤4: æ·»åŠ é…éŸ³å’ŒBGMï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if video_composer and audio_paths:
        print("=" * 60)
        print("æ·»åŠ é…éŸ³å’ŒBGM...")
        print("=" * 60)
        
        # åˆå¹¶æ‰€æœ‰é…éŸ³éŸ³é¢‘
        merged_audio_path = None
        if len(audio_paths) > 1:
            print("åˆå¹¶é…éŸ³éŸ³é¢‘...")
            merged_audio_path = temp_dir / "merged_audio.wav"
            concat_list = temp_dir / "audio_concat.txt"
            try:
                with open(concat_list, 'w', encoding='utf-8') as f:
                    for audio_path in audio_paths:
                        if audio_path.exists():
                            f.write(f"file '{audio_path.absolute()}'\n")
                
                cmd = [
                    'ffmpeg', '-f', 'concat', '-safe', '0',
                    '-i', str(concat_list),
                    '-acodec', 'pcm_s16le',
                    '-ac', '2',  # ç«‹ä½“å£°
                    '-ar', '48000',  # é‡‡æ ·ç‡
                    '-y',
                    str(merged_audio_path)
                ]
                subprocess.run(cmd, capture_output=True, text=True, check=True)
                print(f"âœ“ é…éŸ³éŸ³é¢‘å·²åˆå¹¶: {merged_audio_path}")
            except Exception as e:
                print(f"âš ï¸  éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
                merged_audio_path = audio_paths[0] if audio_paths else None
        elif len(audio_paths) == 1:
            merged_audio_path = audio_paths[0]
        
        if merged_audio_path and merged_audio_path.exists():
            # ç”Ÿæˆå­—å¹•ï¼ˆä½¿ç”¨narrationæ–‡æœ¬æ›¿æ¢è¯†åˆ«ç»“æœï¼‰
            subtitle_path = None
            if subtitle_generator:
                print("=" * 60)
                print("ç”Ÿæˆå­—å¹•ï¼ˆä½¿ç”¨narrationæ–‡æœ¬æ›¿æ¢è¯†åˆ«ç»“æœï¼‰...")
                print("=" * 60)
                
                try:
                    # æ”¶é›†æ‰€æœ‰åœºæ™¯çš„narrationæ–‡æœ¬ï¼ˆç”¨äºå­—å¹•åˆ†æ®µå’Œæ›¿æ¢ï¼‰
                    # æ³¨æ„ï¼šé¡ºåºå¿…é¡»ä¸audio_pathså’Œaudio_durationså®Œå…¨ä¸€è‡´
                    # æŒ‰ç…§scenesçš„é¡ºåºéå†ï¼Œåªæ”¶é›†æœ‰narrationçš„åœºæ™¯ï¼ˆä¸generate_audio_for_scenesé€»è¾‘ä¸€è‡´ï¼‰
                    scene_texts = []  # åˆ†æ®µæ–‡æœ¬åˆ—è¡¨
                    narration_text = ""  # å®Œæ•´æ—ç™½æ–‡æœ¬
                    
                    for scene in scenes:
                        narration = scene.get("narration", "")
                        if narration:  # åªæ”¶é›†æœ‰narrationçš„åœºæ™¯ï¼ˆä¸éŸ³é¢‘ç”Ÿæˆé€»è¾‘ä¸€è‡´ï¼‰
                            scene_texts.append(narration)
                            narration_text += narration
                    
                    # éªŒè¯æ•°é‡æ˜¯å¦åŒ¹é…
                    if scene_texts and len(audio_durations) == len(scene_texts):
                        subtitle_path = temp_dir / "subtitle.srt"
                        total_duration = sum(audio_durations)
                        
                        print(f"  å®Œæ•´æ—ç™½æ–‡æœ¬: {len(narration_text)} å­—")
                        print(f"  åˆ†æ®µæ•°: {len(scene_texts)} ä¸ª")
                        print(f"  æ€»æ—¶é•¿: {total_duration:.2f}ç§’")
                        
                        subtitle_generator.generate(
                            str(merged_audio_path),
                            str(subtitle_path),
                            narration=narration_text,  # å®Œæ•´æ—ç™½æ–‡æœ¬ï¼ˆç”¨äºæ›¿æ¢è¯†åˆ«ç»“æœï¼‰
                            segments=scene_texts,  # åˆ†æ®µæ–‡æœ¬ï¼ˆç”¨äºå­—å¹•åˆ†æ®µï¼‰
                            video_durations=audio_durations,  # éŸ³é¢‘æ—¶é•¿åˆ—è¡¨ï¼ˆç¡®ä¿æ—¶é—´è½´å¯¹é½ï¼‰
                            total_duration=total_duration,  # æ€»éŸ³é¢‘æ—¶é•¿
                        )
                        
                        if subtitle_path.exists():
                            print(f"âœ“ å­—å¹•å·²ç”Ÿæˆ: {subtitle_path}")
                        else:
                            print(f"âš ï¸  å­—å¹•æ–‡ä»¶æœªç”Ÿæˆ")
                            subtitle_path = None
                    else:
                        print(f"âš ï¸  åœºæ™¯æ–‡æœ¬æ•°é‡ ({len(scene_texts)}) ä¸éŸ³é¢‘æ•°é‡ ({len(audio_durations)}) ä¸åŒ¹é…ï¼Œè·³è¿‡å­—å¹•ç”Ÿæˆ")
                except Exception as e:
                    print(f"âš ï¸  å­—å¹•ç”Ÿæˆå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    subtitle_path = None
            
            try:
                # ä½¿ç”¨VideoComposeræ·»åŠ é…éŸ³ã€BGMå’Œå­—å¹•
                print("=" * 60)
                print("ä½¿ç”¨VideoComposeråˆæˆæœ€ç»ˆè§†é¢‘ï¼ˆé…éŸ³+BGM+å­—å¹•ï¼‰...")
                print("=" * 60)
                
                # å°†æ‹¼æ¥å¥½çš„è§†é¢‘ä½œä¸ºå•ä¸ªè§†é¢‘ç‰‡æ®µä¼ å…¥
                composed_path = video_composer.compose(
                    video_paths=[str(p) for p in video_segments],
                    audio_path=str(merged_audio_path),
                    subtitle_path=str(subtitle_path) if subtitle_path and subtitle_path.exists() else None,
                    bgm_path=None,  # ä½¿ç”¨é…ç½®ä¸­çš„BGM
                    output_path=str(output_path),
                    scene_metadata=scenes,  # ä¼ é€’åœºæ™¯å…ƒæ•°æ®ç”¨äºBGMé€‰æ‹©
                )
                output_path = Path(composed_path)
                print(f"âœ“ æœ€ç»ˆè§†é¢‘å·²ç”Ÿæˆï¼ˆåŒ…å«é…éŸ³ã€BGMå’Œå­—å¹•ï¼‰: {output_path}")

                # å¯é€‰ï¼šæ‰§è¡Œ Real-ESRGAN è¶…åˆ†ï¼ˆéœ€è¦é…ç½®å¯ç”¨æ¨¡å‹ï¼‰
                realesrgan_cfg = video_composer.composition_config.get("postprocess", {})
                if realesrgan_cfg.get("enabled"):
                    try:
                        print("å‡†å¤‡æ‰§è¡Œ Real-ESRGAN è¶…åˆ†å¤„ç†...")
                        # VideoComposer.compose å·²åœ¨å†…éƒ¨å¤„ç†è¶…åˆ†é€»è¾‘ï¼Œä½†ç¡®ä¿è·¯å¾„åˆ·æ–°
                        output_path = Path(composed_path)
                    except Exception as re_err:
                        print(f"âš  Real-ESRGAN è¶…åˆ†å¤±è´¥: {re_err}")
            except Exception as e:
                print(f"âš ï¸  ä½¿ç”¨VideoComposeråˆæˆå¤±è´¥: {e}")
                print("  å›é€€åˆ°ä»…æ‹¼æ¥è§†é¢‘ï¼ˆæ— é…éŸ³å’ŒBGMï¼‰")
                import shutil
                shutil.copy2(temp_video_silent, output_path)
                import traceback
                traceback.print_exc()
        else:
            print("âš ï¸  é…éŸ³éŸ³é¢‘ä¸å­˜åœ¨ï¼Œä»…æ‹¼æ¥è§†é¢‘ï¼ˆæ— é…éŸ³å’ŒBGMï¼‰")
            import shutil
            shutil.copy2(temp_video_silent, output_path)
    else:
        # æ²¡æœ‰VideoComposeræˆ–é…éŸ³ï¼Œç›´æ¥ä½¿ç”¨æ‹¼æ¥çš„è§†é¢‘
        import shutil
        shutil.copy2(temp_video_silent, output_path)
        if not video_composer:
            print("âš ï¸  VideoComposeræœªåŠ è½½ï¼Œæ— æ³•æ·»åŠ BGMå’Œé…éŸ³")
        if not audio_paths:
            print("âš ï¸  æ— é…éŸ³éŸ³é¢‘ï¼Œæ— æ³•æ·»åŠ é…éŸ³")
    
    total_duration = get_media_duration(output_path)
    print(f"\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
    print(f"  è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"  æ€»æ—¶é•¿: {total_duration:.2f}ç§’ ({total_duration/60:.2f}åˆ†é’Ÿ)")
    if audio_paths:
        print(f"  éŸ³é¢‘æ–‡ä»¶: {len(audio_paths)} ä¸ªï¼ˆä¿å­˜åœ¨ {audio_dir}ï¼‰")
    print()
    
    if video_composer and audio_paths:
        print("âœ… å·²åŒ…å«ï¼š")
        print("  âœ“ é…éŸ³éŸ³é¢‘ï¼ˆTTSç”Ÿæˆï¼‰")
        print("  âœ“ èƒŒæ™¯éŸ³ä¹ï¼ˆBGMï¼Œå·²æ™ºèƒ½é€‰æ‹©å’Œå‡è¡¡ï¼‰")
        if subtitle_generator:
            print("  âœ“ å­—å¹•ï¼ˆä½¿ç”¨narrationæ–‡æœ¬æ›¿æ¢è¯†åˆ«ç»“æœï¼‰")
        print()
        print("ğŸ’¡ è§†é¢‘å·²å®Œæ•´ç”Ÿæˆï¼Œå¯ç›´æ¥ä½¿ç”¨")
    else:
        print("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
        if not video_composer:
            print("  1. æ·»åŠ BGM")
        if not audio_paths:
            print("  2. å°†é…éŸ³éŸ³é¢‘æ·»åŠ åˆ°è§†é¢‘ä¸­")
        if not subtitle_generator:
            print("  3. ç”Ÿæˆå­—å¹•")
    print()
    
    return True

def main():
    parser = argparse.ArgumentParser(description='æ ¹æ®JSONæ–‡ä»¶ç”Ÿæˆå®Œæ•´è§†é¢‘ï¼ˆå®Œæ•´å·¥ä½œæµï¼‰')
    parser.add_argument('--json', '-j', required=False,
                       help='JSONæ–‡ä»¶è·¯å¾„ (renjie/episode_*.json)')
    parser.add_argument('--index', required=False,
                       help='FAISSç´¢å¼•è·¯å¾„')
    parser.add_argument('--metadata', required=False,
                       help='ç´¢å¼•metadataè·¯å¾„')
    parser.add_argument('--scenes', '-s', required=False, nargs='+',
                       help='åœºæ™¯metadata JSONæ–‡ä»¶ï¼ˆå¯å¤šä¸ªï¼‰')
    parser.add_argument('--video-dir', required=False,
                       help='è§†é¢‘æ–‡ä»¶åŸºç¡€ç›®å½•ï¼ˆprocessed/ï¼‰')
    parser.add_argument('--opening', 
                       help='å¼€å¤´è§†é¢‘è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--ending',
                       help='ç»“å°¾è§†é¢‘è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--output', '-o', required=True,
                       help='è¾“å‡ºè§†é¢‘è·¯å¾„')
    parser.add_argument('--gen-video-config',
                       help='gen_videoé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: gen_video/config.yamlï¼‰')
    parser.add_argument('--skip-opening', action='store_true',
                       help='è·³è¿‡å¼€å¤´è§†é¢‘')
    parser.add_argument('--skip-ending', action='store_true',
                       help='è·³è¿‡ç»“å°¾è§†é¢‘')
    parser.add_argument('--skip-tts', action='store_true',
                       help='è·³è¿‡TTSé…éŸ³ç”Ÿæˆï¼ˆä½¿ç”¨JSONä¸­çš„durationï¼‰')
    parser.add_argument('--upscale-only',
                       help='ä»…æ‰§è¡Œ Real-ESRGAN è¶…åˆ†ï¼ˆè¾“å…¥è§†é¢‘è·¯å¾„ï¼‰')
    parser.add_argument('--upscale-output',
                       help='ä»…è¶…åˆ†æ¨¡å¼ä¸‹çš„è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    if args.upscale_only:
        config_path = Path(args.gen_video_config) if args.gen_video_config else None
        output_path = Path(args.upscale_output) if args.upscale_output else None
        success = run_upscale_only(Path(args.upscale_only), output_path, config_path)
        return 0 if success else 1
    
    required_args = {
        'json': args.json,
        'index': args.index,
        'metadata': args.metadata,
        'scenes': args.scenes,
        'video_dir': args.video_dir,
        'output': args.output,
    }
    missing = [name for name, value in required_args.items() if not value]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…è¦å‚æ•°: {', '.join(missing)} ï¼ˆæˆ–ä½¿ç”¨ --upscale-onlyï¼‰")
        return 1
    
    opening_video = Path(args.opening) if args.opening else None
    ending_video = Path(args.ending) if args.ending else None
    gen_video_config = Path(args.gen_video_config) if args.gen_video_config else None
    
    success = generate_video_from_json_complete(
        Path(args.json),
        Path(args.index),
        Path(args.metadata),
        [Path(f) for f in args.scenes],
        Path(args.video_dir),
        opening_video,
        ending_video,
        Path(args.output),
        gen_video_config=gen_video_config,
        skip_opening=args.skip_opening,
        skip_ending=args.skip_ending,
        skip_tts=args.skip_tts
    )
    
    return 0 if success else 1

if __name__ == '__main__':
    sys.exit(main())